<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.28">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-05-07">

<title>ai_survey_sums – Energy AI Study</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-b719d3d4935f2b08311a76135e2bf442.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-dd3c8dc041147f57ee52a32de3378d30.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Energy AI Study</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../survey_dash.html"> 
<span class="menu-text">Dash</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-dash_js" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Dash_js</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-dash_js">    
        <li>
    <a class="dropdown-item" href="../../task.html">
 <span class="dropdown-text">Task</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../demos/dash/dash5.html">
 <span class="dropdown-text">Dash</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../demos/dash/dash3.html">
 <span class="dropdown-text">Dash_js</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../dash.html">
 <span class="dropdown-text">Demo Dashboard</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-tutorials" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Tutorials</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-tutorials">    
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#summary-report-of-ai-related-survey-instruments" id="toc-summary-report-of-ai-related-survey-instruments" class="nav-link active" data-scroll-target="#summary-report-of-ai-related-survey-instruments">Summary Report of AI-Related Survey Instruments</a>
  <ul class="collapse">
  <li><a href="#ai-literacy-scales" id="toc-ai-literacy-scales" class="nav-link" data-scroll-target="#ai-literacy-scales">1. AI Literacy Scales</a>
  <ul class="collapse">
  <li><a href="#mails---meta-artificial-intelligence-literacy-scale" id="toc-mails---meta-artificial-intelligence-literacy-scale" class="nav-link" data-scroll-target="#mails---meta-artificial-intelligence-literacy-scale">1.1. MAILS - Meta-Artificial Intelligence Literacy Scale</a></li>
  <li><a href="#mails---short-version" id="toc-mails---short-version" class="nav-link" data-scroll-target="#mails---short-version">1.2. MAILS - Short Version</a></li>
  <li><a href="#tully-longoni-appel-2023-ai-literacy-measure-25-item" id="toc-tully-longoni-appel-2023-ai-literacy-measure-25-item" class="nav-link" data-scroll-target="#tully-longoni-appel-2023-ai-literacy-measure-25-item">1.3. Tully, Longoni, &amp; Appel (2023) AI Literacy Measure (25-Item)</a></li>
  <li><a href="#tully-longoni-appel-2023-ai-literacy-measure-17-item" id="toc-tully-longoni-appel-2023-ai-literacy-measure-17-item" class="nav-link" data-scroll-target="#tully-longoni-appel-2023-ai-literacy-measure-17-item">1.4. Tully, Longoni, &amp; Appel (2023) AI Literacy Measure (17-Item)</a></li>
  <li><a href="#rheu-cho-2025-ai-literacy-measure" id="toc-rheu-cho-2025-ai-literacy-measure" class="nav-link" data-scroll-target="#rheu-cho-2025-ai-literacy-measure">1.5. Rheu &amp; Cho (2025) AI Literacy Measure</a></li>
  <li><a href="#ai-literacy-questionnaire-ailq" id="toc-ai-literacy-questionnaire-ailq" class="nav-link" data-scroll-target="#ai-literacy-questionnaire-ailq">1.6. AI Literacy Questionnaire (AILQ)</a></li>
  <li><a href="#weber-et-al.-2023-objective-measurement-scale" id="toc-weber-et-al.-2023-objective-measurement-scale" class="nav-link" data-scroll-target="#weber-et-al.-2023-objective-measurement-scale">1.7. Weber et al.&nbsp;(2023) Objective Measurement Scale</a></li>
  <li><a href="#scale-for-the-assessment-of-non-experts-ai-literacy-snail" id="toc-scale-for-the-assessment-of-non-experts-ai-literacy-snail" class="nav-link" data-scroll-target="#scale-for-the-assessment-of-non-experts-ai-literacy-snail">1.8. Scale for the assessment of non-experts’ AI literacy (SNAIL)</a></li>
  <li><a href="#morrill-noetel-2023-subjective-ai-literacy-scale" id="toc-morrill-noetel-2023-subjective-ai-literacy-scale" class="nav-link" data-scroll-target="#morrill-noetel-2023-subjective-ai-literacy-scale">1.9. Morrill &amp; Noetel (2023) Subjective AI Literacy Scale</a></li>
  <li><a href="#morrill-noetel-2023-objective-ai-literacy-scale" id="toc-morrill-noetel-2023-objective-ai-literacy-scale" class="nav-link" data-scroll-target="#morrill-noetel-2023-objective-ai-literacy-scale">1.10. Morrill &amp; Noetel (2023) Objective AI Literacy Scale</a></li>
  <li><a href="#the-scale-of-artificial-intelligence-literacy-for-all-sail4all" id="toc-the-scale-of-artificial-intelligence-literacy-for-all-sail4all" class="nav-link" data-scroll-target="#the-scale-of-artificial-intelligence-literacy-for-all-sail4all">1.11. The Scale of Artificial Intelligence Literacy for all (SAIL4ALL)</a></li>
  <li><a href="#puppart-aru-2025-ai-literacy-self-assessment" id="toc-puppart-aru-2025-ai-literacy-self-assessment" class="nav-link" data-scroll-target="#puppart-aru-2025-ai-literacy-self-assessment">1.12. Puppart &amp; Aru (2025) AI Literacy Self-Assessment</a></li>
  </ul></li>
  <li><a href="#ai-attitude-scales" id="toc-ai-attitude-scales" class="nav-link" data-scroll-target="#ai-attitude-scales">2. AI Attitude Scales</a>
  <ul class="collapse">
  <li><a href="#attitude-towards-artificial-intelligence-atai-scale" id="toc-attitude-towards-artificial-intelligence-atai-scale" class="nav-link" data-scroll-target="#attitude-towards-artificial-intelligence-atai-scale">2.1. Attitude Towards Artificial Intelligence (ATAI) Scale</a></li>
  <li><a href="#ai-attitude-scale-aias-4" id="toc-ai-attitude-scale-aias-4" class="nav-link" data-scroll-target="#ai-attitude-scale-aias-4">2.2. AI Attitude Scale (AIAS-4)</a></li>
  <li><a href="#attitudes-towards-artificial-intelligence-scale-attari-12" id="toc-attitudes-towards-artificial-intelligence-scale-attari-12" class="nav-link" data-scroll-target="#attitudes-towards-artificial-intelligence-scale-attari-12">2.3. Attitudes Towards Artificial Intelligence Scale (ATTARI-12)</a></li>
  <li><a href="#gnambs-et-al.-2025-domain-specific-ai-attitudes" id="toc-gnambs-et-al.-2025-domain-specific-ai-attitudes" class="nav-link" data-scroll-target="#gnambs-et-al.-2025-domain-specific-ai-attitudes">2.4. Gnambs et al.&nbsp;(2025) Domain-Specific AI Attitudes</a></li>
  <li><a href="#perceptions-on-ai-by-the-citizens-of-europe-questionnaire-paice---attitude-items" id="toc-perceptions-on-ai-by-the-citizens-of-europe-questionnaire-paice---attitude-items" class="nav-link" data-scroll-target="#perceptions-on-ai-by-the-citizens-of-europe-questionnaire-paice---attitude-items">2.5. Perceptions on AI by the Citizens of Europe questionnaire (PAICE) - Attitude Items</a></li>
  <li><a href="#zhang-dafoe-2019-support-for-developing-ai" id="toc-zhang-dafoe-2019-support-for-developing-ai" class="nav-link" data-scroll-target="#zhang-dafoe-2019-support-for-developing-ai">2.6. Zhang &amp; Dafoe (2019) Support for Developing AI</a></li>
  </ul></li>
  <li><a href="#ai-trust-reliance-scales" id="toc-ai-trust-reliance-scales" class="nav-link" data-scroll-target="#ai-trust-reliance-scales">3. AI Trust &amp; Reliance Scales</a>
  <ul class="collapse">
  <li><a href="#scale-of-trust-in-automated-systems-jian-bisantz-drury-2000-trust-perception-scale---ai-tpa" id="toc-scale-of-trust-in-automated-systems-jian-bisantz-drury-2000-trust-perception-scale---ai-tpa" class="nav-link" data-scroll-target="#scale-of-trust-in-automated-systems-jian-bisantz-drury-2000-trust-perception-scale---ai-tpa">3.1. Scale of Trust in Automated Systems (Jian, Bisantz, &amp; Drury, 2000) / Trust Perception Scale - AI (TPA)</a></li>
  <li><a href="#shang-et-al.-2025-affective-and-cognitive-trust-scale" id="toc-shang-et-al.-2025-affective-and-cognitive-trust-scale" class="nav-link" data-scroll-target="#shang-et-al.-2025-affective-and-cognitive-trust-scale">3.2. Shang et al.&nbsp;(2025) Affective and Cognitive Trust Scale</a></li>
  <li><a href="#trust-in-automation-tia-questionnaire" id="toc-trust-in-automation-tia-questionnaire" class="nav-link" data-scroll-target="#trust-in-automation-tia-questionnaire">3.3. Trust in Automation (TiA) Questionnaire</a></li>
  <li><a href="#propensity-to-trust-in-automated-technology-ptt-a-scale" id="toc-propensity-to-trust-in-automated-technology-ptt-a-scale" class="nav-link" data-scroll-target="#propensity-to-trust-in-automated-technology-ptt-a-scale">3.4. Propensity to Trust in Automated Technology (PTT-A) Scale</a></li>
  <li><a href="#trust-in-llms-index-tillmi" id="toc-trust-in-llms-index-tillmi" class="nav-link" data-scroll-target="#trust-in-llms-index-tillmi">3.5. Trust-In-LLMs Index (TILLMI)</a></li>
  <li><a href="#morrill-noetel-2023-trust-in-ai-scale" id="toc-morrill-noetel-2023-trust-in-ai-scale" class="nav-link" data-scroll-target="#morrill-noetel-2023-trust-in-ai-scale">3.6. Morrill &amp; Noetel (2023) Trust in AI Scale</a></li>
  <li><a href="#kim-et-al.-2024-trust-beliefs-intentions" id="toc-kim-et-al.-2024-trust-beliefs-intentions" class="nav-link" data-scroll-target="#kim-et-al.-2024-trust-beliefs-intentions">3.7. Kim et al.&nbsp;(2024) Trust Beliefs &amp; Intentions</a></li>
  <li><a href="#scharowski-et-al.-2025-single-trustuse-items" id="toc-scharowski-et-al.-2025-single-trustuse-items" class="nav-link" data-scroll-target="#scharowski-et-al.-2025-single-trustuse-items">3.8. Scharowski et al.&nbsp;(2025) Single Trust/Use Items</a></li>
  <li><a href="#scharowski-et-al.-2025-situation-specific-trust-scales-sts-ad-sts-chatbot" id="toc-scharowski-et-al.-2025-situation-specific-trust-scales-sts-ad-sts-chatbot" class="nav-link" data-scroll-target="#scharowski-et-al.-2025-situation-specific-trust-scales-sts-ad-sts-chatbot">3.9. Scharowski et al.&nbsp;(2025) Situation-Specific Trust Scales (STS-AD / STS-Chatbot)</a></li>
  <li><a href="#trust-in-explainable-ai-txai-items-adapted-by-scharowski-et-al.-2025" id="toc-trust-in-explainable-ai-txai-items-adapted-by-scharowski-et-al.-2025" class="nav-link" data-scroll-target="#trust-in-explainable-ai-txai-items-adapted-by-scharowski-et-al.-2025">3.10. Trust in Explainable AI (TXAI) Items (Adapted by Scharowski et al., 2025)</a></li>
  <li><a href="#paice-questionnaire---trust-items" id="toc-paice-questionnaire---trust-items" class="nav-link" data-scroll-target="#paice-questionnaire---trust-items">3.11. PAICE Questionnaire - Trust Items</a></li>
  <li><a href="#gerlich-2025-ai-trust-item" id="toc-gerlich-2025-ai-trust-item" class="nav-link" data-scroll-target="#gerlich-2025-ai-trust-item">3.12. Gerlich (2025) AI Trust Item</a></li>
  <li><a href="#madsen-gregor-2000-human-computer-trust-instrument" id="toc-madsen-gregor-2000-human-computer-trust-instrument" class="nav-link" data-scroll-target="#madsen-gregor-2000-human-computer-trust-instrument">3.13. Madsen &amp; Gregor (2000) Human-Computer Trust Instrument</a></li>
  <li><a href="#shape-automation-trust-index-sati-v0.3" id="toc-shape-automation-trust-index-sati-v0.3" class="nav-link" data-scroll-target="#shape-automation-trust-index-sati-v0.3">3.14. SHAPE Automation Trust Index (SATI v0.3)</a></li>
  </ul></li>
  <li><a href="#ai-perception-experience-scales" id="toc-ai-perception-experience-scales" class="nav-link" data-scroll-target="#ai-perception-experience-scales">4. AI Perception &amp; Experience Scales</a>
  <ul class="collapse">
  <li><a href="#chen-et-al.-2025-mental-capacity-attribution" id="toc-chen-et-al.-2025-mental-capacity-attribution" class="nav-link" data-scroll-target="#chen-et-al.-2025-mental-capacity-attribution">4.1. Chen et al.&nbsp;(2025) Mental Capacity Attribution</a></li>
  <li><a href="#chen-et-al.-2025-anthropomorphism-measure" id="toc-chen-et-al.-2025-anthropomorphism-measure" class="nav-link" data-scroll-target="#chen-et-al.-2025-anthropomorphism-measure">4.2. Chen et al.&nbsp;(2025) Anthropomorphism Measure</a></li>
  <li><a href="#general-self-efficacy-scale-for-use-with-artificial-intelligence-gse-6ai" id="toc-general-self-efficacy-scale-for-use-with-artificial-intelligence-gse-6ai" class="nav-link" data-scroll-target="#general-self-efficacy-scale-for-use-with-artificial-intelligence-gse-6ai">4.4. General Self-Efficacy Scale for use with Artificial Intelligence (GSE-6AI)</a></li>
  <li><a href="#chen-et-al.-2025-self-efficacy-items" id="toc-chen-et-al.-2025-self-efficacy-items" class="nav-link" data-scroll-target="#chen-et-al.-2025-self-efficacy-items">4.5. Chen et al.&nbsp;(2025) Self-Efficacy Items</a></li>
  <li><a href="#gnambs-et-al.-2025-ai-experience-familiarity" id="toc-gnambs-et-al.-2025-ai-experience-familiarity" class="nav-link" data-scroll-target="#gnambs-et-al.-2025-ai-experience-familiarity">4.6. Gnambs et al.&nbsp;(2025) AI Experience &amp; Familiarity</a></li>
  <li><a href="#paice-questionnaire---awareness-competency-items" id="toc-paice-questionnaire---awareness-competency-items" class="nav-link" data-scroll-target="#paice-questionnaire---awareness-competency-items">4.7. PAICE Questionnaire - Awareness &amp; Competency Items</a></li>
  <li><a href="#lee-et-al.-2024-prediction-believability-evaluation" id="toc-lee-et-al.-2024-prediction-believability-evaluation" class="nav-link" data-scroll-target="#lee-et-al.-2024-prediction-believability-evaluation">4.8. Lee et al.&nbsp;(2024) Prediction Believability Evaluation</a></li>
  <li><a href="#lee-et-al.-2024-perception-of-prediction-methods" id="toc-lee-et-al.-2024-perception-of-prediction-methods" class="nav-link" data-scroll-target="#lee-et-al.-2024-perception-of-prediction-methods">4.9. Lee et al.&nbsp;(2024) Perception of Prediction Methods</a></li>
  <li><a href="#ovsyannikova-et-al.-2025-perceived-compassion-responsiveness" id="toc-ovsyannikova-et-al.-2025-perceived-compassion-responsiveness" class="nav-link" data-scroll-target="#ovsyannikova-et-al.-2025-perceived-compassion-responsiveness">4.10. Ovsyannikova et al.&nbsp;(2025) Perceived Compassion &amp; Responsiveness</a></li>
  <li><a href="#fang-et-al.-2025-emotional-dependence-problematic-use" id="toc-fang-et-al.-2025-emotional-dependence-problematic-use" class="nav-link" data-scroll-target="#fang-et-al.-2025-emotional-dependence-problematic-use">4.11. Fang et al.&nbsp;(2025) Emotional Dependence &amp; Problematic Use</a></li>
  <li><a href="#fang-et-al.-2025-impressions-of-agents" id="toc-fang-et-al.-2025-impressions-of-agents" class="nav-link" data-scroll-target="#fang-et-al.-2025-impressions-of-agents">4.12. Fang et al.&nbsp;(2025) Impressions of Agent(s)</a></li>
  <li><a href="#complacency-potential-rating-scale" id="toc-complacency-potential-rating-scale" class="nav-link" data-scroll-target="#complacency-potential-rating-scale">4.13. Complacency-Potential Rating Scale</a></li>
  <li><a href="#gerlich-2025-cognitive-offloading-critical-thinking-items" id="toc-gerlich-2025-cognitive-offloading-critical-thinking-items" class="nav-link" data-scroll-target="#gerlich-2025-cognitive-offloading-critical-thinking-items">4.14. Gerlich (2025) Cognitive Offloading &amp; Critical Thinking Items</a></li>
  <li><a href="#rheu-cho-2025-machine-heuristics-credibility" id="toc-rheu-cho-2025-machine-heuristics-credibility" class="nav-link" data-scroll-target="#rheu-cho-2025-machine-heuristics-credibility">4.15. Rheu &amp; Cho (2025) Machine Heuristics &amp; Credibility</a></li>
  <li><a href="#song-et-al.-2024-social-influence-items" id="toc-song-et-al.-2024-social-influence-items" class="nav-link" data-scroll-target="#song-et-al.-2024-social-influence-items">4.16. Song et al.&nbsp;(2024) Social Influence Items</a></li>
  <li><a href="#zhu-et-al.-2024-goal-interpretation-needs-attribution" id="toc-zhu-et-al.-2024-goal-interpretation-needs-attribution" class="nav-link" data-scroll-target="#zhu-et-al.-2024-goal-interpretation-needs-attribution">4.17. Zhu et al.&nbsp;(2024) Goal Interpretation &amp; Needs Attribution</a></li>
  </ul></li>
  <li><a href="#ai-usage-intention-scales" id="toc-ai-usage-intention-scales" class="nav-link" data-scroll-target="#ai-usage-intention-scales">5. AI Usage &amp; Intention Scales</a>
  <ul class="collapse">
  <li><a href="#gnambs-et-al.-2025-future-ai-experience-intentions" id="toc-gnambs-et-al.-2025-future-ai-experience-intentions" class="nav-link" data-scroll-target="#gnambs-et-al.-2025-future-ai-experience-intentions">5.1. Gnambs et al.&nbsp;(2025) Future AI Experience Intentions</a></li>
  <li><a href="#gerlich-2025-ai-tool-usage-items" id="toc-gerlich-2025-ai-tool-usage-items" class="nav-link" data-scroll-target="#gerlich-2025-ai-tool-usage-items">5.2. Gerlich (2025) AI Tool Usage Items</a></li>
  <li><a href="#tully-longoni-appel-2023-ai-receptivity-measures" id="toc-tully-longoni-appel-2023-ai-receptivity-measures" class="nav-link" data-scroll-target="#tully-longoni-appel-2023-ai-receptivity-measures">5.3. Tully, Longoni, &amp; Appel (2023) AI Receptivity Measures</a></li>
  <li><a href="#rheu-cho-2025-fact-checking-behavior" id="toc-rheu-cho-2025-fact-checking-behavior" class="nav-link" data-scroll-target="#rheu-cho-2025-fact-checking-behavior">5.4. Rheu &amp; Cho (2025) Fact-checking Behavior</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#ai-literacy-scales-1" id="toc-ai-literacy-scales-1" class="nav-link" data-scroll-target="#ai-literacy-scales-1">1 AI Literacy Scales</a>
  <ul class="collapse">
  <li><a href="#mails-meta-artificial-intelligence-literacy-scale" id="toc-mails-meta-artificial-intelligence-literacy-scale" class="nav-link" data-scroll-target="#mails-meta-artificial-intelligence-literacy-scale">1.1 MAILS – <em>Meta-Artificial Intelligence Literacy Scale</em></a></li>
  <li><a href="#mails-short-10-items" id="toc-mails-short-10-items" class="nav-link" data-scroll-target="#mails-short-10-items">1.2 MAILS-Short (10 items)</a></li>
  <li><a href="#ailq-ai-literacy-questionnaire" id="toc-ailq-ai-literacy-questionnaire" class="nav-link" data-scroll-target="#ailq-ai-literacy-questionnaire">1.3 AILQ – <em>AI Literacy Questionnaire</em></a></li>
  <li><a href="#snail-38-items" id="toc-snail-38-items" class="nav-link" data-scroll-target="#snail-38-items">1.4 SNAIL (38 items)</a></li>
  <li><a href="#mails-related-objective-test-aicos" id="toc-mails-related-objective-test-aicos" class="nav-link" data-scroll-target="#mails-related-objective-test-aicos">1.5 MAILS-related Objective Test (AICOS)</a></li>
  <li><a href="#tully-longoni-appel-2023-item-set" id="toc-tully-longoni-appel-2023-item-set" class="nav-link" data-scroll-target="#tully-longoni-appel-2023-item-set">1.6 Tully, Longoni &amp; Appel (2023) Item Set</a></li>
  <li><a href="#rheu-cho-2025-trap-of-ai-literacy-battery" id="toc-rheu-cho-2025-trap-of-ai-literacy-battery" class="nav-link" data-scroll-target="#rheu-cho-2025-trap-of-ai-literacy-battery">1.7 Rheu &amp; Cho (2025) “Trap of AI Literacy” Battery</a></li>
  <li><a href="#sail4all-23-items" id="toc-sail4all-23-items" class="nav-link" data-scroll-target="#sail4all-23-items">1.8 SAIL4ALL (23 items)</a></li>
  <li><a href="#gse-6-ai" id="toc-gse-6-ai" class="nav-link" data-scroll-target="#gse-6-ai">1.9 GSE-6-AI</a></li>
  </ul></li>
  <li><a href="#general-attitude-toward-ai-scales" id="toc-general-attitude-toward-ai-scales" class="nav-link" data-scroll-target="#general-attitude-toward-ai-scales">2 General Attitude Toward AI Scales</a>
  <ul class="collapse">
  <li><a href="#atai-5-items" id="toc-atai-5-items" class="nav-link" data-scroll-target="#atai-5-items">2.1 ATAI (5 items)</a></li>
  <li><a href="#aias-4" id="toc-aias-4" class="nav-link" data-scroll-target="#aias-4">2.2 AIAS-4</a></li>
  <li><a href="#attari-12" id="toc-attari-12" class="nav-link" data-scroll-target="#attari-12">2.3 ATTARI-12</a></li>
  <li><a href="#paice-european-barometer" id="toc-paice-european-barometer" class="nav-link" data-scroll-target="#paice-european-barometer">2.4 PAICE (European Barometer)</a></li>
  <li><a href="#zhang-dafoe-2019-american-attitudes-trends-top-line" id="toc-zhang-dafoe-2019-american-attitudes-trends-top-line" class="nav-link" data-scroll-target="#zhang-dafoe-2019-american-attitudes-trends-top-line">2.5 Zhang &amp; Dafoe (2019) “American Attitudes &amp; Trends” Top-line</a></li>
  </ul></li>
  <li><a href="#trust-focused-instruments" id="toc-trust-focused-instruments" class="nav-link" data-scroll-target="#trust-focused-instruments">3 Trust-Focused Instruments</a>
  <ul class="collapse">
  <li><a href="#tpa-trust-perception-of-automation" id="toc-tpa-trust-perception-of-automation" class="nav-link" data-scroll-target="#tpa-trust-perception-of-automation">3.1 TPA – <em>Trust Perception of Automation</em></a></li>
  <li><a href="#tia-körber-2019" id="toc-tia-körber-2019" class="nav-link" data-scroll-target="#tia-körber-2019">3.2 TiA (Körber, 2019)</a></li>
  <li><a href="#semantic-differential-ai-trust-27-items" id="toc-semantic-differential-ai-trust-27-items" class="nav-link" data-scroll-target="#semantic-differential-ai-trust-27-items">3.3 Semantic-Differential AI-Trust (27 items)</a></li>
  <li><a href="#ptt-a-propensity-to-trust-technology" id="toc-ptt-a-propensity-to-trust-technology" class="nav-link" data-scroll-target="#ptt-a-propensity-to-trust-technology">3.4 PTT-A (Propensity to Trust Technology)</a></li>
  <li><a href="#tia-derived-trust-in-automation-short-forms" id="toc-tia-derived-trust-in-automation-short-forms" class="nav-link" data-scroll-target="#tia-derived-trust-in-automation-short-forms">3.5 TiA-derived <em>Trust in Automation</em> Short Forms</a></li>
  </ul></li>
  <li><a href="#other-relevant-measures" id="toc-other-relevant-measures" class="nav-link" data-scroll-target="#other-relevant-measures">4 Other Relevant Measures</a></li>
  <li><a href="#comparative-table" id="toc-comparative-table" class="nav-link" data-scroll-target="#comparative-table">5 Comparative Table</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/tegorman13/llm_energy_task/blob/main/surveys_items/AI_Surveys/AI_Survey_Sums.md" class="toc-action"><i class="bi bi-github"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content"><div class="quarto-title-block"><div class="quarto-title-tools-only"><h1></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
</div>



<div class="quarto-title-meta column-page-left">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 7, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="summary-report-of-ai-related-survey-instruments" class="level1">
<h1>Summary Report of AI-Related Survey Instruments</h1>
<p>This report organizes and summarizes various survey instruments related to Artificial Intelligence (AI), drawing from the provided list of references and associated details. The instruments are categorized based on their primary focus.</p>
<hr>
<section id="ai-literacy-scales" class="level2">
<h2 class="anchored" data-anchor-id="ai-literacy-scales">1. AI Literacy Scales</h2>
<p>Instruments designed to measure knowledge, understanding, skills, and competencies related to AI.</p>
<section id="mails---meta-artificial-intelligence-literacy-scale" class="level3">
<h3 class="anchored" data-anchor-id="mails---meta-artificial-intelligence-literacy-scale">1.1. MAILS - Meta-Artificial Intelligence Literacy Scale</h3>
<ul>
<li><strong>Reference:</strong> Carolus, A., Koch, M. J., Straka, S., Latoschik, M. E., &amp; Wienrich, C. (2023). MAILS - Meta AI literacy scale: Development and testing of an AI literacy questionnaire based on well-founded competency models and psychological change- and meta-competencies. <em>Computers in Human Behavior: Artificial Humans, 1</em>(2), 100014. https://doi.org/10.1016/j.chbah.2023.100014</li>
<li><strong>Description:</strong> A comprehensive scale measuring AI literacy based on competency models and psychological meta-competencies.</li>
<li><strong>Constructs:</strong> AI Literacy (Use &amp; Apply, Know &amp; Understand, Detect AI, AI Ethics), Create AI, AI Self-Efficacy (Problem-Solving, Learning), AI Self-Competency (Persuasion Literacy, Emotion Regulation).</li>
<li><strong>Details:</strong> 34 items rated on an 11-point scale (0-10).</li>
<li><strong>Link:</strong> https://hci.uni-wuerzburg.de/research/MAILS/</li>
</ul>
</section>
<section id="mails---short-version" class="level3">
<h3 class="anchored" data-anchor-id="mails---short-version">1.2. MAILS - Short Version</h3>
<ul>
<li><strong>Reference:</strong> Koch, M. J., Carolus, A., Wienrich, C., &amp; Latoschik, M. E. (2024). Meta AI literacy scale: Further validation and development of a short version. <em>Heliyon, 10</em>(21), e39686. https://doi.org/10.1016/j.heliyon.2024.e39686</li>
<li><strong>Description:</strong> A validated short form of the MAILS.</li>
<li><strong>Constructs:</strong> AI Literacy (Detect, Apply, Understand, Ethics), Create AI, AI Self-Efficacy (Learning, Problem-Solving), AI Self-Competency (Persuasion Literacy, Emotion Regulation).</li>
<li><strong>Details:</strong> 10 items rated on an 11-point scale (0-10).</li>
</ul>
</section>
<section id="tully-longoni-appel-2023-ai-literacy-measure-25-item" class="level3">
<h3 class="anchored" data-anchor-id="tully-longoni-appel-2023-ai-literacy-measure-25-item">1.3. Tully, Longoni, &amp; Appel (2023) AI Literacy Measure (25-Item)</h3>
<ul>
<li><strong>Reference:</strong> Tully, S., Longoni, C., &amp; Appel, G. (2023). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. OSF. https://doi.org/10.31234/osf.io/t9u8g (Used in Studies 2, 4, 6)</li>
<li><strong>Description:</strong> Measures objective AI literacy through multiple-choice questions covering various AI concepts.</li>
<li><strong>Details:</strong> 25 multiple-choice questions. Full items available in Appendix A of the source file (<code>Tully25_AI_Survey.md</code>).</li>
</ul>
</section>
<section id="tully-longoni-appel-2023-ai-literacy-measure-17-item" class="level3">
<h3 class="anchored" data-anchor-id="tully-longoni-appel-2023-ai-literacy-measure-17-item">1.4. Tully, Longoni, &amp; Appel (2023) AI Literacy Measure (17-Item)</h3>
<ul>
<li><strong>Reference:</strong> Tully, S., Longoni, C., &amp; Appel, G. (2023). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. OSF. https://doi.org/10.31234/osf.io/t9u8g (Used in Studies 3, 5, 7)</li>
<li><strong>Description:</strong> A shorter version measuring objective AI literacy through multiple-choice questions, structured by competencies from Long and Magerko (2020).</li>
<li><strong>Details:</strong> 17 multiple-choice questions. Full items available in Appendix B of the source file (<code>Tully25_AI_Survey.md</code>).</li>
</ul>
</section>
<section id="rheu-cho-2025-ai-literacy-measure" class="level3">
<h3 class="anchored" data-anchor-id="rheu-cho-2025-ai-literacy-measure">1.5. Rheu &amp; Cho (2025) AI Literacy Measure</h3>
<ul>
<li><strong>Reference:</strong> Rheu, M. (MJ), &amp; Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. <em>Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</em>, 1–7. https://doi.org/10.1145/3706599.3719681</li>
<li><strong>Description:</strong> Combines items from Ng et al.&nbsp;(2024) and Pinski &amp; Benlian (2023) to measure AI literacy in college students using LLMs.</li>
<li><strong>Constructs:</strong> Self-Efficacy, Cognitive Learning, AI Technology Knowledge, AI-Steps Knowledge.</li>
<li><strong>Details:</strong> Items rated on a 7-point Likert scale (Strongly disagree to Strongly agree).</li>
</ul>
</section>
<section id="ai-literacy-questionnaire-ailq" class="level3">
<h3 class="anchored" data-anchor-id="ai-literacy-questionnaire-ailq">1.6. AI Literacy Questionnaire (AILQ)</h3>
<ul>
<li><strong>Reference:</strong> Ng, D. T. K., Wu, W., Leung, J. K. L., Chiu, T. K. F., &amp; Chu, S. K. W. (2024). Design and validation of the AI literacy questionnaire: The affective, behavioural, cognitive and ethical approach. <em>British Journal of Educational Technology, 55</em>(3), 1082–1104. https://doi.org/10.1111/bjet.13411</li>
<li><strong>Description:</strong> Measures AI literacy across affective, behavioral, cognitive, and ethical dimensions.</li>
<li><strong>Constructs:</strong> Affective (Intrinsic Motivation, Self-Efficacy, Confidence), Behavioral (Commitment, Collaboration), Cognitive (Know &amp; Understand, Apply/Evaluate/Create), Ethical (AI Ethics).</li>
<li><strong>Details:</strong> Developed with an initial pool of items, validated version likely uses a subset. Response scale typically Likert-type.</li>
</ul>
</section>
<section id="weber-et-al.-2023-objective-measurement-scale" class="level3">
<h3 class="anchored" data-anchor-id="weber-et-al.-2023-objective-measurement-scale">1.7. Weber et al.&nbsp;(2023) Objective Measurement Scale</h3>
<ul>
<li><strong>Reference:</strong> Weber, P., Pinski, M., &amp; Baum, L. (2023). Toward an Objective Measurement of AI Literacy. <em>PACIS 2023 Proceedings</em>. https://aisel.aisnet.org/pacis2023/60/</li>
<li><strong>Description:</strong> Measures objective AI literacy using multiple-choice questions covering socio-user, socio-creator/evaluator, technical-user, and technical-creator/evaluator aspects.</li>
<li><strong>Details:</strong> 16 multiple-choice questions.</li>
</ul>
</section>
<section id="scale-for-the-assessment-of-non-experts-ai-literacy-snail" class="level3">
<h3 class="anchored" data-anchor-id="scale-for-the-assessment-of-non-experts-ai-literacy-snail">1.8. Scale for the assessment of non-experts’ AI literacy (SNAIL)</h3>
<ul>
<li><strong>Reference:</strong> Laupichler, M. C., Aster, A., Haverkamp, N., &amp; Raupach, T. (2023). Development of the “Scale for the assessment of non-experts’ AI literacy” – An exploratory factor analysis. <em>Computers in Human Behavior Reports, 12</em>, 100338. https://doi.org/10.1016/j.chbr.2023.100338</li>
<li><strong>Description:</strong> Measures self-perceived AI literacy among non-experts. Developed via Delphi study and EFA.</li>
<li><strong>Details:</strong> Final scale has 31 items (reduced from 39) rated on a 7-point Likert scale (Strongly disagree to Strongly agree). Initial 39 items available in the source file (<code>Laupichler_AI_Survey.md</code>).</li>
</ul>
</section>
<section id="morrill-noetel-2023-subjective-ai-literacy-scale" class="level3">
<h3 class="anchored" data-anchor-id="morrill-noetel-2023-subjective-ai-literacy-scale">1.9. Morrill &amp; Noetel (2023) Subjective AI Literacy Scale</h3>
<ul>
<li><strong>Reference:</strong> Morrill, J., &amp; Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc</li>
<li><strong>Description:</strong> A brief subjective measure of AI literacy adapted from Laupichler et al.&nbsp;(2023).</li>
<li><strong>Details:</strong> 6 items rated on a 7-point Likert scale (Strongly disagree to Strongly agree), plus an attention check. Items available in the source file (<code>Morrill23_AI_Survey.md</code>).</li>
</ul>
</section>
<section id="morrill-noetel-2023-objective-ai-literacy-scale" class="level3">
<h3 class="anchored" data-anchor-id="morrill-noetel-2023-objective-ai-literacy-scale">1.10. Morrill &amp; Noetel (2023) Objective AI Literacy Scale</h3>
<ul>
<li><strong>Reference:</strong> Morrill, J., &amp; Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc</li>
<li><strong>Description:</strong> A brief objective measure of AI literacy developed for the study, partly adapted from Weber et al.&nbsp;(2023).</li>
<li><strong>Details:</strong> 5 multiple-choice questions with an “I’m not sure” option. Items available in the source file (<code>Morrill23_AI_Survey.md</code>).</li>
</ul>
</section>
<section id="the-scale-of-artificial-intelligence-literacy-for-all-sail4all" class="level3">
<h3 class="anchored" data-anchor-id="the-scale-of-artificial-intelligence-literacy-for-all-sail4all">1.11. The Scale of Artificial Intelligence Literacy for all (SAIL4ALL)</h3>
<ul>
<li><strong>Reference:</strong> Soto-Sanfiel, M. T., Angulo-Brunet, A., &amp; Lutz, C. (2024). The Scale of Artificial Intelligence Literacy for all (SAIL4ALL): A Tool for Assessing Knowledge on Artificial Intelligence in All Adult Populations and Settings. OSF. https://doi.org/10.31235/osf.io/bvyku</li>
<li><strong>Description:</strong> Assesses AI knowledge suitable for diverse adult populations, covering fundamental concepts, capabilities, mechanisms, and ethics.</li>
<li><strong>Themes:</strong> What is AI? (Recognizing/Understanding, General/Narrow), What can AI do?, How does AI Work? (Representation, Reasoning, Learning, Data, Human Role, Action/Reaction, Sensors), How should AI be used? (Ethics).</li>
<li><strong>Details:</strong> 59 items. Can be used with True/False or a 5-point confidence scale. Full items available in the source file (<code>Soto-Sanfiel_AI_Survey.md</code>).</li>
</ul>
</section>
<section id="puppart-aru-2025-ai-literacy-self-assessment" class="level3">
<h3 class="anchored" data-anchor-id="puppart-aru-2025-ai-literacy-self-assessment">1.12. Puppart &amp; Aru (2025) AI Literacy Self-Assessment</h3>
<ul>
<li><strong>Reference:</strong> Puppart, B., &amp; Aru, J. (2025). Short-term AI literacy intervention does not reduce over-reliance on incorrect ChatGPT recommendations (No.&nbsp;arXiv:2503.10556). arXiv. https://doi.org/10.48550/arXiv.2503.10556</li>
<li><strong>Description:</strong> A brief self-assessment used post-intervention to gauge perceived changes in understanding of ChatGPT’s workings, limitations/risks, and wise usage.</li>
<li><strong>Details:</strong> 3 items rated on a 4-point forced-choice Likert scale. Items available in the source file (<code>Puppart_Aru25_AI_Survey.md</code>).</li>
</ul>
<hr>
</section>
</section>
<section id="ai-attitude-scales" class="level2">
<h2 class="anchored" data-anchor-id="ai-attitude-scales">2. AI Attitude Scales</h2>
<p>Instruments measuring general feelings, beliefs, and evaluations towards AI.</p>
<section id="attitude-towards-artificial-intelligence-atai-scale" class="level3">
<h3 class="anchored" data-anchor-id="attitude-towards-artificial-intelligence-atai-scale">2.1. Attitude Towards Artificial Intelligence (ATAI) Scale</h3>
<ul>
<li><strong>Reference:</strong> Sindermann, C., Sha, P., Zhou, M., Wernicke, J., Schmitt, H. S., Li, M., Sariyska, R., Stavrou, M., Becker, B., &amp; Montag, C. (2021). Assessing the Attitude Towards Artificial Intelligence: Introduction of a Short Measure in German, Chinese, and English Language. <em>KI - Künstliche Intelligenz, 35</em>(1), 109–118. https://doi.org/10.1007/s13218-020-00689-0</li>
<li><strong>Description:</strong> A brief scale measuring general attitude towards AI, focusing on fear, trust, and perceived impact (benefit/destruction, job losses).</li>
<li><strong>Details:</strong> 5 items rated on an 11-point Likert scale (0-10).</li>
</ul>
</section>
<section id="ai-attitude-scale-aias-4" class="level3">
<h3 class="anchored" data-anchor-id="ai-attitude-scale-aias-4">2.2. AI Attitude Scale (AIAS-4)</h3>
<ul>
<li><strong>Reference:</strong> Grassini, S. (2023). Development and validation of the AI attitude scale (AIAS-4): a brief measure of general attitude toward artificial intelligence. <em>Frontiers in Psychology, 14</em>. https://doi.org/10.3389/fpsyg.2023.1191628</li>
<li><strong>Description:</strong> A very brief measure of general positive attitude toward AI.</li>
<li><strong>Details:</strong> 4 items rated on a 10-point Likert scale (1-10).</li>
</ul>
</section>
<section id="attitudes-towards-artificial-intelligence-scale-attari-12" class="level3">
<h3 class="anchored" data-anchor-id="attitudes-towards-artificial-intelligence-scale-attari-12">2.3. Attitudes Towards Artificial Intelligence Scale (ATTARI-12)</h3>
<ul>
<li><strong>Reference:</strong> Stein, J.-P., Messingschlager, T., Gnambs, T., Hutmacher, F., &amp; Appel, M. (2024). Attitudes towards AI: Measurement and associations with personality. <em>Scientific Reports, 14</em>(1), 2909. https://doi.org/10.1038/s41598-024-53335-2</li>
<li><strong>Description:</strong> Measures attitudes towards AI across cognitive, affective, and behavioral dimensions, balanced for positive and negative valence.</li>
<li><strong>Constructs:</strong> Cognitive (Positive/Negative), Affective (Positive/Negative), Behavioral (Positive/Negative).</li>
<li><strong>Details:</strong> 12 items rated on a 5-point Likert scale (Strongly disagree to Strongly agree). Items available in the source file (<code>Stein24_AI_Survey.md</code>).</li>
</ul>
</section>
<section id="gnambs-et-al.-2025-domain-specific-ai-attitudes" class="level3">
<h3 class="anchored" data-anchor-id="gnambs-et-al.-2025-domain-specific-ai-attitudes">2.4. Gnambs et al.&nbsp;(2025) Domain-Specific AI Attitudes</h3>
<ul>
<li><strong>Reference:</strong> Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., &amp; Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. <em>Telematics and Informatics, 98</em>, 102265. https://doi.org/10.1016/j.tele.2025.102265</li>
<li><strong>Description:</strong> Measures cognitive, affective, and behavioral attitudes towards AI within specific domains (Work, Healthcare, Education).</li>
<li><strong>Details:</strong> 9 items (3 per domain) rated on a 5-point scale (0-4), plus a “cannot answer” option. Items available in the source file (<code>Gnabs_AI_Survey.md</code>).</li>
</ul>
</section>
<section id="perceptions-on-ai-by-the-citizens-of-europe-questionnaire-paice---attitude-items" class="level3">
<h3 class="anchored" data-anchor-id="perceptions-on-ai-by-the-citizens-of-europe-questionnaire-paice---attitude-items">2.5. Perceptions on AI by the Citizens of Europe questionnaire (PAICE) - Attitude Items</h3>
<ul>
<li><strong>Reference:</strong> Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., &amp; Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. <em>IEEE Transactions on Artificial Intelligence, 6</em>(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633</li>
<li><strong>Description:</strong> Includes items assessing general attitude towards AI (Q2) and attitudes towards AI use in specific sectors (Q8: Healthcare, Insurance, Agriculture, Finance, Military, Law Enforcement, Environmental, Transportation, Manufacturing, HR).</li>
<li><strong>Details:</strong> Items rated on 5-point scales (Strongly disapprove to Strongly approve). Full questionnaire available in the source file (<code>Scantamburlo_AI_Survey.md</code>).</li>
</ul>
</section>
<section id="zhang-dafoe-2019-support-for-developing-ai" class="level3">
<h3 class="anchored" data-anchor-id="zhang-dafoe-2019-support-for-developing-ai">2.6. Zhang &amp; Dafoe (2019) Support for Developing AI</h3>
<ul>
<li><strong>Reference:</strong> Zhang, B., &amp; Dafoe, A. (2019). Artificial Intelligence: American Attitudes and Trends. <em>SSRN Electronic Journal</em>. https://doi.org/10.2139/ssrn.3312874</li>
<li><strong>Description:</strong> Measures general support or opposition to the development of AI after presenting examples of AI applications.</li>
<li><strong>Details:</strong> 1 item rated on a 5-point scale (Strongly oppose to Strongly support), plus “I don’t know”. Item available in the source file (<code>Zhang_Dafoe_AI_Survey.md</code>).</li>
</ul>
<hr>
</section>
</section>
<section id="ai-trust-reliance-scales" class="level2">
<h2 class="anchored" data-anchor-id="ai-trust-reliance-scales">3. AI Trust &amp; Reliance Scales</h2>
<p>Instruments measuring trust, confidence, and reliance on AI systems or automation in general.</p>
<section id="scale-of-trust-in-automated-systems-jian-bisantz-drury-2000-trust-perception-scale---ai-tpa" class="level3">
<h3 class="anchored" data-anchor-id="scale-of-trust-in-automated-systems-jian-bisantz-drury-2000-trust-perception-scale---ai-tpa">3.1. Scale of Trust in Automated Systems (Jian, Bisantz, &amp; Drury, 2000) / Trust Perception Scale - AI (TPA)</h3>
<ul>
<li><strong>Reference:</strong> Jian, J.-Y., Bisantz, A. M., &amp; Drury, C. G. (2000). Foundations for an Empirically Determined Scale of Trust in Automated System. <em>International Journal of Cognitive Ergonomics, 4</em>(1), 53–71. https://doi.org/10.1207/S15327566IJCE0401_04 (Also used/cited in Adams et al., 2003; Scharowski et al., 2025)</li>
<li><strong>Description:</strong> A widely used scale measuring trust in automated systems, often adapted for AI contexts (as TPA). Assesses aspects like deceptiveness, suspicion, confidence, integrity, dependability, reliability, and familiarity.</li>
<li><strong>Details:</strong> 12 items rated on a 7-point scale (Not at all to Extremely).</li>
</ul>
</section>
<section id="shang-et-al.-2025-affective-and-cognitive-trust-scale" class="level3">
<h3 class="anchored" data-anchor-id="shang-et-al.-2025-affective-and-cognitive-trust-scale">3.2. Shang et al.&nbsp;(2025) Affective and Cognitive Trust Scale</h3>
<ul>
<li><strong>Reference:</strong> Shang, R., &amp; Hsieh, G. (2025). Trusting Your AI Agent Emotionally and Cognitively: Development and Validation of a Semantic Differential Scale for AI Trust. <em>Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society</em>, 1343–1356.</li>
<li><strong>Description:</strong> A semantic differential scale designed to measure distinct cognitive (reliability, competence, understandability, integrity) and affective (empathy, sensitivity, care, altruism, responsiveness, etc.) dimensions of trust in AI agents.</li>
<li><strong>Constructs:</strong> Cognitive Trust (18 items), Affective Trust (9 items).</li>
<li><strong>Details:</strong> 27 bipolar adjective pairs rated on a 7-point semantic differential scale (-3 to +3). Items available in the source file (<code>Shang25_AI_Trust_Scale.md</code>).</li>
</ul>
</section>
<section id="trust-in-automation-tia-questionnaire" class="level3">
<h3 class="anchored" data-anchor-id="trust-in-automation-tia-questionnaire">3.3. Trust in Automation (TiA) Questionnaire</h3>
<ul>
<li><strong>Reference:</strong> Körber, M. (2019). Theoretical Considerations and Development of a Questionnaire to Measure Trust in Automation. In S. Bagnara, et al.&nbsp;(Eds.), <em>Proceedings of the 20th Congress of the International Ergonomics Association (IEA 2018)</em> (Vol. 823, pp.&nbsp;13–30). Springer. http://link.springer.com/10.1007/978-3-319-96074-6_2</li>
<li><strong>Description:</strong> Measures trust in automation based on theoretical considerations, including reliability/competence, understanding/predictability, familiarity, intention of developers, and propensity to trust.</li>
<li><strong>Constructs:</strong> Reliability/Competence, Understanding/Predictability, Familiarity, Intention of Developers, Propensity to Trust, Trust in Automation.</li>
<li><strong>Details:</strong> 19 items rated on a 5-point Likert scale (Strongly disagree to Strongly agree), with some reverse-coded.</li>
</ul>
</section>
<section id="propensity-to-trust-in-automated-technology-ptt-a-scale" class="level3">
<h3 class="anchored" data-anchor-id="propensity-to-trust-in-automated-technology-ptt-a-scale">3.4. Propensity to Trust in Automated Technology (PTT-A) Scale</h3>
<ul>
<li><strong>Reference:</strong> Scholz, D. D., Kraus, J., &amp; Miller, L. (2025). Measuring the Propensity to Trust in Automated Technology: Examining Similarities to Dispositional Trust in Other Humans and Validation of the PTT-A Scale. <em>International Journal of Human–Computer Interaction, 41</em>(2), 970–993. https://doi.org/10.1080/10447318.2024.2307691</li>
<li><strong>Description:</strong> Measures an individual’s general tendency (disposition) to trust automated technology, mirroring scales for trust in humans. Includes a short form.</li>
<li><strong>Constructs:</strong> Trusting Stance, Competence, Benevolence, Integrity.</li>
<li><strong>Details:</strong> 14 items (6 bolded for short scale) rated on a 5-point Likert scale (Strongly disagree to Strongly agree), with some reverse-coded.</li>
</ul>
</section>
<section id="trust-in-llms-index-tillmi" class="level3">
<h3 class="anchored" data-anchor-id="trust-in-llms-index-tillmi">3.5. Trust-In-LLMs Index (TILLMI)</h3>
<ul>
<li><strong>Reference:</strong> Duro, E. S. D., Veltri, G. A., Golino, H., &amp; Stella, M. (2025). Measuring and identifying factors of individuals’ trust in Large Language Models (No.&nbsp;arXiv:2502.21028). arXiv. https://doi.org/10.48550/arXiv.2502.21028</li>
<li><strong>Description:</strong> Measures trust specifically in Large Language Models (LLMs), focusing on closeness/ease of sharing and reliance/competence.</li>
<li><strong>Constructs:</strong> Closeness with LLMs, Reliance on LLMs.</li>
<li><strong>Details:</strong> Final scale has 6 items (reduced from 8) rated on a 5-point frequency scale (Never experience it to Always experience it). Items available in the source file (<code>Duro_AI_Survey.md</code>).</li>
</ul>
</section>
<section id="morrill-noetel-2023-trust-in-ai-scale" class="level3">
<h3 class="anchored" data-anchor-id="morrill-noetel-2023-trust-in-ai-scale">3.6. Morrill &amp; Noetel (2023) Trust in AI Scale</h3>
<ul>
<li><strong>Reference:</strong> Morrill, J., &amp; Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc</li>
<li><strong>Description:</strong> Measures willingness to trust, rely on, and depend on AI systems, adapted from Gillespie et al.&nbsp;(2023).</li>
<li><strong>Details:</strong> 6 items rated on a 7-point Likert scale (Completely Unwilling to Completely Willing). Items available in the source file (<code>Morrill23_AI_Survey.md</code>).</li>
</ul>
</section>
<section id="kim-et-al.-2024-trust-beliefs-intentions" class="level3">
<h3 class="anchored" data-anchor-id="kim-et-al.-2024-trust-beliefs-intentions">3.7. Kim et al.&nbsp;(2024) Trust Beliefs &amp; Intentions</h3>
<ul>
<li><strong>Reference:</strong> Kim, S. S. Y., Liao, Q. V., Vorvoreanu, M., Ballard, S., &amp; Vaughan, J. W. (2024). “I’m Not Sure, But…”: Examining the Impact of Large Language Models’ Uncertainty Expression on User Reliance and Trust (No.&nbsp;arXiv:2405.00623). arXiv. https://doi.org/10.48550/arXiv.2405.00623</li>
<li><strong>Description:</strong> Measures trust beliefs (competence, honesty, benevolence) and trust intentions (reliance, comfort acting on info) towards a specific AI system experienced in a task.</li>
<li><strong>Constructs:</strong> TrustBelief, TrustIntention.</li>
<li><strong>Details:</strong> 10 items (6 belief, 4 intention) rated on a 5-point Likert scale (Strongly disagree to Strongly agree), some reverse-coded.</li>
</ul>
</section>
<section id="scharowski-et-al.-2025-single-trustuse-items" class="level3">
<h3 class="anchored" data-anchor-id="scharowski-et-al.-2025-single-trustuse-items">3.8. Scharowski et al.&nbsp;(2025) Single Trust/Use Items</h3>
<ul>
<li><strong>Reference:</strong> Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., &amp; Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No.&nbsp;arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582</li>
<li><strong>Description:</strong> Simple, direct measures of trust and willingness to use an AI after observing it in a specific scenario (Self-Driving Vehicle or Chatbot).</li>
<li><strong>Details:</strong> 2 items (“I would trust…”, “I would use…”) rated on a 7-point Likert scale (Fully disagree to Fully agree).</li>
</ul>
</section>
<section id="scharowski-et-al.-2025-situation-specific-trust-scales-sts-ad-sts-chatbot" class="level3">
<h3 class="anchored" data-anchor-id="scharowski-et-al.-2025-situation-specific-trust-scales-sts-ad-sts-chatbot">3.9. Scharowski et al.&nbsp;(2025) Situation-Specific Trust Scales (STS-AD / STS-Chatbot)</h3>
<ul>
<li><strong>Reference:</strong> Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., &amp; Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No.&nbsp;arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582</li>
<li><strong>Description:</strong> Measures trust and evaluation of AI performance within the specific context of the observed scenario (Self-Driving Vehicle or Chatbot). Includes comparative judgment (vs.&nbsp;self), perceived safety, and appropriateness.</li>
<li><strong>Details:</strong> 6 items for STS-AD, 8 items for STS-Chatbot, rated on a 7-point Likert scale (Fully disagree to Fully agree).</li>
</ul>
</section>
<section id="trust-in-explainable-ai-txai-items-adapted-by-scharowski-et-al.-2025" class="level3">
<h3 class="anchored" data-anchor-id="trust-in-explainable-ai-txai-items-adapted-by-scharowski-et-al.-2025">3.10. Trust in Explainable AI (TXAI) Items (Adapted by Scharowski et al., 2025)</h3>
<ul>
<li><strong>Reference:</strong> Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., &amp; Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No.&nbsp;arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582 (Adapted from original source, likely related to explainability literature).</li>
<li><strong>Description:</strong> Measures confidence, predictability, reliability, safety, efficiency, wariness, perceived competence (vs.&nbsp;novice human), and liking for decision-making regarding an observed AI.</li>
<li><strong>Details:</strong> 8 items rated on a 5-point Likert scale (I disagree strongly to I agree strongly).</li>
</ul>
</section>
<section id="paice-questionnaire---trust-items" class="level3">
<h3 class="anchored" data-anchor-id="paice-questionnaire---trust-items">3.11. PAICE Questionnaire - Trust Items</h3>
<ul>
<li><strong>Reference:</strong> Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., &amp; Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. <em>IEEE Transactions on Artificial Intelligence, 6</em>(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633</li>
<li><strong>Description:</strong> Includes items assessing the importance of various measures (laws, certifications, monitoring, codes of conduct, transparency, diverse teams) for increasing trust in AI (Q12), and trust in different entities (governments, EU, universities, CSOs, tech companies, social media) to ensure AI serves public interest (Q14).</li>
<li><strong>Details:</strong> Items rated on 5-point scales (Not important at all to Very important; Not at all to A lot). Full questionnaire available in the source file (<code>Scantamburlo_AI_Survey.md</code>).</li>
</ul>
</section>
<section id="gerlich-2025-ai-trust-item" class="level3">
<h3 class="anchored" data-anchor-id="gerlich-2025-ai-trust-item">3.12. Gerlich (2025) AI Trust Item</h3>
<ul>
<li><strong>Reference:</strong> Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. <em>Societies, 15</em>(1), Article 1. https://doi.org/10.3390/soc15010006</li>
<li><strong>Description:</strong> Includes a single item assessing trust in recommendations provided by AI tools.</li>
<li><strong>Details:</strong> Item 9: “I trust the recommendations provided by AI tools.” Rated on a 6-point Likert scale (Strongly Disagree to Strongly Agree).</li>
</ul>
</section>
<section id="madsen-gregor-2000-human-computer-trust-instrument" class="level3">
<h3 class="anchored" data-anchor-id="madsen-gregor-2000-human-computer-trust-instrument">3.13. Madsen &amp; Gregor (2000) Human-Computer Trust Instrument</h3>
<ul>
<li><strong>Reference:</strong> Madsen, M., &amp; Gregor, S. (2000). Measuring Human-Computer Trust. <em>Proceedings of the 11th Australasian Conference on Information Systems</em>. (As cited/used in Adams et al., 2003).</li>
<li><strong>Description:</strong> Measures trust in computer systems (potentially applicable to AI) across dimensions of reliability, technical competence, understandability, faith, and personal attachment.</li>
<li><strong>Constructs:</strong> Perceived Reliability, Perceived Technical Competence, Perceived Understandability, Faith, Personal Attachment.</li>
<li><strong>Details:</strong> 25 items (5 per construct). Original response scale not specified in the Adams et al.&nbsp;</li>
</ul>
</section>
<section id="shape-automation-trust-index-sati-v0.3" class="level3">
<h3 class="anchored">3.14. SHAPE Automation Trust Index (SATI v0.3)</h3>
<ul>
<li><strong>Reference:</strong> Goillau, P., Kelly, M., Boardman, J., &amp; Jeannot, E. (2001). <em>SHAPE Automation Trust Index (SATI v0.3)</em>. Eurocontrol Experimental Centre. (As cited/used in Adams et al., 2003).</li>
<li><strong>Description:</strong> A two-part index assessing trust and confidence in a simulated automated system before and after interaction, including reasons for trust/confidence levels.</li>
<li><h2 id="details-includes-rating-scales-bad-ok-good-none-ok-full-confidence-yesno-trust-question-and-open-ended-reasons.-administered-pre--and-post-simulation." class="anchored" data-anchor-id="shape-automation-trust-index-sati-v0.3"><strong>Details:</strong> Includes rating scales (Bad-OK-Good, None-OK-Full confidence), Yes/No trust question, and open-ended reasons. Administered pre- and post-simulation.</h2></li>
</ul>
</section>
</section>
<section id="ai-perception-experience-scales" class="level2">
<h2 class="anchored" data-anchor-id="ai-perception-experience-scales">4. AI Perception &amp; Experience Scales</h2>
<p>Instruments measuring how AI is perceived, user experiences, and related psychological constructs.</p>
<section id="chen-et-al.-2025-mental-capacity-attribution" class="level3">
<h3 class="anchored" data-anchor-id="chen-et-al.-2025-mental-capacity-attribution">4.1. Chen et al.&nbsp;(2025) Mental Capacity Attribution</h3>
<ul>
<li><strong>Reference:</strong> Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., &amp; Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. <em>Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</em>, 1–14. https://doi.org/10.1145/3706599.3719710</li>
<li><strong>Description:</strong> Measures the extent to which people attribute various mental capacities (related to Body, Heart, Mind) to LLMs. Based on Weisman et al.&nbsp;(2017) with additions.</li>
<li><strong>Details:</strong> 40 items rated on a 7-point capability scale (Not at all capable to Highly capable).</li>
</ul>
</section>
<section id="chen-et-al.-2025-anthropomorphism-measure" class="level3">
<h3 class="anchored" data-anchor-id="chen-et-al.-2025-anthropomorphism-measure">4.2. Chen et al.&nbsp;(2025) Anthropomorphism Measure</h3>
<ul>
<li><strong>Reference:</strong> Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., &amp; Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. <em>Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</em>, 1–14. https://doi.org/10.1145/3706599.3719710</li>
<li><strong>Description:</strong> Measures perceived human-likeness of LLMs.</li>
<li><strong>Details:</strong> 1 item rated on a 7-point scale (Not human-like at all to Very human-like), plus an open-ended explanation. ### 4.3. Kim et al.&nbsp;(2024) Anthropomorphism Measure</li>
<li><strong>Reference:</strong> Kim, S. S. Y., Liao, Q. V., Vorvoreanu, M., Ballard, S., &amp; Vaughan, J. W. (2024). “I’m Not Sure, But…”: Examining the Impact of Large Language Models’ Uncertainty Expression on User Reliance and Trust (No.&nbsp;arXiv:2405.00623). arXiv. https://doi.org/10.48550/arXiv.2405.00623</li>
<li><strong>Description:</strong> Measures impression of an AI system using semantic differential scales related to human-likeness.</li>
<li><strong>Details:</strong> 4 bipolar adjective pairs (Fake-Natural, Machinelike-Humanlike, Unconscious-Conscious, Artificial-Lifelike) rated on a 5-point scale.</li>
</ul>
</section>
<section id="general-self-efficacy-scale-for-use-with-artificial-intelligence-gse-6ai" class="level3">
<h3 class="anchored" data-anchor-id="general-self-efficacy-scale-for-use-with-artificial-intelligence-gse-6ai">4.4. General Self-Efficacy Scale for use with Artificial Intelligence (GSE-6AI)</h3>
<ul>
<li><strong>Reference:</strong> Morales-García, W. C., Sairitupa-Sanchez, L. Z., Morales-García, S. B., &amp; Morales-García, M. (2024). Adaptation and psychometric properties of a brief version of the general self-efficacy scale for use with artificial intelligence (GSE-6AI) among university students. <em>Frontiers in Education, 9</em>. https://doi.org/10.3389/feduc.2024.1293437</li>
<li><strong>Description:</strong> Measures perceived self-efficacy in using AI, adapted from the general self-efficacy scale.</li>
<li><strong>Details:</strong> 6 items rated on a 4-point scale (Not at all true to Exactly true).</li>
</ul>
</section>
<section id="chen-et-al.-2025-self-efficacy-items" class="level3">
<h3 class="anchored" data-anchor-id="chen-et-al.-2025-self-efficacy-items">4.5. Chen et al.&nbsp;(2025) Self-Efficacy Items</h3>
<ul>
<li><strong>Reference:</strong> Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., &amp; Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. <em>Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</em>, 1–14. https://doi.org/10.1145/3706599.3719710</li>
<li><strong>Description:</strong> Includes items measuring confidence in learning to program LLMs and getting LLMs to perform desired tasks.</li>
<li><strong>Details:</strong> 2 items rated on a 7-point Likert scale (Strongly Disagree to Strongly Agree).</li>
</ul>
</section>
<section id="gnambs-et-al.-2025-ai-experience-familiarity" class="level3">
<h3 class="anchored" data-anchor-id="gnambs-et-al.-2025-ai-experience-familiarity">4.6. Gnambs et al.&nbsp;(2025) AI Experience &amp; Familiarity</h3>
<ul>
<li><strong>Reference:</strong> Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., &amp; Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. <em>Telematics and Informatics, 98</em>, 102265. https://doi.org/10.1016/j.tele.2025.102265</li>
<li><strong>Description:</strong> Assesses familiarity (how often heard of) and past 12-month experience with specific AI scenarios/types (virtual assistants, recommender systems, robots, predictive analytics, monitoring, content generation) across different domains (workplace, healthcare, education).</li>
<li><strong>Details:</strong> Questions rated on 5-point scales (0-4).</li>
</ul>
</section>
<section id="paice-questionnaire---awareness-competency-items" class="level3">
<h3 class="anchored" data-anchor-id="paice-questionnaire---awareness-competency-items">4.7. PAICE Questionnaire - Awareness &amp; Competency Items</h3>
<ul>
<li><strong>Reference:</strong> Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., &amp; Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. <em>IEEE Transactions on Artificial Intelligence, 6</em>(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633</li>
<li><strong>Description:</strong> Includes items assessing self-rated competency on AI (Q1), perceived impact on daily life (Q3, Q15), awareness of European AI initiatives (Q4), awareness of interacting with AI (Q5), and identification of AI in common applications (Q6).</li>
<li><strong>Details:</strong> Various scales (5-point Likert, Yes/No, Multiple Choice).</li>
</ul>
</section>
<section id="lee-et-al.-2024-prediction-believability-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="lee-et-al.-2024-prediction-believability-evaluation">4.8. Lee et al.&nbsp;(2024) Prediction Believability Evaluation</h3>
<ul>
<li><strong>Reference:</strong> Lee, E., Pataranutaporn, P., Amores, J., &amp; Maes, P. (2024). <em>Super-intelligence or Superstition? Exploring Psychological Factors Influencing Belief in AI Predictions about Personal Behavior</em> (No.&nbsp;arXiv:2408.06602). arXiv. https://doi.org/10.48550/arXiv.2408.06602</li>
<li><strong>Description:</strong> Measures the perceived validity, personalization, reliability, and usefulness of predictions about personal behavior attributed to different sources (AI, Astrology, Personality).</li>
<li><strong>Constructs:</strong> Validity, Personalization, Reliability, Usefulness.</li>
<li><strong>Details:</strong> 8 items (2 per construct) rated on a 7-point Likert scale (Strongly disagree to Strongly agree).</li>
</ul>
</section>
<section id="lee-et-al.-2024-perception-of-prediction-methods" class="level3">
<h3 class="anchored" data-anchor-id="lee-et-al.-2024-perception-of-prediction-methods">4.9. Lee et al.&nbsp;(2024) Perception of Prediction Methods</h3>
<ul>
<li><strong>Reference:</strong> Lee, E., Pataranutaporn, P., Amores, J., &amp; Maes, P. (2024). <em>Super-intelligence or Superstition? Exploring Psychological Factors Influencing Belief in AI Predictions about Personal Behavior</em> (No.&nbsp;arXiv:2408.06602). arXiv. https://doi.org/10.48550/arXiv.2408.06602</li>
<li><strong>Description:</strong> Measures agreement with statements about the accuracy of predictions based on personality type, astrology, AI models, and past behavior.</li>
<li><strong>Details:</strong> 4 items rated on a 7-point Likert scale (Strongly disagree to Strongly agree).</li>
</ul>
</section>
<section id="ovsyannikova-et-al.-2025-perceived-compassion-responsiveness" class="level3">
<h3 class="anchored" data-anchor-id="ovsyannikova-et-al.-2025-perceived-compassion-responsiveness">4.10. Ovsyannikova et al.&nbsp;(2025) Perceived Compassion &amp; Responsiveness</h3>
<ul>
<li><strong>Reference:</strong> Ovsyannikova, D., De Mello, V. O., &amp; Inzlicht, M. (2025). Third-party evaluators perceive AI as more compassionate than expert humans. <em>Communications Psychology, 3</em>(1). https://doi.org/10.1038/s44271-024-00182-6</li>
<li><strong>Description:</strong> Measures third-party evaluations of compassion (reflecting emotion, compassionate, impersonal) and responsiveness (understanding, validation, caring) in responses (from humans or AI) to empathy prompts.</li>
<li><strong>Details:</strong> Items rated on a 5-point Likert scale (Strongly Disagree to Strongly Agree).</li>
</ul>
</section>
<section id="fang-et-al.-2025-emotional-dependence-problematic-use" class="level3">
<h3 class="anchored" data-anchor-id="fang-et-al.-2025-emotional-dependence-problematic-use">4.11. Fang et al.&nbsp;(2025) Emotional Dependence &amp; Problematic Use</h3>
<ul>
<li><strong>Reference:</strong> Fang, C. M., Liu, A. R., Danry, V., Lee, E., Chan, S. W. T., Pataranutaporn, P., Maes, P., Phang, J., Lampe, M., Ahmad, L., &amp; Agarwal, S. (2025). How AI and Human Behaviors Shape Psychosocial Effects of Chatbot Use: A Longitudinal Randomized Controlled Study (No.&nbsp;arXiv:2503.17473). arXiv. https://doi.org/10.48550/arXiv.2503.17473</li>
<li><strong>Description:</strong> Measures emotional dependence on AI chatbots (ADS-9 adapted) and problematic use patterns (PCUS).</li>
<li><strong>Constructs:</strong> Emotional Dependence, Problematic Use.</li>
<li><strong>Details:</strong> Items rated on a 5-point Likert scale (Disagree to Agree).</li>
</ul>
</section>
<section id="fang-et-al.-2025-impressions-of-agents" class="level3">
<h3 class="anchored" data-anchor-id="fang-et-al.-2025-impressions-of-agents">4.12. Fang et al.&nbsp;(2025) Impressions of Agent(s)</h3>
<ul>
<li><strong>Reference:</strong> Fang, C. M., Liu, A. R., Danry, V., Lee, E., Chan, S. W. T., Pataranutaporn, P., Maes, P., Phang, J., Lampe, M., Ahmad, L., &amp; Agarwal, S. (2025). How AI and Human Behaviors Shape Psychosocial Effects of Chatbot Use: A Longitudinal Randomized Controlled Study (No.&nbsp;arXiv:2503.17473). arXiv. https://doi.org/10.48550/arXiv.2503.17473</li>
<li><strong>Description:</strong> Measures user impressions of AI agent(s) after interaction, focusing on understanding, expertise, balance, inspiration, intelligence, and likeability.</li>
<li><strong>Details:</strong> 6 items rated on a 7-point Likert scale.</li>
</ul>
</section>
<section id="complacency-potential-rating-scale" class="level3">
<h3 class="anchored" data-anchor-id="complacency-potential-rating-scale">4.13. Complacency-Potential Rating Scale</h3>
<ul>
<li><strong>Reference:</strong> Singh, I. L., Molloy, R., &amp; Parasuraman, R. (1993). Automation-induced “complacency”: Development of the complacency-potential rating scale. <em>The International Journal of Aviation Psychology, 3</em>(2), 111-121. (As cited/used in Adams et al., 2003).</li>
<li><strong>Description:</strong> Measures potential for complacency when interacting with automated systems across various domains (library, surgery, banking, aviation, VCRs, medicine). Assesses trust, perceived reliability, safety, ease of use, and job satisfaction aspects.</li>
<li><strong>Details:</strong> 20 items rated on a 5-point Likert scale (Strongly disagree to Strongly agree).</li>
</ul>
</section>
<section id="gerlich-2025-cognitive-offloading-critical-thinking-items" class="level3">
<h3 class="anchored" data-anchor-id="gerlich-2025-cognitive-offloading-critical-thinking-items">4.14. Gerlich (2025) Cognitive Offloading &amp; Critical Thinking Items</h3>
<ul>
<li><strong>Reference:</strong> Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. <em>Societies, 15</em>(1), Article 1. https://doi.org/10.3390/soc15010006</li>
<li><strong>Description:</strong> Includes items measuring reliance on external tools (search engines, devices) for information retrieval and memory (Cognitive Offloading), and self-reported critical evaluation habits regarding information sources, including AI (Critical Thinking).</li>
<li><strong>Details:</strong> Items rated on 6-point frequency or Likert scales.</li>
</ul>
</section>
<section id="rheu-cho-2025-machine-heuristics-credibility" class="level3">
<h3 class="anchored" data-anchor-id="rheu-cho-2025-machine-heuristics-credibility">4.15. Rheu &amp; Cho (2025) Machine Heuristics &amp; Credibility</h3>
<ul>
<li><strong>Reference:</strong> Rheu, M. (MJ), &amp; Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. <em>Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</em>, 1–7. https://doi.org/10.1145/3706599.3719681</li>
<li><strong>Description:</strong> Measures perception of LLMs as expert, objective, and accurate (Machine Heuristics), and overall perceived credibility (Credibility).</li>
<li><strong>Constructs:</strong> Machine Heuristics (Expert, Objective, Accurate), Credibility.</li>
<li><strong>Details:</strong> Machine Heuristics uses 12 items on a 7-point Likert scale. Credibility uses 4 items on a 7-point semantic differential scale (-3 to +3).</li>
</ul>
</section>
<section id="song-et-al.-2024-social-influence-items" class="level3">
<h3 class="anchored" data-anchor-id="song-et-al.-2024-social-influence-items">4.16. Song et al.&nbsp;(2024) Social Influence Items</h3>
<ul>
<li><strong>Reference:</strong> Song, T., Tan, Y., Zhu, Z., Feng, Y., &amp; Lee, Y.-C. (2024). Multi-Agents are Social Groups: Investigating Social Influence of Multiple Agents in Human-Agent Interactions. https://doi.org/10.48550/ARXIV.2411.04578</li>
<li><strong>Description:</strong> Measures perceived informational (persuasion-based) and normative (compliance-based) social influence exerted by AI agent(s) during a discussion task.</li>
<li><strong>Constructs:</strong> Informational Influence, Normative Influence.</li>
<li><strong>Details:</strong> 4 items rated on a 7-point Likert scale, plus open-ended questions.</li>
</ul>
</section>
<section id="zhu-et-al.-2024-goal-interpretation-needs-attribution" class="level3">
<h3 class="anchored" data-anchor-id="zhu-et-al.-2024-goal-interpretation-needs-attribution">4.17. Zhu et al.&nbsp;(2024) Goal Interpretation &amp; Needs Attribution</h3>
<ul>
<li><strong>Reference:</strong> Zhu, Q., Chong, L., Yang, M., &amp; Luo, J. (2024). Reading Users’ Minds from What They Say: An Investigation into LLM-based Empathic Mental Inference. <em>ASME. J. Mech. Des. August 2024; 146</em>(6): 061401. https://doi.org/10.1115/DETC2024-143961</li>
<li><strong>Description:</strong> A task-based measure where participants (users or designers interpreting user comments) articulate goals at different levels (task, sub-action, overarching) and attribute these goals to fundamental psychological needs.</li>
<li><strong>Details:</strong> Involves open-ended goal generation and rating goal attribution to 13 needs on a 5-point scale (Not attributed at all to Highly attributed).</li>
</ul>
<hr>
</section>
</section>
<section id="ai-usage-intention-scales" class="level2">
<h2 class="anchored" data-anchor-id="ai-usage-intention-scales">5. AI Usage &amp; Intention Scales</h2>
<p>Instruments focused on measuring frequency, patterns, and intentions regarding AI use.</p>
<section id="gnambs-et-al.-2025-future-ai-experience-intentions" class="level3">
<h3 class="anchored" data-anchor-id="gnambs-et-al.-2025-future-ai-experience-intentions">5.1. Gnambs et al.&nbsp;(2025) Future AI Experience Intentions</h3>
<ul>
<li><strong>Reference:</strong> Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., &amp; Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. <em>Telematics and Informatics, 98</em>, 102265. https://doi.org/10.1016/j.tele.2025.102265</li>
<li><strong>Description:</strong> Assesses desired future experience (intention to use) with specific AI scenarios/types (virtual assistants, recommender systems, robots, predictive analytics, monitoring, content generation) across different domains (workplace, healthcare, education).</li>
<li><strong>Details:</strong> Question rated on a 5-point scale (0=none to 4=very much).</li>
</ul>
</section>
<section id="gerlich-2025-ai-tool-usage-items" class="level3">
<h3 class="anchored" data-anchor-id="gerlich-2025-ai-tool-usage-items">5.2. Gerlich (2025) AI Tool Usage Items</h3>
<ul>
<li><strong>Reference:</strong> Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. <em>Societies, 15</em>(1), Article 1. https://doi.org/10.3390/soc15010006</li>
<li><strong>Description:</strong> Includes items measuring frequency of AI tool use for information/problem solving and extent of reliance on AI for decision-making.</li>
<li><strong>Details:</strong> Items 6 &amp; 7 rated on a 6-point scale (Never/Not at all to Always/Completely). Items available in the source file (<code>Gerlich25_Survey.md</code>).</li>
</ul>
</section>
<section id="tully-longoni-appel-2023-ai-receptivity-measures" class="level3">
<h3 class="anchored" data-anchor-id="tully-longoni-appel-2023-ai-receptivity-measures">5.3. Tully, Longoni, &amp; Appel (2023) AI Receptivity Measures</h3>
<ul>
<li><strong>Reference:</strong> Tully, S., Longoni, C., &amp; Appel, G. (2023). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. OSF. https://doi.org/10.31234/osf.io/t9u8g</li>
<li><strong>Description:</strong> Uses various measures across studies to assess AI receptivity, including:
<ul>
<li><strong>Adoption Readiness:</strong> Agreement with statements about AI’s impact, benefits, and trustworthiness (Study 1, 5). 4 items, Yes/No or 7-point Likert scale.</li>
<li><strong>Propensity to Use Generative AI:</strong> Likelihood of using GenAI for specific academic assignments (Study 2). 4 scenarios rated on a 5-point scale of usage depth.</li>
<li><strong>Past AI Usage:</strong> Frequency of using specific AI tools in the last six months (Study 3). 5 tool types rated on a 5-point frequency scale.</li>
<li><strong>Relative Preference (Human vs.&nbsp;AI):</strong> Preference for human or AI agent for various tasks (Study 4, 6, 7). Multiple tasks rated on a 7-point preference scale.</li>
</ul></li>
<li><strong>Details:</strong> Specific items and scales vary by study.</li>
</ul>
</section>
<section id="rheu-cho-2025-fact-checking-behavior" class="level3">
<h3 class="anchored" data-anchor-id="rheu-cho-2025-fact-checking-behavior">5.4. Rheu &amp; Cho (2025) Fact-checking Behavior</h3>
<ul>
<li><strong>Reference:</strong> Rheu, M. (MJ), &amp; Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. <em>Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</em>, 1–7. https://doi.org/10.1145/3706599.3719681</li>
<li><strong>Description:</strong> Measures the frequency of engaging in specific fact-checking behaviors (verifying credentials, checking currency, considering source reputation, using other search engines, seeking opinions) when using LLMs.</li>
<li><strong>Details:</strong> 5 items rated on a 7-point frequency scale (Never to Always).</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="ai-literacy-scales-1" class="level1">
<h1>1 AI Literacy Scales</h1>
<section id="mails-meta-artificial-intelligence-literacy-scale" class="level3">
<h3 class="anchored" data-anchor-id="mails-meta-artificial-intelligence-literacy-scale">1.1 MAILS – <em>Meta-Artificial Intelligence Literacy Scale</em></h3>
<p>Carolus et al.&nbsp;(2023) introduced a 72-item battery (60 literacy + 12 psychological meta-competence items). Factor analyses yielded seven first-order facets—<em>Use &amp; Apply</em>, <em>Understand</em>, <em>Detect</em>, <em>Create</em>, <em>Ethics</em>, <em>AI Self-Efficacy</em>, and <em>AI Self-Management</em>—plus a higher-order literacy factor ([arXiv][1]). Items use 11-point Likert response anchors; Cronbach’s α for subscales ranged .79–.92. All items are freely available via the authors’ OSF/ArXiv materials.</p>
</section>
<section id="mails-short-10-items" class="level3">
<h3 class="anchored" data-anchor-id="mails-short-10-items">1.2 MAILS-Short (10 items)</h3>
<p>Koch et al.&nbsp;(2024) distilled the original scale to ten indicators representing the same seven domains; the abbreviated form retains acceptable composite reliability (ω =.83) and strict measurement invariance across four validation samples ([HCI Downloads][2]).</p>
</section>
<section id="ailq-ai-literacy-questionnaire" class="level3">
<h3 class="anchored" data-anchor-id="ailq-ai-literacy-questionnaire">1.3 AILQ – <em>AI Literacy Questionnaire</em></h3>
<p>Ng et al.&nbsp;(2024) validated a 32-item self-report covering <em>Affective, Behavioural, Cognitive,</em> and <em>Ethical</em> dimensions (8 items each). A second-order CFA supported the four-factor structure (CFI =.95; RMSEA =.05) with student samples in Hong Kong ([ResearchGate][3]).</p>
</section>
<section id="snail-38-items" class="level3">
<h3 class="anchored" data-anchor-id="snail-38-items">1.4 SNAIL (38 items)</h3>
<p>Laupichler et al.&nbsp;(2023) produced an expert-elicited item bank for non-experts. No factorial solution was reported, so psychometric quality remains provisional ([CEUR-WS][4]).</p>
</section>
<section id="mails-related-objective-test-aicos" class="level3">
<h3 class="anchored" data-anchor-id="mails-related-objective-test-aicos">1.5 MAILS-related Objective Test (AICOS)</h3>
<p>Weber et al.&nbsp;(2023) proposed an 11-point performance-style test aligned with MAILS’ domains; convergent validity with self-report literacy is modest (r ≈ .20) ([arXiv][5]).</p>
</section>
<section id="tully-longoni-appel-2023-item-set" class="level3">
<h3 class="anchored" data-anchor-id="tully-longoni-appel-2023-item-set">1.6 Tully, Longoni &amp; Appel (2023) Item Set</h3>
<p>A 25-item knowledge quiz assessing misconceptions about AI capabilities; higher error rates predict greater <em>AI receptivity</em> across six studies ([The ARF][6]).</p>
</section>
<section id="rheu-cho-2025-trap-of-ai-literacy-battery" class="level3">
<h3 class="anchored" data-anchor-id="rheu-cho-2025-trap-of-ai-literacy-battery">1.7 Rheu &amp; Cho (2025) “Trap of AI Literacy” Battery</h3>
<p>College-focused 14-item scale (α =.87) combining conceptual and procedural knowledge; higher scores correlate with <strong>less</strong> fact-checking when using LLMs ([arXiv][7]).</p>
</section>
<section id="sail4all-23-items" class="level3">
<h3 class="anchored" data-anchor-id="sail4all-23-items">1.8 SAIL4ALL (23 items)</h3>
<p>Soto-Sanfiel et al.&nbsp;(2024) supply a broad adult-population instrument; preliminary EFA indicates a three-factor solution (Understanding, Ethics, Societal Impact). Full item list on OSF.</p>
</section>
<section id="gse-6-ai" class="level3">
<h3 class="anchored" data-anchor-id="gse-6-ai">1.9 GSE-6-AI</h3>
<p>Morales-García et al.&nbsp;(2024) adapted the general self-efficacy scale for AI contexts (6 items; α =.88).</p>
<hr>
</section>
</section>
<section id="general-attitude-toward-ai-scales" class="level1">
<h1>2 General Attitude Toward AI Scales</h1>
<section id="atai-5-items" class="level3">
<h3 class="anchored" data-anchor-id="atai-5-items">2.1 ATAI (5 items)</h3>
<p>Sindermann et al.&nbsp;(2021) created a bi-dimensional scale (<em>Acceptance</em> vs.&nbsp;<em>Fear</em>). Items use 0-10 sliders; α =.80/.84 across German, Chinese, and UK samples ([SpringerLink][8]).</p>
</section>
<section id="aias-4" class="level3">
<h3 class="anchored" data-anchor-id="aias-4">2.2 AIAS-4</h3>
<p>Grassini (2023) validated a unidimensional 4-item measure capturing perceived societal utility; final CFA fit: CFI =.99, RMSEA =.02 ([Frontiers][9]).</p>
</section>
<section id="attari-12" class="level3">
<h3 class="anchored" data-anchor-id="attari-12">2.3 ATTARI-12</h3>
<p>Stein et al.&nbsp;(2024) offer a 12-item inventory emphasising anthropomorphic and ethical connotations; Big-Five traits predict scores modestly (|r| &lt; .25) ([Nature][10]).</p>
</section>
<section id="paice-european-barometer" class="level3">
<h3 class="anchored" data-anchor-id="paice-european-barometer">2.4 PAICE (European Barometer)</h3>
<p>Scantamburlo et al.&nbsp;(2025) administered a 40-item omnibus survey (knowledge, trust, experience) to 17 k EU citizens; publicly released codebook supports secondary analyses.</p>
</section>
<section id="zhang-dafoe-2019-american-attitudes-trends-top-line" class="level3">
<h3 class="anchored" data-anchor-id="zhang-dafoe-2019-american-attitudes-trends-top-line">2.5 Zhang &amp; Dafoe (2019) “American Attitudes &amp; Trends” Top-line</h3>
<p>Large-N (n ≈ 2,000) repeat survey employing 28 fixed items; replication datasets available via SSRN.</p>
<hr>
</section>
</section>
<section id="trust-focused-instruments" class="level1">
<h1>3 Trust-Focused Instruments</h1>
<section id="tpa-trust-perception-of-automation" class="level3">
<h3 class="anchored" data-anchor-id="tpa-trust-perception-of-automation">3.1 TPA – <em>Trust Perception of Automation</em></h3>
<p>Jian et al.&nbsp;(2000) distilled 12 bipolar adjectives into <em>Trust</em> vs.&nbsp;<em>Distrust</em> subscales; α =.85. Widely reused in HRI and displays convergent validity with behavioural reliance ([Finding the “Perfect” Scale][11]).</p>
</section>
<section id="tia-körber-2019" class="level3">
<h3 class="anchored" data-anchor-id="tia-körber-2019">3.2 TiA (Körber, 2019)</h3>
<p>Seven subscales (e.g., <em>Reliability, Predictability, Intention of Developers</em>). The GitHub repository hosts English &amp; German PDFs plus scoring manual ([GitHub][12]).</p>
</section>
<section id="semantic-differential-ai-trust-27-items" class="level3">
<h3 class="anchored" data-anchor-id="semantic-differential-ai-trust-27-items">3.3 Semantic-Differential AI-Trust (27 items)</h3>
<p>Shang &amp; Hsieh (2025) separate <strong>Affective</strong> (15 items) from <strong>Cognitive</strong> (12 items) trust; multi-sample CFA confirms a correlated-two-factor model (CFI =.96) ([Ruoxi Shang][13]).</p>
</section>
<section id="ptt-a-propensity-to-trust-technology" class="level3">
<h3 class="anchored" data-anchor-id="ptt-a-propensity-to-trust-technology">3.4 PTT-A (Propensity to Trust Technology)</h3>
<p>Scholz et al.&nbsp;(2025) adapt dispositional trust to automated tech (8 items; α =.83); overlaps ϕ ≈ .40 with interpersonal trust.</p>
</section>
<section id="tia-derived-trust-in-automation-short-forms" class="level3">
<h3 class="anchored" data-anchor-id="tia-derived-trust-in-automation-short-forms">3.5 TiA-derived <em>Trust in Automation</em> Short Forms</h3>
<p>Scharowski et al.&nbsp;(2025) benchmark nine variants (including Jian-12, TiA-5) against behavioural calibration; only Jian-12 met scalar invariance.</p>
<hr>
</section>
</section>
<section id="other-relevant-measures" class="level1">
<h1>4 Other Relevant Measures</h1>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 36%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Domain</th>
<th>Example Scales</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Mental-Model / Capacity Attribution</strong></td>
<td>Chen et al.&nbsp;(2025); Song et al.&nbsp;(2024); Ovsyannikova et al.&nbsp;(2025)</td>
<td>Scenario-based vignettes manipulating agent framing (<em>machine vs.&nbsp;companion</em>).</td>
</tr>
<tr class="even">
<td><strong>Uncertainty &amp; Reliance</strong></td>
<td>Kim et al.&nbsp;(2024) prompts; Duro et al.&nbsp;(2025) trust-factors battery</td>
<td>Focus on LLM confidence displays and user calibration.</td>
</tr>
<tr class="odd">
<td><strong>Self-Efficacy &amp; Offloading</strong></td>
<td>Gerlich (2025); Puppart &amp; Aru (2025) pre/post intervention quizzes</td>
<td>Examine cognitive offloading tendencies after literacy training.</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="comparative-table" class="level1">
<h1>5 Comparative Table</h1>
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 31%">
<col style="width: 3%">
<col style="width: 14%">
<col style="width: 6%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Instrument</th>
<th>Construct</th>
<th>Items</th>
<th>Subscales / Factors</th>
<th>Sample α</th>
<th>Link / Access</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>MAILS</strong></td>
<td>AI literacy (perceived + meta-competence)</td>
<td>72</td>
<td>7</td>
<td>.79–.92</td>
<td>ArXiv OSF ([arXiv][1])</td>
</tr>
<tr class="even">
<td><strong>MAILS-S</strong></td>
<td>AI literacy</td>
<td>10</td>
<td>7</td>
<td>.77</td>
<td>PDF ([HCI Downloads][2])</td>
</tr>
<tr class="odd">
<td><strong>AILQ</strong></td>
<td>AI literacy</td>
<td>32</td>
<td>ABC&amp;E (4)</td>
<td>.82–.90</td>
<td>RG PDF ([ResearchGate][3])</td>
</tr>
<tr class="even">
<td><strong>SNAIL</strong></td>
<td>AI literacy (non-experts)</td>
<td>38</td>
<td>–</td>
<td>–</td>
<td>CEUR ([CEUR-WS][4])</td>
</tr>
<tr class="odd">
<td><strong>ATAI</strong></td>
<td>Acceptance/Fear of AI</td>
<td>5</td>
<td>2</td>
<td>.80/.84</td>
<td>Springer OA ([SpringerLink][8])</td>
</tr>
<tr class="even">
<td><strong>AIAS-4</strong></td>
<td>General attitude</td>
<td>4</td>
<td>1</td>
<td>.78</td>
<td>Frontiers ([Frontiers][9])</td>
</tr>
<tr class="odd">
<td><strong>ATTARI-12</strong></td>
<td>Attitude toward AI</td>
<td>12</td>
<td>3</td>
<td>.84</td>
<td>SciRep ([Nature][10])</td>
</tr>
<tr class="even">
<td><strong>TPA</strong></td>
<td>Trust (automation)</td>
<td>12</td>
<td>2</td>
<td>.85</td>
<td>Scale DB ([Finding the “Perfect” Scale][11])</td>
</tr>
<tr class="odd">
<td><strong>TiA</strong></td>
<td>Trust in automation</td>
<td>20</td>
<td>7</td>
<td>.70–.90</td>
<td>GitHub ([GitHub][12])</td>
</tr>
<tr class="even">
<td><strong>SD-AI-Trust</strong></td>
<td>Affective/Cognitive trust</td>
<td>27</td>
<td>2</td>
<td>.93/.91</td>
<td>PDF ([Ruoxi Shang][13])</td>
</tr>
</tbody>
</table>
<p><em>(Blank cells indicate data not reported in publicly available sources.)</em></p>
<hr>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/tegorman13\.github\.io\/llm_energy_task\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Summary Report of AI-Related Survey Instruments</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>This report organizes and summarizes various survey instruments related to Artificial Intelligence (AI), drawing from the provided list of references and associated details. The instruments are categorized based on their primary focus.</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">## 1. AI Literacy Scales</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>Instruments designed to measure knowledge, understanding, skills, and competencies related to AI.</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.1. MAILS - Meta-Artificial Intelligence Literacy Scale</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Carolus, A., Koch, M. J., Straka, S., Latoschik, M. E., &amp; Wienrich, C. (2023). MAILS - Meta AI literacy scale: Development and testing of an AI literacy questionnaire based on well-founded competency models and psychological change- and meta-competencies. *Computers in Human Behavior: Artificial Humans, 1*(2), 100014. https://doi.org/10.1016/j.chbah.2023.100014</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** A comprehensive scale measuring AI literacy based on competency models and psychological meta-competencies.</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** AI Literacy (Use &amp; Apply, Know &amp; Understand, Detect AI, AI Ethics), Create AI, AI Self-Efficacy (Problem-Solving, Learning), AI Self-Competency (Persuasion Literacy, Emotion Regulation).</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 34 items rated on an 11-point scale (0-10).</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Link:** https://hci.uni-wuerzburg.de/research/MAILS/</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.2. MAILS - Short Version</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Koch, M. J., Carolus, A., Wienrich, C., &amp; Latoschik, M. E. (2024). Meta AI literacy scale: Further validation and development of a short version. *Heliyon, 10*(21), e39686. https://doi.org/10.1016/j.heliyon.2024.e39686</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** A validated short form of the MAILS.</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** AI Literacy (Detect, Apply, Understand, Ethics), Create AI, AI Self-Efficacy (Learning, Problem-Solving), AI Self-Competency (Persuasion Literacy, Emotion Regulation).</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 10 items rated on an 11-point scale (0-10). </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.3. Tully, Longoni, &amp; Appel (2023) AI Literacy Measure (25-Item)</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Tully, S., Longoni, C., &amp; Appel, G. (2023). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. OSF. https://doi.org/10.31234/osf.io/t9u8g (Used in Studies 2, 4, 6)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures objective AI literacy through multiple-choice questions covering various AI concepts.</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 25 multiple-choice questions. Full items available in Appendix A of the source file (<span class="in">`Tully25_AI_Survey.md`</span>).</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.4. Tully, Longoni, &amp; Appel (2023) AI Literacy Measure (17-Item)</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Tully, S., Longoni, C., &amp; Appel, G. (2023). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. OSF. https://doi.org/10.31234/osf.io/t9u8g (Used in Studies 3, 5, 7)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** A shorter version measuring objective AI literacy through multiple-choice questions, structured by competencies from Long and Magerko (2020).</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 17 multiple-choice questions. Full items available in Appendix B of the source file (<span class="in">`Tully25_AI_Survey.md`</span>).</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.5. Rheu &amp; Cho (2025) AI Literacy Measure</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Rheu, M. (MJ), &amp; Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–7. https://doi.org/10.1145/3706599.3719681</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Combines items from Ng et al. (2024) and Pinski &amp; Benlian (2023) to measure AI literacy in college students using LLMs.</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** Self-Efficacy, Cognitive Learning, AI Technology Knowledge, AI-Steps Knowledge.</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Items rated on a 7-point Likert scale (Strongly disagree to Strongly agree). </span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.6. AI Literacy Questionnaire (AILQ)</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Ng, D. T. K., Wu, W., Leung, J. K. L., Chiu, T. K. F., &amp; Chu, S. K. W. (2024). Design and validation of the AI literacy questionnaire: The affective, behavioural, cognitive and ethical approach. *British Journal of Educational Technology, 55*(3), 1082–1104. https://doi.org/10.1111/bjet.13411</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures AI literacy across affective, behavioral, cognitive, and ethical dimensions.</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** Affective (Intrinsic Motivation, Self-Efficacy, Confidence), Behavioral (Commitment, Collaboration), Cognitive (Know &amp; Understand, Apply/Evaluate/Create), Ethical (AI Ethics).</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Developed with an initial pool of items, validated version likely uses a subset. Response scale typically Likert-type. </span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.7. Weber et al. (2023) Objective Measurement Scale</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Weber, P., Pinski, M., &amp; Baum, L. (2023). Toward an Objective Measurement of AI Literacy. *PACIS 2023 Proceedings*. https://aisel.aisnet.org/pacis2023/60/</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures objective AI literacy using multiple-choice questions covering socio-user, socio-creator/evaluator, technical-user, and technical-creator/evaluator aspects.</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 16 multiple-choice questions. </span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.8. Scale for the assessment of non-experts’ AI literacy (SNAIL)</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Laupichler, M. C., Aster, A., Haverkamp, N., &amp; Raupach, T. (2023). Development of the “Scale for the assessment of non-experts’ AI literacy” – An exploratory factor analysis. *Computers in Human Behavior Reports, 12*, 100338. https://doi.org/10.1016/j.chbr.2023.100338</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures self-perceived AI literacy among non-experts. Developed via Delphi study and EFA.</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Final scale has 31 items (reduced from 39) rated on a 7-point Likert scale (Strongly disagree to Strongly agree). Initial 39 items available in the source file (<span class="in">`Laupichler_AI_Survey.md`</span>).</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.9. Morrill &amp; Noetel (2023) Subjective AI Literacy Scale</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Morrill, J., &amp; Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** A brief subjective measure of AI literacy adapted from Laupichler et al. (2023).</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 6 items rated on a 7-point Likert scale (Strongly disagree to Strongly agree), plus an attention check. Items available in the source file (<span class="in">`Morrill23_AI_Survey.md`</span>).</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.10. Morrill &amp; Noetel (2023) Objective AI Literacy Scale</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Morrill, J., &amp; Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** A brief objective measure of AI literacy developed for the study, partly adapted from Weber et al. (2023).</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 5 multiple-choice questions with an "I'm not sure" option. Items available in the source file (<span class="in">`Morrill23_AI_Survey.md`</span>).</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.11. The Scale of Artificial Intelligence Literacy for all (SAIL4ALL)</span></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Soto-Sanfiel, M. T., Angulo-Brunet, A., &amp; Lutz, C. (2024). The Scale of Artificial Intelligence Literacy for all (SAIL4ALL): A Tool for Assessing Knowledge on Artificial Intelligence in All Adult Populations and Settings. OSF. https://doi.org/10.31235/osf.io/bvyku</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Assesses AI knowledge suitable for diverse adult populations, covering fundamental concepts, capabilities, mechanisms, and ethics.</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Themes:** What is AI? (Recognizing/Understanding, General/Narrow), What can AI do?, How does AI Work? (Representation, Reasoning, Learning, Data, Human Role, Action/Reaction, Sensors), How should AI be used? (Ethics).</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 59 items. Can be used with True/False or a 5-point confidence scale. Full items available in the source file (<span class="in">`Soto-Sanfiel_AI_Survey.md`</span>).</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.12. Puppart &amp; Aru (2025) AI Literacy Self-Assessment</span></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Puppart, B., &amp; Aru, J. (2025). Short-term AI literacy intervention does not reduce over-reliance on incorrect ChatGPT recommendations (No. arXiv:2503.10556). arXiv. https://doi.org/10.48550/arXiv.2503.10556</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** A brief self-assessment used post-intervention to gauge perceived changes in understanding of ChatGPT's workings, limitations/risks, and wise usage.</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 3 items rated on a 4-point forced-choice Likert scale. Items available in the source file (<span class="in">`Puppart_Aru25_AI_Survey.md`</span>).</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2. AI Attitude Scales</span></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>Instruments measuring general feelings, beliefs, and evaluations towards AI.</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.1. Attitude Towards Artificial Intelligence (ATAI) Scale</span></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Sindermann, C., Sha, P., Zhou, M., Wernicke, J., Schmitt, H. S., Li, M., Sariyska, R., Stavrou, M., Becker, B., &amp; Montag, C. (2021). Assessing the Attitude Towards Artificial Intelligence: Introduction of a Short Measure in German, Chinese, and English Language. *KI - Künstliche Intelligenz, 35*(1), 109–118. https://doi.org/10.1007/s13218-020-00689-0</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** A brief scale measuring general attitude towards AI, focusing on fear, trust, and perceived impact (benefit/destruction, job losses).</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 5 items rated on an 11-point Likert scale (0-10). </span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.2. AI Attitude Scale (AIAS-4)</span></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Grassini, S. (2023). Development and validation of the AI attitude scale (AIAS-4): a brief measure of general attitude toward artificial intelligence. *Frontiers in Psychology, 14*. https://doi.org/10.3389/fpsyg.2023.1191628</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** A very brief measure of general positive attitude toward AI.</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 4 items rated on a 10-point Likert scale (1-10). </span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.3. Attitudes Towards Artificial Intelligence Scale (ATTARI-12)</span></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Stein, J.-P., Messingschlager, T., Gnambs, T., Hutmacher, F., &amp; Appel, M. (2024). Attitudes towards AI: Measurement and associations with personality. *Scientific Reports, 14*(1), 2909. https://doi.org/10.1038/s41598-024-53335-2</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures attitudes towards AI across cognitive, affective, and behavioral dimensions, balanced for positive and negative valence.</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** Cognitive (Positive/Negative), Affective (Positive/Negative), Behavioral (Positive/Negative).</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 12 items rated on a 5-point Likert scale (Strongly disagree to Strongly agree). Items available in the source file (<span class="in">`Stein24_AI_Survey.md`</span>).</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.4. Gnambs et al. (2025) Domain-Specific AI Attitudes</span></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., &amp; Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. *Telematics and Informatics, 98*, 102265. https://doi.org/10.1016/j.tele.2025.102265</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures cognitive, affective, and behavioral attitudes towards AI within specific domains (Work, Healthcare, Education).</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 9 items (3 per domain) rated on a 5-point scale (0-4), plus a "cannot answer" option. Items available in the source file (<span class="in">`Gnabs_AI_Survey.md`</span>).</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.5. Perceptions on AI by the Citizens of Europe questionnaire (PAICE) - Attitude Items</span></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., &amp; Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. *IEEE Transactions on Artificial Intelligence, 6*(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Includes items assessing general attitude towards AI (Q2) and attitudes towards AI use in specific sectors (Q8: Healthcare, Insurance, Agriculture, Finance, Military, Law Enforcement, Environmental, Transportation, Manufacturing, HR).</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Items rated on 5-point scales (Strongly disapprove to Strongly approve). Full questionnaire available in the source file (<span class="in">`Scantamburlo_AI_Survey.md`</span>).</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.6. Zhang &amp; Dafoe (2019) Support for Developing AI</span></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Zhang, B., &amp; Dafoe, A. (2019). Artificial Intelligence: American Attitudes and Trends. *SSRN Electronic Journal*. https://doi.org/10.2139/ssrn.3312874</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures general support or opposition to the development of AI after presenting examples of AI applications.</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 1 item rated on a 5-point scale (Strongly oppose to Strongly support), plus "I don't know". Item available in the source file (<span class="in">`Zhang_Dafoe_AI_Survey.md`</span>).</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="fu">## 3. AI Trust &amp; Reliance Scales</span></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>Instruments measuring trust, confidence, and reliance on AI systems or automation in general.</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.1. Scale of Trust in Automated Systems (Jian, Bisantz, &amp; Drury, 2000) / Trust Perception Scale - AI (TPA)</span></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Jian, J.-Y., Bisantz, A. M., &amp; Drury, C. G. (2000). Foundations for an Empirically Determined Scale of Trust in Automated System. *International Journal of Cognitive Ergonomics, 4*(1), 53–71. https://doi.org/10.1207/S15327566IJCE0401_04 (Also used/cited in Adams et al., 2003; Scharowski et al., 2025)</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** A widely used scale measuring trust in automated systems, often adapted for AI contexts (as TPA). Assesses aspects like deceptiveness, suspicion, confidence, integrity, dependability, reliability, and familiarity.</span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 12 items rated on a 7-point scale (Not at all to Extremely).</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.2. Shang et al. (2025) Affective and Cognitive Trust Scale</span></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Shang, R., &amp; Hsieh, G. (2025). Trusting Your AI Agent Emotionally and Cognitively: Development and Validation of a Semantic Differential Scale for AI Trust. *Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society*, 1343–1356.</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** A semantic differential scale designed to measure distinct cognitive (reliability, competence, understandability, integrity) and affective (empathy, sensitivity, care, altruism, responsiveness, etc.) dimensions of trust in AI agents.</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** Cognitive Trust (18 items), Affective Trust (9 items).</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 27 bipolar adjective pairs rated on a 7-point semantic differential scale (-3 to +3). Items available in the source file (<span class="in">`Shang25_AI_Trust_Scale.md`</span>).</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.3. Trust in Automation (TiA) Questionnaire</span></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Körber, M. (2019). Theoretical Considerations and Development of a Questionnaire to Measure Trust in Automation. In S. Bagnara, et al. (Eds.), *Proceedings of the 20th Congress of the International Ergonomics Association (IEA 2018)* (Vol. 823, pp. 13–30). Springer. http://link.springer.com/10.1007/978-3-319-96074-6_2</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures trust in automation based on theoretical considerations, including reliability/competence, understanding/predictability, familiarity, intention of developers, and propensity to trust.</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** Reliability/Competence, Understanding/Predictability, Familiarity, Intention of Developers, Propensity to Trust, Trust in Automation.</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 19 items rated on a 5-point Likert scale (Strongly disagree to Strongly agree), with some reverse-coded. </span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.4. Propensity to Trust in Automated Technology (PTT-A) Scale</span></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Scholz, D. D., Kraus, J., &amp; Miller, L. (2025). Measuring the Propensity to Trust in Automated Technology: Examining Similarities to Dispositional Trust in Other Humans and Validation of the PTT-A Scale. *International Journal of Human–Computer Interaction, 41*(2), 970–993. https://doi.org/10.1080/10447318.2024.2307691</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures an individual's general tendency (disposition) to trust automated technology, mirroring scales for trust in humans. Includes a short form.</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** Trusting Stance, Competence, Benevolence, Integrity.</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 14 items (6 bolded for short scale) rated on a 5-point Likert scale (Strongly disagree to Strongly agree), with some reverse-coded. </span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.5. Trust-In-LLMs Index (TILLMI)</span></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Duro, E. S. D., Veltri, G. A., Golino, H., &amp; Stella, M. (2025). Measuring and identifying factors of individuals’ trust in Large Language Models (No. arXiv:2502.21028). arXiv. https://doi.org/10.48550/arXiv.2502.21028</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures trust specifically in Large Language Models (LLMs), focusing on closeness/ease of sharing and reliance/competence.</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** Closeness with LLMs, Reliance on LLMs.</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Final scale has 6 items (reduced from 8) rated on a 5-point frequency scale (Never experience it to Always experience it). Items available in the source file (<span class="in">`Duro_AI_Survey.md`</span>).</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.6. Morrill &amp; Noetel (2023) Trust in AI Scale</span></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Morrill, J., &amp; Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures willingness to trust, rely on, and depend on AI systems, adapted from Gillespie et al. (2023).</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 6 items rated on a 7-point Likert scale (Completely Unwilling to Completely Willing). Items available in the source file (<span class="in">`Morrill23_AI_Survey.md`</span>).</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.7. Kim et al. (2024) Trust Beliefs &amp; Intentions</span></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Kim, S. S. Y., Liao, Q. V., Vorvoreanu, M., Ballard, S., &amp; Vaughan, J. W. (2024). “I’m Not Sure, But...”: Examining the Impact of Large Language Models’ Uncertainty Expression on User Reliance and Trust (No. arXiv:2405.00623). arXiv. https://doi.org/10.48550/arXiv.2405.00623</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures trust beliefs (competence, honesty, benevolence) and trust intentions (reliance, comfort acting on info) towards a specific AI system experienced in a task.</span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** TrustBelief, TrustIntention.</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 10 items (6 belief, 4 intention) rated on a 5-point Likert scale (Strongly disagree to Strongly agree), some reverse-coded.</span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.8. Scharowski et al. (2025) Single Trust/Use Items</span></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., &amp; Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No. arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Simple, direct measures of trust and willingness to use an AI after observing it in a specific scenario (Self-Driving Vehicle or Chatbot).</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 2 items ("I would trust...", "I would use...") rated on a 7-point Likert scale (Fully disagree to Fully agree). </span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.9. Scharowski et al. (2025) Situation-Specific Trust Scales (STS-AD / STS-Chatbot)</span></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., &amp; Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No. arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures trust and evaluation of AI performance within the specific context of the observed scenario (Self-Driving Vehicle or Chatbot). Includes comparative judgment (vs. self), perceived safety, and appropriateness.</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 6 items for STS-AD, 8 items for STS-Chatbot, rated on a 7-point Likert scale (Fully disagree to Fully agree). </span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.10. Trust in Explainable AI (TXAI) Items (Adapted by Scharowski et al., 2025)</span></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., &amp; Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No. arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582 (Adapted from original source, likely related to explainability literature).</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures confidence, predictability, reliability, safety, efficiency, wariness, perceived competence (vs. novice human), and liking for decision-making regarding an observed AI.</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 8 items rated on a 5-point Likert scale (I disagree strongly to I agree strongly). </span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.11. PAICE Questionnaire - Trust Items</span></span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., &amp; Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. *IEEE Transactions on Artificial Intelligence, 6*(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Includes items assessing the importance of various measures (laws, certifications, monitoring, codes of conduct, transparency, diverse teams) for increasing trust in AI (Q12), and trust in different entities (governments, EU, universities, CSOs, tech companies, social media) to ensure AI serves public interest (Q14).</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Items rated on 5-point scales (Not important at all to Very important; Not at all to A lot). Full questionnaire available in the source file (<span class="in">`Scantamburlo_AI_Survey.md`</span>).</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.12. Gerlich (2025) AI Trust Item</span></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. *Societies, 15*(1), Article 1. https://doi.org/10.3390/soc15010006</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Includes a single item assessing trust in recommendations provided by AI tools.</span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Item 9: "I trust the recommendations provided by AI tools." Rated on a 6-point Likert scale (Strongly Disagree to Strongly Agree). </span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.13. Madsen &amp; Gregor (2000) Human-Computer Trust Instrument</span></span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Madsen, M., &amp; Gregor, S. (2000). Measuring Human-Computer Trust. *Proceedings of the 11th Australasian Conference on Information Systems*. (As cited/used in Adams et al., 2003).</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures trust in computer systems (potentially applicable to AI) across dimensions of reliability, technical competence, understandability, faith, and personal attachment.</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** Perceived Reliability, Perceived Technical Competence, Perceived Understandability, Faith, Personal Attachment.</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 25 items (5 per construct). Original response scale not specified in the Adams et al. </span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.14. SHAPE Automation Trust Index (SATI v0.3)</span></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Goillau, P., Kelly, M., Boardman, J., &amp; Jeannot, E. (2001). *SHAPE Automation Trust Index (SATI v0.3)*. Eurocontrol Experimental Centre. (As cited/used in Adams et al., 2003).</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** A two-part index assessing trust and confidence in a simulated automated system before and after interaction, including reasons for trust/confidence levels.</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Includes rating scales (Bad-OK-Good, None-OK-Full confidence), Yes/No trust question, and open-ended reasons. Administered pre- and post-simulation. </span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a><span class="fu">## 4. AI Perception &amp; Experience Scales</span></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a>Instruments measuring how AI is perceived, user experiences, and related psychological constructs.</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.1. Chen et al. (2025) Mental Capacity Attribution</span></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., &amp; Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–14. https://doi.org/10.1145/3706599.3719710</span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures the extent to which people attribute various mental capacities (related to Body, Heart, Mind) to LLMs. Based on Weisman et al. (2017) with additions.</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 40 items rated on a 7-point capability scale (Not at all capable to Highly capable). </span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.2. Chen et al. (2025) Anthropomorphism Measure</span></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., &amp; Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–14. https://doi.org/10.1145/3706599.3719710</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures perceived human-likeness of LLMs.</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 1 item rated on a 7-point scale (Not human-like at all to Very human-like), plus an open-ended explanation. </span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.3. Kim et al. (2024) Anthropomorphism Measure</span></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Kim, S. S. Y., Liao, Q. V., Vorvoreanu, M., Ballard, S., &amp; Vaughan, J. W. (2024). “I’m Not Sure, But...”: Examining the Impact of Large Language Models’ Uncertainty Expression on User Reliance and Trust (No. arXiv:2405.00623). arXiv. https://doi.org/10.48550/arXiv.2405.00623</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures impression of an AI system using semantic differential scales related to human-likeness.</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 4 bipolar adjective pairs (Fake-Natural, Machinelike-Humanlike, Unconscious-Conscious, Artificial-Lifelike) rated on a 5-point scale. </span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.4. General Self-Efficacy Scale for use with Artificial Intelligence (GSE-6AI)</span></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Morales-García, W. C., Sairitupa-Sanchez, L. Z., Morales-García, S. B., &amp; Morales-García, M. (2024). Adaptation and psychometric properties of a brief version of the general self-efficacy scale for use with artificial intelligence (GSE-6AI) among university students. *Frontiers in Education, 9*. https://doi.org/10.3389/feduc.2024.1293437</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures perceived self-efficacy in using AI, adapted from the general self-efficacy scale.</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 6 items rated on a 4-point scale (Not at all true to Exactly true).</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.5. Chen et al. (2025) Self-Efficacy Items</span></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., &amp; Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–14. https://doi.org/10.1145/3706599.3719710</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Includes items measuring confidence in learning to program LLMs and getting LLMs to perform desired tasks.</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 2 items rated on a 7-point Likert scale (Strongly Disagree to Strongly Agree). </span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.6. Gnambs et al. (2025) AI Experience &amp; Familiarity</span></span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., &amp; Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. *Telematics and Informatics, 98*, 102265. https://doi.org/10.1016/j.tele.2025.102265</span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Assesses familiarity (how often heard of) and past 12-month experience with specific AI scenarios/types (virtual assistants, recommender systems, robots, predictive analytics, monitoring, content generation) across different domains (workplace, healthcare, education).</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Questions rated on 5-point scales (0-4). </span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.7. PAICE Questionnaire - Awareness &amp; Competency Items</span></span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., &amp; Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. *IEEE Transactions on Artificial Intelligence, 6*(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Includes items assessing self-rated competency on AI (Q1), perceived impact on daily life (Q3, Q15), awareness of European AI initiatives (Q4), awareness of interacting with AI (Q5), and identification of AI in common applications (Q6).</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Various scales (5-point Likert, Yes/No, Multiple Choice). </span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.8. Lee et al. (2024) Prediction Believability Evaluation</span></span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Lee, E., Pataranutaporn, P., Amores, J., &amp; Maes, P. (2024). *Super-intelligence or Superstition? Exploring Psychological Factors Influencing Belief in AI Predictions about Personal Behavior* (No. arXiv:2408.06602). arXiv. https://doi.org/10.48550/arXiv.2408.06602</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures the perceived validity, personalization, reliability, and usefulness of predictions about personal behavior attributed to different sources (AI, Astrology, Personality).</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** Validity, Personalization, Reliability, Usefulness.</span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 8 items (2 per construct) rated on a 7-point Likert scale (Strongly disagree to Strongly agree). </span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.9. Lee et al. (2024) Perception of Prediction Methods</span></span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Lee, E., Pataranutaporn, P., Amores, J., &amp; Maes, P. (2024). *Super-intelligence or Superstition? Exploring Psychological Factors Influencing Belief in AI Predictions about Personal Behavior* (No. arXiv:2408.06602). arXiv. https://doi.org/10.48550/arXiv.2408.06602</span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures agreement with statements about the accuracy of predictions based on personality type, astrology, AI models, and past behavior.</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 4 items rated on a 7-point Likert scale (Strongly disagree to Strongly agree). </span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.10. Ovsyannikova et al. (2025) Perceived Compassion &amp; Responsiveness</span></span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Ovsyannikova, D., De Mello, V. O., &amp; Inzlicht, M. (2025). Third-party evaluators perceive AI as more compassionate than expert humans. *Communications Psychology, 3*(1). https://doi.org/10.1038/s44271-024-00182-6</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures third-party evaluations of compassion (reflecting emotion, compassionate, impersonal) and responsiveness (understanding, validation, caring) in responses (from humans or AI) to empathy prompts.</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Items rated on a 5-point Likert scale (Strongly Disagree to Strongly Agree). </span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.11. Fang et al. (2025) Emotional Dependence &amp; Problematic Use</span></span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Fang, C. M., Liu, A. R., Danry, V., Lee, E., Chan, S. W. T., Pataranutaporn, P., Maes, P., Phang, J., Lampe, M., Ahmad, L., &amp; Agarwal, S. (2025). How AI and Human Behaviors Shape Psychosocial Effects of Chatbot Use: A Longitudinal Randomized Controlled Study (No. arXiv:2503.17473). arXiv. https://doi.org/10.48550/arXiv.2503.17473</span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures emotional dependence on AI chatbots (ADS-9 adapted) and problematic use patterns (PCUS).</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** Emotional Dependence, Problematic Use.</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Items rated on a 5-point Likert scale (Disagree to Agree). </span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.12. Fang et al. (2025) Impressions of Agent(s)</span></span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Fang, C. M., Liu, A. R., Danry, V., Lee, E., Chan, S. W. T., Pataranutaporn, P., Maes, P., Phang, J., Lampe, M., Ahmad, L., &amp; Agarwal, S. (2025). How AI and Human Behaviors Shape Psychosocial Effects of Chatbot Use: A Longitudinal Randomized Controlled Study (No. arXiv:2503.17473). arXiv. https://doi.org/10.48550/arXiv.2503.17473</span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures user impressions of AI agent(s) after interaction, focusing on understanding, expertise, balance, inspiration, intelligence, and likeability.</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 6 items rated on a 7-point Likert scale.</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.13. Complacency-Potential Rating Scale</span></span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Singh, I. L., Molloy, R., &amp; Parasuraman, R. (1993). Automation-induced "complacency": Development of the complacency-potential rating scale. *The International Journal of Aviation Psychology, 3*(2), 111-121. (As cited/used in Adams et al., 2003).</span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures potential for complacency when interacting with automated systems across various domains (library, surgery, banking, aviation, VCRs, medicine). Assesses trust, perceived reliability, safety, ease of use, and job satisfaction aspects.</span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 20 items rated on a 5-point Likert scale (Strongly disagree to Strongly agree). </span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.14. Gerlich (2025) Cognitive Offloading &amp; Critical Thinking Items</span></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. *Societies, 15*(1), Article 1. https://doi.org/10.3390/soc15010006</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Includes items measuring reliance on external tools (search engines, devices) for information retrieval and memory (Cognitive Offloading), and self-reported critical evaluation habits regarding information sources, including AI (Critical Thinking).</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Items rated on 6-point frequency or Likert scales. </span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.15. Rheu &amp; Cho (2025) Machine Heuristics &amp; Credibility</span></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Rheu, M. (MJ), &amp; Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–7. https://doi.org/10.1145/3706599.3719681</span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures perception of LLMs as expert, objective, and accurate (Machine Heuristics), and overall perceived credibility (Credibility).</span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** Machine Heuristics (Expert, Objective, Accurate), Credibility.</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Machine Heuristics uses 12 items on a 7-point Likert scale. Credibility uses 4 items on a 7-point semantic differential scale (-3 to +3).</span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.16. Song et al. (2024) Social Influence Items</span></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Song, T., Tan, Y., Zhu, Z., Feng, Y., &amp; Lee, Y.-C. (2024). Multi-Agents are Social Groups: Investigating Social Influence of Multiple Agents in Human-Agent Interactions. https://doi.org/10.48550/ARXIV.2411.04578</span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures perceived informational (persuasion-based) and normative (compliance-based) social influence exerted by AI agent(s) during a discussion task.</span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Constructs:** Informational Influence, Normative Influence.</span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 4 items rated on a 7-point Likert scale, plus open-ended questions. </span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.17. Zhu et al. (2024) Goal Interpretation &amp; Needs Attribution</span></span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Zhu, Q., Chong, L., Yang, M., &amp; Luo, J. (2024). Reading Users’ Minds from What They Say: An Investigation into LLM-based Empathic Mental Inference. *ASME. J. Mech. Des. August 2024; 146*(6): 061401. https://doi.org/10.1115/DETC2024-143961</span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** A task-based measure where participants (users or designers interpreting user comments) articulate goals at different levels (task, sub-action, overarching) and attribute these goals to fundamental psychological needs.</span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Involves open-ended goal generation and rating goal attribution to 13 needs on a 5-point scale (Not attributed at all to Highly attributed). </span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a><span class="fu">## 5. AI Usage &amp; Intention Scales</span></span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a>Instruments focused on measuring frequency, patterns, and intentions regarding AI use.</span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.1. Gnambs et al. (2025) Future AI Experience Intentions</span></span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., &amp; Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. *Telematics and Informatics, 98*, 102265. https://doi.org/10.1016/j.tele.2025.102265</span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Assesses desired future experience (intention to use) with specific AI scenarios/types (virtual assistants, recommender systems, robots, predictive analytics, monitoring, content generation) across different domains (workplace, healthcare, education).</span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Question rated on a 5-point scale (0=none to 4=very much). </span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.2. Gerlich (2025) AI Tool Usage Items</span></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. *Societies, 15*(1), Article 1. https://doi.org/10.3390/soc15010006</span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Includes items measuring frequency of AI tool use for information/problem solving and extent of reliance on AI for decision-making.</span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Items 6 &amp; 7 rated on a 6-point scale (Never/Not at all to Always/Completely). Items available in the source file (<span class="in">`Gerlich25_Survey.md`</span>).</span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.3. Tully, Longoni, &amp; Appel (2023) AI Receptivity Measures</span></span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Tully, S., Longoni, C., &amp; Appel, G. (2023). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. OSF. https://doi.org/10.31234/osf.io/t9u8g</span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Uses various measures across studies to assess AI receptivity, including:</span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Adoption Readiness:** Agreement with statements about AI's impact, benefits, and trustworthiness (Study 1, 5). 4 items, Yes/No or 7-point Likert scale.</span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Propensity to Use Generative AI:** Likelihood of using GenAI for specific academic assignments (Study 2). 4 scenarios rated on a 5-point scale of usage depth.</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Past AI Usage:** Frequency of using specific AI tools in the last six months (Study 3). 5 tool types rated on a 5-point frequency scale.</span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Relative Preference (Human vs. AI):** Preference for human or AI agent for various tasks (Study 4, 6, 7). Multiple tasks rated on a 7-point preference scale.</span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** Specific items and scales vary by study. </span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.4. Rheu &amp; Cho (2025) Fact-checking Behavior</span></span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Reference:** Rheu, M. (MJ), &amp; Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–7. https://doi.org/10.1145/3706599.3719681</span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Description:** Measures the frequency of engaging in specific fact-checking behaviors (verifying credentials, checking currency, considering source reputation, using other search engines, seeking opinions) when using LLMs.</span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Details:** 5 items rated on a 7-point frequency scale (Never to Always). </span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a>--------</span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a><span class="fu"># 1 AI Literacy Scales</span></span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.1 MAILS – *Meta-Artificial Intelligence Literacy Scale*</span></span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a>Carolus et al. (2023) introduced a 72-item battery (60 literacy + 12 psychological meta-competence items).  Factor analyses yielded seven first-order facets—*Use &amp; Apply*, *Understand*, *Detect*, *Create*, *Ethics*, *AI Self-Efficacy*, and *AI Self-Management*—plus a higher-order literacy factor (<span class="co">[</span><span class="ot">arXiv</span><span class="co">][1]</span>).  Items use 11-point Likert response anchors; Cronbach’s α for subscales ranged .79–.92.  All items are freely available via the authors’ OSF/ArXiv materials.</span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.2 MAILS-Short (10 items)</span></span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a>Koch et al. (2024) distilled the original scale to ten indicators representing the same seven domains; the abbreviated form retains acceptable composite reliability (ω =.83) and strict measurement invariance across four validation samples (<span class="co">[</span><span class="ot">HCI Downloads</span><span class="co">][2]</span>).</span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.3 AILQ – *AI Literacy Questionnaire*</span></span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a>Ng et al. (2024) validated a 32-item self-report covering *Affective, Behavioural, Cognitive,* and *Ethical* dimensions (8 items each).  A second-order CFA supported the four-factor structure (CFI =.95; RMSEA =.05) with student samples in Hong Kong (<span class="co">[</span><span class="ot">ResearchGate</span><span class="co">][3]</span>).</span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.4 SNAIL (38 items)</span></span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a>Laupichler et al. (2023) produced an expert-elicited item bank for non-experts.  No factorial solution was reported, so psychometric quality remains provisional (<span class="co">[</span><span class="ot">CEUR-WS</span><span class="co">][4]</span>).</span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.5 MAILS-related Objective Test (AICOS)</span></span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a>Weber et al. (2023) proposed an 11-point performance-style test aligned with MAILS’ domains; convergent validity with self-report literacy is modest (r ≈ .20) (<span class="co">[</span><span class="ot">arXiv</span><span class="co">][5]</span>).</span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.6 Tully, Longoni &amp; Appel (2023) Item Set</span></span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a>A 25-item knowledge quiz assessing misconceptions about AI capabilities; higher error rates predict greater *AI receptivity* across six studies (<span class="co">[</span><span class="ot">The ARF</span><span class="co">][6]</span>).</span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.7 Rheu &amp; Cho (2025) “Trap of AI Literacy” Battery</span></span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a>College-focused 14-item scale (α =.87) combining conceptual and procedural knowledge; higher scores correlate with **less** fact-checking when using LLMs (<span class="co">[</span><span class="ot">arXiv</span><span class="co">][7]</span>).</span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.8 SAIL4ALL (23 items)</span></span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a>Soto-Sanfiel et al. (2024) supply a broad adult-population instrument; preliminary EFA indicates a three-factor solution (Understanding, Ethics, Societal Impact).  Full item list on OSF.</span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1.9 GSE-6-AI</span></span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a>Morales-García et al. (2024) adapted the general self-efficacy scale for AI contexts (6 items; α =.88).</span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a><span class="fu"># 2 General Attitude Toward AI Scales</span></span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.1 ATAI (5 items)</span></span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a>Sindermann et al. (2021) created a bi-dimensional scale (*Acceptance* vs. *Fear*).  Items use 0-10 sliders; α =.80/.84 across German, Chinese, and UK samples (<span class="co">[</span><span class="ot">SpringerLink</span><span class="co">][8]</span>).</span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.2 AIAS-4</span></span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a>Grassini (2023) validated a unidimensional 4-item measure capturing perceived societal utility; final CFA fit: CFI =.99, RMSEA =.02 (<span class="co">[</span><span class="ot">Frontiers</span><span class="co">][9]</span>).</span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.3 ATTARI-12</span></span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a>Stein et al. (2024) offer a 12-item inventory emphasising anthropomorphic and ethical connotations; Big-Five traits predict scores modestly (|r| &lt; .25) (<span class="co">[</span><span class="ot">Nature</span><span class="co">][10]</span>).</span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.4 PAICE (European Barometer)</span></span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a>Scantamburlo et al. (2025) administered a 40-item omnibus survey (knowledge, trust, experience) to 17 k EU citizens; publicly released codebook supports secondary analyses.</span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.5 Zhang &amp; Dafoe (2019) “American Attitudes &amp; Trends” Top-line</span></span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a>Large-N (n ≈ 2,000) repeat survey employing 28 fixed items; replication datasets available via SSRN.</span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a><span class="fu"># 3 Trust-Focused Instruments</span></span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.1 TPA – *Trust Perception of Automation*</span></span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a>Jian et al. (2000) distilled 12 bipolar adjectives into *Trust* vs. *Distrust* subscales; α =.85.  Widely reused in HRI and displays convergent validity with behavioural reliance (<span class="co">[</span><span class="ot">Finding the “Perfect” Scale</span><span class="co">][11]</span>).</span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.2 TiA (Körber, 2019)</span></span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a>Seven subscales (e.g., *Reliability, Predictability, Intention of Developers*).  The GitHub repository hosts English &amp; German PDFs plus scoring manual (<span class="co">[</span><span class="ot">GitHub</span><span class="co">][12]</span>).</span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.3 Semantic-Differential AI-Trust (27 items)</span></span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a>Shang &amp; Hsieh (2025) separate **Affective** (15 items) from **Cognitive** (12 items) trust; multi-sample CFA confirms a correlated-two-factor model (CFI =.96) (<span class="co">[</span><span class="ot">Ruoxi Shang</span><span class="co">][13]</span>).</span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.4 PTT-A (Propensity to Trust Technology)</span></span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a>Scholz et al. (2025) adapt dispositional trust to automated tech (8 items; α =.83); overlaps ϕ ≈ .40 with interpersonal trust.</span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.5 TiA-derived *Trust in Automation* Short Forms</span></span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a>Scharowski et al. (2025) benchmark nine variants (including Jian-12, TiA-5) against behavioural calibration; only Jian-12 met scalar invariance.</span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a><span class="fu"># 4 Other Relevant Measures</span></span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Domain                                  <span class="pp">|</span> Example Scales                                                      <span class="pp">|</span> Notes                                                                          <span class="pp">|</span></span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a><span class="pp">| ---------------------------------------</span> <span class="pp">| -------------------------------------------------------------------</span> <span class="pp">| ------------------------------------------------------------------------------</span> <span class="pp">|</span></span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Mental-Model / Capacity Attribution** <span class="pp">|</span> Chen et al. (2025); Song et al. (2024); Ovsyannikova et al. (2025)  <span class="pp">|</span> Scenario-based vignettes manipulating agent framing (*machine vs. companion*). <span class="pp">|</span></span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Uncertainty &amp; Reliance**              <span class="pp">|</span> Kim et al. (2024) prompts; Duro et al. (2025) trust-factors battery <span class="pp">|</span> Focus on LLM confidence displays and user calibration.                         <span class="pp">|</span></span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Self-Efficacy &amp; Offloading**          <span class="pp">|</span> Gerlich (2025); Puppart &amp; Aru (2025) pre/post intervention quizzes  <span class="pp">|</span> Examine cognitive offloading tendencies after literacy training.               <span class="pp">|</span></span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a><span class="fu"># 5 Comparative Table</span></span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Instrument      <span class="pp">|</span> Construct                                 <span class="pp">|</span> Items <span class="pp">|</span> Subscales / Factors <span class="pp">|</span> Sample α <span class="pp">|</span> Link / Access                                <span class="pp">|</span></span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a><span class="pp">| ---------------</span> <span class="pp">| -----------------------------------------</span> <span class="pp">| -----</span> <span class="pp">| -------------------</span> <span class="pp">| --------</span> <span class="pp">| --------------------------------------------</span> <span class="pp">|</span></span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **MAILS**       <span class="pp">|</span> AI literacy (perceived + meta-competence) <span class="pp">|</span> 72    <span class="pp">|</span> 7                   <span class="pp">|</span> .79–.92  <span class="pp">|</span> ArXiv OSF (<span class="co">[</span><span class="ot">arXiv</span><span class="co">][1]</span>)                       <span class="pp">|</span></span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **MAILS-S**     <span class="pp">|</span> AI literacy                               <span class="pp">|</span> 10    <span class="pp">|</span> 7                   <span class="pp">|</span> .77      <span class="pp">|</span> PDF (<span class="co">[</span><span class="ot">HCI Downloads</span><span class="co">][2]</span>)                     <span class="pp">|</span></span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **AILQ**        <span class="pp">|</span> AI literacy                               <span class="pp">|</span> 32    <span class="pp">|</span> ABC<span class="sc">\&amp;</span>E (4)          <span class="pp">|</span> .82–.90  <span class="pp">|</span> RG PDF (<span class="co">[</span><span class="ot">ResearchGate</span><span class="co">][3]</span>)                   <span class="pp">|</span></span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **SNAIL**       <span class="pp">|</span> AI literacy (non-experts)                 <span class="pp">|</span> 38    <span class="pp">|</span> –                   <span class="pp">|</span> –        <span class="pp">|</span> CEUR (<span class="co">[</span><span class="ot">CEUR-WS</span><span class="co">][4]</span>)                          <span class="pp">|</span></span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **ATAI**        <span class="pp">|</span> Acceptance/Fear of AI                     <span class="pp">|</span> 5     <span class="pp">|</span> 2                   <span class="pp">|</span> .80/.84  <span class="pp">|</span> Springer OA (<span class="co">[</span><span class="ot">SpringerLink</span><span class="co">][8]</span>)              <span class="pp">|</span></span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **AIAS-4**      <span class="pp">|</span> General attitude                          <span class="pp">|</span> 4     <span class="pp">|</span> 1                   <span class="pp">|</span> .78      <span class="pp">|</span> Frontiers (<span class="co">[</span><span class="ot">Frontiers</span><span class="co">][9]</span>)                   <span class="pp">|</span></span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **ATTARI-12**   <span class="pp">|</span> Attitude toward AI                        <span class="pp">|</span> 12    <span class="pp">|</span> 3                   <span class="pp">|</span> .84      <span class="pp">|</span> SciRep (<span class="co">[</span><span class="ot">Nature</span><span class="co">][10]</span>)                        <span class="pp">|</span></span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **TPA**         <span class="pp">|</span> Trust (automation)                        <span class="pp">|</span> 12    <span class="pp">|</span> 2                   <span class="pp">|</span> .85      <span class="pp">|</span> Scale DB (<span class="co">[</span><span class="ot">Finding the “Perfect” Scale</span><span class="co">][11]</span>) <span class="pp">|</span></span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **TiA**         <span class="pp">|</span> Trust in automation                       <span class="pp">|</span> 20    <span class="pp">|</span> 7                   <span class="pp">|</span> .70–.90  <span class="pp">|</span> GitHub (<span class="co">[</span><span class="ot">GitHub</span><span class="co">][12]</span>)                        <span class="pp">|</span></span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **SD-AI-Trust** <span class="pp">|</span> Affective/Cognitive trust                 <span class="pp">|</span> 27    <span class="pp">|</span> 2                   <span class="pp">|</span> .93/.91  <span class="pp">|</span> PDF (<span class="co">[</span><span class="ot">Ruoxi Shang</span><span class="co">][13]</span>)                      <span class="pp">|</span></span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a>*(Blank cells indicate data not reported in publicly available sources.)*</span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/tegorman13/llm_energy_task/blob/main/surveys_items/AI_Surveys/AI_Survey_Sums.md" class="toc-action"><i class="bi bi-github"></i>View source</a></li></ul></div></div></div></footer></body></html>