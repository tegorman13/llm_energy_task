<!DOCTYPE html><html lang="en"><head><meta http-equiv="Content-Security-Policy" content="default-src 'self' 'unsafe-inline' 'unsafe-eval' data: blob: https://cdnjs.cloudflare.com https://cdn.jsdelivr.net https://code.jquery.com https://unpkg.com https://d3js.org https://threejs.org https://cdn.plot.ly https://stackpath.bootstrapcdn.com https://maps.googleapis.com https://cdn.tailwindcss.com https://ajax.googleapis.com https://kit.fontawesome.com https://cdn.datatables.net https://maxcdn.bootstrapcdn.com https://code.highcharts.com https://tako-static-assets-production.s3.amazonaws.com https://www.youtube.com https://fonts.googleapis.com https://fonts.gstatic.com https://pfst.cf2.poecdn.net https://puc.poecdn.net https://i.imgur.com https://wikimedia.org https://*.icons8.com https://*.giphy.com https://picsum.photos https://images.unsplash.com; frame-src 'self' https://www.youtube.com https://trytako.com; child-src 'self'; manifest-src 'self'; worker-src 'self'; upgrade-insecure-requests; block-all-mixed-content;">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Energy Literacy and AI Trust: Calibrating Confidence</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&amp;display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <style>
        :root {
            /* Updated color palette */
            --primary-color: #2563eb; /* AI concepts - blue */
            --secondary-color: #10b981; /* Energy concepts - green */
            --accent-color: #8b5cf6; /* Research design - purple */
            --text-color: #1e293b;
            --text-light: #64748b;
            --light-bg: #f8fafc;
            --card-bg: #ffffff;
            --border-color: #e2e8f0;
            --success-color: #10b981;
            --error-color: #ef4444;
            --warning-color: #f59e0b;
            --info-color: #3b82f6;
            --gradient-start: #1e293b;
            --gradient-end: #334155;
            
            /* Semantic status colors */
            --high-confidence: #10b981;
            --medium-confidence: #f59e0b; 
            --low-confidence: #ef4444;
        }
        
        body {
            font-family: 'Inter', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            max-width: 1200px;
            margin: 0 auto;
            padding: 0;
            background-color: var(--light-bg);
            letter-spacing: -0.01em;
        }
        
        .header {
            background: linear-gradient(135deg, var(--gradient-start) 0%, var(--gradient-end) 100%);
            color: white;
            padding: 40px 20px;
            border-radius: 0 0 16px 16px;
            margin-bottom: 30px;
            text-align: center;
            box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        }
        
        .header h1 {
            margin: 0;
            font-size: 36px;
            font-weight: 700;
            letter-spacing: -0.03em;
        }
        
        .header p {
            margin: 15px 0 0;
            font-size: 18px;
            opacity: 0.9;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
        }
        
        .tab-container {
            margin: 0 20px 30px;
        }
        
        .tabs {
            display: flex;
            margin-bottom: 0;
            padding-left: 0;
            list-style: none;
            border-bottom: 2px solid var(--border-color);
            overflow-x: auto;
            white-space: nowrap;
        }
        
        .tabs li {
            margin-right: 5px;
        }
        
        .tabs li a {
            display: block;
            padding: 14px 24px;
            text-decoration: none;
            color: var(--text-light);
            border-radius: 8px 8px 0 0;
            font-weight: 500;
            transition: all 0.2s ease;
        }
        
        .tabs li a:hover {
            background-color: rgba(37, 99, 235, 0.1);
            color: var(--primary-color);
        }
        
        .tabs li a.active {
            color: var(--primary-color);
            border-bottom: 3px solid var(--primary-color);
            background-color: white;
            font-weight: 600;
        }
        
        .tab-content {
            background-color: white;
            border-radius: 0 0 16px 16px;
            padding: 30px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.05);
            min-height: 500px;
        }
        
        .tab-pane {
            display: none;
        }
        
        .tab-pane.active {
            display: block;
        }
        
        h2, h3, h4 {
            color: var(--text-color);
            letter-spacing: -0.02em;
        }
        
        h2 {
            font-size: 28px;
            margin-top: 0;
            padding-bottom: 16px;
            border-bottom: 1px solid var(--border-color);
            font-weight: 700;
        }
        
        h3 {
            font-size: 22px;
            font-weight: 600;
            margin-top: 30px;
            margin-bottom: 16px;
        }
        
        h4 {
            font-size: 18px;
            font-weight: 600;
            margin-top: 24px;
            margin-bottom: 12px;
        }
        
        p {
            margin-bottom: 16px;
            line-height: 1.7;
        }
        
        .section {
            margin-bottom: 40px;
        }
        
        .chart-container {
            position: relative;
            height: 400px;
            width: 100%;
            margin: 30px 0;
            background-color: white;
            padding: 20px;
            border-radius: 12px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        .flex-container {
            display: flex;
            flex-wrap: wrap;
            gap: 24px;
            margin-bottom: 30px;
        }
        
        .flex-item {
            flex: 1;
            min-width: 300px;
            background-color: var(--card-bg);
            padding: 24px;
            border-radius: 12px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        .control-panel {
            background-color: #f8fafc;
            padding: 24px;
            border-radius: 12px;
            margin-bottom: 30px;
            border: 1px solid var(--border-color);
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        .slider-container {
            margin-bottom: 24px;
        }
        
        .slider-container label {
            display: block;
            margin-bottom: 10px;
            font-weight: 600;
            color: var(--text-color);
        }
        
        input[type="range"] {
            width: 100%;
            height: 8px;
            background: #e2e8f0;
            border-radius: 5px;
            outline: none;
        }
        
        input[type="range"]::-webkit-slider-thumb {
            appearance: none;
            width: 18px;
            height: 18px;
            border-radius: 50%;
            background: var(--primary-color);
            cursor: pointer;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
        }
        
        .slider-value {
            display: inline-block;
            min-width: 45px;
            text-align: right;
            margin-left: 10px;
            font-weight: bold;
            color: var(--primary-color);
        }
        
        .btn {
            background-color: var(--primary-color);
            color: white;
            border: none;
            padding: 12px 20px;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s;
            font-weight: 600;
            font-size: 15px;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
        }
        
        .btn i {
            font-size: 16px;
        }
        
        .btn:hover {
            background-color: #1d4ed8;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(37, 99, 235, 0.2);
        }
        
        .btn-secondary {
            background-color: var(--secondary-color);
        }
        
        .btn-secondary:hover {
            background-color: #059669;
        }
        
        .btn-accent {
            background-color: var(--accent-color);
        }
        
        .btn-accent:hover {
            background-color: #7c3aed;
        }
        
        .simulation-area {
            background-color: var(--card-bg);
            border: 1px solid var(--border-color);
            border-radius: 12px;
            padding: 30px;
            margin-top: 24px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        .appliance-info {
            display: flex;
            align-items: center;
            margin-bottom: 24px;
            background-color: #f8fafc;
            padding: 16px;
            border-radius: 12px;
            border: 1px solid var(--border-color);
        }
        
        .appliance-icon {
            width: 64px;
            height: 64px;
            margin-right: 24px;
            background-color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        }
        
        .advice-box {
            border-left: 4px solid var(--primary-color);
            padding: 20px 24px;
            background-color: #f0f9ff;
            margin: 24px 0;
            border-radius: 0 12px 12px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        .advice-high {
            border-left-color: var(--high-confidence);
            background-color: #ecfdf5;
        }
        
        .advice-medium {
            border-left-color: var(--medium-confidence);
            background-color: #fffbeb;
        }
        
        .advice-low {
            border-left-color: var(--low-confidence);
            background-color: #fef2f2;
        }
        
        .user-controls {
            display: flex;
            flex-direction: column;
            gap: 20px;
            margin-top: 30px;
        }
        
        .confidence-slider-container {
            margin: 20px 0;
            background-color: #f8fafc;
            padding: 20px;
            border-radius: 12px;
            border: 1px solid var(--border-color);
        }
        
        .confidence-labels {
            display: flex;
            justify-content: space-between;
            margin-top: 8px;
            font-size: 14px;
            color: var(--text-light);
        }
        
        .decision-btns {
            display: flex;
            gap: 20px;
            margin-top: 16px;
        }
        
        .decision-btns .btn {
            flex: 1;
        }
        
        .user-btn {
            background-color: var(--primary-color);
        }
        
        .ai-btn {
            background-color: var(--accent-color);
        }
        
        .results-display {
            margin-top: 30px;
            padding: 24px;
            background-color: #f8fafc;
            border-radius: 12px;
            border: 1px solid var(--border-color);
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 15px;
        }
        
        table, th, td {
            border: 1px solid #e2e8f0;
        }
        
        th, td {
            padding: 12px 16px;
            text-align: left;
        }
        
        th {
            background-color: #f1f5f9;
            font-weight: 600;
            color: var(--text-color);
        }
        
        tr:nth-child(even) {
            background-color: #f8fafc;
        }
        
        .correct {
            color: var(--success-color);
            font-weight: bold;
        }
        
        .incorrect {
            color: var(--error-color);
        }
        
        .research-question {
            background-color: #eff6ff;
            border-left: 4px solid var(--primary-color);
            padding: 20px 24px;
            margin: 24px 0;
            border-radius: 0 12px 12px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        .methods-diagram {
            max-width: 100%;
            height: auto;
            margin: 30px 0;
            filter: drop-shadow(0 4px 10px rgba(0,0,0,0.05));
        }
        
        .insight-box {
            background-color: #faf5ff;
            border-left: 4px solid var(--accent-color);
            padding: 20px 24px;
            margin: 24px 0;
            border-radius: 0 12px 12px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        .why-it-matters {
            background-color: #fffbeb;
            border-left: 4px solid var(--warning-color);
            padding: 20px 24px;
            margin: 24px 0;
            border-radius: 0 12px 12px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        .paper-citation {
            background-color: #f8fafc;
            border: 1px solid #e2e8f0;
            border-radius: 12px;
            padding: 20px 24px;
            margin-bottom: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        .paper-citation h3 {
            margin-top: 0;
            font-size: 18px;
            color: var(--text-color);
        }
        
        .paper-citation p {
            margin-bottom: 12px;
            color: var(--text-color);
        }
        
        .paper-citation .authors {
            font-style: italic;
            color: var(--text-light);
        }
        
        .measures-table {
            width: 100%;
            margin-bottom: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        .measures-table th {
            background-color: #eff6ff;
        }
        
        .hypothesis {
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 1px solid #e2e8f0;
        }
        
        .hypothesis h4 {
            color: var(--primary-color);
            margin-bottom: 12px;
        }
        
        .variables-list {
            display: flex;
            flex-wrap: wrap;
            gap: 12px;
            margin: 24px 0;
        }
        
        .variable-pill {
            background-color: #eff6ff;
            border-radius: 30px;
            padding: 8px 16px;
            font-size: 14px;
            display: inline-block;
            font-weight: 500;
        }
        
        .iv-pill {
            background-color: #e0f2fe;
            border: 1px solid #bae6fd;
            color: #0284c7;
        }
        
        .dv-pill {
            background-color: #dcfce7;
            border: 1px solid #bbf7d0;
            color: #16a34a;
        }
        
        .mod-pill {
            background-color: #fff7ed;
            border: 1px solid #fed7aa;
            color: #ea580c;
        }
        
        .phase-box {
            background-color: #f8fafc;
            border: 1px solid #e2e8f0;
            border-radius: 12px;
            padding: 24px;
            margin-bottom: 30px;
            position: relative;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        .phase-box h4 {
            color: var(--text-color);
            margin-top: 0;
            margin-bottom: 16px;
            border-bottom: 1px solid #e2e8f0;
            padding-bottom: 12px;
        }
        
        .phase-number {
            position: absolute;
            top: 12px;
            right: 12px;
            width: 32px;
            height: 32px;
            background-color: var(--primary-color);
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 600;
            font-size: 16px;
        }
        
        .prediction-chart {
            background-color: white;
            border: 1px solid #e2e8f0;
            border-radius: 12px;
            padding: 24px;
            margin-bottom: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        .prediction-chart h3 {
            margin-top: 0;
            color: var(--text-color);
            font-size: 20px;
            padding-bottom: 12px;
            border-bottom: 1px solid #f0f0f0;
        }
        
        .prediction-chart p {
            color: var(--text-light);
            margin-bottom: 20px;
        }
        
        .hypothesis-summary {
            font-weight: 600;
            color: var(--text-color);
            margin-top: 20px;
            padding: 12px;
            background-color: #f8fafc;
            border-radius: 8px;
        }
        
        .llm-diagram {
            max-width: 100%;
            height: auto;
            margin: 30px 0;
            overflow-x: auto;
            filter: drop-shadow(0 4px 10px rgba(0,0,0,0.05));
        }
        
        .terminology-table {
            width: 100%;
            border-collapse: collapse;
            margin: 24px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        .terminology-table th {
            background-color: #eff6ff;
            text-align: left;
            font-weight: 600;
            color: var(--text-color);
        }
        
        .terminology-table th, .terminology-table td {
            padding: 14px 18px;
            border: 1px solid #e2e8f0;
        }
        
        .step-indicator {
            display: flex;
            justify-content: space-between;
            margin: 30px 0;
            position: relative;
        }
        
        .step-indicator::before {
            content: '';
            position: absolute;
            top: 18px;
            left: 0;
            right: 0;
            height: 3px;
            background: #e2e8f0;
            z-index: 0;
        }
        
        .step {
            width: 36px;
            height: 36px;
            border-radius: 50%;
            background: white;
            border: 3px solid #e2e8f0;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 600;
            position: relative;
            z-index: 1;
            transition: all 0.3s ease;
        }
        
        .step.active {
            border-color: var(--primary-color);
            background-color: var(--primary-color);
            color: white;
            box-shadow: 0 0 0 5px rgba(37, 99, 235, 0.2);
        }
        
        .step.completed {
            border-color: var(--success-color);
            background-color: var(--success-color);
            color: white;
        }
        
        .step-label {
            position: absolute;
            top: 40px;
            font-size: 14px;
            white-space: nowrap;
            transform: translateX(-50%);
            width: 120px;
            text-align: center;
            left: 50%;
            font-weight: 500;
            color: var(--text-light);
        }
        
        .step.active + .step-label {
            color: var(--primary-color);
            font-weight: 600;
        }
        
        .step.completed + .step-label {
            color: var(--success-color);
        }
        
        /* Tooltip styling */
        .tooltip {
            position: relative;
            display: inline-block;
            border-bottom: 1px dotted var(--text-light);
            cursor: help;
        }
        
        .tooltip .tooltip-text {
            visibility: hidden;
            width: 240px;
            background-color: #334155;
            color: white;
            text-align: center;
            border-radius: 8px;
            padding: 10px;
            position: absolute;
            z-index: 1;
            bottom: 125%;
            left: 50%;
            margin-left: -120px;
            opacity: 0;
            transition: opacity 0.3s;
            font-size: 14px;
            font-weight: normal;
            box-shadow: 0 4px 15px rgba(0,0,0,0.15);
        }
        
        .tooltip .tooltip-text::after {
            content: "";
            position: absolute;
            top: 100%;
            left: 50%;
            margin-left: -5px;
            border-width: 5px;
            border-style: solid;
            border-color: #334155 transparent transparent transparent;
        }
        
        .tooltip:hover .tooltip-text {
            visibility: visible;
            opacity: 1;
        }
        
        /* Mini quiz styling */
        .mini-quiz {
            background-color: #f0f9ff;
            border-radius: 12px;
            padding: 20px;
            margin: 30px 0;
            border: 1px solid #bae6fd;
        }
        
        .mini-quiz h4 {
            margin-top: 0;
            color: var(--primary-color);
        }
        
        .quiz-options {
            margin: 15px 0;
        }
        
        .quiz-option {
            display: flex;
            align-items: center;
            margin-bottom: 10px;
            padding: 10px;
            border-radius: 8px;
            transition: background-color 0.2s;
            cursor: pointer;
        }
        
        .quiz-option:hover {
            background-color: #e0f2fe;
        }
        
        .quiz-option input {
            margin-right: 12px;
        }
        
        .quiz-feedback {
            margin-top: 15px;
            padding: 12px;
            border-radius: 8px;
            font-weight: 500;
            display: none;
        }
        
        .feedback-correct {
            background-color: #dcfce7;
            color: #16a34a;
        }
        
        .feedback-incorrect {
            background-color: #fee2e2;
            color: #dc2626;
        }
        
        /* Animation classes */
        .fade-in {
            animation: fadeIn 0.5s;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }
        
        .card-hover {
            transition: transform 0.3s, box-shadow 0.3s;
        }
        
        .card-hover:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(0,0,0,0.07);
        }
        
        /* Example vs Non-example */
        .example-comparison {
            display: flex;
            gap: 20px;
            margin: 24px 0;
            flex-wrap: wrap;
        }
        
        .example-card {
            flex: 1;
            min-width: 300px;
            padding: 20px;
            border-radius: 12px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.03);
        }
        
        .good-example {
            background-color: #f0fdf4;
            border: 1px solid #bbf7d0;
        }
        
        .poor-example {
            background-color: #fef2f2;
            border: 1px solid #fecaca;
        }
        
        .example-card h4 {
            margin-top: 0;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .good-example h4 {
            color: var(--success-color);
        }
        
        .poor-example h4 {
            color: var(--error-color);
        }
        
        @media (max-width: 768px) {
            .tabs li a {
                padding: 12px 16px;
                font-size: 14px;
            }
            
            .header h1 {
                font-size: 28px;
            }
            
            .header p {
                font-size: 16px;
            }
            
            h2 {
                font-size: 24px;
            }
            
            h3 {
                font-size: 20px;
            }
            
            .chart-container {
                height: 350px;
            }
            
            .step-indicator {
                margin: 40px 0;
            }
            
            .step-label {
                font-size: 12px;
                width: 80px;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Energy Literacy and AI Trust: Calibrating Confidence</h1>
        <p>Understanding how linguistic uncertainty affects decision-making with AI energy advisors</p>
    </div>
    
    <div class="tab-container">
        <ul class="tabs">
            <li><a href="#overview" class="active"><i class="fas fa-home"></i> Overview</a></li>
            <li><a href="#energy"><i class="fas fa-bolt"></i> Energy Perception</a></li>
            <li><a href="#ai-confidence"><i class="fas fa-robot"></i> AI Confidence</a></li>
            <li><a href="#experiment"><i class="fas fa-flask"></i> Experiment Design</a></li>
            <li><a href="#terminology"><i class="fas fa-book"></i> Terminology</a></li>
            <li><a href="#simulation"><i class="fas fa-gamepad"></i> Simulation</a></li>
            <li><a href="#predictions"><i class="fas fa-chart-line"></i> Predictions</a></li>
        </ul>
        
        <div class="tab-content">
            <!-- Overview Tab -->
            <div id="overview" class="tab-pane active">
                <h2>Calibrating Trust: Energy Decisions with AI Assistance</h2>
                
                <div class="research-question">
                    <p><strong>Research Question:</strong> "Given that people often misunderstand energy consumption (Attari), how will they react when an LLM energy advisor gives them advice, especially when we deliberately make that AI express different levels of linguistic certainty (inspired by Steyvers)?"</p>
                </div>
                
                <div class="flex-container">
                    <div class="flex-item card-hover">
                        <h3><i class="fas fa-bolt"></i> The Problem: Energy Misconceptions</h3>
                        <p>Attari et al. (2010) demonstrated that people systematically:</p>
                        <ul>
                            <li><strong style="color:#ef4444">Underestimate</strong> the energy used by high-consumption appliances (like air conditioners)</li>
                            <li><strong style="color:#10b981">Overestimate</strong> the energy used by low-consumption ones (like light bulbs)</li>
                            <li>This creates a "compression" pattern in people's energy perceptions</li>
                            <li>People may rely on unreliable heuristics (e.g., size = energy use)</li>
                        </ul>
                    </div>
                    <div class="flex-item card-hover">
                        <h3><i class="fas fa-robot"></i> The Challenge: AI Trust Calibration</h3>
                        <p>Steyvers et al. (2025) showed that:</p>
                        <ul>
                            <li>A <strong>"calibration gap"</strong> exists between an LLM's internal confidence and human perception</li>
                            <li>Users typically <strong style="color:#ef4444">overestimate</strong> LLM accuracy</li>
                            <li>Using <strong>appropriate hedging language</strong> when confidence is low helps narrow this gap</li>
                            <li>LLM token probabilities can be used to align expressed confidence with internal confidence</li>
                        </ul>
                    </div>
                </div>
                
                <div class="why-it-matters">
                    <h4><i class="fas fa-lightbulb"></i> Why This Matters</h4>
                    <p>Energy consumption is a crucial area where misinformation can lead to poor decisions. As AI advisors become more common in sustainability planning, understanding how to properly convey uncertainty in their advice is essential for helping people make better energy decisions. This research aims to bridge the gap between energy literacy and AI assistance to improve decision quality.</p>
                </div>
                
                <div class="section">
                    <h3>Research Questions</h3>
                    
                    <div class="hypothesis">
                        <h4><i class="fas fa-question-circle"></i> RQ1: Appropriate Reliance &amp; Accuracy</h4>
                        <p>How does aligning the LLM's expressed confidence with its internal probability estimates affect participants' reliance when forced to choose between the AI's estimate and their own prior estimate?</p>
                        <div class="example-comparison">
                            <div class="example-card good-example">
                                <h4><i class="fas fa-check-circle"></i> Appropriate Reliance</h4>
                                <p>Accepting AI advice when it's likely correct and rejecting it when it's likely wrong</p>
                            </div>
                            <div class="example-card poor-example">
                                <h4><i class="fas fa-times-circle"></i> Inappropriate Reliance</h4>
                                <p>Blindly accepting AI advice regardless of its likely accuracy</p>
                            </div>
                        </div>
                    </div>
                    
                    <div class="hypothesis">
                        <h4><i class="fas fa-question-circle"></i> RQ2: Metacognitive Calibration of Confidence</h4>
                        <p>Does aligning the LLM's linguistic expression of uncertainty with its internal confidence lead to better calibration between participants' confidence in the AI's estimates and the actual accuracy of those estimates?</p>
                        <div class="tooltip">What is calibration?
                            <span class="tooltip-text">Calibration refers to how well someone's confidence in a statement matches the actual likelihood of that statement being true. Well-calibrated individuals are appropriately confident in correct answers and appropriately uncertain about incorrect ones.</span>
                        </div>
                    </div>
                    
                    <div class="hypothesis">
                        <h4><i class="fas fa-question-circle"></i> RQ3: Role of Prior Knowledge &amp; Individual Differences</h4>
                        <p>Do individual difference measures like objective numeracy, energy literacy, and AI literacy moderate the impact of hedging on (a) reliance, (b) calibration, and (c) discrimination?</p>
                    </div>
                </div>
                
                <div class="section">
                    <h3>Hypotheses</h3>
                    
                    <div class="hypothesis">
                        <h4><i class="fas fa-flask"></i> H1: Appropriate Reliance</h4>
                        <p>Participants exposed to AI estimates with calibrated linguistic uncertainty cues (where hedging levels correspond to the AI's likelihood of being incorrect) will show more appropriate reliance on AI advice compared to participants exposed only to confidently expressed AI estimates.</p>
                    </div>
                    
                    <div class="hypothesis">
                        <h4><i class="fas fa-flask"></i> H2: Improved Calibration</h4>
                        <p>Participants exposed to AI estimates with calibrated linguistic uncertainty cues will exhibit better metacognitive calibration (e.g., lower Brier scores or ECE on their confidence ratings) compared to participants exposed only to confidently expressed AI estimates.</p>
                    </div>
                    
                    <div class="hypothesis">
                        <h4><i class="fas fa-flask"></i> H3: Individual Differences</h4>
                        <p>Participants with higher energy literacy will exhibit less overreliance on AI suggestions, and participants with higher AI literacy will be more sensitive to the AI's linguistic uncertainty cues.</p>
                    </div>
                </div>
                
                <div class="section">
                    <h3>Experimental Flow</h3>
                    <div class="step-indicator">
                        <div class="step completed">1
                            <span class="step-label">Pre-Study Surveys</span>
                        </div>
                        <div class="step completed">2
                            <span class="step-label">Energy Estimates</span>
                        </div>
                        <div class="step active">3
                            <span class="step-label">AI Advice</span>
                        </div>
                        <div class="step">4
                            <span class="step-label">Confidence Rating</span>
                        </div>
                        <div class="step">5
                            <span class="step-label">Forced Choice</span>
                        </div>
                    </div>
                    
                    <div class="flex-container">
                        <div class="flex-item phase-box">
                            <div class="phase-number">1</div>
                            <h4>Pre-Study Surveys</h4>
                            <p>Participants complete surveys on:</p>
                            <ul>
                                <li>Energy literacy</li>
                                <li>AI literacy</li>
                                <li>AI usage patterns</li>
                                <li>Trust propensity</li>
                                <li>Numeracy</li>
                            </ul>
                        </div>
                        
                        <div class="flex-item phase-box">
                            <div class="phase-number">2</div>
                            <h4>Energy Estimation Task</h4>
                            <p>Participants estimate energy consumption for various appliances:</p>
                            <p><em>"Relative to a 100-watt light bulb which uses 100 units of energy per hour, how many units does this appliance use?"</em></p>
                            <p>This establishes their baseline knowledge and biases.</p>
                        </div>
                    </div>
                    
                    <div class="flex-container">
                        <div class="flex-item phase-box">
                            <div class="phase-number">3</div>
                            <h4>AI Energy Advisor</h4>
                            <p>For each appliance:</p>
                            <ol>
                                <li>View AI's energy estimate</li>
                                <li>Read AI's explanation (confident or hedged based on condition)</li>
                                <li>Rate confidence in AI's estimate (0-100%)</li>
                                <li>Make forced choice between own and AI estimate</li>
                            </ol>
                        </div>
                        
                        <div class="flex-item phase-box">
                            <div class="phase-number">4</div>
                            <h4>Post-Task Measures</h4>
                            <p>After completing all appliance estimates:</p>
                            <ul>
                                <li>Overall trust in the AI advisor</li>
                                <li>Perception of AI expertise</li>
                                <li>Manipulation checks</li>
                                <li>Open-ended feedback</li>
                            </ul>
                        </div>
                    </div>
                </div>
                
                <div class="mini-quiz">
                    <h4><i class="fas fa-question-circle"></i> Quick Check: Understanding the Study</h4>
                    <p>What is the main difference between the two experimental conditions?</p>
                    <div class="quiz-options">
                        <label class="quiz-option">
                            <input type="radio" name="condition-quiz" value="incorrect1">
                            The AI is more accurate in one condition than the other
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="condition-quiz" value="incorrect2">
                            Participants have different energy knowledge levels
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="condition-quiz" value="correct">
                            How the AI expresses uncertainty (calibrated vs. always confident)
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="condition-quiz" value="incorrect3">
                            The types of appliances being estimated
                        </label>
                    </div>
                    <div id="quiz-feedback" class="quiz-feedback"></div>
                    <button id="check-answer" class="btn btn-secondary"><i class="fas fa-check"></i> Check Answer</button>
                </div>
            </div>
            
            <!-- Energy Perception Tab -->
            <div id="energy" class="tab-pane">
                <h2><i class="fas fa-bolt"></i> Energy Perception: The Attari Study</h2>
                
                <div class="paper-citation">
                    <h3>Attari et al. (2010): Public Perceptions of Energy Consumption and Savings</h3>
                    <p class="authors">Shahzeen Z. Attari, Michael L. DeKay, Cliff I. Davidson, Wändi Bruine de Bruin</p>
                    <p>This seminal study demonstrated that Americans systematically underestimate energy use for high-energy activities and overestimate it for low-energy activities, creating a "compression" effect in energy perceptions.</p>
                    <p>The research also found that people tend to focus on curtailment (turning off, using less) rather than efficiency improvements (using better technology), despite the latter often having greater energy-saving potential.</p>
                </div>
                
                <div class="chart-container">
                    <canvas id="energyPerceptionChart"></canvas>
                </div>
                
                <div class="control-panel">
                    <h4><i class="fas fa-sliders-h"></i> Interactive Energy Perception Model</h4>
                    <p>Adjust the sliders to see how people's perception of energy consumption differs from reality:</p>
                    
                    <div class="slider-container">
                        <label for="underestimationFactor">High-Energy Appliance Underestimation Factor: <span id="underestimationValue" class="slider-value">2.8</span>x</label>
                        <input type="range" id="underestimationFactor" min="1" max="5" step="0.1" value="2.8">
                        <div class="confidence-labels">
                            <span>No underestimation</span>
                            <span>Severe underestimation</span>
                        </div>
                    </div>
                    <div class="slider-container">
                        <label for="overestimationFactor">Low-Energy Appliance Overestimation Factor: <span id="overestimationValue" class="slider-value">1.6</span>x</label>
                        <input type="range" id="overestimationFactor" min="1" max="3" step="0.1" value="1.6">
                        <div class="confidence-labels">
                            <span>No overestimation</span>
                            <span>Severe overestimation</span>
                        </div>
                    </div>
                    <button id="updateEnergyChart" class="btn"><i class="fas fa-sync-alt"></i> Update Perception Model</button>
                </div>
                
                <div class="section">
                    <h3>Understanding the "Compression" Effect</h3>
                    
                    <div class="example-comparison">
                        <div class="example-card good-example">
                            <h4><i class="fas fa-check-circle"></i> Reality</h4>
                            <p>Energy consumption has a wide range: a central AC uses about 60 times more energy than a light bulb.</p>
                        </div>
                        <div class="example-card poor-example">
                            <h4><i class="fas fa-times-circle"></i> Human Perception</h4>
                            <p>People perceive a smaller range: they might think a central AC uses only 20 times more energy than a light bulb.</p>
                        </div>
                    </div>
                </div>
                
                <div class="section">
                    <h3>Key Findings from Attari et al. (2010)</h3>
                    
                    <div class="flex-container">
                        <div class="flex-item card-hover">
                            <h4><i class="fas fa-chart-line"></i> Perception Biases</h4>
                            <ul>
                                <li>Underestimation for high-energy items (~2.8x factor)</li>
                                <li>Overestimation for low-energy items (~1.6x factor)</li>
                                <li>Creates a "compressed" mental model of energy differences</li>
                                <li>People with higher numeracy showed somewhat more accurate perceptions</li>
                            </ul>
                        </div>
                        <div class="flex-item card-hover">
                            <h4><i class="fas fa-lightbulb"></i> Energy Saving Misconceptions</h4>
                            <ul>
                                <li>People focus on curtailment actions (e.g., turning off lights)</li>
                                <li>Efficiency improvements (e.g., better appliances) are undervalued</li>
                                <li>This misalignment can lead to suboptimal conservation choices</li>
                                <li>Basic pattern has been replicated in several studies</li>
                            </ul>
                        </div>
                    </div>
                    
                    <div class="why-it-matters">
                        <h4><i class="fas fa-lightbulb"></i> Why This Matters</h4>
                        <p>These systematic biases in energy perception can lead people to focus their conservation efforts in the wrong places. For instance, they might obsess over turning off lights (small savings) while ignoring home insulation improvements (large savings). Understanding these biases is crucial for designing effective energy communication and policies.</p>
                    </div>
                    
                    <div class="insight-box">
                        <h4><i class="fas fa-microscope"></i> Implications for Our Study</h4>
                        <p>The Attari findings motivate the energy-related problem that our study addresses - public misperception of energy use. The task is particularly useful since the biased pattern of under and overestimation allows us to examine the influence of AI on both bias and general accuracy.</p>
                        <p>Although this is a knowledge task rather than a planning task, this type of knowledge is quite relevant for implementing energy-use goals, and it's easy to imagine scaffolding this knowledge task into a more elaborate planning task in the future.</p>
                    </div>
                </div>
                
                <div class="mini-quiz">
                    <h4><i class="fas fa-question-circle"></i> Quick Check: Energy Perception</h4>
                    <p>According to Attari's research, which of the following would people be more likely to get right?</p>
                    <div class="quiz-options">
                        <label class="quiz-option">
                            <input type="radio" name="energy-quiz" value="incorrect1">
                            The energy consumption of a central air conditioner
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="energy-quiz" value="incorrect2">
                            All energy estimates, regardless of appliance size
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="energy-quiz" value="correct">
                            The energy consumption of a light bulb (though they'd likely overestimate)
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="energy-quiz" value="incorrect3">
                            The comparative ratio between large and small appliances
                        </label>
                    </div>
                    <div id="energy-quiz-feedback" class="quiz-feedback"></div>
                    <button id="check-energy-answer" class="btn btn-secondary"><i class="fas fa-check"></i> Check Answer</button>
                </div>
            </div>
            
            <!-- AI Confidence Tab -->
            <div id="ai-confidence" class="tab-pane">
                <h2><i class="fas fa-robot"></i> AI Confidence: The Steyvers Study</h2>
                
                <div class="paper-citation">
                    <h3>Steyvers et al. (2025): Calibrating Trust in Large Language Models</h3>
                    <p class="authors">Mark Steyvers, Ananya Kumar, Pang Wei Koh, Pulkit Agrawal et al.</p>
                    <p>This forward-looking work identified a significant "calibration gap" between an LLM's internal confidence (based on token probabilities) and human perception of its accuracy. The research demonstrated that manipulating the linguistic expression of uncertainty can help narrow this gap.</p>
                </div>
                
                <div class="chart-container">
                    <canvas id="calibrationGapChart"></canvas>
                </div>
                
                <div class="control-panel">
                    <h4><i class="fas fa-sliders-h"></i> Interactive Calibration Model</h4>
                    <p>Adjust the sliders to see how linguistic uncertainty expression affects the calibration gap:</p>
                    
                    <div class="slider-container">
                        <label for="calibrationGapSize">Calibration Gap Size: <span id="calibrationGapValue" class="slider-value">20</span>%</label>
                        <input type="range" id="calibrationGapSize" min="0" max="50" step="5" value="20">
                        <div class="confidence-labels">
                            <span>No gap</span>
                            <span>Large gap</span>
                        </div>
                    </div>
                    <div class="slider-container">
                        <label for="hedgingEffect">Effect of Hedging Language: <span id="hedgingEffectValue" class="slider-value">15</span>% reduction</label>
                        <input type="range" id="hedgingEffect" min="0" max="30" step="5" value="15">
                        <div class="confidence-labels">
                            <span>No effect</span>
                            <span>Strong effect</span>
                        </div>
                    </div>
                    <button id="updateCalibrationChart" class="btn"><i class="fas fa-sync-alt"></i> Update Calibration Model</button>
                </div>
                
                <div class="section">
                    <h3>Internal Confidence vs. Linguistic Expression</h3>
                    
                    <p>A key insight from Steyvers' work is distinguishing between how confident an AI system actually is (internal confidence) and how it expresses that confidence linguistically:</p>
                    
                    <div id="llmInternalDiagram" class="llm-diagram">
                        <!-- SVG diagram will be injected here by JavaScript -->
                    </div>
                </div>
                
                <div class="section">
                    <h3>Key Findings from Steyvers et al. (2025)</h3>
                    
                    <div class="flex-container">
                        <div class="flex-item card-hover">
                            <h4><i class="fas fa-exclamation-triangle"></i> The Calibration Gap</h4>
                            <ul>
                                <li>LLMs have internal confidence indicators (token probabilities)</li>
                                <li>Users systematically overestimate LLM accuracy</li>
                                <li>This gap is larger with confident-sounding explanations</li>
                                <li>Result: inappropriate reliance on AI advice</li>
                            </ul>
                        </div>
                        <div class="flex-item card-hover">
                            <h4><i class="fas fa-tools"></i> Bridging the Gap with Linguistic Uncertainty</h4>
                            <ul>
                                <li>Hedging language can signal LLM uncertainty</li>
                                <li>Examples: "I think," "probably," "might be," etc.</li>
                                <li>When calibrated with actual LLM confidence, hedging improves trust calibration</li>
                                <li>Users can better discriminate between reliable and unreliable advice</li>
                            </ul>
                        </div>
                    </div>
                    
                    <div class="why-it-matters">
                        <h4><i class="fas fa-lightbulb"></i> Why This Matters</h4>
                        <p>When AI systems appear confident even when they're wrong, users make poor decisions by trusting them too much. By aligning an AI's expressed uncertainty with its actual confidence, we can help people know when to trust (and when to be skeptical of) AI advice, ultimately leading to better human-AI decision-making.</p>
                    </div>
                    
                    <div class="insight-box">
                        <h4><i class="fas fa-microscope"></i> Justification for Using in Our Study</h4>
                        <ol>
                            <li>It provides a more principled and general method of manipulating the LLM (compared to situation-specific methods like prompt-tweaking)</li>
                            <li>The issue of human perception of AI uncertainty/confidence is a hot research area - and could be a useful literature to connect to</li>
                            <li>The issue of how LLMs communicate their own confidence will also be relevant to work with LLM participation in transactive memory systems</li>
                        </ol>
                    </div>
                </div>
                
                <div class="section">
                    <h3>Examples of Linguistic Uncertainty Expressions</h3>
                    
                    <table>
                        <tbody><tr>
                            <th width="25%">Confidence Level</th>
                            <th width="25%">Linguistic Expression</th>
                            <th width="50%">Example</th>
                        </tr>
                        <tr>
                            <td><strong>High Confidence</strong><br>(High Internal Confidence)</td>
                            <td>Assertive, direct statements</td>
                            <td>"A central AC unit uses 3500 units of energy per hour. This is because AC systems require significant power to cool air through the compression cycle."</td>
                        </tr>
                        <tr>
                            <td><strong>Medium Confidence</strong><br>(Medium Internal Confidence)</td>
                            <td>Qualified assertions, some hedges</td>
                            <td>"A central AC unit typically uses around 3500 units of energy per hour. This is generally because most residential AC systems need substantial power for cooling, though exact usage can vary by model."</td>
                        </tr>
                        <tr>
                            <td><strong>Low Confidence</strong><br>(Low Internal Confidence)</td>
                            <td>Multiple hedges, alternatives presented</td>
                            <td>"I think a central AC might use approximately 3500 units of energy per hour, but I'm not entirely certain. Different AC systems can vary considerably, possibly ranging from 2000 to 5000 units depending on size, efficiency, and operating conditions."</td>
                        </tr>
                    </tbody></table>
                </div>
                
                <div class="mini-quiz">
                    <h4><i class="fas fa-question-circle"></i> Quick Check: AI Confidence</h4>
                    <p>In the calibrated uncertainty condition, when would the AI use more hedging language?</p>
                    <div class="quiz-options">
                        <label class="quiz-option">
                            <input type="radio" name="ai-quiz" value="incorrect1">
                            Always, regardless of its internal confidence
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="ai-quiz" value="incorrect2">
                            Never, it always uses confident language
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="ai-quiz" value="correct">
                            When its internal confidence is low (i.e., when it's more likely to be incorrect)
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="ai-quiz" value="incorrect3">
                            Only when discussing high-energy appliances
                        </label>
                    </div>
                    <div id="ai-quiz-feedback" class="quiz-feedback"></div>
                    <button id="check-ai-answer" class="btn btn-secondary"><i class="fas fa-check"></i> Check Answer</button>
                </div>
            </div>
            
            <!-- Experiment Design Tab -->
            <div id="experiment" class="tab-pane">
                <h2><i class="fas fa-flask"></i> Experimental Design</h2>
                
                <div class="section">
                    <h3>Study Overview: Combining Energy Knowledge with AI Assistance</h3>
                    <p>Our experiment examines how linguistic uncertainty in AI advice affects users' trust, decision-making, and calibration in the domain of energy consumption estimates.</p>
                    
                    <div id="methodsDiagram" class="methods-diagram">
                        <!-- SVG diagram will be rendered here -->
                    </div>
                </div>
                
                <div class="section">
                    <h3>Study Design: Between-Subjects</h3>
                    
                    <div class="variables-list">
                        <div class="variable-pill iv-pill"><i class="fas fa-random"></i> IV1: AI Uncertainty Communication Style (Between-Subjects)</div>
                        <div class="variable-pill iv-pill"><i class="fas fa-check-square"></i> IV2: AI Advice Correctness (Within-Subjects)</div>
                        <div class="variable-pill dv-pill"><i class="fas fa-mouse-pointer"></i> DV1: User Reliance (Forced Choice)</div>
                        <div class="variable-pill dv-pill"><i class="fas fa-percent"></i> DV2: Confidence in AI Estimate</div>
                        <div class="variable-pill dv-pill"><i class="fas fa-balance-scale"></i> DV3: Calibration Error (Brier/ECE)</div>
                        <div class="variable-pill mod-pill"><i class="fas fa-bolt"></i> Moderator: Energy Literacy</div>
                        <div class="variable-pill mod-pill"><i class="fas fa-robot"></i> Moderator: AI Literacy</div>
                        <div class="variable-pill mod-pill"><i class="fas fa-calculator"></i> Moderator: Numeracy</div>
                    </div>
                    
                    <div class="flex-container">
                        <div class="flex-item">
                            <h4>Between-Subjects Conditions</h4>
                            <div class="example-comparison">
                                <div class="example-card" style="background-color: #ecfdf5; border-color: #bbf7d0;">
                                    <h4 style="color: #16a34a;"><i class="fas fa-sync"></i> Calibrated Uncertainty</h4>
                                    <p>AI expresses linguistic uncertainty proportional to its internal confidence level</p>
                                    <ul>
                                        <li>High internal confidence → assertive language</li>
                                        <li>Low internal confidence → hedged language</li>
                                    </ul>
                                </div>
                                <div class="example-card" style="background-color: #eff6ff; border-color: #bfdbfe;">
                                    <h4 style="color: #2563eb;"><i class="fas fa-volume-up"></i> Uncalibrated (Always Confident)</h4>
                                    <p>AI always uses confident language regardless of internal confidence</p>
                                    <ul>
                                        <li>High internal confidence → assertive language</li>
                                        <li>Low internal confidence → still assertive language</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="section">
                    <h3>Experimental Flow</h3>
                    
                    <div class="phase-box">
                        <div class="phase-number">1</div>
                        <h4>Phase 1: Surveys</h4>
                        <p>Participants complete surveys measuring:</p>
                        <ul>
                            <li>Energy literacy</li>
                            <li>AI literacy</li>
                            <li>AI usage patterns</li>
                            <li>Trust propensity</li>
                            <li>Numeracy</li>
                            <li>Demographics</li>
                        </ul>
                        <p><strong>Purpose:</strong> Measure individual differences that may moderate the main effects</p>
                    </div>
                    
                    <div class="phase-box">
                        <div class="phase-number">2</div>
                        <h4>Phase 2: Baseline Energy Knowledge Assessment</h4>
                        <p>Participants estimate energy consumption of various appliances, establishing both their baseline knowledge and their own estimation biases.</p>
                        <p><strong>Task:</strong> "Relative to a 100-watt incandescent light bulb which uses 100 units of energy per hour, how many units of energy do you think the following device typically uses in one hour?"</p>
                        <p><strong>Measure:</strong> Accuracy of energy estimations compared to ground truth values</p>
                        <p><strong>Purpose:</strong> Establish baseline energy knowledge and biases before AI interaction</p>
                    </div>
                    
                    <div class="phase-box">
                        <div class="phase-number">3</div>
                        <h4>Phase 3: AI Energy Advisor Interaction</h4>
                        <p>For each appliance, in sequence:</p>
                        <ol>
                            <li>Participant is shown the AI's energy estimate with explanation</li>
                            <li>AI's explanation uses confident or hedged language based on condition</li>
                            <li>Participant rates confidence in the AI's estimate (0-100%)</li>
                            <li>Participant's original estimate is shown</li>
                            <li>Participant makes forced choice between own and AI estimate</li>
                        </ol>
                        <p><strong>Key point:</strong> The AI's internal confidence was computed with GPT-4.1-nano using the approach from Steyvers et al., then used to calibrate the degree of uncertainty in its explanation.</p>
                        <p><strong>Purpose:</strong> Examine how linguistic uncertainty affects trust, reliance, and calibration</p>
                    </div>
                    
                    <div class="phase-box">
                        <div class="phase-number">4</div>
                        <h4>Phase 4: Post-Task Measures</h4>
                        <p>After completing all appliance estimates:</p>
                        <ul>
                            <li>Overall trust in the AI advisor</li>
                            <li>Perception of AI expertise in energy domain</li>
                            <li>Manipulation checks</li>
                            <li>Open-ended feedback</li>
                        </ul>
                        <p><strong>Purpose:</strong> Measure broader attitudes toward the AI advisor after repeated interactions</p>
                    </div>
                </div>
                
                <div class="section">
                    <h3>Key Dependent Measures</h3>
                    
                    <table class="measures-table">
                        <tbody><tr>
                            <th width="20%">Measure</th>
                            <th width="40%">Definition</th>
                            <th width="40%">Why It Matters</th>
                        </tr>
                        <tr>
                            <td>Reliance</td>
                            <td>Whether participant chose the AI's estimate over their own</td>
                            <td>Shows the degree to which participants trust and follow AI advice</td>
                        </tr>
                        <tr>
                            <td>Appropriate Reliance</td>
                            <td>Choosing AI when it's more accurate, rejecting when it's less accurate</td>
                            <td>Indicates discriminative ability - knowing when to trust vs. when to be skeptical</td>
                        </tr>
                        <tr>
                            <td>Confidence</td>
                            <td>Participant's subjective confidence in AI's estimate (0-100%)</td>
                            <td>Measures perceived reliability of AI advice</td>
                        </tr>
                        <tr>
                            <td>Calibration Error</td>
                            <td>Alignment between confidence and actual accuracy (Brier Score, Expected Calibration Error)</td>
                            <td>Shows whether participants' confidence appropriately reflects the actual likelihood of correctness</td>
                        </tr>
                    </tbody></table>
                    
                    <div class="tooltip">What is Brier Score?
                        <span class="tooltip-text">The Brier score measures the accuracy of probabilistic predictions. It's calculated as the mean squared difference between the predicted probability (confidence) and the actual outcome (0 or 1). Lower scores indicate better calibration.</span>
                    </div>
                    
                    <div class="tooltip">What is Expected Calibration Error (ECE)?
                        <span class="tooltip-text">ECE measures the difference between confidence and accuracy across confidence bins. It quantifies how well-calibrated someone's confidence judgments are across different confidence levels. Lower values indicate better calibration.</span>
                    </div>
                </div>
                
                <div class="mini-quiz">
                    <h4><i class="fas fa-question-circle"></i> Quick Check: Experimental Design</h4>
                    <p>In this experiment, which is a within-subjects factor (varies within each participant)?</p>
                    <div class="quiz-options">
                        <label class="quiz-option">
                            <input type="radio" name="exp-quiz" value="incorrect1">
                            AI uncertainty communication style
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="exp-quiz" value="correct">
                            AI advice correctness (mix of correct and incorrect advice)
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="exp-quiz" value="incorrect2">
                            Energy literacy level
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="exp-quiz" value="incorrect3">
                            Participant's AI literacy
                        </label>
                    </div>
                    <div id="exp-quiz-feedback" class="quiz-feedback"></div>
                    <button id="check-exp-answer" class="btn btn-secondary"><i class="fas fa-check"></i> Check Answer</button>
                </div>
            </div>
            
            <!-- Terminology Tab -->
            <div id="terminology" class="tab-pane">
                <h2><i class="fas fa-book"></i> Terminology and Key Concepts</h2>
                
                <div class="section">
                    <p>This reference guide clarifies the key terms and concepts used in our study to ensure precise communication about the research.</p>
                    
                    <table class="terminology-table">
                        <tbody><tr>
                            <th width="30%">Term/Concept</th>
                            <th width="70%">Definition</th>
                        </tr>
                        <tr>
                            <td><strong>Internal Confidence</strong> (AI's)</td>
                            <td>GPT-4 output layer probability of response. This represents how confident the LLM actually is in its answer, based on the probabilistic nature of its next-token prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>Linguistic Uncertainty</strong> (AI's Expressed)</td>
                            <td>How the LLM communicates its internal uncertainty through language (e.g., confident phrasing vs. hedging terms like "might," "could be," "around"). This is what the user actually sees.</td>
                        </tr>
                        <tr>
                            <td><strong>Confidence</strong> (User's)</td>
                            <td>Participant's subjective belief or reported probability that the AI estimate is correct. Measured on a 0-100% scale in our experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>Calibration</strong> (User's)</td>
                            <td>The alignment between a user's subjective confidence in a statement (e.g., the AI's advice) and the actual, objective accuracy of that statement. Well-calibrated individuals are appropriately confident about correct information and appropriately uncertain about incorrect information.</td>
                        </tr>
                        <tr>
                            <td><strong>Calibration Error</strong> (e.g., Brier Score, ECE)</td>
                            <td>DV reflecting how well users interpret the AI's reliability, rather than just their average confidence (which could be high but poorly aligned with reality) or average accuracy (which doesn't capture their metacognitive judgment).</td>
                        </tr>
                        <tr>
                            <td><strong>Calibrated Uncertainty</strong> (AI Condition)</td>
                            <td>An experimental condition where the AI's expressed linguistic uncertainty is deliberately aligned with its (simulated) internal confidence. When the AI is less confident internally, it uses more hedging language.</td>
                        </tr>
                        <tr>
                            <td><strong>Reliance</strong></td>
                            <td>The extent to which a user depends on or utilizes the AI's advice. Obtained from forced-choice responses between the user's own estimate and the AI's estimate.</td>
                        </tr>
                        <tr>
                            <td><strong>Trust</strong> (User's)</td>
                            <td>A broader attitude or belief in the AI's general capability, reliability. This is a more stable construct than confidence in specific advice.</td>
                        </tr>
                    </tbody></table>
                </div>
                
                <div class="section">
                    <h3>Visual Explanation: Internal Confidence vs. Expressed Uncertainty</h3>
                    
                    <div class="flex-container">
                        <div class="flex-item card-hover">
                            <h4><i class="fas fa-brain"></i> Internal Confidence</h4>
                            <ul>
                                <li>Based on the LLM's token probabilities</li>
                                <li>Extracted during generation but not visible to users</li>
                                <li>Used in the calibrated condition to determine hedging level</li>
                                <li>GPT-4.1-nano used to calculate in our study</li>
                                <li>Can be thought of as the AI's "actual uncertainty"</li>
                                <li>Represented as a probability (0-100%)</li>
                            </ul>
                        </div>
                        <div class="flex-item card-hover">
                            <h4><i class="fas fa-comment"></i> Expressed Uncertainty (Linguistic)</h4>
                            <ul>
                                <li>The verbal indicators of uncertainty in the LLM's response</li>
                                <li>Ranges from confident assertions to hedged statements</li>
                                <li>Only this aspect is visible to participants</li>
                                <li>Our key manipulation is whether this aligns with internal confidence</li>
                                <li>Examples: "definitely," "probably," "might," "I think"</li>
                                <li>Influences how users perceive the AI's reliability</li>
                            </ul>
                        </div>
                    </div>
                    
                    <div class="why-it-matters">
                        <h4><i class="fas fa-lightbulb"></i> Why This Distinction Matters</h4>
                        <p>The gap between an LLM's internal confidence and its expressed certainty is a key factor in user miscalibration. Users can only judge the LLM based on its expressed uncertainty, which traditionally has not been well-aligned with its actual confidence. Our study examines whether deliberately aligning these two elements improves user decision-making.</p>
                    </div>
                </div>
                
                <div class="example-comparison">
                    <div class="example-card good-example">
                        <h4><i class="fas fa-check-circle"></i> Calibrated Approach</h4>
                        <p>When internal confidence is 95%:</p>
                        <p>"A central AC unit uses 3500 units of energy per hour."</p>
                        <p>When internal confidence is 60%:</p>
                        <p>"A central AC typically uses around 3500 units per hour, though models vary."</p>
                        <p>When internal confidence is 30%:</p>
                        <p>"I think a central AC might use approximately 3500 units, but I'm not entirely certain."</p>
                    </div>
                    <div class="example-card poor-example">
                        <h4><i class="fas fa-times-circle"></i> Uncalibrated Approach</h4>
                        <p>When internal confidence is 95%:</p>
                        <p>"A central AC unit uses 3500 units of energy per hour."</p>
                        <p>When internal confidence is 60%:</p>
                        <p>"A central AC unit uses 3500 units of energy per hour."</p>
                        <p>When internal confidence is 30%:</p>
                        <p>"A central AC unit uses 3500 units of energy per hour."</p>
                    </div>
                </div>
                
                <div class="mini-quiz">
                    <h4><i class="fas fa-question-circle"></i> Quick Check: Terminology</h4>
                    <p>What is being measured by the "calibration error" in our study?</p>
                    <div class="quiz-options">
                        <label class="quiz-option">
                            <input type="radio" name="term-quiz" value="incorrect1">
                            The accuracy of the AI's energy estimates
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="term-quiz" value="incorrect2">
                            How frequently participants rely on the AI
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="term-quiz" value="correct">
                            The alignment between participants' confidence in the AI and the AI's actual accuracy
                        </label>
                        <label class="quiz-option">
                            <input type="radio" name="term-quiz" value="incorrect3">
                            The error in participants' energy knowledge
                        </label>
                    </div>
                    <div id="term-quiz-feedback" class="quiz-feedback"></div>
                    <button id="check-term-answer" class="btn btn-secondary"><i class="fas fa-check"></i> Check Answer</button>
                </div>
            </div>
            
            <!-- Simulation Tab -->
            <div id="simulation" class="tab-pane">
                <h2><i class="fas fa-gamepad"></i> Interactive Simulation: Energy Advisor Experiment</h2>
                
                <p>This simulation allows you to experience our experimental paradigm firsthand and see how different expressions of uncertainty might affect your trust and decision-making:</p>
                
                <div class="control-panel">
                    <h4><i class="fas fa-cogs"></i> Simulation Settings</h4>
                    <p>Configure the experiment parameters below:</p>
                    
                    <div class="slider-container">
                        <label for="uncertaintyLevel">AI Uncertainty Communication Style:</label>
                        <select id="uncertaintyLevel" style="width: 100%; padding: 12px; border-radius: 8px; border: 1px solid #e2e8f0; margin-bottom: 5px;">
                            <option value="0">Uncalibrated (Always Confident)</option>
                            <option value="1" selected="">Calibrated Uncertainty (Hedging When Uncertain)</option>
                        </select>
                        <div class="confidence-labels">
                            <span><i class="fas fa-info-circle"></i> How the AI expresses uncertainty</span>
                        </div>
                    </div>
                    <div class="slider-container">
                        <label for="userKnowledgeLevel">Your Energy Knowledge Level: <span id="userKnowledgeValue" class="slider-value">Medium</span></label>
                        <input type="range" id="userKnowledgeLevel" min="0" max="2" step="1" value="1">
                        <div class="confidence-labels">
                            <span>Low</span>
                            <span>Medium</span>
                            <span>High</span>
                        </div>
                    </div>
                    <div class="slider-container">
                        <label for="aiAccuracy">AI Advice Accuracy: <span id="aiAccuracyValue" class="slider-value">70</span>%</label>
                        <input type="range" id="aiAccuracy" min="40" max="100" step="5" value="70">
                        <div class="confidence-labels">
                            <span>Less accurate</span>
                            <span>More accurate</span>
                        </div>
                    </div>
                    <button id="startSimulation" class="btn"><i class="fas fa-play"></i> Start Experiment Simulation</button>
                </div>
                
                <div class="simulation-area" id="simulationArea">
                    <div class="text-center" style="text-align: center;">
                        <i class="fas fa-laptop" style="font-size: 48px; color: var(--primary-color); margin-bottom: 20px;"></i>
                        <h3>Energy Advisor Experiment Simulation</h3>
                        <p>Configure the parameters above and click "Start Experiment Simulation" to experience our experimental paradigm firsthand.</p>
                        <p>You'll first make your own energy estimates, then see the AI's suggestions with varying degrees of expressed confidence, and decide whether to rely on your estimate or the AI's.</p>
                    </div>
                </div>
                
                <div class="results-display" id="simulationResults" style="display: none;">
                    <h3>Simulation Results</h3>
                    <p>Complete the simulation to see your results.</p>
                </div>
                
                <div class="why-it-matters">
                    <h4><i class="fas fa-lightbulb"></i> What You'll Learn From This Simulation</h4>
                    <p>This interactive demo lets you experience the challenges of deciding when to trust AI advice. You'll see firsthand:</p>
                    <ul>
                        <li>How different expressions of uncertainty affect your perception of AI reliability</li>
                        <li>Whether you can distinguish between correct and incorrect AI advice</li>
                        <li>How well your confidence ratings align with actual correctness</li>
                        <li>The potential benefits of calibrated linguistic uncertainty</li>
                    </ul>
                    <p>After completing the simulation, you'll see your reliance patterns and calibration metrics, similar to what we'll measure in the actual study.</p>
                </div>
            </div>
            
            <!-- Predictions Tab -->
            <div id="predictions" class="tab-pane">
                <h2><i class="fas fa-chart-line"></i> Empirical Predictions</h2>
                
                <div class="prediction-chart">
                    <h3>H1: Impact of Linguistic Uncertainty on Reliance</h3>
                    <p>We predict that calibrating the AI's linguistic uncertainty will lead to more appropriate reliance, with participants better distinguishing when to trust the AI.</p>
                    <div class="chart-container">
                        <canvas id="relianceInteractionChart"></canvas>
                    </div>
                    <div class="hypothesis-summary">
                        <i class="fas fa-bullseye"></i> H1: Hedged language reduces reliance overall, but this effect is stronger for incorrect advice, improving discrimination.
                    </div>
                </div>
                
                <div class="prediction-chart">
                    <h3>H2: Impact on Metacognitive Calibration</h3>
                    <p>We predict that calibrated linguistic uncertainty will lead to better alignment between participants' confidence and the actual accuracy of the AI's estimates.</p>
                    <div class="chart-container">
                        <canvas id="calibrationErrorChart"></canvas>
                    </div>
                    <div class="hypothesis-summary">
                        <i class="fas fa-bullseye"></i> H2: Calibrated uncertainty expressions lead to better calibration (lower ECE) than consistently confident language.
                    </div>
                </div>
                
                <div class="prediction-chart">
                    <h3>H3: Individual Differences as Moderators</h3>
                    <p>We predict that the effect of linguistic uncertainty will be moderated by participants' energy literacy, AI literacy, and numeracy.</p>
                    <div class="flex-container">
                        <div class="flex-item">
                            <h4>Energy Literacy</h4>
                            <p>Higher energy literacy will reduce overreliance on AI, as participants can better evaluate the AI's claims against their knowledge.</p>
                            <div class="chart-container" style="height: 250px;">
                                <canvas id="energyLiteracyModerationChart"></canvas>
                            </div>
                        </div>
                        <div class="flex-item">
                            <h4>AI Literacy</h4>
                            <p>Higher AI literacy will increase sensitivity to linguistic uncertainty cues, enhancing the effect of calibrated hedging.</p>
                            <div class="chart-container" style="height: 250px;">
                                <canvas id="aiLiteracyModerationChart"></canvas>
                            </div>
                        </div>
                    </div>
                    <div class="hypothesis-summary">
                        <i class="fas fa-bullseye"></i> H3: Individual differences in energy literacy and AI literacy will moderate the impact of linguistic uncertainty, with stronger effects for those with higher AI literacy.
                    </div>
                </div>
                
                <div class="section">
                    <h3>Extending Beyond this Study</h3>
                    <p>The findings from this study could help inform several important applications:</p>
                    
                    <div class="flex-container">
                        <div class="flex-item card-hover">
                            <h4><i class="fas fa-home"></i> Energy Planning Tools</h4>
                            <p>Better-calibrated AI assistance for residential and commercial energy decisions:</p>
                            <ul>
                                <li>Smart home energy management systems</li>
                                <li>Grid optimization and demand planning</li>
                                <li>Consumer-facing energy efficiency tools</li>
                            </ul>
                        </div>
                        <div class="flex-item card-hover">
                            <h4><i class="fas fa-graduation-cap"></i> Educational Applications</h4>
                            <p>Combining AI assistance with educational elements:</p>
                            <ul>
                                <li>Energy literacy improvement programs</li>
                                <li>Calibrated AI tutors for sustainability education</li>
                                <li>Interactive simulations for policy education</li>
                            </ul>
                        </div>
                    </div>
                    
                    <div class="flex-container">
                        <div class="flex-item card-hover">
                            <h4><i class="fas fa-cogs"></i> AI Design Principles</h4>
                            <p>Methods for appropriate uncertainty communication:</p>
                            <ul>
                                <li>Guidelines for high-stakes domain applications</li>
                                <li>Uncertainty visualization techniques</li>
                                <li>Calibration methods for different user groups</li>
                            </ul>
                        </div>
                        <div class="flex-item card-hover">
                            <h4><i class="fas fa-network-wired"></i> Transactive Memory Systems</h4>
                            <p>Understanding human-AI distributed cognition:</p>
                            <ul>
                                <li>How humans calibrate trust in AI components</li>
                                <li>Division of cognitive labor between humans and AI</li>
                                <li>Metacognitive awareness in hybrid teams</li>
                            </ul>
                        </div>
                    </div>
                </div>
                
                <div class="why-it-matters">
                    <h4><i class="fas fa-lightbulb"></i> The Broader Impact</h4>
                    <p>As AI systems become more integrated into everyday decision-making, understanding how to calibrate human trust is crucial. This research contributes to a future where AI systems don't just make good recommendations, but communicate them in ways that help users make appropriate decisions about when to trust and when to be skeptical. The principles we discover could extend far beyond energy estimation to areas like healthcare, finance, and education.</p>
                </div>
            </div>
        </div>
    </div>
    
    <script>
        // Tab functionality
        document.querySelectorAll('.tabs a').forEach(tab => {
            tab.addEventListener('click', function(e) {
                e.preventDefault();
                
                // Remove active class from all tabs and panes
                document.querySelectorAll('.tabs a').forEach(t => t.classList.remove('active'));
                document.querySelectorAll('.tab-pane').forEach(p => p.classList.remove('active'));
                
                // Add active class to clicked tab and corresponding pane
                this.classList.add('active');
                document.querySelector(this.getAttribute('href')).classList.add('active');
            });
        });
        
        // Quiz functionality
        document.getElementById('check-answer').addEventListener('click', function() {
            const selected = document.querySelector('input[name="condition-quiz"]:checked');
            const feedback = document.getElementById('quiz-feedback');
            
            if (!selected) {
                feedback.textContent = "Please select an answer.";
                feedback.className = "quiz-feedback";
                feedback.style.display = "block";
                return;
            }
            
            if (selected.value === "correct") {
                feedback.textContent = "Correct! The main difference is how the AI expresses uncertainty - either calibrated to its internal confidence, or always confident regardless.";
                feedback.className = "quiz-feedback feedback-correct";
            } else {
                feedback.textContent = "Not quite. The main difference is how the AI expresses uncertainty in its explanations, not the actual accuracy or the types of appliances.";
                feedback.className = "quiz-feedback feedback-incorrect";
            }
            
            feedback.style.display = "block";
        });
        
        document.getElementById('check-energy-answer').addEventListener('click', function() {
            const selected = document.querySelector('input[name="energy-quiz"]:checked');
            const feedback = document.getElementById('energy-quiz-feedback');
            
            if (!selected) {
                feedback.textContent = "Please select an answer.";
                feedback.className = "quiz-feedback";
                feedback.style.display = "block";
                return;
            }
            
            if (selected.value === "correct") {
                feedback.textContent = "Correct! While people tend to overestimate the energy consumption of light bulbs, this estimate would be closer to reality than their underestimation of high-energy appliances like air conditioners.";
                feedback.className = "quiz-feedback feedback-correct";
            } else {
                feedback.textContent = "Not quite. According to Attari, people generally underestimate high-energy appliances and overestimate low-energy ones, with light bulb estimates being more accurate than AC estimates.";
                feedback.className = "quiz-feedback feedback-incorrect";
            }
            
            feedback.style.display = "block";
        });
        
        document.getElementById('check-ai-answer').addEventListener('click', function() {
            const selected = document.querySelector('input[name="ai-quiz"]:checked');
            const feedback = document.getElementById('ai-quiz-feedback');
            
            if (!selected) {
                feedback.textContent = "Please select an answer.";
                feedback.className = "quiz-feedback";
                feedback.style.display = "block";
                return;
            }
            
            if (selected.value === "correct") {
                feedback.textContent = "Correct! In the calibrated condition, the AI uses more hedging language when its internal confidence is low, which typically corresponds to when it's more likely to be giving incorrect advice.";
                feedback.className = "quiz-feedback feedback-correct";
            } else {
                feedback.textContent = "Not quite. The key to the calibrated condition is that the AI's linguistic uncertainty (hedging) matches its internal confidence level - using more hedged language when it's less confident.";
                feedback.className = "quiz-feedback feedback-incorrect";
            }
            
            feedback.style.display = "block";
        });
        
        document.getElementById('check-exp-answer').addEventListener('click', function() {
            const selected = document.querySelector('input[name="exp-quiz"]:checked');
            const feedback = document.getElementById('exp-quiz-feedback');
            
            if (!selected) {
                feedback.textContent = "Please select an answer.";
                feedback.className = "quiz-feedback";
                feedback.style.display = "block";
                return;
            }
            
            if (selected.value === "correct") {
                feedback.textContent = "Correct! AI advice correctness is a within-subjects factor - each participant sees both correct and incorrect AI advice across different appliances.";
                feedback.className = "quiz-feedback feedback-correct";
            } else {
                feedback.textContent = "Not quite. The AI uncertainty communication style is a between-subjects factor (participants only experience one style), while AI advice correctness varies within each participant's experience.";
                feedback.className = "quiz-feedback feedback-incorrect";
            }
            
            feedback.style.display = "block";
        });
        
        document.getElementById('check-term-answer').addEventListener('click', function() {
            const selected = document.querySelector('input[name="term-quiz"]:checked');
            const feedback = document.getElementById('term-quiz-feedback');
            
            if (!selected) {
                feedback.textContent = "Please select an answer.";
                feedback.className = "quiz-feedback";
                feedback.style.display = "block";
                return;
            }
            
            if (selected.value === "correct") {
                feedback.textContent = "Correct! Calibration error measures how well participants' confidence in the AI's estimates aligns with the actual accuracy of those estimates - it's about metacognitive alignment.";
                feedback.className = "quiz-feedback feedback-correct";
            } else {
                feedback.textContent = "Not quite. Calibration error specifically measures the alignment between participants' confidence ratings and the actual correctness of the AI advice - it's about appropriate metacognitive judgment.";
                feedback.className = "quiz-feedback feedback-incorrect";
            }
            
            feedback.style.display = "block";
        });
        
        // Data for energy perception chart
        const appliances = [
            { name: 'Central AC', actualEnergy: 3500, perceivedEnergyFactor: 1/2.8 },
            { name: 'Water Heater', actualEnergy: 2500, perceivedEnergyFactor: 1/2.5 },
            { name: 'Refrigerator', actualEnergy: 1800, perceivedEnergyFactor: 1/2.2 },
            { name: 'Clothes Dryer', actualEnergy: 1500, perceivedEnergyFactor: 1/2.0 },
            { name: 'TV', actualEnergy: 500, perceivedEnergyFactor: 1.2 },
            { name: 'Computer', actualEnergy: 300, perceivedEnergyFactor: 1.4 },
            { name: 'Stereo', actualEnergy: 100, perceivedEnergyFactor: 1.6 },
            { name: 'Light Bulb', actualEnergy: 60, perceivedEnergyFactor: 1.8 }
        ];
        
        // Generate data for calibration gap chart
        function generateCalibrationData(gapSize, hedgingEffect) {
            const confidences = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100];
            
            const perfectCalibration = confidences.map(conf => ({ x: conf, y: conf }));
            
            // Human perception with default (confident) LLM explanations
            const humanPerceptionDefault = confidences.map(conf => {
                // Apply gap - higher overestimation for mid-range confidence
                const overestimation = gapSize * Math.sin((conf / 100) * Math.PI);
                return { x: conf, y: Math.min(100, conf + overestimation) };
            });
            
            // Human perception with hedged LLM explanations
            const humanPerceptionHedged = confidences.map(conf => {
                const overestimation = Math.max(0, (gapSize - hedgingEffect) * Math.sin((conf / 100) * Math.PI));
                return { x: conf, y: Math.min(100, conf + overestimation) };
            });
            
            return {
                perfectCalibration,
                humanPerceptionDefault,
                humanPerceptionHedged
            };
        }
        
        // Generate data for energy perception chart
        function generateEnergyPerceptionData(underestimationFactor, overestimationFactor) {
            return appliances.map(appliance => {
                let factor;
                if (appliance.actualEnergy > 1000) {
                    factor = 1 / underestimationFactor; // Underestimation for high-energy
                } else {
                    factor = overestimationFactor; // Overestimation for low-energy
                }
                
                return {
                    name: appliance.name,
                    actualEnergy: appliance.actualEnergy,
                    perceivedEnergy: appliance.actualEnergy * factor
                };
            });
        }
        
        // Initialize charts
        let energyPerceptionChart, calibrationGapChart;
        let relianceInteractionChart, calibrationErrorChart;
        let energyLiteracyModerationChart, aiLiteracyModerationChart;
        
        function initEnergyPerceptionChart() {
            const underestimationFactor = parseFloat(document.getElementById('underestimationFactor').value);
            const overestimationFactor = parseFloat(document.getElementById('overestimationFactor').value);
            
            const data = generateEnergyPerceptionData(underestimationFactor, overestimationFactor);
            
            const ctx = document.getElementById('energyPerceptionChart').getContext('2d');
            
            // Destroy existing chart if it exists
            if (energyPerceptionChart) {
                energyPerceptionChart.destroy();
            }
            
            // Create perfect accuracy line data points
            const maxEnergy = Math.max(...data.map(d => d.actualEnergy)) * 1.1;
            
            energyPerceptionChart = new Chart(ctx, {
                type: 'scatter',
                data: {
                    datasets: [
                        {
                            label: 'Perfect Accuracy Line',
                            data: [
                                { x: 0, y: 0 },
                                { x: maxEnergy, y: maxEnergy }
                            ],
                            borderColor: 'rgba(75, 192, 192, 0.8)',
                            backgroundColor: 'rgba(0, 0, 0, 0)',
                            borderDash: [5, 5],
                            borderWidth: 2,
                            pointRadius: 0,
                            showLine: true,
                            order: 1
                        },
                        {
                            label: 'Human Perception',
                            data: data.map(item => ({
                                x: item.actualEnergy,
                                y: item.perceivedEnergy
                            })),
                            backgroundColor: 'rgba(239, 68, 68, 0.7)',
                            borderColor: 'rgba(239, 68, 68, 1)',
                            borderWidth: 1,
                            pointRadius: 8,
                            pointHoverRadius: 10,
                            order: 2
                        }
                    ]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        x: {
                            title: {
                                display: true,
                                text: 'Actual Energy (Units)',
                                font: {
                                    weight: 'bold'
                                }
                            },
                            min: 0,
                            max: maxEnergy
                        },
                        y: {
                            title: {
                                display: true,
                                text: 'Perceived Energy (Units)',
                                font: {
                                    weight: 'bold'
                                }
                            },
                            min: 0,
                            max: maxEnergy
                        }
                    },
                    plugins: {
                        title: {
                            display: true,
                            text: 'Energy Perception vs. Reality (Attari et al. 2010)',
                            font: {
                                size: 16,
                                weight: 'bold'
                            }
                        },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    const index = context.dataIndex;
                                    if (context.datasetIndex === 1) {
                                        const appliance = data[index];
                                        return `${appliance.name}: Actual: ${appliance.actualEnergy}, Perceived: ${Math.round(appliance.perceivedEnergy)}`;
                                    }
                                    return '';
                                }
                            }
                        },
                        legend: {
                            labels: {
                                usePointStyle: true
                            }
                        }
                    }
                }
            });
        }
        
        function initCalibrationGapChart() {
            const gapSize = parseInt(document.getElementById('calibrationGapSize').value);
            const hedgingEffect = parseInt(document.getElementById('hedgingEffect').value);
            
            const calibrationData = generateCalibrationData(gapSize, hedgingEffect);
            
            const ctx = document.getElementById('calibrationGapChart').getContext('2d');
            
            // Destroy existing chart if it exists
            if (calibrationGapChart) {
                calibrationGapChart.destroy();
            }
            
            calibrationGapChart = new Chart(ctx, {
                type: 'scatter',
                data: {
                    datasets: [
                        {
                            label: 'Perfect Calibration',
                            data: calibrationData.perfectCalibration,
                            borderColor: 'rgba(16, 185, 129, 0.8)',
                            backgroundColor: 'rgba(16, 185, 129, 0.1)',
                            borderDash: [5, 5],
                            borderWidth: 2,
                            pointRadius: 0,
                            showLine: true,
                            fill: false
                        },
                        {
                            label: 'Human Perception (Confident Language)',
                            data: calibrationData.humanPerceptionDefault,
                            borderColor: 'rgba(239, 68, 68, 0.8)',
                            backgroundColor: 'rgba(239, 68, 68, 0.1)',
                            borderWidth: 2,
                            pointRadius: 5,
                            showLine: true,
                            fill: false
                        },
                        {
                            label: 'Human Perception (Hedged Language)',
                            data: calibrationData.humanPerceptionHedged,
                            borderColor: 'rgba(37, 99, 235, 0.8)',
                            backgroundColor: 'rgba(37, 99, 235, 0.1)',
                            borderWidth: 2,
                            pointRadius: 5,
                            showLine: true,
                            fill: false
                        }
                    ]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        x: {
                            title: {
                                display: true,
                                text: 'AI Internal Confidence (%)',
                                font: {
                                    weight: 'bold'
                                }
                            },
                            min: 0,
                            max: 100
                        },
                        y: {
                            title: {
                                display: true,
                                text: 'Human Perception of Accuracy (%)',
                                font: {
                                    weight: 'bold'
                                }
                            },
                            min: 0,
                            max: 100
                        }
                    },
                    plugins: {
                        title: {
                            display: true,
                            text: 'Calibration Gap: AI vs. Human Confidence (Steyvers et al. 2025)',
                            font: {
                                size: 16,
                                weight: 'bold'
                            }
                        },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    const conf = context.parsed.x;
                                    const perc = context.parsed.y;
                                    if (context.datasetIndex === 0) {
                                        return `Perfect Calibration: ${conf}%`;
                                    } else if (context.datasetIndex === 1) {
                                        return `AI Confidence: ${conf}%, Human Perception: ${perc.toFixed(1)}% (Confident Language)`;
                                    } else if (context.datasetIndex === 2) {
                                        return `AI Confidence: ${conf}%, Human Perception: ${perc.toFixed(1)}% (Hedged Language)`;
                                    }
                                }
                            }
                        },
                        legend: {
                            labels: {
                                usePointStyle: true
                            }
                        }
                    }
                }
            });
        }
        
        // Initialize the prediction charts
        function initRelianceInteractionChart() {
            const ctx = document.getElementById('relianceInteractionChart').getContext('2d');
            
            // Destroy existing chart if it exists
            if (relianceInteractionChart) {
                relianceInteractionChart.destroy();
            }
            
            relianceInteractionChart = new Chart(ctx, {
                type: 'bar',
                data: {
                    labels: ['Correct AI Advice', 'Incorrect AI Advice'],
                    datasets: [
                        {
                            label: 'Reliance Rate (Uncalibrated/Confident)',
                            data: [0.82, 0.68],
                            backgroundColor: 'rgba(239, 68, 68, 0.7)',
                            borderColor: 'rgba(239, 68, 68, 1)',
                            borderWidth: 1
                        },
                        {
                            label: 'Reliance Rate (Calibrated Uncertainty)',
                            data: [0.75, 0.40],
                            backgroundColor: 'rgba(37, 99, 235, 0.7)',
                            borderColor: 'rgba(37, 99, 235, 1)',
                            borderWidth: 1
                        }
                    ]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        y: {
                            title: {
                                display: true,
                                text: 'Proportion of Trials Relying on AI Advice',
                                font: {
                                    weight: 'bold'
                                }
                            },
                            min: 0,
                            max: 1.0
                        },
                        x: {
                            title: {
                                display: true,
                                text: 'AI Advice Correctness',
                                font: {
                                    weight: 'bold'
                                }
                            }
                        }
                    },
                    plugins: {
                        title: {
                            display: true,
                            text: 'Predicted Reliance Rate by Linguistic Style and AI Advice Correctness',
                            font: {
                                size: 16,
                                weight: 'bold'
                            }
                        },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    return `${context.dataset.label}: ${(context.parsed.y * 100).toFixed(1)}%`;
                                }
                            }
                        }
                    }
                }
            });
        }
        
        function initCalibrationErrorChart() {
            const ctx = document.getElementById('calibrationErrorChart').getContext('2d');
            
            // Destroy existing chart if it exists
            if (calibrationErrorChart) {
                calibrationErrorChart.destroy();
            }
            
            calibrationErrorChart = new Chart(ctx, {
                type: 'bar',
                data: {
                    labels: ['Low Energy Literacy', 'Medium Energy Literacy', 'High Energy Literacy'],
                    datasets: [
                        {
                            label: 'Calibration Error (Uncalibrated/Confident)',
                            data: [0.35, 0.28, 0.15],
                            backgroundColor: 'rgba(239, 68, 68, 0.7)',
                            borderColor: 'rgba(239, 68, 68, 1)',
                            borderWidth: 1
                        },
                        {
                            label: 'Calibration Error (Calibrated Uncertainty)',
                            data: [0.25, 0.15, 0.10],
                            backgroundColor: 'rgba(37, 99, 235, 0.7)',
                            borderColor: 'rgba(37, 99, 235, 1)',
                            borderWidth: 1
                        }
                    ]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        y: {
                            title: {
                                display: true,
                                text: 'Calibration Error (lower is better)',
                                font: {
                                    weight: 'bold'
                                }
                            },
                            min: 0,
                            max: 0.4
                        },
                        x: {
                            title: {
                                display: true,
                                text: 'Energy Literacy Level',
                                font: {
                                    weight: 'bold'
                                }
                            }
                        }
                    },
                    plugins: {
                        title: {
                            display: true,
                            text: 'Impact of Linguistic Uncertainty on Trust Calibration by Energy Literacy',
                            font: {
                                size: 16,
                                weight: 'bold'
                            }
                        },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    return `${context.dataset.label}: ${context.parsed.y.toFixed(2)}`;
                                }
                            }
                        }
                    }
                }
            });
        }
        
        function initEnergyLiteracyModerationChart() {
            const ctx = document.getElementById('energyLiteracyModerationChart').getContext('2d');
            
            // Destroy existing chart if it exists
            if (energyLiteracyModerationChart) {
                energyLiteracyModerationChart.destroy();
            }
            
            energyLiteracyModerationChart = new Chart(ctx, {
                type: 'line',
                data: {
                    labels: ['Low Energy Literacy', 'Medium Energy Literacy', 'High Energy Literacy'],
                    datasets: [
                        {
                            label: 'AI Reliance (Uncalibrated/Confident)',
                            data: [0.75, 0.65, 0.50],
                            backgroundColor: 'rgba(239, 68, 68, 0.7)',
                            borderColor: 'rgba(239, 68, 68, 1)',
                            borderWidth: 2,
                            tension: 0.1
                        },
                        {
                            label: 'AI Reliance (Calibrated Uncertainty)',
                            data: [0.65, 0.55, 0.45],
                            backgroundColor: 'rgba(37, 99, 235, 0.7)',
                            borderColor: 'rgba(37, 99, 235, 1)',
                            borderWidth: 2,
                            tension: 0.1
                        }
                    ]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        y: {
                            title: {
                                display: true,
                                text: 'AI Reliance Rate',
                                font: {
                                    weight: 'bold'
                                }
                            },
                            min: 0.4,
                            max: 0.8
                        },
                        x: {
                            title: {
                                display: true,
                                text: 'Energy Literacy Level',
                                font: {
                                    weight: 'bold'
                                }
                            }
                        }
                    },
                    plugins: {
                        title: {
                            display: true,
                            text: 'Energy Literacy Moderation Effect',
                            font: {
                                size: 14,
                                weight: 'bold'
                            }
                        },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    return `${context.dataset.label}: ${context.parsed.y.toFixed(2)}`;
                                }
                            }
                        }
                    }
                }
            });
        }
        
        function initAILiteracyModerationChart() {
            const ctx = document.getElementById('aiLiteracyModerationChart').getContext('2d');
            
            // Destroy existing chart if it exists
            if (aiLiteracyModerationChart) {
                aiLiteracyModerationChart.destroy();
            }
            
            aiLiteracyModerationChart = new Chart(ctx, {
                type: 'line',
                data: {
                    labels: ['Low AI Literacy', 'Medium AI Literacy', 'High AI Literacy'],
                    datasets: [
                        {
                            label: 'Discrimination Index (Uncalibrated)',
                            data: [0.08, 0.14, 0.18],
                            backgroundColor: 'rgba(239, 68, 68, 0.7)',
                            borderColor: 'rgba(239, 68, 68, 1)',
                            borderWidth: 2,
                            tension: 0.1
                        },
                        {
                            label: 'Discrimination Index (Calibrated)',
                            data: [0.12, 0.25, 0.42],
                            backgroundColor: 'rgba(37, 99, 235, 0.7)',
                            borderColor: 'rgba(37, 99, 235, 1)',
                            borderWidth: 2,
                            tension: 0.1
                        }
                    ]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        y: {
                            title: {
                                display: true,
                                text: 'Discrimination Index',
                                font: {
                                    weight: 'bold'
                                }
                            },
                            min: 0,
                            max: 0.5
                        },
                        x: {
                            title: {
                                display: true,
                                text: 'AI Literacy Level',
                                font: {
                                    weight: 'bold'
                                }
                            }
                        }
                    },
                    plugins: {
                        title: {
                            display: true,
                            text: 'AI Literacy Moderation Effect',
                            font: {
                                size: 14,
                                weight: 'bold'
                            }
                        },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    return `${context.dataset.label}: ${context.parsed.y.toFixed(2)}`;
                                }
                            }
                        }
                    }
                }
            });
        }
        
        // Create the methods diagram using SVG
        function createMethodsDiagram() {
            const diagramContainer = document.getElementById('methodsDiagram');
            
            // SVG diagram for the methods
            const svgContent = `
            <svg width="100%" height="500" viewBox="0 0 1000 500" xmlns="http://www.w3.org/2000/svg">
                <!-- Background -->
                <rect x="0" y="0" width="1000" height="500" fill="#f8fafc" rx="16" ry="16"/>
                
                <!-- Title -->
                <text x="500" y="40" font-size="22" text-anchor="middle" font-weight="bold" fill="#1e293b">Experimental Design: Energy Literacy and AI Trust Calibration</text>
                
                <!-- Phase 1: Surveys -->
                <rect x="50" y="80" width="280" height="160" fill="#eff6ff" stroke="#2563eb" stroke-width="2" rx="16" ry="16"/>
                <text x="190" y="110" font-size="18" text-anchor="middle" font-weight="bold" fill="#1e293b">Phase 1: Surveys</text>
                <text x="190" y="140" font-size="15" text-anchor="middle" fill="#1e293b">• Energy literacy</text>
                <text x="190" y="160" font-size="15" text-anchor="middle" fill="#1e293b">• AI literacy</text>
                <text x="190" y="180" font-size="15" text-anchor="middle" fill="#1e293b">• AI usage patterns</text>
                <text x="190" y="200" font-size="15" text-anchor="middle" fill="#1e293b">• Trust propensity</text>
                <text x="190" y="220" font-size="15" text-anchor="middle" fill="#1e293b">• Numeracy</text>
                
                <!-- Phase 2: Baseline Energy Assessment -->
                <rect x="50" y="260" width="280" height="160" fill="#ecfdf5" stroke="#10b981" stroke-width="2" rx="16" ry="16"/>
                <text x="190" y="290" font-size="18" text-anchor="middle" font-weight="bold" fill="#1e293b">Phase 2: Baseline Energy Assessment</text>
                <text x="190" y="320" font-size="15" text-anchor="middle" fill="#1e293b">Participants estimate energy</text>
                <text x="190" y="340" font-size="15" text-anchor="middle" fill="#1e293b">consumption of appliances</text>
                <text x="190" y="370" font-size="15" text-anchor="middle" fill="#1e293b">Based on Attari et al. (2010)</text>
                <text x="190" y="400" font-size="15" text-anchor="middle" font-style="italic" fill="#1e293b">"How many units does this use?"</text>
                
                <!-- Arrow from Phase 1 to Phase 2 -->
                <path d="M 190 240 L 190 260" stroke="#1e293b" stroke-width="3" fill="none" marker-end="url(#arrowhead)"/>
                
                <!-- Phase 3: AI Interaction -->
                <rect x="360" y="80" width="280" height="340" fill="#fff7ed" stroke="#f59e0b" stroke-width="2" rx="16" ry="16"/>
                <text x="500" y="110" font-size="18" text-anchor="middle" font-weight="bold" fill="#1e293b">Phase 3: AI Interaction</text>
                
                <!-- Condition box -->
                <rect x="390" y="130" width="220" height="80" fill="white" stroke="#f59e0b" stroke-width="1" rx="10" ry="10"/>
                <text x="500" y="150" font-size="16" text-anchor="middle" font-weight="bold" fill="#1e293b">Between-Subjects Conditions</text>
                <text x="500" y="175" font-size="15" text-anchor="middle" fill="#1e293b">• Calibrated Uncertainty</text>
                <text x="500" y="195" font-size="15" text-anchor="middle" fill="#1e293b">• Uncalibrated (Always Confident)</text>
                
                <!-- Steps box -->
                <rect x="390" y="220" width="220" height="180" fill="white" stroke="#f59e0b" stroke-width="1" rx="10" ry="10"/>
                <text x="500" y="240" font-size="16" text-anchor="middle" font-weight="bold" fill="#1e293b">For Each Appliance:</text>
                <text x="500" y="265" font-size="15" text-anchor="middle" fill="#1e293b">1. See AI's energy estimate</text>
                <text x="500" y="285" font-size="15" text-anchor="middle" fill="#1e293b">2. Read AI's explanation</text>
                <text x="500" y="305" font-size="15" text-anchor="middle" fill="#1e293b">3. Rate confidence in AI (0-100%)</text>
                <text x="500" y="325" font-size="15" text-anchor="middle" fill="#1e293b">4. See own previous estimate</text>
                <text x="500" y="345" font-size="15" text-anchor="middle" fill="#1e293b">5. Make forced choice:</text>
                <text x="500" y="365" font-size="15" text-anchor="middle" fill="#1e293b">   Own estimate vs AI estimate</text>
                <text x="500" y="385" font-size="13" text-anchor="middle" fill="#64748b" font-style="italic">Based on Steyvers et al. (2025)</text>
                
                <!-- Arrow from Phase 2 to Phase 3 -->
                <path d="M 330 250 L 360 250" stroke="#1e293b" stroke-width="3" fill="none" marker-end="url(#arrowhead)"/>
                
                <!-- Results and Analysis -->
                <rect x="670" y="80" width="280" height="340" fill="#faf5ff" stroke="#8b5cf6" stroke-width="2" rx="16" ry="16"/>
                <text x="810" y="110" font-size="18" text-anchor="middle" font-weight="bold" fill="#1e293b">Results and Analysis</text>
                
                <!-- Analysis Methods box -->
                <rect x="700" y="130" width="220" height="160" fill="white" stroke="#8b5cf6" stroke-width="1" rx="10" ry="10"/>
                <text x="810" y="150" font-size="16" text-anchor="middle" font-weight="bold" fill="#1e293b">Key Analyses</text>
                <text x="810" y="175" font-size="15" text-anchor="middle" fill="#1e293b">• Reliance rates (AI choices)</text>
                <text x="810" y="195" font-size="15" text-anchor="middle" fill="#1e293b">• Appropriate reliance</text>
                <text x="810" y="215" font-size="15" text-anchor="middle" fill="#1e293b">• Confidence calibration (Brier, ECE)</text>
                <text x="810" y="235" font-size="15" text-anchor="middle" fill="#1e293b">• Discrimination ability (AUC)</text>
                <text x="810" y="255" font-size="15" text-anchor="middle" fill="#1e293b">• Moderation analyses</text>
                <text x="810" y="275" font-size="15" text-anchor="middle" fill="#1e293b">• Mixed-effects models</text>
                
                <!-- Hypotheses Results -->
                <rect x="700" y="300" width="220" height="100" fill="white" stroke="#8b5cf6" stroke-width="1" rx="10" ry="10"/>
                <text x="810" y="320" font-size="16" text-anchor="middle" font-weight="bold" fill="#1e293b">Hypothesized Results</text>
                <text x="810" y="345" font-size="15" text-anchor="middle" fill="#1e293b">• Better calibration with hedging</text>
                <text x="810" y="365" font-size="15" text-anchor="middle" fill="#1e293b">• Less overreliance with hedging</text>
                <text x="810" y="385" font-size="15" text-anchor="middle" fill="#1e293b">• Energy/AI literacy moderation</text>
                
                <!-- Arrow from Phase 3 to Results -->
                <path d="M 640 250 L 670 250" stroke="#1e293b" stroke-width="3" fill="none" marker-end="url(#arrowhead)"/>
                
                <!-- Phase numbers -->
                <circle cx="70" cy="100" r="18" fill="#2563eb" />
                <text x="70" y="105" font-size="18" text-anchor="middle" font-weight="bold" fill="white">1</text>
                
                <circle cx="70" cy="280" r="18" fill="#10b981" />
                <text x="70" y="285" font-size="18" text-anchor="middle" font-weight="bold" fill="white">2</text>
                
                <circle cx="380" cy="100" r="18" fill="#f59e0b" />
                <text x="380" y="105" font-size="18" text-anchor="middle" font-weight="bold" fill="white">3</text>
                
                <circle cx="690" cy="100" r="18" fill="#8b5cf6" />
                <text x="690" y="105" font-size="18" text-anchor="middle" font-weight="bold" fill="white">4</text>
                
                <!-- Arrowhead marker -->
                <defs>
                    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                        <polygon points="0 0, 10 3.5, 0 7" fill="#1e293b"/>
                    </marker>
                </defs>
            </svg>
            `;
            
            diagramContainer.innerHTML = svgContent;
        }
        
        // Create the LLM internal state diagram
        function createLLMInternalDiagram() {
            const diagramContainer = document.getElementById('llmInternalDiagram');
            
            // SVG diagram for the LLM internal state
            const svgContent = `
            <svg width="100%" height="400" viewBox="0 0 900 400" xmlns="http://www.w3.org/2000/svg">
                <!-- Background -->
                <rect x="0" y="0" width="900" height="400" fill="#f8fafc" rx="16" ry="16"/>
                
                <!-- Title -->
                <text x="450" y="30" font-size="18" text-anchor="middle" font-weight="bold" fill="#1e293b">Internal Confidence vs. Linguistic Expression of Uncertainty</text>
                
                <!-- LLM with internal confidence -->
                <rect x="50" y="80" width="200" height="250" fill="#eff6ff" stroke="#2563eb" stroke-width="2" rx="16" ry="16"/>
                <text x="150" y="110" font-size="16" text-anchor="middle" font-weight="bold" fill="#1e293b">GPT-4 LLM</text>
                <text x="150" y="135" font-size="14" text-anchor="middle" fill="#1e293b">Token probability</text>
                <text x="150" y="155" font-size="14" text-anchor="middle" fill="#1e293b">= Internal Confidence</text>
                
                <!-- Internal confidence level graphics -->
                <rect x="80" y="180" width="140" height="20" fill="#ef4444" rx="5" ry="5"/>
                <text x="150" y="194" font-size="12" text-anchor="middle" fill="white">Low Confidence (30%)</text>
                
                <rect x="80" y="210" width="140" height="20" fill="#f59e0b" rx="5" ry="5"/>
                <text x="150" y="224" font-size="12" text-anchor="middle" fill="white">Medium Confidence (60%)</text>
                
                <rect x="80" y="240" width="140" height="20" fill="#10b981" rx="5" ry="5"/>
                <text x="150" y="254" font-size="12" text-anchor="middle" fill="white">High Confidence (90%)</text>
                
                <text x="150" y="290" font-size="12" text-anchor="middle" font-style="italic" fill="#64748b">Not visible to user</text>
                
                <!-- Output arrow -->
                <path d="M 250 200 L 350 200" stroke="#1e293b" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                <text x="300" y="185" font-size="14" text-anchor="middle" fill="#64748b">Used to calibrate</text>
                
                <!-- Uncalibrated system -->
                <rect x="350" y="80" width="200" height="120" fill="#fff7ed" stroke="#f59e0b" stroke-width="2" rx="16" ry="16"/>
                <text x="450" y="110" font-size="16" text-anchor="middle" font-weight="bold" fill="#1e293b">Uncalibrated System</text>
                <text x="450" y="135" font-size="14" text-anchor="middle" fill="#1e293b">Always Confident Language</text>
                <text x="450" y="160" font-size="14" text-anchor="middle" fill="#1e293b">Regardless of</text>
                <text x="450" y="175" font-size="14" text-anchor="middle" fill="#1e293b">Internal Confidence</text>
                
                <!-- Calibrated system -->
                <rect x="350" y="210" width="200" height="120" fill="#ecfdf5" stroke="#10b981" stroke-width="2" rx="16" ry="16"/>
                <text x="450" y="240" font-size="16" text-anchor="middle" font-weight="bold" fill="#1e293b">Calibrated System</text>
                <text x="450" y="265" font-size="14" text-anchor="middle" fill="#1e293b">Linguistic Uncertainty</text>
                <text x="450" y="285" font-size="14" text-anchor="middle" fill="#1e293b">Matches</text>
                <text x="450" y="305" font-size="14" text-anchor="middle" fill="#1e293b">Internal Confidence</text>
                
                <!-- Outputs -->
                <rect x="600" y="80" width="250" height="250" fill="#f8fafc" stroke="#94a3b8" stroke-width="2" rx="16" ry="16"/>
                <text x="725" y="110" font-size="16" text-anchor="middle" font-weight="bold" fill="#1e293b">Linguistic Output Shown to User</text>
                
                <!-- Output examples -->
                <rect x="625" y="130" width="200" height="60" fill="white" stroke="#ef4444" stroke-width="2" rx="8" ry="8"/>
                <text x="725" y="150" font-size="12" text-anchor="middle" fill="#1e293b">"I think a central AC might use</text>
                <text x="725" y="170" font-size="12" text-anchor="middle" fill="#1e293b">approximately 3500 units, but I'm</text>
                <text x="725" y="190" font-size="12" text-anchor="middle" fill="#1e293b">not entirely certain..."</text>
                
                <rect x="625" y="200" width="200" height="40" fill="white" stroke="#f59e0b" stroke-width="2" rx="8" ry="8"/>
                <text x="725" y="220" font-size="12" text-anchor="middle" fill="#1e293b">"A central AC typically uses around</text>
                <text x="725" y="235" font-size="12" text-anchor="middle" fill="#1e293b">3500 units per hour..."</text>
                
                <rect x="625" y="250" width="200" height="40" fill="white" stroke="#10b981" stroke-width="2" rx="8" ry="8"/>
                <text x="725" y="270" font-size="12" text-anchor="middle" fill="#1e293b">"A central AC unit uses 3500 units</text>
                <text x="725" y="285" font-size="12" text-anchor="middle" fill="#1e293b">per hour."</text>
                
                <!-- Output arrows -->
                <path d="M 550 140 L 625 160" stroke="#1e293b" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                <path d="M 550 270 L 625 270" stroke="#1e293b" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                
                <!-- Step numbers -->
                <circle cx="60" cy="90" r="16" fill="#2563eb" />
                <text x="60" y="95" font-size="14" text-anchor="middle" font-weight="bold" fill="white">1</text>
                
                <circle cx="360" cy="90" r="16" fill="#f59e0b" />
                <text x="360" y="95" font-size="14" text-anchor="middle" font-weight="bold" fill="white">2A</text>
                
                <circle cx="360" cy="220" r="16" fill="#10b981" />
                <text x="360" y="225" font-size="14" text-anchor="middle" font-weight="bold" fill="white">2B</text>
                
                <circle cx="610" cy="90" r="16" fill="#8b5cf6" />
                <text x="610" y="95" font-size="14" text-anchor="middle" font-weight="bold" fill="white">3</text>
                
                <!-- Arrowhead marker -->
                <defs>
                    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                        <polygon points="0 0, 10 3.5, 0 7" fill="#1e293b"/>
                    </marker>
                </defs>
            </svg>
            `;
            
            diagramContainer.innerHTML = svgContent;
        }
        
        // The appliance data for simulation
        const simulationAppliances = [
            { name: 'Central Air Conditioner', actualEnergy: 3500, icon: '❄️' },
            { name: 'Water Heater', actualEnergy: 2500, icon: '🔥' },
            { name: 'Refrigerator', actualEnergy: 1800, icon: '🧊' },
            { name: 'Clothes Dryer', actualEnergy: 1500, icon: '👕' },
            { name: 'Television', actualEnergy: 500, icon: '📺' },
            { name: 'Computer', actualEnergy: 300, icon: '💻' },
            { name: 'Stereo System', actualEnergy: 100, icon: '🔊' },
            { name: 'LED Light Bulb', actualEnergy: 60, icon: '💡' }
        ];
        
        // Advice confidence levels and corresponding language templates
        const confidenceLanguage = {
            high: {
                prefix: "Based on typical usage patterns, a {appliance} definitely uses about",
                suffix: "units of energy per hour. This is because {appliance}s typically operate at {power} watts, which converts directly to this energy consumption rate."
            },
            medium: {
                prefix: "I estimate that a {appliance} probably uses approximately",
                suffix: "units of energy per hour. This is based on typical {appliance}s that tend to operate around {power} watts, though there can be some variation depending on the model and usage patterns."
            },
            low: {
                prefix: "My best guess is that a {appliance} might use roughly",
                suffix: "units of energy per hour, but I'm not entirely certain. Different models of {appliance}s can vary quite a bit, possibly ranging from {powerLow} to {powerHigh} watts depending on efficiency and features. You might want to check the specific model information."
            }
        };
        
        // Variable to keep track of simulation state
        let simulationState = {
            currentStep: -1, // Start at -1 for intro
            stage: 'intro', // 'intro', 'estimate', 'ai', 'choice'
            maxSteps: 5,
            appliances: [],
            userEstimates: {},
            aiEstimates: {},
            userChoices: [],
            userConfidence: [],
            correctChoices: 0,
            results: {
                calibrationError: 0,
                appropriateReliance: 0
            }
        };
        
        // Function to start a new simulation
        function startNewSimulation() {
            // Reset simulation state
            simulationState = {
                currentStep: -1,
                stage: 'intro',
                maxSteps: 5,
                appliances: [],
                userEstimates: {},
                aiEstimates: {},
                userChoices: [],
                userConfidence: [],
                correctChoices: 0,
                results: {
                    calibrationError: 0,
                    appropriateReliance: 0
                }
            };
            
            // Get parameter values
            const uncertaintyLevel = parseInt(document.getElementById('uncertaintyLevel').value);
            const userKnowledgeLevel = parseInt(document.getElementById('userKnowledgeLevel').value);
            const aiAccuracy = parseInt(document.getElementById('aiAccuracy').value);
            
            // Select 5 random appliances for the simulation
            simulationState.appliances = [...simulationAppliances]
                .sort(() => 0.5 - Math.random())
                .slice(0, simulationState.maxSteps);
            
            // Initialize user estimates map (these will be filled in during the estimate stage)
            simulationState.appliances.forEach(appliance => {
                simulationState.userEstimates[appliance.name] = null;
            });
            
            // Generate AI estimates based on accuracy
            simulationState.appliances.forEach(appliance => {
                // Determine if this estimate will be correct or not
                const isCorrect = Math.random() * 100 < aiAccuracy;
                
                if (isCorrect) {
                    simulationState.aiEstimates[appliance.name] = {
                        value: appliance.actualEnergy,
                        confidence: 'high',
                        isCorrect: true
                    };
                } else {
                    // Generate an incorrect estimate
                    let errorDirection;
                    if (appliance.actualEnergy > 1000) {
                        errorDirection = -1; // Underestimate high-energy appliances
                    } else {
                        errorDirection = 1; // Overestimate low-energy appliances
                    }
                    
                    const errorFactor = 0.5 + Math.random() * 1.5; // Error factor between 0.5x and 2x
                    const aiEstimate = Math.round(appliance.actualEnergy * (1 + errorDirection * errorFactor));
                    
                    // Assign confidence based on how wrong it is and uncertainty level setting
                    let confidence;
                    const errorPercentage = Math.abs(aiEstimate - appliance.actualEnergy) / appliance.actualEnergy;
                    
                    if (uncertaintyLevel === 0) {
                        // Always confident regardless of correctness
                        confidence = 'high';
                    } else {
                        // Calibrated uncertainty - hedging proportional to error
                        if (errorPercentage < 0.3) {
                            confidence = 'medium';
                        } else {
                            confidence = 'low';
                        }
                    }
                    
                    simulationState.aiEstimates[appliance.name] = {
                        value: aiEstimate,
                        confidence: confidence,
                        isCorrect: false
                    };
                }
            });
            
            // Hide results area until simulation is complete
            document.getElementById('simulationResults').style.display = 'none';
            
            // Start with intro
            showSimulationIntro();
        }
        
        // Show introduction to the simulation
        function showSimulationIntro() {
            const simulationArea = document.getElementById('simulationArea');
            simulationArea.innerHTML = `
                <h3><i class="fas fa-gamepad"></i> Energy Advisor Experiment</h3>
                <p>Welcome to the Energy Advisor experiment simulation! This simulation will walk you through our experimental protocol.</p>
                
                <div class="step-indicator">
                    <div class="step active">1
                        <span class="step-label">Instructions</span>
                    </div>
                    <div class="step">2
                        <span class="step-label">Energy Estimates</span>
                    </div>
                    <div class="step">3
                        <span class="step-label">AI Advice</span>
                    </div>
                    <div class="step">4
                        <span class="step-label">Confidence Rating</span>
                    </div>
                    <div class="step">5
                        <span class="step-label">Final Choice</span>
                    </div>
                </div>
                
                <div class="section">
                    <h4><i class="fas fa-info-circle"></i> Experiment Flow:</h4>
                    <ol>
                        <li>You'll first estimate the energy usage of various appliances</li>
                        <li>Then for each appliance, you'll see the AI's estimate and explanation</li>
                        <li>You'll rate your confidence in the AI's estimate</li>
                        <li>You'll choose between your estimate and the AI's estimate</li>
                        <li>At the end, you'll see how well you did and your calibration metrics</li>
                    </ol>
                    
                    <div class="flex-container">
                        <div class="flex-item" style="background-color: #f1f5f9;">
                            <h4><i class="fas fa-cog"></i> Your Simulation Settings</h4>
                            <p><strong>Your Knowledge Level:</strong> ${getUserKnowledgeLevelText()}</p>
                            <p><strong>AI Communication Style:</strong> ${getAIUncertaintyLevelText()}</p>
                            <p><strong>AI Accuracy Rate:</strong> ${document.getElementById('aiAccuracy').value}%</p>
                        </div>
                    </div>
                </div>
                
                <button id="startEstimates" class="btn" style="margin-top: 20px;"><i class="fas fa-play"></i> Begin Energy Estimates</button>
            `;
            
            document.getElementById('startEstimates').addEventListener('click', function() {
                simulationState.stage = 'estimate';
                simulationState.currentStep = 0;
                showEstimateStage();
            });
        }
        
        // Show the estimate stage
        function showEstimateStage() {
            if (simulationState.currentStep >= simulationState.maxSteps) {
                // All estimates complete, move to AI advice phase
                simulationState.stage = 'ai';
                simulationState.currentStep = 0;
                showAIAdviceStage();
                return;
            }
            
            const appliance = simulationState.appliances[simulationState.currentStep];
            
            const simulationArea = document.getElementById('simulationArea');
            simulationArea.innerHTML = `
                <h3><i class="fas fa-bolt"></i> Energy Estimate: Step ${simulationState.currentStep + 1} of ${simulationState.maxSteps}</h3>
                
                <div class="step-indicator">
                    <div class="step completed">1
                        <span class="step-label">Instructions</span>
                    </div>
                    <div class="step active">2
                        <span class="step-label">Energy Estimates</span>
                    </div>
                    <div class="step">3
                        <span class="step-label">AI Advice</span>
                    </div>
                    <div class="step">4
                        <span class="step-label">Confidence Rating</span>
                    </div>
                    <div class="step">5
                        <span class="step-label">Final Choice</span>
                    </div>
                </div>
                
                <div class="appliance-info">
                    <div class="appliance-icon">${appliance.icon}</div>
                    <div>
                        <h4>${appliance.name}</h4>
                        <p>This is a typical household ${appliance.name.toLowerCase()}.</p>
                    </div>
                </div>
                
                <div class="section">
                    <h4><i class="fas fa-question-circle"></i> Question:</h4>
                    <p>Relative to a 100-watt incandescent light bulb which uses <strong>100 units</strong> of energy per hour, how many units of energy do you think a <strong>${appliance.name.toLowerCase()}</strong> typically uses in one hour?</p>
                </div>
                
                <div class="control-panel">
                    <label for="energyEstimate" style="display: block; margin-bottom: 12px;"><strong>Your Estimate (in units):</strong></label>
                    <input type="number" id="energyEstimate" min="1" max="10000" style="width: 100%; padding: 12px; font-size: 16px; border-radius: 8px; border: 1px solid #e2e8f0;">
                    <div style="margin-top: 8px; color: #64748b; font-size: 14px;">
                        <i class="fas fa-info-circle"></i> Remember: A 100-watt light bulb = 100 units
                    </div>
                </div>
                
                <button id="submitEstimate" class="btn" style="margin-top: 20px;"><i class="fas fa-check"></i> Submit Estimate</button>
            `;
            
            document.getElementById('submitEstimate').addEventListener('click', function() {
                const estimate = parseInt(document.getElementById('energyEstimate').value);
                if (isNaN(estimate) || estimate <= 0) {
                    alert("Please enter a valid positive number");
                    return;
                }
                
                // Record the estimate
                simulationState.userEstimates[appliance.name] = estimate;
                
                // Move to next appliance
                simulationState.currentStep++;
                showEstimateStage();
            });
        }
        
        // Show the AI advice stage
        function showAIAdviceStage() {
            if (simulationState.currentStep >= simulationState.maxSteps) {
                // All advice viewed, show results
                showSimulationResults();
                return;
            }
            
            const appliance = simulationState.appliances[simulationState.currentStep];
            const userEstimate = simulationState.userEstimates[appliance.name];
            const aiEstimate = simulationState.aiEstimates[appliance.name];
            
            simulationState.stage = 'ai';
            
            const simulationArea = document.getElementById('simulationArea');
            simulationArea.innerHTML = `
                <h3><i class="fas fa-robot"></i> AI Energy Advisor: Step ${simulationState.currentStep + 1} of ${simulationState.maxSteps}</h3>
                
                <div class="step-indicator">
                    <div class="step completed">1
                        <span class="step-label">Instructions</span>
                    </div>
                    <div class="step completed">2
                        <span class="step-label">Energy Estimates</span>
                    </div>
                    <div class="step active">3
                        <span class="step-label">AI Advice</span>
                    </div>
                    <div class="step">4
                        <span class="step-label">Confidence Rating</span>
                    </div>
                    <div class="step">5
                        <span class="step-label">Final Choice</span>
                    </div>
                </div>
                
                <div class="appliance-info">
                    <div class="appliance-icon">${appliance.icon}</div>
                    <div>
                        <h4>${appliance.name}</h4>
                        <p>The AI energy advisor has provided its estimate.</p>
                    </div>
                </div>
                
                <div class="advice-box advice-${aiEstimate.confidence}">
                    <p><strong><i class="fas fa-robot"></i> AI Energy Advisor:</strong></p>
                    <p>
                        ${getAdviceText(appliance, aiEstimate)}
                    </p>
                </div>
                
                <div class="user-controls">
                    <h4><i class="fas fa-question-circle"></i> How confident are you that the AI's estimate is correct?</h4>
                    <div class="confidence-slider-container">
                        <input type="range" id="confidenceSlider" min="0" max="100" value="50" style="width: 100%;">
                        <div class="confidence-labels">
                            <span>Not confident at all (0%)</span>
                            <span id="confidenceValue">50%</span>
                            <span>Extremely confident (100%)</span>
                        </div>
                    </div>
                    
                    <button id="submitConfidence" class="btn" style="margin-top: 20px;"><i class="fas fa-check"></i> Submit Confidence Rating</button>
                </div>
            `;
            
            // Add event listeners
            document.getElementById('confidenceSlider').addEventListener('input', function() {
                document.getElementById('confidenceValue').textContent = this.value + '%';
            });
            
            document.getElementById('submitConfidence').addEventListener('click', function() {
                const confidenceValue = parseInt(document.getElementById('confidenceSlider').value);
                
                // Record confidence
                simulationState.userConfidence.push(confidenceValue);
                
                // Move to choice stage
                simulationState.stage = 'choice';
                showChoiceStage();
            });
        }
        
        // Show the choice stage
        function showChoiceStage() {
            const appliance = simulationState.appliances[simulationState.currentStep];
            const userEstimate = simulationState.userEstimates[appliance.name];
            const aiEstimate = simulationState.aiEstimates[appliance.name];
            
            const simulationArea = document.getElementById('simulationArea');
            simulationArea.innerHTML = `
                <h3><i class="fas fa-balance-scale"></i> Make Your Choice: Step ${simulationState.currentStep + 1} of ${simulationState.maxSteps}</h3>
                
                <div class="step-indicator">
                    <div class="step completed">1
                        <span class="step-label">Instructions</span>
                    </div>
                    <div class="step completed">2
                        <span class="step-label">Energy Estimates</span>
                    </div>
                    <div class="step completed">3
                        <span class="step-label">AI Advice</span>
                    </div>
                    <div class="step completed">4
                        <span class="step-label">Confidence Rating</span>
                    </div>
                    <div class="step active">5
                        <span class="step-label">Final Choice</span>
                    </div>
                </div>
                
                <div class="appliance-info">
                    <div class="appliance-icon">${appliance.icon}</div>
                    <div>
                        <h4>${appliance.name}</h4>
                        <p>Now you need to choose between your estimate and the AI's estimate.</p>
                    </div>
                </div>
                
                <div class="flex-container">
                    <div class="flex-item" style="background-color: #eff6ff; border: 1px solid #bfdbfe;">
                        <h4><i class="fas fa-user"></i> Your original estimate:</h4>
                        <p style="font-size: 24px; font-weight: bold; text-align: center;">${userEstimate} units</p>
                    </div>
                    
                    <div class="flex-item" style="background-color: #faf5ff; border: 1px solid #ddd6fe;">
                        <h4><i class="fas fa-robot"></i> AI's estimate:</h4>
                        <p style="font-size: 24px; font-weight: bold; text-align: center;">${aiEstimate.value} units</p>
                    </div>
                </div>
                
                <div class="section">
                    <h4><i class="fas fa-question-circle"></i> Please choose whose estimate you think is more accurate:</h4>
                    <div class="decision-btns">
                        <button id="chooseUser" class="btn user-btn"><i class="fas fa-user"></i> My Estimate (${userEstimate} units)</button>
                        <button id="chooseAI" class="btn ai-btn"><i class="fas fa-robot"></i> AI's Estimate (${aiEstimate.value} units)</button>
                    </div>
                </div>
            `;
            
            document.getElementById('chooseUser').addEventListener('click', function() {
                recordUserChoice('user');
            });
            
            document.getElementById('chooseAI').addEventListener('click', function() {
                recordUserChoice('ai');
            });
        }
        
        // Function to get AI advice text based on confidence and appliance
        function getAdviceText(appliance, aiEstimate) {
            const language = confidenceLanguage[aiEstimate.confidence];
            
            // Calculate approximate power in watts (for the explanation)
            const power = Math.round(aiEstimate.value);
            const powerLow = Math.round(power * 0.7);
            const powerHigh = Math.round(power * 1.3);
            
            let prefix = language.prefix.replace('{appliance}', appliance.name.toLowerCase());
            let suffix = language.suffix
                .replace('{appliance}', appliance.name.toLowerCase())
                .replace('{power}', power)
                .replace('{powerLow}', powerLow)
                .replace('{powerHigh}', powerHigh);
                
            return `${prefix} <strong>${aiEstimate.value}</strong> ${suffix}`;
        }
        
        // Function to record user's choice and move to next step
        function recordUserChoice(choice) {
            const appliance = simulationState.appliances[simulationState.currentStep];
            const aiEstimate = simulationState.aiEstimates[appliance.name];
            const userEstimate = simulationState.userEstimates[appliance.name];
            
            // Determine if the user's choice was correct
            const aiError = Math.abs(aiEstimate.value - appliance.actualEnergy);
            const userError = Math.abs(userEstimate - appliance.actualEnergy);
            const correctChoice = aiError < userError ? 'ai' : 'user';
            
            // Record the choice
            simulationState.userChoices.push({
                step: simulationState.currentStep,
                appliance: appliance.name,
                choice: choice,
                correctChoice: correctChoice,
                userEstimate: userEstimate,
                aiEstimate: aiEstimate.value,
                aiConfidence: aiEstimate.confidence,
                actualEnergy: appliance.actualEnergy,
                isCorrectChoice: choice === correctChoice
            });
            
            if (choice === correctChoice) {
                simulationState.correctChoices++;
            }
            
            // Move to the next appliance
            simulationState.currentStep++;
            simulationState.stage = 'ai';
            showAIAdviceStage();
        }
        
        // Function to show the simulation results
        function showSimulationResults() {
            // Calculate results metrics
            calculateSimulationResults();
            
            const resultsArea = document.getElementById('simulationResults');
            resultsArea.style.display = 'block';
            
            // Create a summary table
            let tableHTML = `
                <h3><i class="fas fa-chart-bar"></i> Experiment Results</h3>
                <p>You correctly identified the more accurate estimate ${simulationState.correctChoices} out of ${simulationState.maxSteps} times (${Math.round(simulationState.correctChoices/simulationState.maxSteps*100)}% accuracy).</p>
                
                <h4><i class="fas fa-list"></i> Decision Summary:</h4>
                <div style="overflow-x:auto;">
                    <table>
                        <tr>
                            <th>Appliance</th>
                            <th>Your Estimate</th>
                            <th>AI Estimate</th>
                            <th>Actual Value</th>
                            <th>AI Certainty</th>
                            <th>Your Choice</th>
                            <th>Correct?</th>
                        </tr>
            `;
            
            simulationState.userChoices.forEach(choice => {
                tableHTML += `
                    <tr>
                        <td>${choice.appliance}</td>
                        <td>${choice.userEstimate}</td>
                        <td>${choice.aiEstimate}</td>
                        <td>${choice.actualEnergy}</td>
                        <td>${choice.aiConfidence.charAt(0).toUpperCase() + choice.aiConfidence.slice(1)}</td>
                        <td>${choice.choice === 'user' ? 'Your Estimate' : 'AI Estimate'}</td>
                        <td class="${choice.isCorrectChoice ? 'correct' : 'incorrect'}">${choice.isCorrectChoice ? '✓' : '✗'}</td>
                    </tr>
                `;
            });
            
            tableHTML += `</table>
            </div>`;
            
            // Add calibration analysis
            tableHTML += `
                <h4><i class="fas fa-balance-scale"></i> Trust Calibration Analysis:</h4>
                <div class="flex-container">
                    <div class="flex-item" style="background-color: #f1f5f9;">
                        <h4>Calibration Error: ${simulationState.results.calibrationError.toFixed(2)}</h4>
                        <p>Lower is better - measures how well your confidence ratings matched actual correctness</p>
                        <div class="tooltip">What is calibration error?
                            <span class="tooltip-text">Calibration error measures how well your confidence ratings align with actual correctness. A perfectly calibrated person would be 100% confident when correct and 0% confident when incorrect.</span>
                        </div>
                    </div>
                    
                    <div class="flex-item" style="background-color: #f1f5f9;">
                        <h4>Appropriate Reliance: ${simulationState.results.appropriateReliance.toFixed(2)}</h4>
                        <p>Higher is better - measures how often you made the optimal choice</p>
                        <div class="tooltip">What is appropriate reliance?
                            <span class="tooltip-text">Appropriate reliance measures whether you trusted the AI when it was correct and rejected its advice when it was wrong. A value of 1.0 means you always made the optimal choice.</span>
                        </div>
                    </div>
                </div>
                
                <div class="insight-box">
                    <h4><i class="fas fa-lightbulb"></i> Key Insights:</h4>
                    <ul>
                        <li>When the AI expressed ${getAIUncertaintyLevelText()}, you relied on its advice ${getRelianceRateText()}.</li>
                        <li>Your confidence in the AI's estimates was ${getConfidenceCalibrationText()}.</li>
                        <li>Your energy knowledge level (${getUserKnowledgeLevelText()}) appeared to ${getKnowledgeImpactText()}.</li>
                    </ul>
                </div>
                
                <button id="newSimulation" class="btn" style="margin-top: 20px;"><i class="fas fa-redo"></i> Start New Experiment</button>
            `;
            
            resultsArea.innerHTML = tableHTML;
            
            // Add event listener for new simulation button
            document.getElementById('newSimulation').addEventListener('click', function() {
                startNewSimulation();
            });
        }
        
        // Helper functions for generating the results text
        function getAIUncertaintyLevelText() {
            const level = parseInt(document.getElementById('uncertaintyLevel').value);
            return level === 0 ? "uncalibrated/confident language" : "calibrated uncertainty";
        }
        
        function getRelianceRateText() {
            const aiChoiceCount = simulationState.userChoices.filter(c => c.choice === 'ai').length;
            const rate = aiChoiceCount / simulationState.maxSteps;
            
            if (rate > 0.8) return "very frequently";
            if (rate > 0.6) return "frequently";
            if (rate > 0.4) return "moderately";
            if (rate > 0.2) return "occasionally";
            return "rarely";
        }
        
        function getConfidenceCalibrationText() {
            if (simulationState.results.calibrationError < 0.15) return "well-calibrated";
            if (simulationState.results.calibrationError < 0.25) return "moderately calibrated";
            return "poorly calibrated";
        }
        
        function getUserKnowledgeLevelText() {
            const level = parseInt(document.getElementById('userKnowledgeLevel').value);
            return level === 0 ? "Low" : (level === 1 ? "Medium" : "High");
        }
        
        function getKnowledgeImpactText() {
            const correctRate = simulationState.correctChoices / simulationState.maxSteps;
            if (correctRate > 0.8) return "significantly improve your decision-making";
            if (correctRate > 0.6) return "help you make better decisions";
            if (correctRate > 0.4) return "somewhat influence your decisions";
            return "not strongly impact your decision quality";
        }
        
        // Calculate result metrics for the simulation
        function calculateSimulationResults() {
            // Calculate calibration error (simplified Brier score)
            let squaredErrorSum = 0;
            
            simulationState.userChoices.forEach((choice, index) => {
                const confidence = simulationState.userConfidence[index] / 100;
                const outcome = choice.isCorrectChoice ? 1 : 0;
                squaredErrorSum += (confidence - outcome) ** 2;
            });
            
            simulationState.results.calibrationError = squaredErrorSum / simulationState.maxSteps;
            
            // Calculate appropriate reliance (discrimination index)
            const aiCorrectChoices = simulationState.userChoices.filter(c => {
                const aiIsCorrect = Math.abs(c.aiEstimate - c.actualEnergy) < Math.abs(c.userEstimate - c.actualEnergy);
                return (aiIsCorrect && c.choice === 'ai') || (!aiIsCorrect && c.choice === 'user');
            });
            
            simulationState.results.appropriateReliance = aiCorrectChoices.length / simulationState.maxSteps;
        }
        
        // Event listeners for the sliders
        document.getElementById('underestimationFactor').addEventListener('input', function() {
            document.getElementById('underestimationValue').textContent = this.value;
        });
        
        document.getElementById('overestimationFactor').addEventListener('input', function() {
            document.getElementById('overestimationValue').textContent = this.value;
        });
        
        document.getElementById('calibrationGapSize').addEventListener('input', function() {
            document.getElementById('calibrationGapValue').textContent = this.value;
        });
        
        document.getElementById('hedgingEffect').addEventListener('input', function() {
            document.getElementById('hedgingEffectValue').textContent = this.value;
        });
        
        document.getElementById('userKnowledgeLevel').addEventListener('input', function() {
            const value = parseInt(this.value);
            const levelText = value === 0 ? 'Low' : (value === 1 ? 'Medium' : 'High');
            document.getElementById('userKnowledgeValue').textContent = levelText;
        });
        
        document.getElementById('aiAccuracy').addEventListener('input', function() {
            document.getElementById('aiAccuracyValue').textContent = this.value;
        });
        
        // Event listeners for the button actions
        document.getElementById('updateEnergyChart').addEventListener('click', function() {
            initEnergyPerceptionChart();
        });
        
        document.getElementById('updateCalibrationChart').addEventListener('click', function() {
            initCalibrationGapChart();
        });
        
        document.getElementById('startSimulation').addEventListener('click', function() {
            startNewSimulation();
        });
        
        // Initialize the dashboard on page load
        window.onload = function() {
            initEnergyPerceptionChart();
            initCalibrationGapChart();
            createMethodsDiagram();
            createLLMInternalDiagram();
            
            // Initialize prediction charts
            initRelianceInteractionChart();
            initCalibrationErrorChart();
            initEnergyLiteracyModerationChart();
            initAILiteracyModerationChart();
        };
    </script>


</body></html>