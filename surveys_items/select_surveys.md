


# PTT Scale (scholz et al. )


## General instructions for the PTT scales:

The final scales (14 items) and short scales (6 items) for both the propensity to trust in automated technological systems (PTT-A) and other humans (PTT-H) are presented below.

*   The items should be presented in a randomized order.
*   Some items are negatively poled (indicated by (R) - reversed item).
*   In the present study, a five-point Likert-type scale ranging from 1 (“strongly disagree”) to 5 (“strongly agree") was used.

Items included in the 6-items short scales are printed in **bold**.

**Instruction:**
Now we are interested in your opinions about automated technology – i.e., technology that can perform certain functions automatically without any input from you.

Automated technology is taking on more and more tasks in various areas of life. For example, robots are becoming more widely used in industry and in private households. Many means of transport (airplanes, trains, or cars) are also now increasingly automated.

The term automated technology includes (among other things):

*   Automated means of transport (e.g. autonomous cars, trains, streetcars, airplanes)
*   Industrial robots (e.g. assembly robots, automated logistics robots)
*   Service and assistance robots (e.g. robot vacuum cleaners, robot lawn mowers, healthcare robots)
*   Other programs and systems based on artificial intelligence (e.g. language assistants, image recognition)

There are a number of statements on the next pages about automated technology in general that may apply to you more or less. Please respond to each of these statements by indicating the extent to which you agree or disagree with the statement, i.e. how much it applies to you. There are five options available, ranging from "strongly disagree” to “strongly agree".

## Propensity to Trust in Automated Technology (PTT-A) Scale

**Items:**

### Trusting Stance
1.  **Even though I may sometimes suffer the consequences of trusting automated technological systems, I still prefer to trust than not to trust them.**
2.  I feel good about trusting automated technological systems.
3.  I believe that I am generally better off when I do not trust automated technological systems than when I trust them. (R)
4.  **I rarely trust automated technological systems because I can't handle the uncertainty.** (R)

### Competence
5.  **Automated technological systems are competent.**
6.  Automated technological systems have sound knowledge about problems for which they are intended.
7.  I am wary about the capabilities of automated technological systems. (R)
8.  Automated technological systems do not have the capabilities that could help me reach my goals. (R)

### Benevolence
9.  **I believe that automated technological systems have good intentions.**
10. I feel that automated technological systems are out to get as much as they can for themselves. (R)
11. I don't expect that automated technological systems are willing to assist and support people. (R)

### Integrity
12. **Most automated technological systems are honest.**
13. **I feel that automated technological systems can be relied upon to do what they say they will do.**
14. One cannot expect to be treated fairly by automated technological systems. (R)



# Salah - AI Use Scale

# Survey Items from Salah et al. (2024)

Salah, M., Alhalbusi, H., Ismail, M. M., & Abdelfattah, F. (2024). Chatting with ChatGPT: Decoding the mind of Chatbot users and unveiling the intricate connections between user perception, trust and stereotype perception on self-esteem and psychological well-being. Current Psychology, 43(9), 7843–7858. https://doi.org/10.1007/s12144-023-04989-0

https://educationaltechnologyjournal.springeropen.com/articles/10.1186/s41239-024-00471-4/tables/6



*Rating Scale: 5-point Likert scale (1 = Strongly Disagree, 5 = Strongly Agree), except where noted.*

---

## Items from Table A1

### Knowledge Application
*Source: Al-Sharafi et al. (2022)*
1.  **KAP1:** ChatGPT provides me with instant access to various types of knowledge.
2.  **KAP2:** ChatGPT allows me to integrate different types of knowledge.
3.  **KAP3:** ChatGPT helps me better master the knowledge I learn in university.

### Perceived Intelligence
*Source: Rafiq et al. (2022)*
1.  **PIE1:** I feel that ChatGPT is competent.
2.  **PIE2:** I feel that ChatGPT is knowledgeable.
3.  **PIE3:** I feel that ChatGPT is intelligent.

### Usability
*Source: Rafiq et al. (2022); Borsci et al. (2022); Almaiah and Man (2016)*
1.  **USB1:** The provided contents on ChatGPT are easily accessible.
2.  **USB2:** The provided contents on ChatGPT are easily downloadable.
3.  **USB3:** The provided contents on ChatGPT are easily retrievable.

### Attitude
*Source: Ajzen (1991)*
1.  **ATT1:** ChatGPT is useful.
2.  **ATT2:** ChatGPT is valuable.
3.  **ATT3:** ChatGPT is beneficial.

### Subjective Norms
*Source: Ajzen (1991)*
1.  **SNO1:** Most people who are important to me think it is okay for me to use ChatGPT.
2.  **SNO2:** Most people who are important to me support that I use ChatGPT.
3.  **SNO3:** Most people who are important to me understand that I use ChatGPT.

### Perceived Behavioral Control
*Source: Ajzen (1991)*
1.  **PBC1:** I am capable of using ChatGPT.
2.  **PBC2:** I am confident that if I want to, I can use ChatGPT.
3.  **PBC3:** I have enough resources, time, and opportunities to use ChatGPT.

### Trust
*Source: Nguyen et al. (2019)*
*(Note: This likely contributes to the 'Trust in ChatGPT (TCGPT)' construct analyzed, which used 7 items according to the main paper).*
1.  **TRU1:** When using ChatGPT, I trust that my personal information will not be used for any other purpose.
2.  **TRU2:** When using ChatGPT, I believe that my personal information is protected.
3.  **TRU3:** When using ChatGPT, I'm confident that my personal information is secure.

### Behavioral Intention
*Source: Ajzen (1991)*
1.  **BIT1:** I'd like to continue to use ChatGPT.
2.  **BIT2:** I'll continue to use the shared ChatGPT a lot in the future.
3.  **BIT3:** I plan to use ChatGPT in the future.

### Actual Use
*Source: Aparicio et al. (2017); McLean and Osei-Frimpong (2019)*
1.  **ACU1:** How frequently do you use ChatGPT?
2.  **ACU2:** At present, I consider myself to be a frequent user of ChatGPT.

---


# Grassini PAILQ-6 scale

# Perceived Artificial Intelligence Literacy Questionnaire (PAILQ-6)

Grassini, S. (2024). A Psychometric Validation of the PAILQ-6: Perceived Artificial Intelligence Literacy Questionnaire. Nordic Conference on Human-Computer Interaction, 1–10. https://doi.org/10.1145/3679318.3685359

**Instructions:** Please rate each statement based on your beliefs and feelings from 1 (strongly disagree) to 7 (strongly agree). There are no right or wrong answers.

1.  **I understand the basic concepts of artificial intelligence.**
    ( ) 1 Strongly Disagree | ( ) 2 Disagree | ( ) 3 Somewhat Disagree | ( ) 4 Neutral | ( ) 5 Somewhat Agree | ( ) 6 Agree | ( ) 7 Strongly Agree

2.  **I believe I can contribute to AI projects.**
    ( ) 1 Strongly Disagree | ( ) 2 Disagree | ( ) 3 Somewhat Disagree | ( ) 4 Neutral | ( ) 5 Somewhat Agree | ( ) 6 Agree | ( ) 7 Strongly Agree

3.  **I can judge the pros and cons of AI.**
    ( ) 1 Strongly Disagree | ( ) 2 Disagree | ( ) 3 Somewhat Disagree | ( ) 4 Neutral | ( ) 5 Somewhat Agree | ( ) 6 Agree | ( ) 7 Strongly Agree

4.  **I keep up with the latest AI trends.**
    ( ) 1 Strongly Disagree | ( ) 2 Disagree | ( ) 3 Somewhat Disagree | ( ) 4 Neutral | ( ) 5 Somewhat Agree | ( ) 6 Agree | ( ) 7 Strongly Agree

5.  **I'm comfortable talking about AI with others.**
    ( ) 1 Strongly Disagree | ( ) 2 Disagree | ( ) 3 Somewhat Disagree | ( ) 4 Neutral | ( ) 5 Somewhat Agree | ( ) 6 Agree | ( ) 7 Strongly Agree

6.  **I can think of new ways to use existing AI tools.**
    ( ) 1 Strongly Disagree | ( ) 2 Disagree | ( ) 3 Somewhat Disagree | ( ) 4 Neutral | ( ) 5 Somewhat Agree | ( ) 6 Agree | ( ) 7 Strongly Agree


----

## Instruction for scoring and descriptive data from validation study for reference
*(do not include in the questionnaire)*

### Scoring:

*   **PAILQ-6:** Average of all responses.
*   **PAILQ-6 (factor 1: Awareness Literacy):** Average of responses 1, 3, 5.
*   **PAILQ-6 (factor 2: Engagement Literacy):** Average of responses 2, 4, 6.


---


# Duro - Trust in LLMs scale: 

## 2. Trust-In-LLMs Index (TILLMI) - Final 6 Items

This is the final 6-item version of the TILLMI resulting from the Exploratory Factor Analysis (EFA), where items Q1 and Q5 were removed. The text for the remaining items is taken from the initial list (Table 7). The scale is the same as above.

**Source:** Derived from EFA results (Section 2.8, Page 7) and Initial Item List (Table 7, Page 15). Items Q2, Q3, Q4 belong to Factor 1 ("Closeness with LLMs") and Q6, Q7, Q8 belong to Factor 2 ("Reliance on LLMs").

**Instructions:** Please rate the following items on a scale from 1 to 5 according to how frequently you experience these elements.

1.  **Q2:** I would feel a sense of dismay if my interactions with an LLM were suddenly disrupted or halted.
2.  **Q3:** If I share my wellbeing concerns with LLMs, I know these agents will respond constructively and caringly.
3.  **Q4:** I invest plenty of time developing and improving my prompts to interact with LLMs.
4.  **Q6:** I can rely on LLMs not to make my job more difficult by careless work.
5.  **Q7:** Despite trusting LLMs' results overall, the last word is always mine.
6.  **Q8:** I tend to trust LLMs more than other people.


-----


# Trust Perception Scale - AI (TPA)

Jiun-Yin Jian, Bisantz, A. M., & Drury, C. G. (2000). Foundations for an Empirically Determined Scale of Trust in Automated System. International Journal of Cognitive Ergonomics, 4(1), 53. https://doi.org/10.1207/S15327566IJCE0401_04

Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., & Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No. arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582


**Instructions:** Please mark each statement with the number that best describes your feelings or your impression of trust with the AI you just saw.

**Scale:**
1: Not at all
2:
3:
4: Neutral / Moderate
5:
6:
7: Extremely

---

*   **1. The AI is deceptive**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **2. The AI behaves in an underhanded manner**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **3. I am suspicious of the AI's intent, action, or outputs**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **4. I am wary of the AI**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **5. The AI's actions will have a harmful or injurious outcome**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **6. I am confident in the AI**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **7. The AI provides security**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **8. The AI has integrity**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **9. The AI is dependable**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **10. The AI is reliable**
     ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **11. I can trust the AI**
     ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **12. I am familiar with the AI**
     ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7



# **Subjective AI Literacy (MAILS-S \- 10 Items) (Carolus et al., 2024\)**

**Instructions:** Please rate your own ability regarding the following aspects of Artificial Intelligence (AI). Use the scale from 0 (Ability is not at all or hardly pronounced) to 10 (Ability is very well or almost perfectly pronounced).

(Note: Specific 10 items selected for MAILS-S are detailed in Carolus et al., 2024\.16 Example items below illustrate the format and factors covered.)

1. *(Example \- Use/Apply AI)* I can operate AI applications. (0-10)  
2. *(Example \- Knowledge/Understanding)* I know definitions of artificial intelligence. (0-10)  
3. *(Example \- Evaluate AI)* I can assess what advantages and disadvantages the use of an artificial intelligence entails. (0-10)  
4. *(Example \- Detect AI)* I can tell if I am dealing with an application based on artificial intelligence. (0-10)  
5. *(Example \- Ethics AI)* I can weigh the consequences of using AI for society. (0-10)  
6. *(Example \- Create AI)* I can program new applications in the field of AI. (0-10)  
7. *(Example \- Create AI)* I can develop AI applications. (0-10)  
8. *(Example \- Self-Efficacy: Problem Solving)* I can solve difficult problems using AI if I try hard enough. (0-10)  
9. *(Example \- Self-Efficacy: Learning)* I am confident that I can learn complex things about AI. (0-10)  
10. *(Example \- Self-Competency: Information)* I can find the information I need when dealing with AI. (0-10)



# Custom LLM Accuracy Beliefs Scale: 


**3.4. Beliefs about LLM Accuracy for Energy Tasks:**

* *Evaluation:* This requires a custom measure, as no standard scale exists. The goal is to capture the user's *mental model* of the LLM's specific capabilities in the energy domain.29 Questions should probe perceived accuracy, knowledge boundaries, and potential biases related to energy topics.  
* *Recommendation:* **Improve by:**  
  * **Specificity:** Frame questions around concrete energy tasks (e.g., "How accurate do you think ChatGPT is at estimating the energy cost of running a dishwasher?", "How likely is an LLM to know the most effective way to reduce heating bills?").  
  * **Dimensions:** Include items assessing perceived:  
    * *Factual Accuracy:* Ability to provide correct energy data/facts.  
    * *Conceptual Understanding:* Ability to explain energy concepts correctly.  
    * *Problem-Solving Ability:* Ability to generate useful energy-saving plans or advice.  
    * *Bias Awareness:* Likelihood of reflecting common misconceptions or biases about energy.31  
    * *Knowledge Limits:* Awareness of what energy topics the LLM might *not* know about.  
  * **Format:** Use Likert scales (e.g., 1=Very Inaccurate to 7=Very Accurate; 1=Very Unlikely to 7=Very Likely).  
  * **Example Item:** "Rate your agreement: LLMs generally provide reliable information about the energy consumption of specific home appliances." (Strongly Disagree \- Strongly Agree).

**Instructions:** Please indicate the extent to which you agree or disagree with the following statements about Large Language Models (LLMs) like ChatGPT, specifically regarding energy-related topics. Use the scale from 1 (Strongly Disagree) to 7 (Strongly Agree).

**Beliefs about LLM Capabilities for Energy Tasks (Custom Item)**

1. LLMs generally provide factually accurate information about how much energy different home appliances use.  
2. LLMs can reliably explain complex energy concepts (e.g., how electricity grids work).  
3. LLMs are good at generating useful and effective personalized energy-saving plans.  
4. LLMs are likely to repeat common myths or misconceptions about energy saving.  
5. LLMs understand the difference between effective energy-saving actions (e.g., insulation) and less effective ones (e.g., unplugging chargers).  
6. I would trust an LLM to accurately calculate the potential cost savings from installing solar panels.  
7. LLMs have clear limitations in their knowledge about specific local energy prices or utility programs.  
8. LLMs can provide unbiased comparisons between different energy technologies (e.g., heat pumps vs. furnaces).

-----

# **Energy Heuristics Evaluation (Custom Item based on Kantenbacher & Attari, 2021** 2**)**

**Instructions:** For each pair of statements below, please select the statement that you think is generally a **more accurate** rule of thumb for judging household energy use.

1. Which statement is generally MORE accurate?  
   a) Appliances that primarily heat or cool things use much more energy than most other appliances.  
   b) The physical size of an appliance is the best indicator of its energy use.  
2. Which statement is generally MORE accurate?  
   a) Devices that charge other devices (like phone chargers) are major energy consumers in the home.  
   b) Devices that run for long periods, even at low power, can use a significant amount of energy over time.  
3. Which statement is generally MORE accurate?  
   a) Turning devices off completely is always much more effective than upgrading to energy-efficient models.  
   b) Upgrading to energy-efficient models (like Energy Star appliances) can often save more energy than simply using old devices less often.  
4. Which statement is generally MORE accurate?  
   a) How quickly a device completes its task (e.g., boiling water) is a good indicator of its total energy use for that task.  
   b) The power rating (watts) and the duration of use are the key factors determining total energy use for a task.