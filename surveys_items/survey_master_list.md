# AI Literacy Scales

## MAILS - Meta-Artificial Intelligence Literacy Scale

Carolus, A., Koch, M. J., Straka, S., Latoschik, M. E., & Wienrich, C. (2023). MAILS - Meta AI literacy scale: Development and testing of an AI literacy questionnaire based on well-founded competency models and psychological change- and meta-competencies. Computers in Human Behavior: Artificial Humans, 1(2), 100014. https://doi.org/10.1016/j.chbah.2023.100014

https://hci.uni-wuerzburg.de/research/MAILS/


## Meta-Artificial Intelligence Literacy Scale – Short Version

Koch, M. J., Carolus, A., Wienrich, C., & Latoschik, M. E. (2024). Meta AI literacy scale: Further validation and development of a short version. *Heliyon, 10*(21), e39686. https://doi.org/10.1016/j.heliyon.2024.e39686

## Survey and Scenario Questions from Tully, Longoni, & Appel (2023)

Tully, S., Longoni, C., & Appel, G. (2023). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. OSF. https://doi.org/10.31234/osf.io/t9u8g


## Rheu & Cho (2025) - Supplementary Materials: Survey Items

Rheu, M. (MJ), & Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, 1–7. https://doi.org/10.1145/3706599.3719681

https://ars-els-cdn-com.proxyiub.uits.iu.edu/content/image/1-s2.0-S0736585325000279-mmc1.pdf


# Appendix 2: AI Literacy Questionnaire (AILQ) Items (Ng et al., 2024)

Ng, D. T. K., Wu, W., Leung, J. K. L., Chiu, T. K. F., & Chu, S. K. W. (2024). Design and validation of the AI literacy questionnaire: The affective, behavioural, cognitive and ethical approach. British Journal of Educational Technology, 55(3), 1082–1104. https://doi.org/10.1111/bjet.13411


## Surveys and Questionnaires from Jin et al. (2024)

Jin, Y., Martinez-Maldonado, R., Gašević, D., & Yan, L. (2024). *GLAT: The Generative AI Literacy Assessment Test* (No. arXiv:2411.00283). arXiv. https://doi.org/10.48550/arXiv.2411.00283


## Survey Instruments and Items from Markus et al. (2025)

Markus, A., Carolus, A., & Wienrich, C. (2025). Objective Measurement of AI Literacy: Development and Validation of the AI Competency Objective Scale (AICOS) (No. arXiv:2503.12921). arXiv. https://doi.org/10.48550/arXiv.2503.12921

https://osf.io/ehk8u/files/osfstorage?view_only=df9a6ea06d1446659437a73946f68e5c



# AI General Scales

## Survey Questions from Sindermann et al. (2021)

Sindermann, C., Sha, P., Zhou, M., Wernicke, J., Schmitt, H. S., Li, M., Sariyska, R., Stavrou, M., Becker, B., & Montag, C. (2021). Assessing the Attitude Towards Artificial Intelligence: Introduction of a Short Measure in German, Chinese, and English Language. *KI - Künstliche Intelligenz, 35*(1), 109–118. https://doi.org/10.1007/s13218-020-00689-0

https://static-content.springer.com/esm/art%3A10.1007%2Fs13218-020-00689-0/MediaObjects/13218_2020_689_MOESM1_ESM.pdf


## AI Attitude Scale (AIAS-4 Scale)

Grassini, S. (2023). Development and validation of the AI attitude scale (AIAS-4): a brief measure of general attitude toward artificial intelligence. Frontiers in Psychology, 14. https://doi.org/10.3389/fpsyg.2023.1191628


## Survey Instruments from Stein et al. (2024)

Stein, J.-P., Messingschlager, T., Gnambs, T., Hutmacher, F., & Appel, M. (2024). Attitudes towards AI: Measurement and associations with personality. Scientific Reports, 14(1), 2909. https://doi.org/10.1038/s41598-024-53335-2

https://osf.io/3j67a/files/osfstorage#


# AI Attitudes in Germany (Supplement) - Survey Instruments

Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., & Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. Telematics and Informatics, 98, 102265. https://doi.org/10.1016/j.tele.2025.102265


## Survey Questions and Scenarios from Lee et al. (2024) - Combined Sources

Lee, E., Pataranutaporn, P., Amores, J., & Maes, P. (2024). *Super-intelligence or Superstition? Exploring Psychological Factors Influencing Belief in AI Predictions about Personal Behavior* (No. arXiv:2408.06602). arXiv. https://doi.org/10.48550/arXiv.2408.06602 

https://github.com/mitmedialab/ai-superstition


## Appendix A: Objective measurement scale (Weber et al., 2023)

Weber, P., Pinski, M., & Baum, L. (2023). Toward an Objective Measurement of AI Literacy. https://aisel.aisnet.org/pacis2023/60/


## Survey and Scenario Questions from Chen et al. (2025)

Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., & Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, 1–14. https://doi.org/10.1145/3706599.3719710


## Survey and Scenario Questions from Zhu et al. (2024)

Zhu, Q., Chong, L., Yang, M., & Luo, J. (2024). Reading Users’ Minds from What They Say: An Investigation into LLM-based Empathic Mental Inference. ASME. J. Mech. Des. August 2024; 146(6): 061401. https://doi.org/10.1115/DETC2024-143961 


## Survey Items from Song et al. (2024) - Appendix A.2

Song, T., Tan, Y., Zhu, Z., Feng, Y., & Lee, Y.-C. (2024). Multi-Agents are Social Groups: Investigating Social Influence of Multiple Agents in Human-Agent Interactions. https://doi.org/10.48550/ARXIV.2411.04578


## Survey Components from Ovsyannikova et al. (2025)

Ovsyannikova, D., De Mello, V. O., & Inzlicht, M. (2025). Third-party evaluators perceive AI as more compassionate than expert humans. Communications Psychology, 3(1). https://doi.org/10.1038/s44271-024-00182-6


## Survey Questions and Scenarios from Shang et al. (AI Trust Scale)

Shang, R., & Hsieh, G. (2025). Trusting Your AI Agent Emotionally and Cognitively: Development and Validation of a Semantic Differential Scale for AI Trust. Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society, 1343–1356.

## Trust Perception Scale - AI (TPA)

Jiun-Yin Jian, Bisantz, A. M., & Drury, C. G. (2000). Foundations for an Empirically Determined Scale of Trust in Automated System. International Journal of Cognitive Ergonomics, 4(1), 53. https://doi.org/10.1207/S15327566IJCE0401_04


## Scharowski Trust Survey

Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., & Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No. arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582


## Perceptions on AI by the Citizens of Europe questionnaire (PAICE)

Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., & Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. IEEE Transactions on Artificial Intelligence, 6(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633*


## Gerlich 2025 - Appendix A: Questionnaire

Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. Societies, 15(1), Article 1. https://doi.org/10.3390/soc15010006


## Surveys, Questionnaires, and Prompts from Kim et al. (2024)

Kim, S. S. Y., Liao, Q. V., Vorvoreanu, M., Ballard, S., & Vaughan, J. W. (2024). “I’m Not Sure, But...”: Examining the Impact of Large Language Models’ Uncertainty Expression on User Reliance and Trust (No. arXiv:2405.00623). arXiv. https://doi.org/10.48550/arXiv.2405.00623


## Surveys, questionnaires, and prompts used in Duro et al. (2025) 

Duro, E. S. D., Veltri, G. A., Golino, H., & Stella, M. (2025). Measuring and identifying factors of individuals’ trust in Large Language Models (No. arXiv:2502.21028). arXiv. https://doi.org/10.48550/arXiv.2502.21028


## Questionnaire Items from Laupichler et al. (2023) - SNAIL Development

Laupichler, M. C., Aster, A., Haverkamp, N., & Raupach, T. (2023). Development of the “Scale for the assessment of non-experts’ AI literacy” – An exploratory factor analysis. *Computers in Human Behavior Reports, 12*, 100338. https://doi.org/10.1016/j.chbr.2023.100338

## Morrill & Noetel (2023) Appendix 

Morrill, J., & Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc


## Survey Instrument: General Self-Efficacy Scale for use with Artificial Intelligence (GSE-6AI)

Morales-García, W. C., Sairitupa-Sanchez, L. Z., Morales-García, S. B., & Morales-García, M. (2024). Adaptation and psychometric properties of a brief version of the general self-efficacy scale for use with artificial intelligence (GSE-6AI) among university students. Frontiers in Education, 9. https://doi.org/10.3389/feduc.2024.1293437


## The Scale of Artificial Intelligence Literacy for all (SAIL4ALL)

Soto-Sanfiel, M. T., Angulo-Brunet, A., & Lutz, C. (2024). The Scale of Artificial Intelligence Literacy for all (SAIL4ALL): A Tool for Assessing Knowledge on Artificial Intelligence in All Adult Populations and Settings. OSF. https://doi.org/10.31235/osf.io/bvyku


## AI Attitude Scale (AIAS-4 Scale)

Grassini, S. (2023). Development and validation of the AI attitude scale (AIAS-4): A brief measure of general attitude toward artificial intelligence. *Frontiers in Psychology*, *14*. https://doi.org/10.3389/fpsyg.2023.1191628


## Puppart & Aru (2025) AI Literacy Intervention Study

Puppart, B., & Aru, J. (2025). Short-term AI literacy intervention does not reduce over-reliance on incorrect ChatGPT recommendations (No. arXiv:2503.10556). arXiv. https://doi.org/10.48550/arXiv.2503.10556

## Appendix B: Topline questionnaire

Zhang, B., & Dafoe, A. (2019). Artificial Intelligence: American Attitudes and Trends. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3312874

## The AI Motivation Scale (AIMS)

Li, J., King, R. B., Chai, C. S., Zhai, X., & Lee, V. W. Y. (2025). The AI Motivation Scale (AIMS): A self-determination theory perspective. Journal of Research on Technology in Education. https://www.tandfonline.com/doi/abs/10.1080/15391523.2025.2478424

## Perceived Artificial Intelligence Literacy Questionnaire (PAILQ-6)

Grassini, S. (2024). A Psychometric Validation of the PAILQ-6: Perceived Artificial Intelligence Literacy Questionnaire. Nordic Conference on Human-Computer Interaction, 1–10. https://doi.org/10.1145/3679318.3685359

## Survey Items from Salah et al. (2024)

Salah, M., Alhalbusi, H., Ismail, M. M., & Abdelfattah, F. (2024). Chatting with ChatGPT: Decoding the mind of Chatbot users and unveiling the intricate connections between user perception, trust and stereotype perception on self-esteem and psychological well-being. Current Psychology, 43(9), 7843–7858. https://doi.org/10.1007/s12144-023-04989-0

https://educationaltechnologyjournal.springeropen.com/articles/10.1186/s41239-024-00471-4/tables/6


## Survey/Questionnaire Instrument from Küper et al. (2025)

Küper, A., Lodde, G. C., Livingstone, E., Schadendorf, D., & Krämer, N. (2025). Psychological Factors Influencing Appropriate Reliance on AI-enabled Clinical Decision Support Systems: Experimental Web-Based Study Among Dermatologists. Journal of Medical Internet Research, 27(1), e58660. https://doi.org/10.2196/58660

https://osf.io/87tpu/files/osfstorage#


--------

# Trust Scales

## Trust in Automation (TiA) Questionnaire

Körber, M. (2019). Theoretical Considerations and Development of a Questionnaire to Measure Trust in Automation. In S. Bagnara, R. Tartaglia, S. Albolino, T. Alexander, & Y. Fujita (Eds.), Proceedings of the 20th Congress of the International Ergonomics Association (IEA 2018) (Vol. 823, pp. 13–30). Springer International Publishing. http://link.springer.com/10.1007/978-3-319-96074-6_2
https://github.com/moritzkoerber/TiA_Trust_in_Automation_Questionnaire


## Instructions and Scales from Schulz et al. (2025) PTT Supplement

Scholz, D. D., Kraus ,Johannes, & and Miller, L. (2025). Measuring the Propensity to Trust in Automated Technology: Examining Similarities to Dispositional Trust in Other Humans and Validation of the PTT-A Scale. International Journal of Human–Computer Interaction, 41(2), 970–993. https://doi.org/10.1080/10447318.2024.2307691


## Trust of Automated Systems Test (TOAST)

Wojton, H. M., Porter, D., T Lane, S., Bieber, C., & Madhavan, P. (2020). Initial validation of the trust of automated systems test (TOAST). *The Journal of Social Psychology, 160*(6), 735–750. https://doi.org/10.1080/00224545.2020.1749020


## Trust in AI Scale (TAIS) - Final Items (Study 1 Reduction)

Wischnewski, M., Doebler, P., & Krämer, N. (2025). Development and validation of the Trust in AI Scale (TAIS). OSF. https://doi.org/10.31234/osf.io/eqa9y_v1
https://osf.io/9zp6y/files/osfstorage


## Instruments from Hoffman et al. (2019)

Hoffman, R. R., Mueller, S. T., Klein, G., & Litman, J. (2019). Metrics for Explainable AI: Challenges and Prospects (No. arXiv:1812.04608). arXiv. https://doi.org/10.48550/arXiv.1812.04608


## Questionnaires Used in Perrig et al. (2023)

Perrig, S. A. C., Scharowski, N., & Brühlmann, F. (2023). Trust Issues with Trust Scales: Examining the Psychometric Quality of Trust Measures in the Context of AI. *Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems*, 1–7. https://doi.org/10.1145/3544549.3585808


## General Attitudes towards Artificial Intelligence Scale (GAAIS)

Schepman, A., & and Rodway, P. (2023). The General Attitudes towards Artificial Intelligence Scale (GAAIS): Confirmatory Validation and Associations with Personality, Corporate Distrust, and General Trust. International Journal of Human–Computer Interaction, 39(13), 2724–2741. https://doi.org/10.1080/10447318.2022.2085400


## Surveys and Questionnaires from Smith et al. (2025)

Smith, A., van Wagoner, H. P., Keplinger, K., & Celebi, C. (2025). Navigating AI Convergence in Human–Artificial Intelligence Teams: A Signaling Theory Approach. Journal of Organizational Behavior. https://doi.org/10.1002/job.2856 https://onlinelibrary.wiley.com/doi/pdf/10.1002/job.2856 
https://osf.io/zjwta/?view_only=74a15f71b21c4b0abb69f3e5de543537


## Sun, N. (2023). Delegation to Virtual Agents

Sun, N., Botev, J., Khaluf, Y., & Simoens, P. (2022). Theory of Mind and Delegation to Robotic Virtual Agents. 2022 31st IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), 454–460. https://doi.org/10.1109/RO-MAN53752.2022.9900789


-------


# Energy Scales


## Attari et al. 2010 A Survey on Energy

Attari, S. Z., DeKay, M. L., Davidson, C. I., & Bruine De Bruin, W. (2010). Public perceptions of energy consumption and savings. Proceedings of the National Academy of Sciences, 107(37), 16054–16059

https://www.pnas.org/action/downloadSupplement?doi=10.1073%2Fpnas.1001509107&file=pnas.201001509SI.pdf


## Survey Questions from Marghetis et al. (2019) - Supplementary Information

Marghetis, T., Attari, S. Z., & Landy, D. (2019). Simple interventions can correct misperceptions of home energy use. Nature Energy, 4(10), 874–881. https://doi.org/10.1038/s41560-019-0467-2


## Kantenbacher & Attari 2021 - Supplemental Text

Kantenbacher, J., & Attari, S. Z. (2021). Better rules for judging joules: Exploring how experts make decisions about household energy use. Energy Research & Social Science, 73, 101911. https://doi.org/10.1016/j.erss.2021.101911


# DeWaters & Powers (2011) - Energy Literacy Questionnaire

DeWaters, J. E., & Powers, S. E. (2011). Energy literacy of secondary students in New York State (USA): A measure of knowledge, affect, and behavior. Energy Policy, 39(3), 1699–1710. https://doi.org/10.1016/j.enpol.2010.12.049


## Survey Questions and Experimental Scenarios from He et al. (2024)

He, S., Blasch, J., Robinson, P. J., & van Beukering, P. (2024). Social comparison feedback in decision-making context: Environmental externality levels and psychological traits matter. Ecological Economics, 216, 108047. https://doi.org/10.1016/j.ecolecon.2023.108047



## Canfield SUPPLEMENTAL MATERIALS – DEPENDENT VARIABLES

Canfield, C., Bruine De Bruin, W., & Wong-Parodi, G. (2017). Perceptions of electricity-use communications: Effects of information, format, and individual differences. Journal of Risk Research, 20(9), 1132–1153. https://doi.org/10.1080/13669877.2015.1121909


## Energy Literacy Questionnaire Items (DeWaters et al., 2013)

DeWaters, J., Qaqish, B., Graham, M., & Powers, S. (2013). Designing an Energy Literacy Questionnaire for Middle and High School Youth. The Journal of Environmental Education, 44(1), 56–78. https://doi.org/10.1080/00958964.2012.682615

## Development and Validation of the Energy-Issue Attitude Questionnaire: Relations with Energy Knowledge, Affect, and Behavior

Mei-Shiu, C., Jan, D., & Clarkson University, Potsdam, NY, USA. (2018). Development and Validation of the Energy-Issue Attitude Questionnaire: Relations with Energy Knowledge, Affect, and Behavior. Journal of Advances in Education Research, 3(1). https://doi.org/10.22606/jaer.2018.31003

http://isaac-scientific.com/images/PaperPDF/JAER_100041_2018020109400203155.pdf

## Low Carbon Tech Narratives

Attari, Mishra, Motz, 2025 

https://osf.io/gt46s/


# Survey Instrument Components from Cotton et al. (2021)

Cotton, D. R. E., Zhai, J., Miller, W., Dalla Valle, L., & Winter, J. (2021). Reducing energy demand in China and the United Kingdom: The importance of energy literacy. Journal of Cleaner Production, 278, 123876. https://doi.org/10.1016/j.jclepro.2020.123876



# Numeracy Scales

## Berlin Numeracy Test Formats

Cokely, E. T., Galesic, M., Schulz, E., Ghazal, S., & Garcia-Retamero, R. (2012). Measuring Risk Literacy: The Berlin Numeracy Test. Judgment and Decision Making, 7(1), 25–47. https://doi.org/10.1017/S1930297500001819