# AI Literacy Scales

## MAILS - Meta-Artificial Intelligence Literacy Scale

Carolus, A., Koch, M. J., Straka, S., Latoschik, M. E., & Wienrich, C. (2023). MAILS - Meta AI literacy scale: Development and testing of an AI literacy questionnaire based on well-founded competency models and psychological change- and meta-competencies. Computers in Human Behavior: Artificial Humans, 1(2), 100014. https://doi.org/10.1016/j.chbah.2023.100014

https://hci.uni-wuerzburg.de/research/MAILS/


## Meta-Artificial Intelligence Literacy Scale – Short Version

Koch, M. J., Carolus, A., Wienrich, C., & Latoschik, M. E. (2024). Meta AI literacy scale: Further validation and development of a short version. *Heliyon, 10*(21), e39686. https://doi.org/10.1016/j.heliyon.2024.e39686

## Survey and Scenario Questions from Tully, Longoni, & Appel (2023)

Tully, S., Longoni, C., & Appel, G. (2023). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. OSF. https://doi.org/10.31234/osf.io/t9u8g


## Rheu & Cho (2025) - Supplementary Materials: Survey Items

Rheu, M. (MJ), & Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, 1–7. https://doi.org/10.1145/3706599.3719681

https://ars-els-cdn-com.proxyiub.uits.iu.edu/content/image/1-s2.0-S0736585325000279-mmc1.pdf


# Appendix 2: AI Literacy Questionnaire (AILQ) Items (Ng et al., 2024)

Ng, D. T. K., Wu, W., Leung, J. K. L., Chiu, T. K. F., & Chu, S. K. W. (2024). Design and validation of the AI literacy questionnaire: The affective, behavioural, cognitive and ethical approach. British Journal of Educational Technology, 55(3), 1082–1104. https://doi.org/10.1111/bjet.13411


## Surveys and Questionnaires from Jin et al. (2024)

Jin, Y., Martinez-Maldonado, R., Gašević, D., & Yan, L. (2024). *GLAT: The Generative AI Literacy Assessment Test* (No. arXiv:2411.00283). arXiv. https://doi.org/10.48550/arXiv.2411.00283




# AI General Scales

## Survey Questions from Sindermann et al. (2021)

Sindermann, C., Sha, P., Zhou, M., Wernicke, J., Schmitt, H. S., Li, M., Sariyska, R., Stavrou, M., Becker, B., & Montag, C. (2021). Assessing the Attitude Towards Artificial Intelligence: Introduction of a Short Measure in German, Chinese, and English Language. *KI - Künstliche Intelligenz, 35*(1), 109–118. https://doi.org/10.1007/s13218-020-00689-0

https://static-content.springer.com/esm/art%3A10.1007%2Fs13218-020-00689-0/MediaObjects/13218_2020_689_MOESM1_ESM.pdf


## AI Attitude Scale (AIAS-4 Scale)

Grassini, S. (2023). Development and validation of the AI attitude scale (AIAS-4): a brief measure of general attitude toward artificial intelligence. Frontiers in Psychology, 14. https://doi.org/10.3389/fpsyg.2023.1191628


## Survey Instruments from Stein et al. (2024)

Stein, J.-P., Messingschlager, T., Gnambs, T., Hutmacher, F., & Appel, M. (2024). Attitudes towards AI: Measurement and associations with personality. Scientific Reports, 14(1), 2909. https://doi.org/10.1038/s41598-024-53335-2

https://osf.io/3j67a/files/osfstorage#


# AI Attitudes in Germany (Supplement) - Survey Instruments

Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., & Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. Telematics and Informatics, 98, 102265. https://doi.org/10.1016/j.tele.2025.102265


## Survey Questions and Scenarios from Lee et al. (2024) - Combined Sources

Lee, E., Pataranutaporn, P., Amores, J., & Maes, P. (2024). *Super-intelligence or Superstition? Exploring Psychological Factors Influencing Belief in AI Predictions about Personal Behavior* (No. arXiv:2408.06602). arXiv. https://doi.org/10.48550/arXiv.2408.06602 

https://github.com/mitmedialab/ai-superstition


## Appendix A: Objective measurement scale (Weber et al., 2023)

Weber, P., Pinski, M., & Baum, L. (2023). Toward an Objective Measurement of AI Literacy. https://aisel.aisnet.org/pacis2023/60/


## Survey and Scenario Questions from Chen et al. (2025)

Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., & Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, 1–14. https://doi.org/10.1145/3706599.3719710


## Survey and Scenario Questions from Zhu et al. (2024)

Zhu, Q., Chong, L., Yang, M., & Luo, J. (2024). Reading Users’ Minds from What They Say: An Investigation into LLM-based Empathic Mental Inference. ASME. J. Mech. Des. August 2024; 146(6): 061401. https://doi.org/10.1115/DETC2024-143961 


## Survey Items from Song et al. (2024) - Appendix A.2

Song, T., Tan, Y., Zhu, Z., Feng, Y., & Lee, Y.-C. (2024). Multi-Agents are Social Groups: Investigating Social Influence of Multiple Agents in Human-Agent Interactions. https://doi.org/10.48550/ARXIV.2411.04578


## Survey Components from Ovsyannikova et al. (2025)

Ovsyannikova, D., De Mello, V. O., & Inzlicht, M. (2025). Third-party evaluators perceive AI as more compassionate than expert humans. Communications Psychology, 3(1). https://doi.org/10.1038/s44271-024-00182-6


## Survey Questions and Scenarios from Shang et al. (AI Trust Scale)

Shang, R., & Hsieh, G. (2025). Trusting Your AI Agent Emotionally and Cognitively: Development and Validation of a Semantic Differential Scale for AI Trust. Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society, 1343–1356.

## Trust Perception Scale - AI (TPA)

Jiun-Yin Jian, Bisantz, A. M., & Drury, C. G. (2000). Foundations for an Empirically Determined Scale of Trust in Automated System. International Journal of Cognitive Ergonomics, 4(1), 53. https://doi.org/10.1207/S15327566IJCE0401_04


## Scharowski Trust Survey

Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., & Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No. arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582


## Perceptions on AI by the Citizens of Europe questionnaire (PAICE)

Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., & Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. IEEE Transactions on Artificial Intelligence, 6(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633*


## Gerlich 2025 - Appendix A: Questionnaire

Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. Societies, 15(1), Article 1. https://doi.org/10.3390/soc15010006


## Surveys, Questionnaires, and Prompts from Kim et al. (2024)

Kim, S. S. Y., Liao, Q. V., Vorvoreanu, M., Ballard, S., & Vaughan, J. W. (2024). “I’m Not Sure, But...”: Examining the Impact of Large Language Models’ Uncertainty Expression on User Reliance and Trust (No. arXiv:2405.00623). arXiv. https://doi.org/10.48550/arXiv.2405.00623


## Surveys, questionnaires, and prompts used in Duro et al. (2025) 

Duro, E. S. D., Veltri, G. A., Golino, H., & Stella, M. (2025). Measuring and identifying factors of individuals’ trust in Large Language Models (No. arXiv:2502.21028). arXiv. https://doi.org/10.48550/arXiv.2502.21028


## Questionnaire Items from Laupichler et al. (2023) - SNAIL Development

Laupichler, M. C., Aster, A., Haverkamp, N., & Raupach, T. (2023). Development of the “Scale for the assessment of non-experts’ AI literacy” – An exploratory factor analysis. *Computers in Human Behavior Reports, 12*, 100338. https://doi.org/10.1016/j.chbr.2023.100338

## Morrill & Noetel (2023) Appendix 

Morrill, J., & Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc


## Survey Instrument: General Self-Efficacy Scale for use with Artificial Intelligence (GSE-6AI)

Morales-García, W. C., Sairitupa-Sanchez, L. Z., Morales-García, S. B., & Morales-García, M. (2024). Adaptation and psychometric properties of a brief version of the general self-efficacy scale for use with artificial intelligence (GSE-6AI) among university students. Frontiers in Education, 9. https://doi.org/10.3389/feduc.2024.1293437


## The Scale of Artificial Intelligence Literacy for all (SAIL4ALL)

Soto-Sanfiel, M. T., Angulo-Brunet, A., & Lutz, C. (2024). The Scale of Artificial Intelligence Literacy for all (SAIL4ALL): A Tool for Assessing Knowledge on Artificial Intelligence in All Adult Populations and Settings. OSF. https://doi.org/10.31235/osf.io/bvyku


## AI Attitude Scale (AIAS-4 Scale)

Grassini, S. (2023). Development and validation of the AI attitude scale (AIAS-4): A brief measure of general attitude toward artificial intelligence. *Frontiers in Psychology*, *14*. https://doi.org/10.3389/fpsyg.2023.1191628


## Puppart & Aru (2025) AI Literacy Intervention Study

Puppart, B., & Aru, J. (2025). Short-term AI literacy intervention does not reduce over-reliance on incorrect ChatGPT recommendations (No. arXiv:2503.10556). arXiv. https://doi.org/10.48550/arXiv.2503.10556

## Appendix B: Topline questionnaire

Zhang, B., & Dafoe, A. (2019). Artificial Intelligence: American Attitudes and Trends. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3312874



# The AI Motivation Scale (AIMS)

Li, J., King, R. B., Chai, C. S., Zhai, X., & Lee, V. W. Y. (2025). The AI Motivation Scale (AIMS): A self-determination theory perspective. Journal of Research on Technology in Education. https://www.tandfonline.com/doi/abs/10.1080/15391523.2025.2478424



# Perceived Artificial Intelligence Literacy Questionnaire (PAILQ-6)

Grassini, S. (2024). A Psychometric Validation of the PAILQ-6: Perceived Artificial Intelligence Literacy Questionnaire. Nordic Conference on Human-Computer Interaction, 1–10. https://doi.org/10.1145/3679318.3685359



--------

# Trust Scales

## Trust in Automation (TiA) Questionnaire

Körber, M. (2019). Theoretical Considerations and Development of a Questionnaire to Measure Trust in Automation. In S. Bagnara, R. Tartaglia, S. Albolino, T. Alexander, & Y. Fujita (Eds.), Proceedings of the 20th Congress of the International Ergonomics Association (IEA 2018) (Vol. 823, pp. 13–30). Springer International Publishing. http://link.springer.com/10.1007/978-3-319-96074-6_2
https://github.com/moritzkoerber/TiA_Trust_in_Automation_Questionnaire


# Instructions and Scales from Schulz et al. (2025) PTT Supplement

Scholz, D. D., Kraus ,Johannes, & and Miller, L. (2025). Measuring the Propensity to Trust in Automated Technology: Examining Similarities to Dispositional Trust in Other Humans and Validation of the PTT-A Scale. International Journal of Human–Computer Interaction, 41(2), 970–993. https://doi.org/10.1080/10447318.2024.2307691


# Trust of Automated Systems Test (TOAST)

Wojton, H. M., Porter, D., T Lane, S., Bieber, C., & Madhavan, P. (2020). Initial validation of the trust of automated systems test (TOAST). *The Journal of Social Psychology, 160*(6), 735–750. https://doi.org/10.1080/00224545.2020.1749020




-------


# Energy Scales


## Attari et al. 2010 A Survey on Energy

Attari, S. Z., DeKay, M. L., Davidson, C. I., & Bruine De Bruin, W. (2010). Public perceptions of energy consumption and savings. Proceedings of the National Academy of Sciences, 107(37), 16054–16059

https://www.pnas.org/action/downloadSupplement?doi=10.1073%2Fpnas.1001509107&file=pnas.201001509SI.pdf


## Survey Questions from Marghetis et al. (2019) - Supplementary Information

Marghetis, T., Attari, S. Z., & Landy, D. (2019). Simple interventions can correct misperceptions of home energy use. Nature Energy, 4(10), 874–881. https://doi.org/10.1038/s41560-019-0467-2


## Kantenbacher & Attari 2021 - Supplemental Text

Kantenbacher, J., & Attari, S. Z. (2021). Better rules for judging joules: Exploring how experts make decisions about household energy use. Energy Research & Social Science, 73, 101911. https://doi.org/10.1016/j.erss.2021.101911


# DeWaters & Powers (2011) - Energy Literacy Questionnaire

DeWaters, J. E., & Powers, S. E. (2011). Energy literacy of secondary students in New York State (USA): A measure of knowledge, affect, and behavior. Energy Policy, 39(3), 1699–1710. https://doi.org/10.1016/j.enpol.2010.12.049


## Survey Questions and Experimental Scenarios from He et al. (2024)

He, S., Blasch, J., Robinson, P. J., & van Beukering, P. (2024). Social comparison feedback in decision-making context: Environmental externality levels and psychological traits matter. Ecological Economics, 216, 108047. https://doi.org/10.1016/j.ecolecon.2023.108047



## Canfield SUPPLEMENTAL MATERIALS – DEPENDENT VARIABLES

Canfield, C., Bruine De Bruin, W., & Wong-Parodi, G. (2017). Perceptions of electricity-use communications: Effects of information, format, and individual differences. Journal of Risk Research, 20(9), 1132–1153. https://doi.org/10.1080/13669877.2015.1121909


## Energy Literacy Questionnaire Items (DeWaters et al., 2013)

DeWaters, J., Qaqish, B., Graham, M., & Powers, S. (2013). Designing an Energy Literacy Questionnaire for Middle and High School Youth. The Journal of Environmental Education, 44(1), 56–78. https://doi.org/10.1080/00958964.2012.682615

## Development and Validation of the Energy-Issue Attitude Questionnaire: Relations with Energy Knowledge, Affect, and Behavior

Mei-Shiu, C., Jan, D., & Clarkson University, Potsdam, NY, USA. (2018). Development and Validation of the Energy-Issue Attitude Questionnaire: Relations with Energy Knowledge, Affect, and Behavior. Journal of Advances in Education Research, 3(1). https://doi.org/10.22606/jaer.2018.31003

http://isaac-scientific.com/images/PaperPDF/JAER_100041_2018020109400203155.pdf

## Low Carbon Tech Narratives

Attari, Mishra, Motz, 2025 

https://osf.io/gt46s/


# Survey Instrument Components from Cotton et al. (2021)

Cotton, D. R. E., Zhai, J., Miller, W., Dalla Valle, L., & Winter, J. (2021). Reducing energy demand in China and the United Kingdom: The importance of energy literacy. Journal of Cleaner Production, 278, 123876. https://doi.org/10.1016/j.jclepro.2020.123876



# Numeracy Scales

## Berlin Numeracy Test Formats

Cokely, E. T., Galesic, M., Schulz, E., Ghazal, S., & Garcia-Retamero, R. (2012). Measuring Risk Literacy: The Berlin Numeracy Test. Judgment and Decision Making, 7(1), 25–47. https://doi.org/10.1017/S1930297500001819




----------


# Energy Survey Instruments Summaries

## 1.1. Attari et al. (2010) Public Perceptions of Energy Consumption and Savings

*   **Reference:** Attari, S. Z., DeKay, M. L., Davidson, C. I., & Bruine De Bruin, W. (2010). Public perceptions of energy consumption and savings. *Proceedings of the National Academy of Sciences, 107*(37), 16054–16059. [https://www.pnas.org/action/downloadSupplement?doi=10.1073%2Fpnas.1001509107&file=pnas.201001509SI.pdf](https://www.pnas.org/action/downloadSupplement?doi=10.1073%2Fpnas.1001509107&file=pnas.201001509SI.pdf)
*   **Description:** This survey investigates public understanding of energy consumption, the effectiveness of energy-saving behaviors, and perceptions of energy use by household appliances and activities. It also assesses attitudes towards the environment and climate change, numeracy, and demographics.
*   **Constructs:** Energy-Saving Behavior Effectiveness (Open-ended), Household Energy Consumption Breakdown (Percentage Estimates), Appliance Energy Use Estimation (Relative to 100W bulb), Energy Savings Estimation (Household & Transportation, Relative Scales), Transportation Energy Use Ranking, Recycling/Manufacturing Energy Use Ranking, Perceived Ease/Difficulty of Energy-Saving Behaviors, Environmental Attitudes (NEP Scale items), Climate Change Attitudes, Numeracy (Math Questions), Demographics (including energy-related habits).
*   **Details:** Mix of open-ended questions, percentage estimations, relative numerical estimations (using 100 units reference points for bulbs and car), ranking tasks, Likert-scale attitude questions (7-point agreement), Likert-scale ease/difficulty questions (8-point including "Do it already"), multiple-choice demographic questions, and basic numeracy questions.

## 1.2. Attari et al. (2025) Low Carbon Tech Narratives Survey

*   **Reference:** Attari, Mishra, Motz (2025). Low Carbon Tech Narratives. OSF Preprints. [https://osf.io/gt46s/](https://osf.io/gt46s/)
*   **Description:** This survey explores public familiarity, perceptions, attitudes, and knowledge regarding electric vehicles (EVs) and heat pumps (HPs). It investigates barriers and motivations for adoption and assesses beliefs about the truthfulness of various positive and negative statements concerning these technologies.
*   **Constructs:** Familiarity (EVs, HPs), Ownership/Use (EVs, HPs), Purchase Consideration (EVs, HPs), Barriers/Motivations (Open-ended), Knowledge/Beliefs (True/False statements about practicality, climate impact, cost, maintenance, performance, infrastructure, etc.), Confidence in Knowledge, Perceived Statement Framing (Positive/Negative), Attitudes towards Transition (EVs, HPs), Exposure (Driving, Charging, Seeing, Social Network), Perceived Adoption Rates (Percentage Estimates), Community Discussion, Climate Change Perceptions, Social Media Use, Demographics.
*   **Details:** Uses definitions for EVs and HPs. Includes familiarity scales (5-point), Yes/No questions, open-ended text input for barriers/motivations, True/False questions with confidence sliders, multiple-choice questions, Likert scales (5-point agreement for attitudes, 4-point importance for climate change), percentage estimations, demographic questions (including political orientation, social media use, home ownership, utility bill payment). Ends with debriefing links.

## 1.3. Canfield et al. (2017) Perceptions of Electricity-Use Communications

*   **Reference:** Canfield, C., Bruine De Bruin, W., & Wong-Parodi, G. (2017). Perceptions of electricity-use communications: Effects of information, format, and individual differences. *Journal of Risk Research, 20*(9), 1132–1153. [https://doi.org/10.1080/13669877.2015.1121909](https://doi.org/10.1080/13669877.2015.1121909)
*   **Description:** This study evaluates how different formats of electricity usage information (historical use, neighbor comparison, appliance breakdown) affect user understanding, preferences, and intentions to reduce electricity use. It also includes a measure of energy literacy.
*   **Constructs:** Understanding (Historical Use, Neighbor Comparison, Appliance Breakdown - True/False questions), Preferences (Clarity, Ease of Understanding, Liking, Usability, Desire for Inclusion, Usefulness, Professionalism, Trust, Desire for Detail, Helpfulness for Change - 7-point scales), Intentions to Reduce Electricity Use (7-point scale), Energy Literacy (Knowledge - multiple choice).
*   **Details:** Uses True/False questions to assess understanding of presented information (with some questions focusing on specific values). Preference and intention questions use 7-point Likert-type scales. Energy literacy is measured using multiple-choice questions adapted from DeWaters & Powers (2011).

## 1.4. Chiu & DeWaters (2018) Energy-Issue Attitude Questionnaire (EIAQ)

*   **Reference:** Mei-Shiu, C., Jan, D., & Clarkson University, Potsdam, NY, USA. (2018). Development and Validation of the Energy-Issue Attitude Questionnaire: Relations with Energy Knowledge, Affect, and Behavior. *Journal of Advances in Education Research, 3*(1). [https://doi.org/10.22606/jaer.2018.31003](https://doi.org/10.22606/jaer.2018.31003)
*   **Description:** This study develops and validates the Energy-Issue Attitude Questionnaire (EIAQ) for Taiwanese students, examining relationships between attitudes, energy literacy (knowledge, affect, behavior), and demographics.
*   **Constructs:**
    *   **EIAQ:** Energy-Saving Knowledge, Carbon-Reducing Knowledge, Having Lifestyle, Being Lifestyle, Questioning Authorities, Conforming to Authorities, Technology Approaches, Nature Approaches, Future Goals, Present Goals.
    *   **ELQ (Adapted):** Energy Knowledge, Energy Affect, Energy Behavior.
    *   **Demographics:** Gender, Grade, Parents' Vocation, Cultural/Material Household Possessions (PISA items).
*   **Details:**
    *   **EIAQ:** 40 items across 10 constructs, rated on a 5-point Likert scale (1=Disagree strongly to 5=Agree strongly). Some items are reverse-scored.
    *   **ELQ:** Adapted from DeWaters & Powers (2011) for Taiwanese context. Knowledge (33 multiple-choice items), Affect (17 Likert items), Behavior (8 Likert items). Specific items not listed in the paper. Response scales likely 5-point Likert.
    *   Demographic questions adapted from PISA 2009.

## 1.5. Cotton et al. (2021) Energy Literacy in China and UK

*   **Reference:** Cotton, D. R. E., Zhai, J., Miller, W., Dalla Valle, L., & Winter, J. (2021). Reducing energy demand in China and the United Kingdom: The importance of energy literacy. *Journal of Cleaner Production, 278*, 123876. [https://doi.org/10.1016/j.jclepro.2020.123876](https://doi.org/10.1016/j.jclepro.2020.123876)
*   **Description:** This survey compares energy literacy (knowledge, attitudes, behaviours) among university students in China and the UK, adapting a previous instrument and incorporating the NEP scale.
*   **Constructs:** Demographics (Gender, Subject of Study), Context (Source of energy knowledge, Most important national issue), Perceived Knowledge, Factual Energy Knowledge (Renewables, Efficiency, Technical, Sources, Saving Behaviours), Attitudes (Self-efficacy, Trust in government/scientists, Policy support, Environmental concern, Climate change beliefs/causes, Sustainability benefits), New Ecological Paradigm (NEP Scale), Behaviours (Conservation actions, Sustainable purchasing, Information seeking, Social influence).
*   **Details:** 40 questions total. Includes ranking/selection for sources/issues, a 4-point self-rated knowledge scale, multiple-choice/factual knowledge questions (specifics not listed), 5-point Likert scale (1=strongly disagree to 5=strongly agree) for attitude items, the NEP scale (items not listed), and a 4-point frequency scale (1=never to 4=always) for behaviour items.

## 1.6. DeWaters & Powers (2011) Energy Literacy Questionnaire (ELQ)

*   **Reference:** DeWaters, J. E., & Powers, S. E. (2011). Energy literacy of secondary students in New York State (USA): A measure of knowledge, affect, and behavior. *Energy Policy, 39*(3), 1699–1710. [https://doi.org/10.1016/j.enpol.2010.12.049](https://doi.org/10.1016/j.enpol.2010.12.049)
*   **Description:** This paper details the development and validation of the Energy Literacy Questionnaire (ELQ) for US secondary school students (Middle School and High School versions), measuring cognitive, affective, and behavioral dimensions of energy literacy.
*   **Constructs:** Self-Assessment (Perceived Knowledge, Self-description of energy use, Family discussion frequency), Energy Knowledge (Cognitive: Saving Energy, Forms/Conversions/Units, Home Energy Use, Basic Concepts, Resources, Renewable Analysis, Environmental Impacts, Societal Issues), Energy Attitudes (Affective: Importance of energy education/saving, Self-efficacy, Worry/Responsibility, Support for policies/renewables, Environmental tradeoffs), Energy Behaviors (Behavioral: Conservation actions at home, Encouraging others, Sustainable purchasing).
*   **Details:** Includes initial self-assessment questions (5-point scales). Cognitive subscale uses 5-option multiple-choice items (30 MS, 38 HS). Affective subscale uses 17 items on a 5-point Likert scale (Strongly Disagree to Strongly Agree). Behavioral subscale uses 10 items on a 5-point frequency scale (e.g., Never to Almost Always).

## 1.7. DeWaters et al. (2013) Designing an Energy Literacy Questionnaire

*   **Reference:** DeWaters, J., Qaqish, B., Graham, M., & Powers, S. (2013). Designing an Energy Literacy Questionnaire for Middle and High School Youth. *The Journal of Environmental Education, 44*(1), 56–78. [https://doi.org/10.1080/00958964.2012.682615](https://doi.org/10.1080/00958964.2012.682615)
*   **Description:** This paper further details the refinement and validation process for the Energy Literacy Questionnaire (ELQ) for middle and high school students, building on the DeWaters & Powers (2011) work. It provides a more extensive list of items considered and retained.
*   **Constructs:** Energy Knowledge (Cognitive: Various topics including definitions, units, conversions, efficiency, resources, environmental impacts, home use, conservation), Energy Attitudes (Affective: Importance, responsibility, self-efficacy, policy support, tradeoffs), Energy Behaviors (Behavioral: Conservation actions, encouraging others, purchasing).
*   **Details:** Provides a list of 50 cognitive items (multiple-choice, correct answer indicated), 17 affective items (5-point Likert scale: strongly disagree to strongly agree), and 10 behavioral items (5-point Likert scale: frequency-based, e.g., almost always to never). Indicates which items were specific to High School (HS) or Middle School (MS) forms or newly added. Item numbers refer to the original item pool.

## 1.8. He et al. (2024) Social Comparison Feedback Experiment

*   **Reference:** He, S., Blasch, J., Robinson, P. J., & van Beukering, P. (2024). Social comparison feedback in decision-making context: Environmental externality levels and psychological traits matter. *Ecological Economics, 216*, 108047. [https://doi.org/10.1016/j.ecolecon.2023.108047](https://doi.org/10.1016/j.ecolecon.2023.108047)
*   **Description:** This study uses an online experiment to investigate the effect of different types of social comparison feedback (standard social norm vs. tangible emissions feedback) on pro-environmental purchase decisions under varying environmental externality levels. It also measures psychological traits and climate beliefs.
*   **Constructs:** Norm-Following (Allocation task - Phase 1), Purchase Decision (Modified Dictator Game with environmental externality - Phase 2), Climate Change Beliefs & Concerns (Conviction, General Concern, Direct Concern), Competitiveness Tendency, Risk Preference, Time Preference, Loss Aversion, Socio-Demographics, Experience with Social Comparison Feedback.
*   **Details:** Multi-phase experiment. Phase 1: Norm-following task (allocating balls). Phase 2: Multi-round purchase task with varying CO2 emissions per unit (low/high externality) and different feedback conditions (self-feedback, social comparison, tangible emissions comparison) presented in later rounds. Payoffs based on points, environmental outcome based on CO2 offsets. Phase 3: Survey measuring psychological traits (7-point Likert for competitiveness/loss aversion, 0-10 scale for risk/time), climate beliefs (7-point Likert), demographics, and prior experience with social comparison info (Yes/No, multiple selection).

## 1.9. Kantenbacher & Attari (2021) Expert Decision-Making on Household Energy

*   **Reference:** Kantenbacher, J., & Attari, S. Z. (2021). Better rules for judging joules: Exploring how experts make decisions about household energy use. *Energy Research & Social Science, 73*, 101911. [https://doi.org/10.1016/j.erss.2021.101911](https://doi.org/10.1016/j.erss.2021.101911)
*   **Description:** This study uses interviews and surveys with energy experts (Electrical Engineers, Physicists, Energy Analysts) to explore how they estimate and compare household energy use, focusing on the heuristics (rules of thumb) they employ.
*   **Constructs:** Energy Thinking (Open-ended), Energy Reduction Actions (Open-ended), Heuristics Used (Derived from talk-aloud choice task), Appliance Energy Use Estimation (Relative to 100W bulb), Perceived Accuracy of Heuristics (Survey).
*   **Details:** Mixed-methods approach.
    *   **Interviews:** Included open-ended questions, a talk-aloud warm-up, a pairwise/multi-option choice task ("Which uses least energy?"), and a numerical estimation task (relative to 100 units for a 100W bulb). Verbal reports from the choice task were coded to extract heuristics (using categories: External Cues, Function, Components).
    *   **Survey (Survey 2):** Experts rated the accuracy of a list of 35 potential energy heuristics (including novice heuristics from van den Broek & Walker, 2019 and expert-derived ones) on a 4-point scale (1=mostly inaccurate to 4=mostly accurate). Included an open-ended question for additional rules.

## 1.10. Marghetis et al. (2019) Correcting Misperceptions of Home Energy Use

*   **Reference:** Marghetis, T., Attari, S. Z., & Landy, D. (2019). Simple interventions can correct misperceptions of home energy use. *Nature Energy, 4*(10), 874–881. [https://doi.org/10.1038/s41560-019-0467-2](https://doi.org/10.1038/s41560-019-0467-2)
*   **Description:** This study investigates whether simple interventions (providing scale-use information and/or an explicit heuristic) can improve people's estimations of household appliance energy consumption and their choices in energy-saving scenarios.
*   **Constructs:** Appliance Energy Use Estimation (Watt-hours), Behavioral Choice Task (BCT - selecting least energy-intensive option), Conceptual Understanding (Difference between energy/electricity, power/energy), National Energy Perceptions (Percentages: electricity share, generation sources, residential sector share), Policy Support, Climate Change Beliefs, Environmental Attitudes (NEP Scale), Numeracy/Cognitive Reflection Test (CRT), Demographics (including technical training, energy use habits).
*   **Details:** Experimental design with four conditions (Control, Scale-Use info, Explicit Heuristic, Both).
    *   **Estimation Task:** Estimate Wh for 1 hour of use for 36 appliances (numeric entry), compared to a 100W bulb reference.
    *   **BCT:** 20 pairwise choices about energy use/savings (binary selection).
    *   **Interventions:** Text provided before estimation/BCT.
    *   **Other Measures:** Yes/No/Don't Know and open-ended questions for conceptual understanding; percentage estimates for national energy; Likert scales for policy support (4-point), climate importance (4-point), NEP (5-point); multiple-choice for climate beliefs; standard numeracy/CRT items (numeric entry); various demographic questions. Confidence rating (4-point) after estimation. Open-ended questions on estimation strategies for specific items.



--------




# Summary Report of AI-Related Survey Instruments

This report organizes and summarizes various survey instruments related to Artificial Intelligence (AI), drawing from the provided list of references and associated details. The instruments are categorized based on their primary focus.

---

## 1. AI Literacy Scales

Instruments designed to measure knowledge, understanding, skills, and competencies related to AI.

### 1.1. MAILS - Meta-Artificial Intelligence Literacy Scale
* **Reference:** Carolus, A., Koch, M. J., Straka, S., Latoschik, M. E., & Wienrich, C. (2023). MAILS - Meta AI literacy scale: Development and testing of an AI literacy questionnaire based on well-founded competency models and psychological change- and meta-competencies. *Computers in Human Behavior: Artificial Humans, 1*(2), 100014. https://doi.org/10.1016/j.chbah.2023.100014
* **Description:** A comprehensive scale measuring AI literacy based on competency models and psychological meta-competencies.
* **Constructs:** AI Literacy (Use & Apply, Know & Understand, Detect AI, AI Ethics), Create AI, AI Self-Efficacy (Problem-Solving, Learning), AI Self-Competency (Persuasion Literacy, Emotion Regulation).
* **Details:** 34 items rated on an 11-point scale (0-10).
* **Link:** https://hci.uni-wuerzburg.de/research/MAILS/

### 1.2. MAILS - Short Version
* **Reference:** Koch, M. J., Carolus, A., Wienrich, C., & Latoschik, M. E. (2024). Meta AI literacy scale: Further validation and development of a short version. *Heliyon, 10*(21), e39686. https://doi.org/10.1016/j.heliyon.2024.e39686
* **Description:** A validated short form of the MAILS.
* **Constructs:** AI Literacy (Detect, Apply, Understand, Ethics), Create AI, AI Self-Efficacy (Learning, Problem-Solving), AI Self-Competency (Persuasion Literacy, Emotion Regulation).
* **Details:** 10 items rated on an 11-point scale (0-10). 

### 1.3. Tully, Longoni, & Appel (2023) AI Literacy Measure (25-Item)
* **Reference:** Tully, S., Longoni, C., & Appel, G. (2023). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. OSF. https://doi.org/10.31234/osf.io/t9u8g (Used in Studies 2, 4, 6)
* **Description:** Measures objective AI literacy through multiple-choice questions covering various AI concepts.
* **Details:** 25 multiple-choice questions. Full items available in Appendix A of the source file (`Tully25_AI_Survey.md`).

### 1.4. Tully, Longoni, & Appel (2023) AI Literacy Measure (17-Item)
* **Reference:** Tully, S., Longoni, C., & Appel, G. (2023). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. OSF. https://doi.org/10.31234/osf.io/t9u8g (Used in Studies 3, 5, 7)
* **Description:** A shorter version measuring objective AI literacy through multiple-choice questions, structured by competencies from Long and Magerko (2020).
* **Details:** 17 multiple-choice questions. Full items available in Appendix B of the source file (`Tully25_AI_Survey.md`).

### 1.5. Rheu & Cho (2025) AI Literacy Measure
* **Reference:** Rheu, M. (MJ), & Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–7. https://doi.org/10.1145/3706599.3719681
* **Description:** Combines items from Ng et al. (2024) and Pinski & Benlian (2023) to measure AI literacy in college students using LLMs.
* **Constructs:** Self-Efficacy, Cognitive Learning, AI Technology Knowledge, AI-Steps Knowledge.
* **Details:** Items rated on a 7-point Likert scale (Strongly disagree to Strongly agree). 

### 1.6. AI Literacy Questionnaire (AILQ)
* **Reference:** Ng, D. T. K., Wu, W., Leung, J. K. L., Chiu, T. K. F., & Chu, S. K. W. (2024). Design and validation of the AI literacy questionnaire: The affective, behavioural, cognitive and ethical approach. *British Journal of Educational Technology, 55*(3), 1082–1104. https://doi.org/10.1111/bjet.13411
* **Description:** Measures AI literacy across affective, behavioral, cognitive, and ethical dimensions.
* **Constructs:** Affective (Intrinsic Motivation, Self-Efficacy, Confidence), Behavioral (Commitment, Collaboration), Cognitive (Know & Understand, Apply/Evaluate/Create), Ethical (AI Ethics).
* **Details:** Developed with an initial pool of items, validated version likely uses a subset. Response scale typically Likert-type. 

### 1.7. Weber et al. (2023) Objective Measurement Scale
* **Reference:** Weber, P., Pinski, M., & Baum, L. (2023). Toward an Objective Measurement of AI Literacy. *PACIS 2023 Proceedings*. https://aisel.aisnet.org/pacis2023/60/
* **Description:** Measures objective AI literacy using multiple-choice questions covering socio-user, socio-creator/evaluator, technical-user, and technical-creator/evaluator aspects.
* **Details:** 16 multiple-choice questions. 

### 1.8. Scale for the assessment of non-experts’ AI literacy (SNAIL)
* **Reference:** Laupichler, M. C., Aster, A., Haverkamp, N., & Raupach, T. (2023). Development of the “Scale for the assessment of non-experts’ AI literacy” – An exploratory factor analysis. *Computers in Human Behavior Reports, 12*, 100338. https://doi.org/10.1016/j.chbr.2023.100338
* **Description:** Measures self-perceived AI literacy among non-experts. Developed via Delphi study and EFA.
* **Details:** Final scale has 31 items (reduced from 39) rated on a 7-point Likert scale (Strongly disagree to Strongly agree). Initial 39 items available in the source file (`Laupichler_AI_Survey.md`).

### 1.9. Morrill & Noetel (2023) Subjective AI Literacy Scale
* **Reference:** Morrill, J., & Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc
* **Description:** A brief subjective measure of AI literacy adapted from Laupichler et al. (2023).
* **Details:** 6 items rated on a 7-point Likert scale (Strongly disagree to Strongly agree), plus an attention check. Items available in the source file (`Morrill23_AI_Survey.md`).

### 1.10. Morrill & Noetel (2023) Objective AI Literacy Scale
* **Reference:** Morrill, J., & Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc
* **Description:** A brief objective measure of AI literacy developed for the study, partly adapted from Weber et al. (2023).
* **Details:** 5 multiple-choice questions with an "I'm not sure" option. Items available in the source file (`Morrill23_AI_Survey.md`).

### 1.11. The Scale of Artificial Intelligence Literacy for all (SAIL4ALL)
* **Reference:** Soto-Sanfiel, M. T., Angulo-Brunet, A., & Lutz, C. (2024). The Scale of Artificial Intelligence Literacy for all (SAIL4ALL): A Tool for Assessing Knowledge on Artificial Intelligence in All Adult Populations and Settings. OSF. https://doi.org/10.31235/osf.io/bvyku
* **Description:** Assesses AI knowledge suitable for diverse adult populations, covering fundamental concepts, capabilities, mechanisms, and ethics.
* **Themes:** What is AI? (Recognizing/Understanding, General/Narrow), What can AI do?, How does AI Work? (Representation, Reasoning, Learning, Data, Human Role, Action/Reaction, Sensors), How should AI be used? (Ethics).
* **Details:** 59 items. Can be used with True/False or a 5-point confidence scale. Full items available in the source file (`Soto-Sanfiel_AI_Survey.md`).

### 1.12. Puppart & Aru (2025) AI Literacy Self-Assessment
* **Reference:** Puppart, B., & Aru, J. (2025). Short-term AI literacy intervention does not reduce over-reliance on incorrect ChatGPT recommendations (No. arXiv:2503.10556). arXiv. https://doi.org/10.48550/arXiv.2503.10556
* **Description:** A brief self-assessment used post-intervention to gauge perceived changes in understanding of ChatGPT's workings, limitations/risks, and wise usage.
* **Details:** 3 items rated on a 4-point forced-choice Likert scale. Items available in the source file (`Puppart_Aru25_AI_Survey.md`).

---

## 2. AI Attitude Scales

Instruments measuring general feelings, beliefs, and evaluations towards AI.

### 2.1. Attitude Towards Artificial Intelligence (ATAI) Scale
* **Reference:** Sindermann, C., Sha, P., Zhou, M., Wernicke, J., Schmitt, H. S., Li, M., Sariyska, R., Stavrou, M., Becker, B., & Montag, C. (2021). Assessing the Attitude Towards Artificial Intelligence: Introduction of a Short Measure in German, Chinese, and English Language. *KI - Künstliche Intelligenz, 35*(1), 109–118. https://doi.org/10.1007/s13218-020-00689-0
* **Description:** A brief scale measuring general attitude towards AI, focusing on fear, trust, and perceived impact (benefit/destruction, job losses).
* **Details:** 5 items rated on an 11-point Likert scale (0-10). 

### 2.2. AI Attitude Scale (AIAS-4)
* **Reference:** Grassini, S. (2023). Development and validation of the AI attitude scale (AIAS-4): a brief measure of general attitude toward artificial intelligence. *Frontiers in Psychology, 14*. https://doi.org/10.3389/fpsyg.2023.1191628
* **Description:** A very brief measure of general positive attitude toward AI.
* **Details:** 4 items rated on a 10-point Likert scale (1-10). 

### 2.3. Attitudes Towards Artificial Intelligence Scale (ATTARI-12)
* **Reference:** Stein, J.-P., Messingschlager, T., Gnambs, T., Hutmacher, F., & Appel, M. (2024). Attitudes towards AI: Measurement and associations with personality. *Scientific Reports, 14*(1), 2909. https://doi.org/10.1038/s41598-024-53335-2
* **Description:** Measures attitudes towards AI across cognitive, affective, and behavioral dimensions, balanced for positive and negative valence.
* **Constructs:** Cognitive (Positive/Negative), Affective (Positive/Negative), Behavioral (Positive/Negative).
* **Details:** 12 items rated on a 5-point Likert scale (Strongly disagree to Strongly agree). Items available in the source file (`Stein24_AI_Survey.md`).

### 2.4. Gnambs et al. (2025) Domain-Specific AI Attitudes
* **Reference:** Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., & Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. *Telematics and Informatics, 98*, 102265. https://doi.org/10.1016/j.tele.2025.102265
* **Description:** Measures cognitive, affective, and behavioral attitudes towards AI within specific domains (Work, Healthcare, Education).
* **Details:** 9 items (3 per domain) rated on a 5-point scale (0-4), plus a "cannot answer" option. Items available in the source file (`Gnabs_AI_Survey.md`).

### 2.5. Perceptions on AI by the Citizens of Europe questionnaire (PAICE) - Attitude Items
* **Reference:** Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., & Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. *IEEE Transactions on Artificial Intelligence, 6*(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633
* **Description:** Includes items assessing general attitude towards AI (Q2) and attitudes towards AI use in specific sectors (Q8: Healthcare, Insurance, Agriculture, Finance, Military, Law Enforcement, Environmental, Transportation, Manufacturing, HR).
* **Details:** Items rated on 5-point scales (Strongly disapprove to Strongly approve). Full questionnaire available in the source file (`Scantamburlo_AI_Survey.md`).

### 2.6. Zhang & Dafoe (2019) Support for Developing AI
* **Reference:** Zhang, B., & Dafoe, A. (2019). Artificial Intelligence: American Attitudes and Trends. *SSRN Electronic Journal*. https://doi.org/10.2139/ssrn.3312874
* **Description:** Measures general support or opposition to the development of AI after presenting examples of AI applications.
* **Details:** 1 item rated on a 5-point scale (Strongly oppose to Strongly support), plus "I don't know". Item available in the source file (`Zhang_Dafoe_AI_Survey.md`).

---

## 3. AI Trust & Reliance Scales

Instruments measuring trust, confidence, and reliance on AI systems or automation in general.

### 3.1. Scale of Trust in Automated Systems (Jian, Bisantz, & Drury, 2000) / Trust Perception Scale - AI (TPA)
* **Reference:** Jian, J.-Y., Bisantz, A. M., & Drury, C. G. (2000). Foundations for an Empirically Determined Scale of Trust in Automated System. *International Journal of Cognitive Ergonomics, 4*(1), 53–71. https://doi.org/10.1207/S15327566IJCE0401_04 (Also used/cited in Adams et al., 2003; Scharowski et al., 2025)
* **Description:** A widely used scale measuring trust in automated systems, often adapted for AI contexts (as TPA). Assesses aspects like deceptiveness, suspicion, confidence, integrity, dependability, reliability, and familiarity.
* **Details:** 12 items rated on a 7-point scale (Not at all to Extremely).

### 3.2. Shang et al. (2025) Affective and Cognitive Trust Scale
* **Reference:** Shang, R., & Hsieh, G. (2025). Trusting Your AI Agent Emotionally and Cognitively: Development and Validation of a Semantic Differential Scale for AI Trust. *Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society*, 1343–1356.
* **Description:** A semantic differential scale designed to measure distinct cognitive (reliability, competence, understandability, integrity) and affective (empathy, sensitivity, care, altruism, responsiveness, etc.) dimensions of trust in AI agents.
* **Constructs:** Cognitive Trust (18 items), Affective Trust (9 items).
* **Details:** 27 bipolar adjective pairs rated on a 7-point semantic differential scale (-3 to +3). Items available in the source file (`Shang25_AI_Trust_Scale.md`).

### 3.3. Trust in Automation (TiA) Questionnaire
* **Reference:** Körber, M. (2019). Theoretical Considerations and Development of a Questionnaire to Measure Trust in Automation. In S. Bagnara, et al. (Eds.), *Proceedings of the 20th Congress of the International Ergonomics Association (IEA 2018)* (Vol. 823, pp. 13–30). Springer. http://link.springer.com/10.1007/978-3-319-96074-6_2
* **Description:** Measures trust in automation based on theoretical considerations, including reliability/competence, understanding/predictability, familiarity, intention of developers, and propensity to trust.
* **Constructs:** Reliability/Competence, Understanding/Predictability, Familiarity, Intention of Developers, Propensity to Trust, Trust in Automation.
* **Details:** 19 items rated on a 5-point Likert scale (Strongly disagree to Strongly agree), with some reverse-coded. 

### 3.4. Propensity to Trust in Automated Technology (PTT-A) Scale
* **Reference:** Scholz, D. D., Kraus, J., & Miller, L. (2025). Measuring the Propensity to Trust in Automated Technology: Examining Similarities to Dispositional Trust in Other Humans and Validation of the PTT-A Scale. *International Journal of Human–Computer Interaction, 41*(2), 970–993. https://doi.org/10.1080/10447318.2024.2307691
* **Description:** Measures an individual's general tendency (disposition) to trust automated technology, mirroring scales for trust in humans. Includes a short form.
* **Constructs:** Trusting Stance, Competence, Benevolence, Integrity.
* **Details:** 14 items (6 bolded for short scale) rated on a 5-point Likert scale (Strongly disagree to Strongly agree), with some reverse-coded. 

### 3.5. Trust-In-LLMs Index (TILLMI)
* **Reference:** Duro, E. S. D., Veltri, G. A., Golino, H., & Stella, M. (2025). Measuring and identifying factors of individuals’ trust in Large Language Models (No. arXiv:2502.21028). arXiv. https://doi.org/10.48550/arXiv.2502.21028
* **Description:** Measures trust specifically in Large Language Models (LLMs), focusing on closeness/ease of sharing and reliance/competence.
* **Constructs:** Closeness with LLMs, Reliance on LLMs.
* **Details:** Final scale has 6 items (reduced from 8) rated on a 5-point frequency scale (Never experience it to Always experience it). Items available in the source file (`Duro_AI_Survey.md`).

### 3.6. Morrill & Noetel (2023) Trust in AI Scale
* **Reference:** Morrill, J., & Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc
* **Description:** Measures willingness to trust, rely on, and depend on AI systems, adapted from Gillespie et al. (2023).
* **Details:** 6 items rated on a 7-point Likert scale (Completely Unwilling to Completely Willing). Items available in the source file (`Morrill23_AI_Survey.md`).

### 3.7. Kim et al. (2024) Trust Beliefs & Intentions
* **Reference:** Kim, S. S. Y., Liao, Q. V., Vorvoreanu, M., Ballard, S., & Vaughan, J. W. (2024). “I’m Not Sure, But...”: Examining the Impact of Large Language Models’ Uncertainty Expression on User Reliance and Trust (No. arXiv:2405.00623). arXiv. https://doi.org/10.48550/arXiv.2405.00623
* **Description:** Measures trust beliefs (competence, honesty, benevolence) and trust intentions (reliance, comfort acting on info) towards a specific AI system experienced in a task.
* **Constructs:** TrustBelief, TrustIntention.
* **Details:** 10 items (6 belief, 4 intention) rated on a 5-point Likert scale (Strongly disagree to Strongly agree), some reverse-coded.

### 3.8. Scharowski et al. (2025) Single Trust/Use Items
* **Reference:** Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., & Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No. arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582
* **Description:** Simple, direct measures of trust and willingness to use an AI after observing it in a specific scenario (Self-Driving Vehicle or Chatbot).
* **Details:** 2 items ("I would trust...", "I would use...") rated on a 7-point Likert scale (Fully disagree to Fully agree). 

### 3.9. Scharowski et al. (2025) Situation-Specific Trust Scales (STS-AD / STS-Chatbot)
* **Reference:** Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., & Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No. arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582
* **Description:** Measures trust and evaluation of AI performance within the specific context of the observed scenario (Self-Driving Vehicle or Chatbot). Includes comparative judgment (vs. self), perceived safety, and appropriateness.
* **Details:** 6 items for STS-AD, 8 items for STS-Chatbot, rated on a 7-point Likert scale (Fully disagree to Fully agree). 

### 3.10. Trust in Explainable AI (TXAI) Items (Adapted by Scharowski et al., 2025)
* **Reference:** Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., & Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No. arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582 (Adapted from original source, likely related to explainability literature).
* **Description:** Measures confidence, predictability, reliability, safety, efficiency, wariness, perceived competence (vs. novice human), and liking for decision-making regarding an observed AI.
* **Details:** 8 items rated on a 5-point Likert scale (I disagree strongly to I agree strongly). 

### 3.11. PAICE Questionnaire - Trust Items
* **Reference:** Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., & Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. *IEEE Transactions on Artificial Intelligence, 6*(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633
* **Description:** Includes items assessing the importance of various measures (laws, certifications, monitoring, codes of conduct, transparency, diverse teams) for increasing trust in AI (Q12), and trust in different entities (governments, EU, universities, CSOs, tech companies, social media) to ensure AI serves public interest (Q14).
* **Details:** Items rated on 5-point scales (Not important at all to Very important; Not at all to A lot). Full questionnaire available in the source file (`Scantamburlo_AI_Survey.md`).

### 3.12. Gerlich (2025) AI Trust Item
* **Reference:** Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. *Societies, 15*(1), Article 1. https://doi.org/10.3390/soc15010006
* **Description:** Includes a single item assessing trust in recommendations provided by AI tools.
* **Details:** Item 9: "I trust the recommendations provided by AI tools." Rated on a 6-point Likert scale (Strongly Disagree to Strongly Agree). 

### 3.13. Madsen & Gregor (2000) Human-Computer Trust Instrument
* **Reference:** Madsen, M., & Gregor, S. (2000). Measuring Human-Computer Trust. *Proceedings of the 11th Australasian Conference on Information Systems*. (As cited/used in Adams et al., 2003).
* **Description:** Measures trust in computer systems (potentially applicable to AI) across dimensions of reliability, technical competence, understandability, faith, and personal attachment.
* **Constructs:** Perceived Reliability, Perceived Technical Competence, Perceived Understandability, Faith, Personal Attachment.
* **Details:** 25 items (5 per construct). Original response scale not specified in the Adams et al. 

### 3.14. SHAPE Automation Trust Index (SATI v0.3)
* **Reference:** Goillau, P., Kelly, M., Boardman, J., & Jeannot, E. (2001). *SHAPE Automation Trust Index (SATI v0.3)*. Eurocontrol Experimental Centre. (As cited/used in Adams et al., 2003).
* **Description:** A two-part index assessing trust and confidence in a simulated automated system before and after interaction, including reasons for trust/confidence levels.
* **Details:** Includes rating scales (Bad-OK-Good, None-OK-Full confidence), Yes/No trust question, and open-ended reasons. Administered pre- and post-simulation. 
---

## 4. AI Perception & Experience Scales

Instruments measuring how AI is perceived, user experiences, and related psychological constructs.

### 4.1. Chen et al. (2025) Mental Capacity Attribution
* **Reference:** Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., & Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–14. https://doi.org/10.1145/3706599.3719710
* **Description:** Measures the extent to which people attribute various mental capacities (related to Body, Heart, Mind) to LLMs. Based on Weisman et al. (2017) with additions.
* **Details:** 40 items rated on a 7-point capability scale (Not at all capable to Highly capable). 

### 4.2. Chen et al. (2025) Anthropomorphism Measure
* **Reference:** Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., & Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–14. https://doi.org/10.1145/3706599.3719710
* **Description:** Measures perceived human-likeness of LLMs.
* **Details:** 1 item rated on a 7-point scale (Not human-like at all to Very human-like), plus an open-ended explanation. 
### 4.3. Kim et al. (2024) Anthropomorphism Measure
* **Reference:** Kim, S. S. Y., Liao, Q. V., Vorvoreanu, M., Ballard, S., & Vaughan, J. W. (2024). “I’m Not Sure, But...”: Examining the Impact of Large Language Models’ Uncertainty Expression on User Reliance and Trust (No. arXiv:2405.00623). arXiv. https://doi.org/10.48550/arXiv.2405.00623
* **Description:** Measures impression of an AI system using semantic differential scales related to human-likeness.
* **Details:** 4 bipolar adjective pairs (Fake-Natural, Machinelike-Humanlike, Unconscious-Conscious, Artificial-Lifelike) rated on a 5-point scale. 

### 4.4. General Self-Efficacy Scale for use with Artificial Intelligence (GSE-6AI)
* **Reference:** Morales-García, W. C., Sairitupa-Sanchez, L. Z., Morales-García, S. B., & Morales-García, M. (2024). Adaptation and psychometric properties of a brief version of the general self-efficacy scale for use with artificial intelligence (GSE-6AI) among university students. *Frontiers in Education, 9*. https://doi.org/10.3389/feduc.2024.1293437
* **Description:** Measures perceived self-efficacy in using AI, adapted from the general self-efficacy scale.
* **Details:** 6 items rated on a 4-point scale (Not at all true to Exactly true).

### 4.5. Chen et al. (2025) Self-Efficacy Items
* **Reference:** Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., & Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–14. https://doi.org/10.1145/3706599.3719710
* **Description:** Includes items measuring confidence in learning to program LLMs and getting LLMs to perform desired tasks.
* **Details:** 2 items rated on a 7-point Likert scale (Strongly Disagree to Strongly Agree). 

### 4.6. Gnambs et al. (2025) AI Experience & Familiarity
* **Reference:** Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., & Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. *Telematics and Informatics, 98*, 102265. https://doi.org/10.1016/j.tele.2025.102265
* **Description:** Assesses familiarity (how often heard of) and past 12-month experience with specific AI scenarios/types (virtual assistants, recommender systems, robots, predictive analytics, monitoring, content generation) across different domains (workplace, healthcare, education).
* **Details:** Questions rated on 5-point scales (0-4). 

### 4.7. PAICE Questionnaire - Awareness & Competency Items
* **Reference:** Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., & Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. *IEEE Transactions on Artificial Intelligence, 6*(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633
* **Description:** Includes items assessing self-rated competency on AI (Q1), perceived impact on daily life (Q3, Q15), awareness of European AI initiatives (Q4), awareness of interacting with AI (Q5), and identification of AI in common applications (Q6).
* **Details:** Various scales (5-point Likert, Yes/No, Multiple Choice). 

### 4.8. Lee et al. (2024) Prediction Believability Evaluation
* **Reference:** Lee, E., Pataranutaporn, P., Amores, J., & Maes, P. (2024). *Super-intelligence or Superstition? Exploring Psychological Factors Influencing Belief in AI Predictions about Personal Behavior* (No. arXiv:2408.06602). arXiv. https://doi.org/10.48550/arXiv.2408.06602
* **Description:** Measures the perceived validity, personalization, reliability, and usefulness of predictions about personal behavior attributed to different sources (AI, Astrology, Personality).
* **Constructs:** Validity, Personalization, Reliability, Usefulness.
* **Details:** 8 items (2 per construct) rated on a 7-point Likert scale (Strongly disagree to Strongly agree). 

### 4.9. Lee et al. (2024) Perception of Prediction Methods
* **Reference:** Lee, E., Pataranutaporn, P., Amores, J., & Maes, P. (2024). *Super-intelligence or Superstition? Exploring Psychological Factors Influencing Belief in AI Predictions about Personal Behavior* (No. arXiv:2408.06602). arXiv. https://doi.org/10.48550/arXiv.2408.06602
* **Description:** Measures agreement with statements about the accuracy of predictions based on personality type, astrology, AI models, and past behavior.
* **Details:** 4 items rated on a 7-point Likert scale (Strongly disagree to Strongly agree). 

### 4.10. Ovsyannikova et al. (2025) Perceived Compassion & Responsiveness
* **Reference:** Ovsyannikova, D., De Mello, V. O., & Inzlicht, M. (2025). Third-party evaluators perceive AI as more compassionate than expert humans. *Communications Psychology, 3*(1). https://doi.org/10.1038/s44271-024-00182-6
* **Description:** Measures third-party evaluations of compassion (reflecting emotion, compassionate, impersonal) and responsiveness (understanding, validation, caring) in responses (from humans or AI) to empathy prompts.
* **Details:** Items rated on a 5-point Likert scale (Strongly Disagree to Strongly Agree). 

### 4.11. Fang et al. (2025) Emotional Dependence & Problematic Use
* **Reference:** Fang, C. M., Liu, A. R., Danry, V., Lee, E., Chan, S. W. T., Pataranutaporn, P., Maes, P., Phang, J., Lampe, M., Ahmad, L., & Agarwal, S. (2025). How AI and Human Behaviors Shape Psychosocial Effects of Chatbot Use: A Longitudinal Randomized Controlled Study (No. arXiv:2503.17473). arXiv. https://doi.org/10.48550/arXiv.2503.17473
* **Description:** Measures emotional dependence on AI chatbots (ADS-9 adapted) and problematic use patterns (PCUS).
* **Constructs:** Emotional Dependence, Problematic Use.
* **Details:** Items rated on a 5-point Likert scale (Disagree to Agree). 

### 4.12. Fang et al. (2025) Impressions of Agent(s)
* **Reference:** Fang, C. M., Liu, A. R., Danry, V., Lee, E., Chan, S. W. T., Pataranutaporn, P., Maes, P., Phang, J., Lampe, M., Ahmad, L., & Agarwal, S. (2025). How AI and Human Behaviors Shape Psychosocial Effects of Chatbot Use: A Longitudinal Randomized Controlled Study (No. arXiv:2503.17473). arXiv. https://doi.org/10.48550/arXiv.2503.17473
* **Description:** Measures user impressions of AI agent(s) after interaction, focusing on understanding, expertise, balance, inspiration, intelligence, and likeability.
* **Details:** 6 items rated on a 7-point Likert scale.

### 4.13. Complacency-Potential Rating Scale
* **Reference:** Singh, I. L., Molloy, R., & Parasuraman, R. (1993). Automation-induced "complacency": Development of the complacency-potential rating scale. *The International Journal of Aviation Psychology, 3*(2), 111-121. (As cited/used in Adams et al., 2003).
* **Description:** Measures potential for complacency when interacting with automated systems across various domains (library, surgery, banking, aviation, VCRs, medicine). Assesses trust, perceived reliability, safety, ease of use, and job satisfaction aspects.
* **Details:** 20 items rated on a 5-point Likert scale (Strongly disagree to Strongly agree). 

### 4.14. Gerlich (2025) Cognitive Offloading & Critical Thinking Items
* **Reference:** Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. *Societies, 15*(1), Article 1. https://doi.org/10.3390/soc15010006
* **Description:** Includes items measuring reliance on external tools (search engines, devices) for information retrieval and memory (Cognitive Offloading), and self-reported critical evaluation habits regarding information sources, including AI (Critical Thinking).
* **Details:** Items rated on 6-point frequency or Likert scales. 

### 4.15. Rheu & Cho (2025) Machine Heuristics & Credibility
* **Reference:** Rheu, M. (MJ), & Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–7. https://doi.org/10.1145/3706599.3719681
* **Description:** Measures perception of LLMs as expert, objective, and accurate (Machine Heuristics), and overall perceived credibility (Credibility).
* **Constructs:** Machine Heuristics (Expert, Objective, Accurate), Credibility.
* **Details:** Machine Heuristics uses 12 items on a 7-point Likert scale. Credibility uses 4 items on a 7-point semantic differential scale (-3 to +3).

### 4.16. Song et al. (2024) Social Influence Items
* **Reference:** Song, T., Tan, Y., Zhu, Z., Feng, Y., & Lee, Y.-C. (2024). Multi-Agents are Social Groups: Investigating Social Influence of Multiple Agents in Human-Agent Interactions. https://doi.org/10.48550/ARXIV.2411.04578
* **Description:** Measures perceived informational (persuasion-based) and normative (compliance-based) social influence exerted by AI agent(s) during a discussion task.
* **Constructs:** Informational Influence, Normative Influence.
* **Details:** 4 items rated on a 7-point Likert scale, plus open-ended questions. 

### 4.17. Zhu et al. (2024) Goal Interpretation & Needs Attribution
* **Reference:** Zhu, Q., Chong, L., Yang, M., & Luo, J. (2024). Reading Users’ Minds from What They Say: An Investigation into LLM-based Empathic Mental Inference. *ASME. J. Mech. Des. August 2024; 146*(6): 061401. https://doi.org/10.1115/DETC2024-143961
* **Description:** A task-based measure where participants (users or designers interpreting user comments) articulate goals at different levels (task, sub-action, overarching) and attribute these goals to fundamental psychological needs.
* **Details:** Involves open-ended goal generation and rating goal attribution to 13 needs on a 5-point scale (Not attributed at all to Highly attributed). 

---

## 5. AI Usage & Intention Scales

Instruments focused on measuring frequency, patterns, and intentions regarding AI use.

### 5.1. Gnambs et al. (2025) Future AI Experience Intentions
* **Reference:** Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., & Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. *Telematics and Informatics, 98*, 102265. https://doi.org/10.1016/j.tele.2025.102265
* **Description:** Assesses desired future experience (intention to use) with specific AI scenarios/types (virtual assistants, recommender systems, robots, predictive analytics, monitoring, content generation) across different domains (workplace, healthcare, education).
* **Details:** Question rated on a 5-point scale (0=none to 4=very much). 

### 5.2. Gerlich (2025) AI Tool Usage Items
* **Reference:** Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. *Societies, 15*(1), Article 1. https://doi.org/10.3390/soc15010006
* **Description:** Includes items measuring frequency of AI tool use for information/problem solving and extent of reliance on AI for decision-making.
* **Details:** Items 6 & 7 rated on a 6-point scale (Never/Not at all to Always/Completely). Items available in the source file (`Gerlich25_Survey.md`).

### 5.3. Tully, Longoni, & Appel (2023) AI Receptivity Measures
* **Reference:** Tully, S., Longoni, C., & Appel, G. (2023). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. OSF. https://doi.org/10.31234/osf.io/t9u8g
* **Description:** Uses various measures across studies to assess AI receptivity, including:
    * **Adoption Readiness:** Agreement with statements about AI's impact, benefits, and trustworthiness (Study 1, 5). 4 items, Yes/No or 7-point Likert scale.
    * **Propensity to Use Generative AI:** Likelihood of using GenAI for specific academic assignments (Study 2). 4 scenarios rated on a 5-point scale of usage depth.
    * **Past AI Usage:** Frequency of using specific AI tools in the last six months (Study 3). 5 tool types rated on a 5-point frequency scale.
    * **Relative Preference (Human vs. AI):** Preference for human or AI agent for various tasks (Study 4, 6, 7). Multiple tasks rated on a 7-point preference scale.
* **Details:** Specific items and scales vary by study. 

### 5.4. Rheu & Cho (2025) Fact-checking Behavior
* **Reference:** Rheu, M. (MJ), & Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–7. https://doi.org/10.1145/3706599.3719681
* **Description:** Measures the frequency of engaging in specific fact-checking behaviors (verifying credentials, checking currency, considering source reputation, using other search engines, seeking opinions) when using LLMs.
* **Details:** 5 items rated on a 7-point frequency scale (Never to Always). 








--------

# 1 AI Literacy Scales

### 1.1 MAILS – *Meta-Artificial Intelligence Literacy Scale*

Carolus et al. (2023) introduced a 72-item battery (60 literacy + 12 psychological meta-competence items).  Factor analyses yielded seven first-order facets—*Use & Apply*, *Understand*, *Detect*, *Create*, *Ethics*, *AI Self-Efficacy*, and *AI Self-Management*—plus a higher-order literacy factor ([arXiv][1]).  Items use 11-point Likert response anchors; Cronbach’s α for subscales ranged .79–.92.  All items are freely available via the authors’ OSF/ArXiv materials.

### 1.2 MAILS-Short (10 items)

Koch et al. (2024) distilled the original scale to ten indicators representing the same seven domains; the abbreviated form retains acceptable composite reliability (ω =.83) and strict measurement invariance across four validation samples ([HCI Downloads][2]).

### 1.3 AILQ – *AI Literacy Questionnaire*

Ng et al. (2024) validated a 32-item self-report covering *Affective, Behavioural, Cognitive,* and *Ethical* dimensions (8 items each).  A second-order CFA supported the four-factor structure (CFI =.95; RMSEA =.05) with student samples in Hong Kong ([ResearchGate][3]).

### 1.4 SNAIL (38 items)

Laupichler et al. (2023) produced an expert-elicited item bank for non-experts.  No factorial solution was reported, so psychometric quality remains provisional ([CEUR-WS][4]).

### 1.5 MAILS-related Objective Test (AICOS)

Weber et al. (2023) proposed an 11-point performance-style test aligned with MAILS’ domains; convergent validity with self-report literacy is modest (r ≈ .20) ([arXiv][5]).

### 1.6 Tully, Longoni & Appel (2023) Item Set

A 25-item knowledge quiz assessing misconceptions about AI capabilities; higher error rates predict greater *AI receptivity* across six studies ([The ARF][6]).

### 1.7 Rheu & Cho (2025) “Trap of AI Literacy” Battery

College-focused 14-item scale (α =.87) combining conceptual and procedural knowledge; higher scores correlate with **less** fact-checking when using LLMs ([arXiv][7]).

### 1.8 SAIL4ALL (23 items)

Soto-Sanfiel et al. (2024) supply a broad adult-population instrument; preliminary EFA indicates a three-factor solution (Understanding, Ethics, Societal Impact).  Full item list on OSF.

### 1.9 GSE-6-AI

Morales-García et al. (2024) adapted the general self-efficacy scale for AI contexts (6 items; α =.88).

---

# 2 General Attitude Toward AI Scales

### 2.1 ATAI (5 items)

Sindermann et al. (2021) created a bi-dimensional scale (*Acceptance* vs. *Fear*).  Items use 0-10 sliders; α =.80/.84 across German, Chinese, and UK samples ([SpringerLink][8]).

### 2.2 AIAS-4

Grassini (2023) validated a unidimensional 4-item measure capturing perceived societal utility; final CFA fit: CFI =.99, RMSEA =.02 ([Frontiers][9]).

### 2.3 ATTARI-12

Stein et al. (2024) offer a 12-item inventory emphasising anthropomorphic and ethical connotations; Big-Five traits predict scores modestly (|r| < .25) ([Nature][10]).

### 2.4 PAICE (European Barometer)

Scantamburlo et al. (2025) administered a 40-item omnibus survey (knowledge, trust, experience) to 17 k EU citizens; publicly released codebook supports secondary analyses.

### 2.5 Zhang & Dafoe (2019) “American Attitudes & Trends” Top-line

Large-N (n ≈ 2,000) repeat survey employing 28 fixed items; replication datasets available via SSRN.

---

# 3 Trust-Focused Instruments

### 3.1 TPA – *Trust Perception of Automation*

Jian et al. (2000) distilled 12 bipolar adjectives into *Trust* vs. *Distrust* subscales; α =.85.  Widely reused in HRI and displays convergent validity with behavioural reliance ([Finding the “Perfect” Scale][11]).

### 3.2 TiA (Körber, 2019)

Seven subscales (e.g., *Reliability, Predictability, Intention of Developers*).  The GitHub repository hosts English & German PDFs plus scoring manual ([GitHub][12]).

### 3.3 Semantic-Differential AI-Trust (27 items)

Shang & Hsieh (2025) separate **Affective** (15 items) from **Cognitive** (12 items) trust; multi-sample CFA confirms a correlated-two-factor model (CFI =.96) ([Ruoxi Shang][13]).

### 3.4 PTT-A (Propensity to Trust Technology)

Scholz et al. (2025) adapt dispositional trust to automated tech (8 items; α =.83); overlaps ϕ ≈ .40 with interpersonal trust.

### 3.5 TiA-derived *Trust in Automation* Short Forms

Scharowski et al. (2025) benchmark nine variants (including Jian-12, TiA-5) against behavioural calibration; only Jian-12 met scalar invariance.

---

# 4 Other Relevant Measures

| Domain                                  | Example Scales                                                      | Notes                                                                          |
| --------------------------------------- | ------------------------------------------------------------------- | ------------------------------------------------------------------------------ |
| **Mental-Model / Capacity Attribution** | Chen et al. (2025); Song et al. (2024); Ovsyannikova et al. (2025)  | Scenario-based vignettes manipulating agent framing (*machine vs. companion*). |
| **Uncertainty & Reliance**              | Kim et al. (2024) prompts; Duro et al. (2025) trust-factors battery | Focus on LLM confidence displays and user calibration.                         |
| **Self-Efficacy & Offloading**          | Gerlich (2025); Puppart & Aru (2025) pre/post intervention quizzes  | Examine cognitive offloading tendencies after literacy training.               |

---

# 5 Comparative Table

| Instrument      | Construct                                 | Items | Subscales / Factors | Sample α | Link / Access                                |
| --------------- | ----------------------------------------- | ----- | ------------------- | -------- | -------------------------------------------- |
| **MAILS**       | AI literacy (perceived + meta-competence) | 72    | 7                   | .79–.92  | ArXiv OSF ([arXiv][1])                       |
| **MAILS-S**     | AI literacy                               | 10    | 7                   | .77      | PDF ([HCI Downloads][2])                     |
| **AILQ**        | AI literacy                               | 32    | ABC\&E (4)          | .82–.90  | RG PDF ([ResearchGate][3])                   |
| **SNAIL**       | AI literacy (non-experts)                 | 38    | –                   | –        | CEUR ([CEUR-WS][4])                          |
| **ATAI**        | Acceptance/Fear of AI                     | 5     | 2                   | .80/.84  | Springer OA ([SpringerLink][8])              |
| **AIAS-4**      | General attitude                          | 4     | 1                   | .78      | Frontiers ([Frontiers][9])                   |
| **ATTARI-12**   | Attitude toward AI                        | 12    | 3                   | .84      | SciRep ([Nature][10])                        |
| **TPA**         | Trust (automation)                        | 12    | 2                   | .85      | Scale DB ([Finding the “Perfect” Scale][11]) |
| **TiA**         | Trust in automation                       | 20    | 7                   | .70–.90  | GitHub ([GitHub][12])                        |
| **SD-AI-Trust** | Affective/Cognitive trust                 | 27    | 2                   | .93/.91  | PDF ([Ruoxi Shang][13])                      |

*(Blank cells indicate data not reported in publicly available sources.)*

---


