# Instruments from Hoffman et al. (2019)

Hoffman, R. R., Mueller, S. T., Klein, G., & Litman, J. (2019). Metrics for Explainable AI: Challenges and Prospects (No. arXiv:1812.04608). arXiv. https://doi.org/10.48550/arXiv.1812.04608

### Table 3. The CVR version of the Explanation Satisfaction scale (p. 6)

> For each item listed below, please indicate whether you believe that the item is:
> *   Essential for measuring Explanation Satisfaction,
> *   Useful but not Essential, or
> *   Not Necessary for measuring Explanation Satisfaction.
>
> Indicate your response by circling the appropriate number.

| Item                                                                                     | Essential | Useful but not essential | Not Necessary |
| :--------------------------------------------------------------------------------------- | :-------: | :----------------------: | :-----------: |
| 1. I understand this explanation of how the [software, algorithm, tool] works.           |     1     |            2             |       3       |
| 2. This explanation of how the [software, algorithm, tool] works is satisfying.          |     1     |            2             |       3       |
| 3. This explanation of how the [software, algorithm, tool] works has sufficient detail.  |     1     |            2             |       3       |
| 4. This explanation of how the [software, algorithm, tool] works contains irrelevant details. |     1     |            2             |       3       |
| 5. This explanation of how the [software, algorithm, tool] works seems complete.         |     1     |            2             |       3       |
| 6. This explanation of how the [software, algorithm, tool] works tells me how to use it. |     1     |            2             |       3       |
| 7. This explanation of how the [software, algorithm, tool] works is useful to my goals.  |     1     |            2             |       3       |
| 8. This explanation of says how accurate the [software, algorithm, tool] is.           |     1     |            2             |       3       |
| 9. This explanation lets me judge when I should trust and not trust the [software, algorithm, tool] |     1     |            2             |       3       |

---

### Table 6. Example Prompts from ShadowBox Lite Task (p. 15)

> (These prompts are used after presenting an expert explanation, e.g., for cruise control: "The control unit detects the rotation of the drive shaft from a magnet mounted on the drive shaft, and from that can calculate how fast the car is going. The control unit controls an electric motor that is connected to the accelerator linkage. The cruise control adjusts the engine speed until it is disengaged.")

| Prompt                                               | Response Area        |
| :--------------------------------------------------- | :------------------- |
| What is right and helpful about this explanation?    | (User response area) |
| What is problematic or wrong about this explanation? | (User response area) |

---

### Table 7. A Curiosity Checklist (p. 18)

> Why have you asked for an explanation? Check all that apply.

*   [ ] I want to know what the AI just did.
*   [ ] I want to know that I understand this AI system correctly.
*   [ ] I want to understand what the AI will do next.
*   [ ] I want to know why the AI did not make some other decision.
*   [ ] I want to know what the AI would have done if something had been different.
*   [ ] I was surprised by the AI's actions and want to know what I missed.

---

### Appendix A: Explanation Goodness Checklist (p. 35)

> This checklist is a list of the features that make explanations good, according to the research literature. The reference is to the properties of explanations.
>
> The intended use context is for researchers or domain experts to provide an independent, a priori evaluation of the goodness of explanations that are generated by other researchers or by XAI systems.

*   The explanation helps me **understand** how the [software, algorithm, tool] works.
    [ ] YES [ ] NO
*   The explanation of how the [software, algorithm, tool] works is **satisfying**.
    [ ] YES [ ] NO
*   The explanation of the [software, algorithm, tool] sufficiently **detailed**.
    [ ] YES [ ] NO
*   The explanation of how the [software, algorithm, tool] works is sufficiently **complete**.
    [ ] YES [ ] NO
*   The explanation is **actionable**, that is, it helps me know how to use the [software, algorithm, tool]
    [ ] YES [ ] NO
*   The explanation lets me know how **accurate or reliable** the [software, algorithm] is.
    [ ] YES [ ] NO
*   The explanation lets me know how **trustworthy** the [software, algorithm, tool] is.
    [ ] YES [ ] NO

---

### Appendix B: Materials used in the Evaluation of the Discriminant Validity of the Explanation Satisfaction Scale (pp. 36-38)

#### How do cell phones provide directions?

**Explanation Judged a priori to be Relatively "Good"**

> Cell phones use the Global Positioning System of satellites to determine the exact location of the phone.
> A web-based service (such as Google Maps, Apple Maps, etc.) identifies the phone's coordinates along with the desired destination entered by the phone user.
> This information is transmitted to a computer, where The Map Service calculates the best route based on shortest path, but also traffic and other variables.
> The instructions are then sent back to the phone.
> The Map Service monitors the phone's location in real-time, and each step is given to the user based on the phone's proximity to the next step (or checkpoint).

**Explanation Judged a priori to be Relatively "Bad"**

> Cell phones can provide good directions because they have really accurate maps on them.
> The phone downloads the maps from the internet.
> The phone knows where it is and it calculates the shortest route.
> It tries to give step-by-step directions.

#### How does automobile cruise control work?

**Explanation Judged a priori to be Relatively "Good"**

> The speed of the car at the moment you turn on the cruise control is stored in a memory circuit.
> The cruise control device reads the car's speed by a speed sensor that is on the car's drive shaft.
> The cruise control is linked to the engine accelerator, and accelerates the car when it falls below the speed you set, such as when you start to go uphill, for example.
> It can stop accelerating the car when the car is going downhill, but does not apply the brakes to decelerate the car.
> The cruise control also senses when the brake pedal has been depressed, and disengages from the accelerator.

**Explanation Judged a priori to be Relatively "Bad"**

> The vacuum control unit reads the pulse frequency from a magnet mounted on the drive shaft to figure out how fast the car is going.
> A bidirectional screw-drive electric motor that is connected to the accelerator linkage receives the control signal and transmits it to the throttle.
> When you set the cruise control, the engine detects the engine RPM at that point and tries to maintain that engine speed until it is disengaged.
> The cruise control detects the car gear, which it adjusts to allow the engine to maintain a constant RPM.

#### How do computers predict hurricanes?

**Explanation Judged a priori to be Relatively "Good"**

> Computers have a mathematical model of the atmosphere that divides the world into many small regions, each just a few square kilometers.
> Each region is defined in terms of its air pressure, temperature, winds, and moisture.
> The computer calculates what will happen at the boundaries of each region. For example, strong winds in one region will move air into an adjacent region.
> These calculations must be performed for every boundary between all the regions. This allows the prediction of the path a hurricane will take.

**Explanation Judged a priori to be Relatively "Bad"**

> The computers have a database of all previous hurricanes and the paths that they followed.
> Once a hurricane is located, using a satellite image, the computer accesses the database and determines the path that was most frequently taken by hurricanes having that initial location.
> This process is repeated once every hour, tracking the hurricane as it moves.
> The computers can also tell when the winds and rain will impact the land, and that is when the hurricane warnings are issued.

---

### Appendix C: Explanation Satisfaction Scale (pp. 39-40)

1.  From the explanation, I **understand** how the [software, algorithm, tool] works.
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

2.  This explanation of how the [software, algorithm, tool] works is **satisfying**.
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

3.  This explanation of how the [software, algorithm, tool] works has **sufficient detail**.
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

4.  This explanation of how the [software, algorithm, tool] works seems **complete**.
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

5.  This explanation of how the [software, algorithm, tool] works **tells me how to use it**.
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

6.  This explanation of how the [software, algorithm, tool] works is **useful to my goals**.
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

7.  This explanation of the [software, algorithm, tool] shows me how **accurate** the [software, algorithm, tool] is.
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

8.  This explanation lets me judge when I should **trust and not trust** the [software, algorithm, tool].
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

---

### Appendix D: Synopsis of Representative Trust Scales (pp. 41-48)

#### Cahour-Forzy (2009) Scale; Adams, et al. (2003) Scale

> Defined trust (and distrust) as a sentiment resulting from knowledge, beliefs, emotions and other aspects of experience, generating positive or negative expectations concerning the reactions of a system and the interaction with it. Developed for learning to use a cruise control system. Factors: reliability, predictability, efficiency. Assumes considerable experience. Original scale was bipolar "I agree completely" to "I do not agree at all." Items below modified to fit a 7-point Likert form.

1.  What is your **confidence** in the [tool]? Do you have a feeling of **trust** in it?
    | 1 I do not trust it at all | 2 | 3 | 4 | 5 | 6 | 7 I trust it completely |
    | :----------------------- | :-: | :-: | :-: | :-: | :-: | :---------------------: |
    |                          |     |     |     |     |     |                         |

2.  Are the actions of the [tool] **predictable**?
    | 1 It is not at all predictable | 2 | 3 | 4 | 5 | 6 | 7 It is completely predictable |
    | :----------------------------- | :-: | :-: | :-: | :-: | :-: | :--------------------------- |
    |                                |     |     |     |     |     |                              |

3.  Is the [tool] **reliable**? Do you think it is **safe**?
    | 1 It is not at all safe | 2 | 3 | 4 | 5 | 6 | 7 It is completely safe |
    | :---------------------- | :-: | :-: | :-: | :-: | :-: | :---------------------- |
    |                         |     |     |     |     |     |                         |

4.  Is the [tool] **efficient** at what it does?
    | 1 It is not at all efficient | 2 | 3 | 4 | 5 | 6 | 7 It is completely efficient |
    | :--------------------------- | :-: | :-: | :-: | :-: | :-: | :------------------------- |
    |                              |     |     |     |     |     |                            |

#### Adams, et al. (generic automation scale items)

> Used a bipolar rating scale (-5 to +5) and asked participants to rank the importance of the factors.

*   Is the automation tool useful?
*   How reliable is it?
*   How accurately does it work?
*   Can you understand how it works?
*   Do you like using it?
*   How easy is it to use?

#### Jian, et al. Scale (2000)

> Regards trust as a trait. Factors: Fidelity, loyalty, reliability, security, integrity, familiarity. Widely used. (Note: Item 4 is noted as particularly interesting; 'integrity' item is considered problematic; 'familiarity' may not be relevant if user experience is known).

1.  The system is deceptive.
2.  The system behaves in an underhanded manner.
3.  I am suspicious of the system's intent, action, or outputs.
4.  I am wary of the system.
5.  The system's actions will have a harmful or injurious outcome.
6.  I am confident in the system.
7.  The system provides security.
8.  The system has integrity.
9.  The system is dependable.
10. I can trust the system.
11. I am familiar with the system.

#### Madsen-Gregor Scale (2000)

> Defines trust as both affective and cognitive. Factors: reliability, technical competence, understandability, faith, personal attachment. Focused on intelligent decision aids. (Note: Original response format not specified, possibly Likert. High reliability reported. 'Understandability' and 'competence' factors relate to mental models. 'Faith' factor relates to reliance/uncertainty. 'Personal attachment' factor relates to liking.)

| Factor                     | Item                                                                                                         |
| :------------------------- | :----------------------------------------------------------------------------------------------------------- |
| **Perceived Reliability**  | The system always provides the advice I require to make my decision.                                           |
|                            | The system performs reliably.                                                                                  |
|                            | The system responds the same way under the same conditions at different times.                               |
|                            | I can rely on the system to function properly.                                                               |
| **Perceived Technical Competence** | The system analyzes problems consistently.                                                                 |
|                            | The system uses appropriate methods to reach decisions.                                                        |
|                            | The system has sound knowledge about this type of problem built into it.                                     |
|                            | The advice the system produces is as good as that which a highly competent person could produce.             |
|                            | The system correctly uses the information I enter.                                                             |
|                            | The system makes use of all the knowledge and information available to it to produce its solution to the problem. |
| **Perceived Understandability** | I know what will happen the next time I use the system because I understand how it behaves.                |
|                            | I understand how the system will assist me with decisions I have to make.                                    |
|                            | Although I may not know exactly how the system works, I know how to use it to make decisions about the problem. |
|                            | It is easy to follow what the system does.                                                                     |
|                            | I recognize what I should do to get the advice I need from the system the next time I use it.                  |
| **Faith**                  | I believe advice from the system even when I don't know for certain that it is correct.                        |
|                            | When I am uncertain about a decision I believe the system rather than myself.                                  |
|                            | If I am not sure about a decision, I have faith that the system will provide the best solution.              |
|                            | When the system gives unusual advice I am confident that the advice is correct.                                |
|                            | Even if I have no reason to expect the system will be able to solve a difficult problem, I still feel certain that it will. |
| **Personal Attachment**    | I would feel a sense of loss if the system was unavailable and I could not longer use it.                      |
|                            | I feel a sense of attachment to using the system.                                                              |
|                            | I find the system suitable to my style of decision making.                                                     |
|                            | I like using the system for decision making.                                                                   |
|                            | I have a personal preference for making decisions with the system.                                             |

#### Merritt Scale (2011)

> Regards trust as an emotional, attitudinal judgement. Factors: belief, confidence, dependability, propensity to trust, liking. Evaluated in a baggage screening task. Items are similar to Cahour-Fourzy.

1.  I believe the system is a competent performer.
2.  I trust the system.
3.  I have confidence in the advice given by the system.
4.  I can depend on the system.
5.  I can rely on the system to behave in consistent ways.
6.  I can rely on the system to do its best every time I take its advice.

#### Schaefer Scale (2013)

> Developed for human-robot collaboration. Factors: ability, performance. Unique format: estimate the percentage of time the machine would show each behavior. Many items anthropomorphize and may be inappropriate for XAI.

*Prompt: What percentage of the time will this machine (robot)...*

| Appropriate Items (potentially adaptable for XAI) | Inappropriate/Anthropomorphic Items                                |
| :------------------------------------------------ | :----------------------------------------------------------------- |
| Act consistently                                  | Protect people                                                     |
| Function successfully                             | Act as part of the team                                            |
| Have errors                                       | Malfunction                                                        |
| Perform a task better than a novice human user    | Clearly communicate                                                |
| Possess adequate decision-making capability       | Require frequent maintenance                                       |
| Perform exactly as instructed                     | Openly communicate                                                 |
| Make sensible decisions                           | Know the difference between friend and foe                         |
| Tell the truth                                    | Provide feedback                                                   |
| Perform many functions at one time                | Warn people of potential risks in the environment                  |
| Follow directions                                 | Meet the needs of the mission                                      |
| Incompetent                                       | Provide appropriate information                                    |
| Dependable                                        | Communicate with people                                            |
| Reliable                                          | Work best with a team                                              |
| Predictable                                       | Keep classified information secure                                 |
|                                                   | Work in close proximity with people                                |
|                                                   | Considered part of the team                                        |
|                                                   | Friendly                                                           |
|                                                   | Pleasant                                                           |
|                                                   | Unresponsive                                                       |
|                                                   | Autonomous                                                         |
|                                                   | Conscious                                                          |
|                                                   | Lifelike                                                           |
|                                                   | A good teammate                                                    |
|                                                   | Led astray by unexpected changes in the environment                |

#### Singh, et al. Scale (1993)

> Presupposes prior experience (e.g., ATMs). Defines trust as an attitude reflecting potential for complacency. Factors: confidence, reliance, trust, safety, complacency. Merges trust and reliance. Considered not appropriate for initial XAI use. Items overlap with factors in Cahour-Fourzy. (Specific items not fully listed in Appendix D, focuses on factors and context).
>
> *Factor examples:*
> *   Factor 1: Confidence (e.g., medical device reliability)
> *   Factor 2: Reliance (e.g., ATM safeguards, automation making work easier)
> *   Factor 3: Trust (e.g., reliability of library searches, safety of bank transactions)
> *   Factor 4: Safety (e.g., safety of depositing at ATM vs teller)

#### Wang, et al. Scale (2009)

> Used to evaluate trust in a hypothetical "combat identification system". Items adapted from Jian, et al. Scale. Response format not specified (possibly Likert). Some items context-specific. Noteworthy for explicitly referencing deception and mistrust.

*   The aid is deceptive.
*   The aid behaves in an underhanded (concealed) manner.
*   I am suspicious of the aid's outputs.
*   I am wary of the aid.
*   The aid's action will have a harmful or injurious outcome.
*   I am confident in the aid.
*   The aid provides security.
*   The aid is dependable.
*   The aid is reliable.
*   I can trust the aid.
*   I am familiar with the aid.
*   I can trust that *blue* lights indicate soldiers. (Context-specific example)
*   I can trust that *red* lights indicate terrorists. (Context-specific example)

---

### Appendix E: Trust Scale Recommended for XAI (pp. 49-50)

> Asks users directly whether they are confident in the XAI system, whether the XAI system is predictable, reliable, efficient, and believable. Assumes considerable experience using the XAI system. Items adapted primarily from Cahour-Fourzy Scale (2009), with item 6 from Jian et al. (2000), item 7 from Schaefer (2013), and item 8 from Madsen-Gregor (2000). Uses a 5-point Likert scale.

1.  I am **confident** in the [tool]. I feel that it works well.
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

2.  The outputs of the [tool] are very **predictable**.
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

3.  The tool is very **reliable**. I can count on it to be correct all the time.
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

4.  I feel **safe** that when I rely on the [tool] I will get the right answers.
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

5.  The [tool] is **efficient** in that it works very quickly.
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

6.  I am **wary** of the [tool]. (adopted from the Jian, et al. Scale and the Wang, et al. Scale)
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |
    *(Note: This item would likely be reverse-scored)*

7.  The [tool] can perform the task **better than a novice human user**. (adopted from the Schaefer Scale)
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

8.  I **like using** the system for decision making. (adapted from the Madsen-Gregor Scale)
    | 5 I agree strongly | 4 I agree somewhat | 3 I'm neutral about it | 2 I disagree somewhat | 1 I disagree strongly |
    | :----------------: | :----------------: | :--------------------: | :-------------------: | :-------------------: |
    |                    |                    |                        |                       |                       |

***


----

