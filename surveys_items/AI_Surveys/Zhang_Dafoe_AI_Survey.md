# Appendix B: Topline questionnaire

Zhang, B., & Dafoe, A. (2019). Artificial Intelligence: American Attitudes and Trends. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3312874


*Below, we present the survey text as shown to respondents. The numerical codings are shown in parentheses following each answer choice.*

*In addition, we report the topline results: percentages weighted to be representative of the U.S. adult population, the unweighted raw percentages, and the raw frequencies. Note that in all survey experiments, respondents were randomly assigned to each experimental group with equal probability.*

## B.1 Global risks

[All respondents were presented with the following prompt.]

We want to get your opinion about global risks. A “global risk” is an uncertain event or condition that, if it happens, could cause a significant negative impact for at least 10 percent of the world’s population. That is at least 1 in 10 people around the world could experience a significant negative impact.

You will be asked to consider 5 potential global risks.

[Respondents were presented with five items randomly selected from the list below. One item was shown at a time.]

*   **Failure to address climate change:** Continued failure of governments and businesses to pass effective measures to reduce climate change, protect people, and help those impacted by climate change to adapt.
*   **Failure of regional or global governance:** Regional organizations (e.g., the European Union) or global organizations (e.g., the United Nations) are unable to resolve issues of economic, political, or environmental importance.
*   **Conflict between major countries:** Disputes between major countries that lead to economic, military, cyber, or societal conflicts.
*   **Weapons of mass destruction:** Use of nuclear, chemical, biological or radiological weapons, creating international crises and killing large numbers of people.
*   **Large-scale involuntary migration:** Large-scale involuntary movement of people, such as refugees, caused by conflict, disasters, environmental or economic reasons.
*   **Rapid and massive spread of infectious diseases:** The uncontrolled spread of infectious diseases, for instance as a result of resistance to antibiotics, that leads to widespread deaths and economic disruptions.
*   **Water crises:** A large decline in the available quality and quantity of fresh water that harms human health and economic activity.
*   **Food crises:** Large numbers of people are unable to buy or access food.
*   **Harmful consequences of artificial intelligence (AI):** Intended or unintended consequences of artificial intelligence that causes widespread harm to humans, the economy, and the environment.
*   **Harmful consequences of synthetic biology:** Intended or unintended consequences of synthetic biology, such as genetic engineering, that causes widespread harm to humans, the economy, and the environment.
*   **Large-scale cyber attacks:** Large-scale cyber attacks that cause large economic damages, tensions between countries, and widespread loss of trust in the internet.
*   **Large-scale terrorist attacks:** Individuals or non-government groups with political or religious goals that cause large numbers of deaths and major material damage.
*   **Global recession:** Economic decline in several major countries that leads to a decrease in income and high unemployment.
*   **Extreme weather events:** Extreme weather events that cause large numbers of deaths as well as damage to property, infrastructure, and the environment.
*   **Major natural disasters:** Earthquakes, volcanic activity, landslides, tsunamis, or geomagnetic storms that cause large numbers of deaths as well as damage to property, infrastructure, and the environment.

**QUESTION:**

What is the likelihood of [INSERT GLOBAL RISK] happening globally within the next 10 years? Please use the slider to indicate your answer. 0% chance means it will certainly not happen and 100% chance means it will certainly happen.

**ANSWER CHOICES:** [*Note: For analysis, each multiple-choice answer was coded to the mean value across the probabilities in the answer’s range.*]

*   Very unlikely: less than 5% chance (2.5%)
*   Unlikely: 5-20% chance (12.5%)
*   Somewhat unlikely: 20-40% chance (30%)
*   Equally likely as unlikely: 40-60% chance (50%)
*   Somewhat likely: 60-80% chance (70%)
*   Likely: 80-95% chance (87.5%)
*   Very likely: more than 95% chance (97.5%)
*   I don’t know

**QUESTION:**

If [INSERT GLOBAL RISK] were to happen, what would be the size of the negative impact for several countries or industries within the next 10 years?

**ANSWER CHOICES:**

*   Minimal (0)
*   Minor (1)
*   Moderate (2)
*   Severe (3)
*   Catastrophic (4)
*   I don’t know

## B.2 Survey experiment: what the public considers AI, automation, machine learning, and robotics

[Respondents were randomly assigned to one of the four questions. The order of answer choices was randomized, except that “None of the above” was always shown last.]

**QUESTIONS:**

*   In your opinion, which of the following technologies, if any, uses **artificial intelligence (AI)**? Select all the apply.
*   In your opinion, which of the following technologies, if any, uses **automation**? Select all that apply.
*   In your opinion, which of the following technologies, if any, uses **machine learning**? Select all that apply.
*   In your opinion, which of the following technologies, if any, uses **robotics**? Select all that apply.

**ANSWER CHOICES:**

*   Virtual assistants (e.g., Siri, Google Assistant, Amazon Alexa)
*   Smart speakers (e.g., Amazon Echo, Google Home, Apple Homepod)
*   Facebook photo tagging
*   Google Search
*   Recommendations for Netflix movies or Amazon ebooks
*   Google Translate
*   Driverless cars and trucks
*   Social robots that can interact with humans
*   Industrial robots used in manufacturing
*   Drones that do not require a human controller
*   None of the above

## B.3 Knowledge of computer science (CS)/technology

**QUESTION:**

What is your knowledge of computer science/technology? (Select all that apply.)

**ANSWER CHOICES:**

*   I have taken at least one college-level course in computer science.
*   I have a computer science or engineering undergraduate degree.
*   I have a graduate degree in computer science or engineering.
*   I have programming experience.
*   I don’t have any of the educational or work experiences described above.

## B.4 Support for developing AI

[All respondents were presented with the following prompt.]

Next, we would like to ask you questions about your attitudes toward artificial intelligence.

Artificial Intelligence (AI) refers to computer systems that perform tasks or make decisions that usually require human intelligence. AI can perform these tasks or make these decisions without explicit human instructions. Today, AI has been used in the following applications:

[Respondents were shown five items randomly selected from the list below.]

*   Translate over 100 different languages
*   Predict one’s Google searches
*   Identify people from their photos
*   Diagnose diseases like skin cancer and common illnesses
*   Predict who are at risk of various diseases
*   Help run factories and warehouses
*   Block spam email
*   Play computer games
*   Help conduct legal case research
*   Categorize photos and videos
*   Detect plagiarism in essays
*   Spot abusive messages on social media
*   Predict what one is likely to buy online
*   Predict what movies or TV shows one is likely to watch online

**QUESTION:**

How much do you support or oppose the development of AI?

**ANSWER CHOICES:**

*   Strongly support (2)
*   Somewhat support (1)
*   Neither support nor oppose (0)
*   Somewhat oppose (-1)
*   Strongly oppose (-2)
*   I don’t know

## B.5 Survey experiment: AI and/or robots should be carefully managed

**QUESTION:**

Please tell me to what extent you agree or disagree with the following statement.

[Respondents were presented with one statement randomly selected from the list below.]

*   AI and robots are technologies that require careful management.
*   AI is a technology that requires careful management.
*   Robots are technologies that require careful management.

**ANSWER CHOICES:**

*   Totally agree (2)
*   Tend to agree (1)
*   Tend to disagree (-1)
*   Totally disagree (-2)
*   I don’t know

## B.6 Trust of actors to develop AI

**QUESTION:**

How much confidence, if any, do you have in each of the following to develop AI in the best interests of the public?

[Respondents were shown five items randomly selected from the list below. We included explainer text for actors not well known to the public; respondents could view the explainer text by hovering their mouse over the actor’s name. The items and the answer choices were shown in a matrix format.]

*   The U.S. military
*   The U.S. civilian government
*   National Security Agency (NSA)
*   Federal Bureau of Investigation (FBI)
*   Central Intelligence Agency (CIA)
*   North Atlantic Treaty Organization (NATO)
    *   *Explainer text for NATO: NATO is a military alliance that includes 28 countries including most of Europe, as well as the U.S. and Canada.*
*   An international research organization (e.g., CERN)
    *   *Explainer text for CERN: The European Organization for Nuclear Research, known as CERN, is a European research organization that operates the largest particle physics laboratory in the world.*
*   Tech companies
*   Google
*   Facebook
*   Apple
*   Microsoft
*   Amazon
*   A non-profit AI research organization (e.g., OpenAI)
    *   *Explainer text for OpenAI: Open AI is an AI non-profit organization with backing from tech investors that seeks to develop safe AI.*
*   University researchers

**ANSWER CHOICES:**

*   A great deal of confidence (3)
*   A fair amount of confidence (2)
*   Not too much confidence (1)
*   No confidence (0)
*   I don’t know

## B.7 Trust of actors to manage AI

**QUESTION:**

How much confidence, if any, do you have in each of the following to manage the development and use of AI in the best interests of the public?

[Respondents were shown five items randomly selected from the list below. We included explainer text for actors not well known to the public; respondents could view the explainer text by hovering their mouse over the actor’s name. The items and the answer choices were shown in a matrix format.]

*   U.S. federal government
*   U.S. state governments
*   International organizations (e.g., United Nations, European Union)
*   The United Nations (UN)
*   An intergovernmental research organization (e.g., CERN)
    *   *Explainer text for CERN: The European Organization for Nuclear Research, known as CERN, is a European research organization that operates the largest particle physics laboratory in the world.*
*   Tech companies
*   Google
*   Facebook
*   Apple
*   Microsoft
*   Amazon
*   Non-government scientific organizations (e.g., AAAI)
    *   *Explainer text for AAAI: Association for the Advancement of Artificial Intelligence (AAAI) is a non-government scientific organization that promotes research in, and responsible use of AI.*
*   Partnership on AI, an association of tech companies, academics, and civil society groups

**ANSWER CHOICES:**

*   A great deal of confidence (3)
*   A fair amount of confidence (2)
*   Not too much confidence (1)
*   No confidence (0)
*   I don’t know

## B.8 AI governance challenges

We would like you to consider some potential policy issues related to AI. Please consider the following:

[Respondents were shown five randomly-selected items from the list below, one item at a time. For ease of comprehension, we include the shorten labels used in the figures in square brackets.]

*   **[Hiring bias] Fairness and transparency in AI used in hiring:** Increasingly, employers are using AI to make hiring decisions. AI has the potential to make less biased hiring decisions than humans. But algorithms trained on biased data can lead to lead to hiring practices that discriminate against certain groups. Also, AI used in this application may lack transparency, such that human users do not understand what the algorithm is doing, or why it reaches certain decisions in specific cases.
*   **[Criminal justice bias] Fairness and transparency in AI used in criminal justice:** Increasingly, the criminal justice system is using AI to make sentencing and parole decisions. AI has the potential to make less biased hiring decisions than humans. But algorithms trained on biased data could lead to discrimination against certain groups. Also, AI used in this application may lack transparency such that human users do not understand what the algorithm is doing, or why it reaches certain decisions in specific cases.
*   **[Disease diagnosis] Accuracy and transparency in AI used for disease diagnosis:** Increasingly, AI software has been used to diagnose diseases, such as heart disease and cancer. One challenge is to make sure the AI can correctly diagnose those who have the disease and not mistakenly diagnose those who do not have the disease. Another challenge is that AI used in this application may lack transparency such that human users do not understand what the algorithm is doing, or why it reaches certain decisions in specific cases.
*   **[Data privacy] Protect data privacy:** Algorithms used in AI applications are often trained on vast amounts of personal data, including medical records, social media content, and financial transactions. Some worry that data used to train algorithms are not collected, used, and stored in ways that protect personal privacy.
*   **[Autonomous vehicles] Make sure autonomous vehicles are safe:** Companies are developing self-driving cars and trucks that require little or no input from humans. Some worry about the safety of autonomous vehicles for those riding in them as well as for other vehicles, cyclists, and pedestrians.
*   **[Digital manipulation] Prevent AI from being used to spread fake and harmful content online:** AI has been used by governments, private groups, and individuals to harm or manipulate internet users. For instance, automated bots have been used to generate and spread false and/or harmful news stories, audios, and videos.
*   **[Cyber attacks] Prevent AI cyber attacks against governments, companies, organizations, and individuals:** Computer scientists have shown that AI can be used to launch effective cyber attacks. AI could be used to hack into servers to steal sensitive information, shut down critical infrastructures like power grids or hospital networks, or scale up targeted phishing attacks.
*   **[Surveillance] Prevent AI-assisted surveillance from violating privacy and civil liberties:** AI can be used to process and analyze large amounts of text, photo, audio, and video data from social media, mobile communications, and CCTV cameras. Some worry that governments, companies, and employers could use AI to increase their surveillance capabilities.
*   **[U.S.-China arms race] Prevent escalation of a U.S.-China AI arms race:** Leading analysts believe that an AI arms race is beginning, in which the U.S. and China are investing billions of dollars to develop powerful AI systems for surveillance, autonomous weapons, cyber operations, propaganda, and command and control systems. Some worry that a U.S.-China arms race could lead to extreme dangers. To stay ahead, the U.S. and China may race to deploy advanced military AI systems that they do not fully understand or can control. We could see catastrophic accidents, such as a rapid, automated escalation involving cyber and nuclear weapons.
*   **[Value alignment] Make sure AI systems are safe, trustworthy, and aligned with human values:** As AI systems become more advanced, they will increasingly make decisions without human input. One potential fear is that AI systems, while performing jobs they are programmed to do, could unintentionally make decisions that go against the values of its human users, such as physically harming people.
*   **[Autonomous weapons] Ban the use of lethal autonomous weapons (LAWs):** Lethal autonomous weapons (LAWs) are military robots that can attack targets without control by humans. LAWs could reduce the use of human combatants on the battlefield. But some worry that the adoption of LAWs could lead to mass violence. Because they are cheap and easy to produce in bulk, national militaries, terrorists, and other groups could readily deploy LAWs.
*   **[Technological unemployment] Guarantee a good standard of living for those who lose their jobs to automation:** Some forecast that AI will increasingly be able to do jobs done by humans today. AI could potentially do the jobs of blue-collar workers, like truckers and factory workers, as well as the jobs of white-collar workers, like financial analysts or lawyers. Some worry that in the future, robots and computers can do most of the jobs that are done by humans today.
*   **[Critical AI systems failure] Prevent critical AI systems failures:** As AI systems become more advanced, they could be used by the military or in critical infrastructure, like power grids, highways, or hospital networks. Some worry that the failure of AI systems or unintentional accidents in these applications could cause 10 percent or more of all humans to die.

**QUESTION:**

In the next 10 years, how likely do you think it is that this AI governance challenge will impact large numbers of people in the U.S.?

**ANSWER CHOICES:**

*   Very unlikely: less than 5% chance (2.5%)
*   Unlikely: 5-20% chance (12.5%)
*   Somewhat unlikely: 20-40% chance (30%)
*   Equally likely as unlikely: 40-60% chance (50%)
*   Somewhat likely: 60-80% chance (70%)
*   Likely: 80-95% chance (87.5%)
*   Very likely: more than 95% chance (97.5%)
*   I don’t know

**QUESTION:**

In the next 10 years, how likely do you think it is that this AI governance challenge will impact large numbers of people around the world?

**ANSWER CHOICES:**

*   Very unlikely: less than 5% chance (2.5%)
*   Unlikely: 5-20% chance (12.5%)
*   Somewhat unlikely: 20-40% chance (30%)
*   Equally likely as unlikely: 40-60% chance (50%)
*   Somewhat likely: 60-80% chance (70%)
*   Likely: 80-95% chance (87.5%)
*   Very likely: more than 95% chance (97.5%)
*   I don’t know

**QUESTION:**

In the next 10 years, how important is it for tech companies and governments to carefully manage the following challenge?

**ANSWER CHOICES:**

*   Very important (3)
*   Somewhat important (2)
*   Not too important (1)
*   Not at all important (0)
*   I don’t know

## B.9 Survey experiment: comparing perceptions of U.S. vs. China AI research and development

[Respondents were presented with one randomly-selected question from the two below.]

**QUESTIONS:**

*   Compared with other industrialized countries, how would you rate the **U.S.** in AI research and development?
*   Compared with other industrialized countries, how would you rate **China** in AI research and development?

**ANSWER CHOICES:**

*   Best in the world (3)
*   Above average (2)
*   Average (1)
*   Below average (0)
*   I don’t know

## B.10 Survey experiment: U.S.-China arms race

[All respondents were presented with the following prompt.]

We want to understand your thoughts on some important issues in the news today. Please read the short news article below.

Leading analysts believe that an “AI arms race” is beginning, in which the U.S. and China are investing billions of dollars to develop powerful AI systems for surveillance, autonomous weapons, cyber operations, propaganda, and command and control systems.

[Respondents were randomly assigned to one of the four experimental groups listed below.]

### B.10.1 Control

[No additional text.]

### B.10.2 Nationalism treatment

Some leaders in the U.S. military and tech industry argue that the U.S. government should invest much more resources in AI research to ensure that the U.S.’s AI capabilities stay ahead of China’s. Furthermore, they argue that the U.S. government should partner with American tech companies to develop advanced AI systems, particularly for military use.

According to a leaked memo produced by a senior National Security Council official, China has “assembled the basic components required for winning the Al arms race…Much like America’s success in the competition for nuclear weapons, China’s 21st Century Manhattan Project sets them on a path to getting there first.”

### B.10.3 War risks treatment

Some prominent thinkers are concerned that a U.S.-China arms race could lead to extreme dangers. To stay ahead, the U.S. and China may race to deploy advanced military AI systems that they do not fully understand or can control. We could see catastrophic accidents, such as a rapid, automated escalation involving cyber and nuclear weapons.

“Competition for AI superiority at [the] national level [is the] most likely cause of World War Three,” warned Elon Musk, the CEO of Tesla and SpaceX.

### B.10.4 Common humanity treatment

Some prominent thinkers are concerned that a U.S.-China arms race could lead to extreme dangers. To stay ahead, the U.S. and China may race to deploy advanced military AI systems that they do not fully understand or can control. We could see catastrophic accidents, such as a rapid, automated escalation involving cyber and nuclear weapons.

“Unless we learn how to prepare for, and avoid, the potential risks, AI could be the worst event in the history of our civilization. It brings dangers, like powerful autonomous weapons,” warned the late Stephen Hawking, one of the world’s most prominent physicists. At the same time, he said that with proper management of the technology, researchers “can create AI for the good of the world.”

[The order of the next two questions is randomized.]

**QUESTION:**

How much do you agree or disagree with the following statement?

The U.S. should invest more in AI military capabilities to make sure it doesn’t fall behind China’s, even if doing so may exacerbate the arms race. For instance, the U.S. could increase AI research funding for the military and universities. It could also collaborate with American tech companies to develop AI for military use.

**ANSWER CHOICES:**

*   Strongly agree (2)
*   Somewhat agree (1)
*   Neither agree nor disagree (0)
*   Somewhat disagree (-1)
*   Strongly disagree (-2)
*   I don’t know

**QUESTION:**

How much do you agree or disagree with the following statement?

The U.S. should work hard to cooperate with China to avoid the dangers of an AI arms race, even if doing so requires giving up some of the U.S.’s advantages. Cooperation could include collaborations between American and Chinese AI research labs, or the U.S. and China creating and committing to common safety standards.

**ANSWER CHOICES:**

*   Strongly agree (2)
*   Somewhat agree (1)
*   Neither agree nor disagree (0)
*   Somewhat disagree (-1)
*   Strongly disagree (-2)
*   I don’t know

## B.11 Issue areas for possible U.S.-China cooperation

**QUESTION:**

For the following issues, how likely is it that the U.S. and China can cooperate?

[Respondents were presented with three issues from the list below. All three issues were presented on the same page; the order that they appeared was randomized.]

*   Prevent AI cyber attacks against governments, companies, organizations, and individuals.
*   Prevent AI-assisted surveillance from violating privacy and civil liberties.
*   Make sure AI systems are safe, trustworthy, and aligned with human values.
*   Ban the use of lethal autonomous weapons.
*   Guarantee a good standard of living for those who lose their jobs to automation.

**ANSWER CHOICES:**

*   Very unlikely: less than 5% chance (2.5%)
*   Unlikely: 5-20% chance (12.5%)
*   Somewhat unlikely: 20-40% chance (30%)
*   Equally likely as unlikely: 40-60% chance (50%)
*   Somewhat likely: 60-80% chance (70%)
*   Likely: 80-95% chance (87.5%)
*   Very likely: more than 95% chance (97.5%)
*   I don’t know

## B.12 Trend across time: job creation or job loss

**QUESTION:**

How much do you agree or disagree with the following statement?

[Respondents were presented with one statement randomly selected from the list below.]

*   In general, automation and AI will create more jobs than they will eliminate.
*   In general, automation and AI will create more jobs than they will eliminate in **10 years**.
*   In general, automation and AI will create more jobs than they will eliminate in **20 years**.
*   In general, automation and AI will create more jobs than they will eliminate in **50 years**.

**ANSWER CHOICES:**

*   Strongly agree (2)
*   Agree (1)
*   Disagree (-1)
*   Strongly disagree (-2)
*   I don’t know

## B.13 High-level machine intelligence: forecasting timeline

**QUESTION:**

The following questions ask about high-level machine intelligence. We have high-level machine intelligence when machines are able to perform almost all tasks that are economically relevant today better than the median human (today) at each task. These tasks include asking subtle common-sense questions such as those that travel agents would ask. For the following questions, you should ignore tasks that are legally or culturally restricted to humans, such as serving on a jury.

In your opinion, how likely is it that high-level machine intelligence will exist in 10 years? 20 years? 50 years? For each prediction, please use the slider to indicate the percent chance that you think high-level machine intelligence will exist. 0% chance means it will certainly not exist. 100% chance means it will certainly exist.

______ In 10 years?
______ In 20 years?
______ In 50 years?

**ANSWER CHOICES:** [Used for slider input]

*   Very unlikely: less than 5% chance (2.5%)
*   Unlikely: 5-20% chance (12.5%)
*   Somewhat unlikely: 20-40% chance (30%)
*   Equally likely as unlikely: 40-60% chance (50%)
*   Somewhat likely: 60-80% chance (70%)
*   Likely: 80-95% chance (87.5%)
*   Very likely: more than 95% chance (97.5%)
*   I don’t know

## B.14 Support for developing high-level machine intelligence

**QUESTION:**

How much do you support or oppose the development of high-level machine intelligence?

**ANSWER CHOICES:**

*   Strongly support
*   Somewhat support
*   Neither support nor oppose
*   Somewhat oppose
*   Strongly oppose
*   I don’t know

## B.15 Expected outcome of high-level machine intelligence

**QUESTION:**

Suppose that high-level machine intelligence could be developed one day. How positive or negative do you expect the overall impact of high-level machine intelligence to be on humanity in the long run?

**ANSWER CHOICES:**

*   Extremely good
*   On balance good
*   More or less neutral
*   On balance bad
*   Extremely bad, possibly human extinction
*   I don’t know


----

