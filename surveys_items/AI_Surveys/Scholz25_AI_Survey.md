
# Instructions and Scales from Schulz et al. (2025) PTT Supplement

Scholz, D. D., Kraus ,Johannes, & and Miller, L. (2025). Measuring the Propensity to Trust in Automated Technology: Examining Similarities to Dispositional Trust in Other Humans and Validation of the PTT-A Scale. International Journal of Human–Computer Interaction, 41(2), 970–993. https://doi.org/10.1080/10447318.2024.2307691


## General instructions for the PTT scales:

The final scales (14 items) and short scales (6 items) for both the propensity to trust in automated technological systems (PTT-A) and other humans (PTT-H) are presented below.

*   The items should be presented in a randomized order.
*   Some items are negatively poled (indicated by (R) - reversed item).
*   In the present study, a five-point Likert-type scale ranging from 1 (“strongly disagree”) to 5 (“strongly agree") was used.

Items included in the 6-items short scales are printed in **bold**.

**Instruction:**
Now we are interested in your opinions about automated technology – i.e., technology that can perform certain functions automatically without any input from you.

Automated technology is taking on more and more tasks in various areas of life. For example, robots are becoming more widely used in industry and in private households. Many means of transport (airplanes, trains, or cars) are also now increasingly automated.

The term automated technology includes (among other things):

*   Automated means of transport (e.g. autonomous cars, trains, streetcars, airplanes)
*   Industrial robots (e.g. assembly robots, automated logistics robots)
*   Service and assistance robots (e.g. robot vacuum cleaners, robot lawn mowers, healthcare robots)
*   Other programs and systems based on artificial intelligence (e.g. language assistants, image recognition)

There are a number of statements on the next pages about automated technology in general that may apply to you more or less. Please respond to each of these statements by indicating the extent to which you agree or disagree with the statement, i.e. how much it applies to you. There are five options available, ranging from "strongly disagree” to “strongly agree".

## Propensity to Trust in Automated Technology (PTT-A) Scale

**Items:**

### Trusting Stance
1.  **Even though I may sometimes suffer the consequences of trusting automated technological systems, I still prefer to trust than not to trust them.**
2.  I feel good about trusting automated technological systems.
3.  I believe that I am generally better off when I do not trust automated technological systems than when I trust them. (R)
4.  **I rarely trust automated technological systems because I can't handle the uncertainty.** (R)

### Competence
5.  **Automated technological systems are competent.**
6.  Automated technological systems have sound knowledge about problems for which they are intended.
7.  I am wary about the capabilities of automated technological systems. (R)
8.  Automated technological systems do not have the capabilities that could help me reach my goals. (R)

### Benevolence
9.  **I believe that automated technological systems have good intentions.**
10. I feel that automated technological systems are out to get as much as they can for themselves. (R)
11. I don't expect that automated technological systems are willing to assist and support people. (R)

### Integrity
12. **Most automated technological systems are honest.**
13. **I feel that automated technological systems can be relied upon to do what they say they will do.**
14. One cannot expect to be treated fairly by automated technological systems. (R)

---

## Propensity to Trust in Humans (PTT-H) Scale

**Instruction:**
There are a number of statements on the next pages about people in general that may apply to you more or less. Please respond to each of these statements by indicating the extent to which you agree or disagree with the statement, i.e. how much it applies to you. There are five options available, ranging from "strongly disagree" to "strongly agree".

**Items:**

### Trusting Stance
1.  **Even though I may sometimes suffer the consequences of trusting other people, I still prefer to trust than not to trust them.**
2.  I feel good about trusting other people.
3.  I believe that I am generally better off when I do not trust other people than when I trust them. (R)
4.  **I rarely trust other people because I can't handle the uncertainty.** (R)

### Competence
5.  **Other people are competent.**
6.  Other people have sound knowledge about problems which they are working on.
7.  **I am wary about other people's capabilities.** (R)
8.  Other people do not have the capabilities that could help me reach my goals. (R)

### Benevolence
9.  **I believe that other people have good intentions.**
10. I feel that other people are out to get as much as they can for themselves. (R)
11. I don't expect that people are willing to assist and support other people. (R)

### Integrity
12. **Most other people are honest.**
13. **I feel that other people can be relied upon to do what they say they will do.**
14. One cannot expect to be treated fairly by other people. (R)

---

## Other Prompts (Derived from Main Paper Text)

*The following prompts were described in the main paper (Schulz et al., 2025) but are not included in the supplemental instructions PDF.*

### Trust Game Prompt (Human and Automated Agent versions)

**Instructions (Paraphrased from Section 2.3.3):**
Participants acted as the sender in a one-round trust game. They were given £10 and instructed to imagine playing with either:
a)  A stranger (human interaction partner condition)
b)  An unfamiliar robot (automated technology interaction partner condition)

They were informed that any amount they chose to send to the receiver (the stranger or the robot) would be tripled. The receiver could then choose to send some amount back to the participant.

**Measurement:** Participants were asked:
> How much of your money (£10) do you want to send to the receiver?

Participants could enter an amount between £0 and £10.

### Answerability of Will-Do Items (Benevolence & Integrity) for PTT-A

**Instructions (Paraphrased from Section 2.3.2 & 2.3.3):**
After completing the PTT-A items, participants were asked specifically about the items relating to the Benevolence and Integrity facets for the "automated technological systems" framing:

> Do you feel you could answer the items [referring to Benevolence and Integrity items for PTT-A] properly for the framing to technological systems?

**Measurement:**
*   Yes
*   No

---

## Other Measures (Items Not Provided in Paper or Supplement)

The paper mentions using the following established scales but does not list the individual items:

*   **HEXACO Personality Inventory-Revised (HEXACO-60):** 60 items (K. Lee & Ashton, 2009).
*   **Dark Factor of Personality (D16):** 16 items (Moshagen et al., 2020).
*   **Affinity for Technology (ATI):** 9 items (Franke et al., 2019).
*   **Perceived Trustworthiness (Robots):** 12 items based on Jian et al. (2000).
*   **Intention to Use (Robots):** 5 items (2 adapted from Venkatesh & Davis, 1996, and 3 self-formulated by the authors).


---

