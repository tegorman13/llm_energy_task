
# Surveys and Questionnaires from Smith et al. (2025)

Smith, A., van Wagoner, H. P., Keplinger, K., & Celebi, C. (2025). Navigating AI Convergence in Human–Artificial Intelligence Teams: A Signaling Theory Approach. Journal of Organizational Behavior. https://doi.org/10.1002/job.2856 https://onlinelibrary.wiley.com/doi/pdf/10.1002/job.2856 
https://osf.io/zjwta/?view_only=74a15f71b21c4b0abb69f3e5de543537


## Algorithm Aversion Scale (Developed in Study 3)

**Source:** Section 4.7.2.1, Table 7 (Smith et al., 2025)

**Description:** This scale was developed for Study 3 to measure algorithm aversion. An initial list of 60 content-valid items was generated capturing four hypothesized dimensions (Fear of Inaccuracy, Lack of Trust, Fear of Loss of Control, and Resistance to Change). Participants completed all 60 items. Exploratory factor analysis resulted in a final scale of 45 items across four factors.

**Response Scale:** The specific response scale (e.g., Likert 1-5 or 1-7, Strongly Disagree to Strongly Agree) used for these items was **not explicitly stated** in the provided text sections or Table 7 description.

**Items:**
*(Note: Participants in Study 3 responded to all 60 items listed below for the initial Exploratory Factor Analysis. The factor loadings from Table 7 are indicated. The final measure retained 45 items, typically those with higher or cleaner loadings, often indicated by bolding in the original table note, though precise bolding isn't perfectly clear from OCR. Items are grouped by the factor they primarily loaded onto based on Table 7)*

**Factor 1: Fear of Inaccuracy**
1.  I am concerned about the reliability of algorithms. (Loading: 0.648)
2.  Algorithms could make errors that would negatively impact my life. (Loading: 0.7582)
3.  I feel uncertain about the dependability of algorithm-based decisions. (Loading: 0.6559)
4.  The potential for inaccuracies in algorithmic results worries me. (Loading: 0.7461)
5.  I question the correctness of outcomes produced by algorithms. (Loading: 0.7262)
6.  Algorithms might not handle unexpected situations well. (Loading: 0.7465)
7.  I believe that algorithms can easily misinterpret complex data. (Loading: 0.737)
8.  The risk of error in algorithmic decisions is too high for comfort. (Loading: 0.6523)
9.  Algorithms may not always provide consistent results. (Loading: 0.6921)
10. I am skeptical about the accuracy of algorithms when they process large amounts of data. (Loading: 0.6862)
11. The thought of relying solely on algorithmic accuracy makes me uneasy. (Loading: 0.6815)
12. Algorithms are not infallible and this can lead to serious mistakes. (Loading: 0.6819)
13. I distrust algorithms when the stakes of the decision are high. (Loading: 0.6219)
14. Algorithms could generate incorrect results without any warning signs. (Loading: 0.7461)
15. I am wary of using algorithms for decisions that have long-term consequences. (Loading: 0.6519)
23. I worry about biases embedded in algorithms affecting their judgments. (Loading: 0.4047 - Also loaded on Lack of Trust)
43. I worry about the consequences of errors when control is ceded to algorithms. (Loading: 0.4743)

**Factor 2: Resistance to Change**
39. I prefer decisions made by people because it keeps control within human hands. (Loading: 0.438)
46. I am hesitant to adopt new technologies that rely heavily on algorithms. (Loading: 0.6497)
47. I prefer traditional methods over algorithmic solutions. (Loading: 0.8141)
48. The pace of change toward more algorithm use is concerning. (Loading: 0.622)
49. I am skeptical about replacing human roles with algorithms. (Loading: 0.5336)
50. I prefer the way things were done before algorithms were involved. (Loading: 0.8686)
51. Rapid technological changes involving algorithms are unsettling. (Loading: 0.6641)
52. I resist changes that involve using algorithms in my daily activities. (Loading: 0.7925)
53. I believe that some things are better left unchanged, especially regarding algorithm use. (Loading: 0.6663)
54. The movement toward algorithm-driven processes is too fast for my comfort. (Loading: 0.7089)
55. I am cautious about the increasing reliance on algorithms in professional settings. (Loading: 0.6269)
56. I prefer to stick to methods that have proven successful over time rather than adopting new algorithmic techniques. (Loading: 0.8912)
57. I am wary of changes that could make algorithms central to my life or work. (Loading: 0.7064)
58. I am not ready to embrace the widespread use of algorithms. (Loading: 0.8122)
59. I find it difficult to accept the shift from human expertise to algorithmic control. (Loading: 0.8074)
60. The trend toward automating more with algorithms does not sit well with me. (Loading: 0.7914)

**Factor 3: Loss of Control**
31. Relying on algorithms makes me feel like I am losing control over decisions. (Loading: 0.5915)
32. I prefer to keep important decision-making processes directly under human control. (Loading: 0.5915)
33. Algorithms taking over tasks leave me feeling helpless. (Loading: 0.6165)
34. I am uneasy about delegating critical decisions to algorithms. (Loading: 0.6165)
35. I believe that excessive use of algorithms can erode personal autonomy. (Loading: 0.4447 - *Not marked bold in source*)
36. Algorithms decide too much, too quickly, reducing my control. (Loading: 0.6547)
37. I am concerned about becoming overly dependent on algorithms. (Loading: 0.6418)
38. Using algorithms feels like putting my fate in the hands of a machine. (Loading: 0.5138)
40. The use of algorithms in decision-making processes makes me feel disconnected. (Loading: 0.6046)
45. The shift toward algorithmic decision-making diminishes individual influence. (Loading: 0.4004)

**Factor 4: Lack of Trust**
16. I do not trust algorithms to understand my individual needs. (Loading: 0.4031)
17. Algorithms lack the human insight necessary for many decisions. (Loading: 0.4067)
18. I find it hard to trust a process I cannot easily understand or see. (Loading: 0.6)
19. I am not confident in algorithms to handle tasks that require emotional sensitivity. (Loading: 0.4881)
20. The impersonal nature of algorithms makes them hard to trust. (Loading: 0.6629)
21. I feel that algorithms do not have the capability to adapt to new or evolving situations. (Loading: 0.5061)
22. Algorithms are not transparent enough for me to trust their decisions. (Loading: 0.5947)
24. Trusting algorithms with personal information makes me uncomfortable. (Loading: 0.4584)
25. I am skeptical about the fairness of algorithmic decisions. (Loading: 0.5247)
26. Algorithms do not provide the rationale for their decisions, which diminishes my trust. (Loading: 0.4482)
27. I am concerned that algorithms prioritize efficiency over ethical considerations. (Loading: 0.4473 - *Not marked bold in source*)
28. Algorithms cannot be held accountable in the same way humans can. (Loading: 0.4473)
29. I distrust algorithms because I cannot negotiate or reason with them. (Loading: 0.5247)
30. The idea of algorithms making decisions without human oversight is troubling to me. (Loading: 0.4482)
41. I think that algorithms can make choices that aren’t in my best interest. (*Not marked bold in source*)
42. Algorithms reduce the human touch in decisions that affect me. (Loading: 0.4743)
44. I am reluctant to accept decisions made without human involvement. (Loading: 0.4004)

---

## Other Scales Mentioned (Items Not Provided in Text)

The following scales were used in the studies, but their specific items were not listed in the provided text. Only the source and sample items (where available) were mentioned.

1.  **Trust in AI (Study 1, 2, 3, 4)**
    *   **Source:** Merritt (2011), modified for the specific context (facial recognition or CV screening).
    *   **Description:** Measures trust in the AI system.
    *   **Sample Items (from Section 4.1.3.6):** "I believe facial recognition systems are competent performers,” “I have confidence in the advice given by facial recognition systems," and "I can rely on facial recognition systems to do its best every time I take its advice."
    *   **Response Scale:** 1 (strongly disagree) to 5 (strongly agree).

2.  **Explicit Gender Bias (Study 1, 2, 3, 4)**
    *   **Source:** Swim et al. (1995).
    *   **Description:** Measures explicit bias related to gender.
    *   **Sample Items (from Section 4.1.3.7):** "On average, people in our society treat men and women equally" and "Society has reached the point where women and men have equal opportunities for achievement."
    *   **Response Scale:** 1 (strongly disagree) to 7 (strongly agree).

3.  **Explicit Racial Bias (Study 1, 2, 3, 4)**
    *   **Source:** Uhlmann, Brescoll, and Machery (2010).
    *   **Description:** Measures explicit bias related to race/ethnicity.
    *   **Sample Items (from Section 4.1.3.8):** "If your personal safety is at stake, it's sensible to avoid members of ethnic groups known to behave more aggressively" and "Law enforcement officers should act as if members of all racial groups are equally likely to commit crimes."
    *   **Response Scale:** 1 (strongly disagree) to 7 (strongly agree).

------


