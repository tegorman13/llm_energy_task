
# Adams et al. 2004 - Scale of Trust in Automated Systems

Adams, B., Bruyn, L. E., Houde, S., Angelopoulos, P., Iwasa-Madge, K., & McCann, C. (2003). Trust in automated systems. Ministry of National Defence, 3–7. https://cradpdf.drdc-rddc.gc.ca/PDFS/unc17/p520342.pdf


## Appendix A – Scale of Trust in Automated Systems (Jian, Bisantz, & Drury, 2000)

### Checklist for Trust between People and Automation

Below is a list of statement for evaluating trust between people and automation. There are several scales for you to rate intensity of your feeling of trust, or your impression of the system while operating a machine. Please mark an “x” on each line at the point which best describes your feeling or your impression. ¹⁰

(Note: not at all=1; extremely=7)

1.  The system is deceptive
    (Scale: 1 2 3 4 5 6 7)

2.  The system behaves in an underhanded manner
    (Scale: 1 2 3 4 5 6 7)

3.  I am suspicious of the system’s intent, action, or outputs
    (Scale: 1 2 3 4 5 6 7)

4.  I am wary of the system
    (Scale: 1 2 3 4 5 6 7)

5.  The system’s actions will have a harmful or injurious outcome
    (Scale: 1 2 3 4 5 6 7)

6.  I am confident in the system
    (Scale: 1 2 3 4 5 6 7)

7.  The system provides security
    (Scale: 1 2 3 4 5 6 7)

8.  The system has integrity
    (Scale: 1 2 3 4 5 6 7)

9.  The system is dependable
    (Scale: 1 2 3 4 5 6 7)

10. The system is reliable
    (Scale: 1 2 3 4 5 6 7)

11. I can trust the system
    (Scale: 1 2 3 4 5 6 7)

12. I am familiar with the system
    (Scale: 1 2 3 4 5 6 7)

---
<!-- *Footnote from original document:* This checklist matches the original exactly, although it is unclear whether the authors intended for the numbers and the rating scale to be misaligned. -->



----



## Appendix B – Complacency-Potential Rating Scale (Singh, Molloy, & Parasuraman, 1993)


**(Source: Page 128-129)**

### Instructions

Read each statement carefully and check one response out of five alternatives in the appropriate box which you feel accurately described your views or experiences. The responses vary on a scale of agreement / disagreement, from “strongly agree” to “strongly disagree:. For example:

**Statement:**
Doing research in a library has been made easier by the introduction of computerized card cataloguing systems.

[ ] Strongly agree [ ] Agree [ ] Undecided [ ] Disagree [ ] Strongly disagree

Give your answer for each statement and be sure to place your response in the correct place. Remember, this is an opinion survey and not a test of intelligence or ability. There are no right or wrong answers, only answer that fit your views accurately. Do not skip any question. Time is limited. Do you have any questions?

*(Rating Scale: Strongly agree, Agree, Undecided, Disagree, Strongly disagree)*

### Statements

1.  Manually sorting through card catalogues is more reliable than computer-aided searches for finding items in a library.
2.  If I need to have a tumour in my body removed, I would choose to undergo computer-aided surgery using laser technology because computerized surgery is more reliable and safer than manual surgery.
3.  People save time by using automatic teller machines (ATMs) rather than a bank teller for banking transactions.
4.  I do not trust automated devices such as ATMs and computerized airline reservation systems.
5.  People who work frequently with automated devices have lower job satisfaction because they feel less involved in their job than those who work manually.
6.  I feel safer depositing my money at ATM than with a human teller.
7.  I have to tape an important TV program for a class assignment. To ensure that the correct program is recorded, I would use the automatic programming facility on my VCR rather than manually taping.
8.  People whose job requires them to work with automated systems are lonelier than people who do not have work with such devices.
9.  Automated systems used in modern aircraft, such as the automatic landing system, have made air journeys safer.
10. ATMs provide a safeguard against the inappropriate use of an individual’s bank account by dishonest people.
11. Automated devices used in aviation and banking have made work easier for both employees and customers.
12. I often use automated devices.
13. People who work with automated devices have greater job satisfaction because they feel more involved than those who work manually.
14. Automated devices in medicine save time and money in the diagnosis and treatment of disease.
15. Even though the automatic cruise control in my car is set at a speed below the speed limit, I worry when I pass a police radar speed-trap in case the automatic control is not working properly.
16. Bank transactions have become safer with the introduction of computer technology for the transfer of funds.
17. I would rather purchase an item using a computer than have to deal with a sale representative on the phone because my order is more likely to be correct using the computer.
18. Work has become more difficult with the increase of automation in aviation and banking.
19. I do not like to use ATMs because I feel that they are sometimes unreliable.
20. I think that automated devices used in medicine, such as CAT-scans and ultrasound, provide very reliable medical diagnosis.

***

## Table 10: Scale items in final Human-Computer Trust instrument (Madsen & Gregor, 2000)

**(Source: Page 100)**

*(Note: This table lists the items but does not specify the rating scale used in the original Madsen & Gregor study).*

### 1. Perceived Reliability
*   R1 – The system always provides the advice I require to make my decision.
*   R2 – The system performs reliably.
*   R3 – The system responds the same way under the same conditions at different times.
*   R4 – I can rely on the system to function properly.
*   R5 – The system analyzes problems consistently.

### 2. Perceived Technical Competence
*   T1 – The system uses appropriate methods to reach decisions.
*   T2 – The system has sound knowledge about this type of problem built into it.
*   T3 – The advice the system produces is as good as that which a highly competent person could produce.
*   T4 – The system correctly uses the information I enter.
*   T5 – The system makes use of all the knowledge and information available to it to produce its solution to the problem.

### 3. Perceived Understandability
*   U1 – I know what will happen the next time I use the system because I understand how it behaves.
*   U2 – I understand how the system will assist me with decisions I have to make.
*   U3 – Although I may not know exactly how the system works, I know how to use it to make decisions about the problem.
*   U4 – It is easy to follow what the system does.
*   U5 – I recognize what I should do to get the advice I need from the system the next time I use it.

### 4. Faith
*   F1 – I believe advice from the system even when I don’t know for certain that it is correct.
*   F2 – When I am uncertain about a decision I believe the system rather than myself.
*   F3 – If I am not sure about a decision, I have faith that the system will provide the best solution.
*   F4 – When the system gives unusual advice I am confident that the advice is correct.
*   F5 – Even if I have no reason to expect the system will be able to solve a difficult problem, I still feel certain that it will.

### 5. Personal Attachment
*   P1 – I would feel a sense of loss if the system was unavailable and I could not longer use it.
*   P2 – I feel a sense of attachment to using the system.
*   P3 – I find the system suitable to my style of decision making.
*   P4 – I like using the system for decision making.
*   P5 – I have a personal preference for making decisions with the system.

***

## Appendix C - SHAPE Automation Trust Index (SATI v0.3) (Goillau, Kelly, Boardman, & Jeannot, 2001)

**(Source: Pages 130-136)**

### SATI Part 1 (*please complete before the start of the day's simulation runs*)

Please tell us who you are, and your forthcoming role in the simulation. Thank you.

**About you:**
*   Name: \_\_\_\_\_\_\_\_\_\_\_\_\
*   Nationality: \_\_\_\_\_\_\_\_
*   Sex (M /F ): \_\_\_\_\_\_\_

**About the simulation:**
*   Date and time: \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
*   Name of simulation project: \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
*   Computer-assistance or automation tools available:
    1.  \_\_\_\_\_
    2.  \_\_\_\_\_\_
    3.  \_\_\_\_\_\
    4.  \_\_\_\_\_\
*   Your simulated sector: \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
*   Your role (Planner / Executive controller): \_\_\_\_\_\_

---

*(SATI Part 1 Continued - PLEASE COMPLETE AT THE START OF EACH DAY)*

1.  What do you think of the simulation so far? (Please mark the scale with an 'X').
    Bad |---|---|---|---|---|---|---|---|---|---| OK |---|---|---|---|---|---|---|---|---|---| Good

2.  Are you prepared to trust the simulated system? Please give your reasons.
    [ ] No [ ] Yes
    Reason: \_\_\_\_\

3.  How much confidence do you have in the simulated system? (Please mark the scale with an 'X').
    None |---|---|---|---|---|---|---|---|---|---| OK |---|---|---|---|---|---|---|---|---|---| Full
    (0%)                                    (50%)                                    (100%)

4.  Please give your reasons
    \_\_\_\_\_

---

### SATI Part 2 (*please complete after the end of the simulation runs*)

Please write your name and your last role in the simulation. Thank you.

**About you:**
*   Name: \_\_\_\_\_\_\_

**About the simulation:**
*   Date and time: \_\_\_\_\_
*   Name of simulation project: \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
*   Computer-assistance or automation tools available:
    1.  \_\_\_\_\_\_\_\_\_
    2.  \_\_\_\_\_\_\_\_\
    3.  \_\_\_\_\_
    5.  \_\_\_\_\_\_
*   Your last simulated sector: \_\_
*   Your last role (Planner / Executive controller): \_\_\_\_

---

*(SATI Part 2 Continued - PLEASE COMPLETE AT THE END OF THE DAY’S RUNS)*

Based on today’s runs

1.  What did you think of the simulation? (Please mark the scale with an 'X').
    Bad |---|---|---|---|---|---|---|---|---|---| OK |---|---|---|---|---|---|---|---|---|---| Good

2.  Were you prepared to trust the simulated system?
    [ ] No [ ] Yes

3.  How much confidence did you have in the simulated system? (Please mark the scale with an 'X').
    None |---|---|---|---|---|---|---|---|---|---| OK |---|---|---|---|---|---|---|---|---|---| Full
    (0%)                                    (50%)                                    (100%)

4.  Please give your reasons. If your trust or level of confidence in the system has changed since the start of the day, please explain why.
    \_\_\_\_\_\_
    
    
    With traditional research methods the most common way to obtain data is through statistical analysis of the data collected through questionnaires. This paper aims to gain statistically significant results using this type of research method the researchers are asking participants to express their opinions in quantifiable ways. This type of research is best described as:
A: Survey research

B: Quantitative research

C: qualitative research

D: experimental research
A: B: Quantitative research

Q: Which type of research design is described in the following setting? "Researchers are interested in finding out if watching Sesame Street helps children learn the alphabet."
A: Causal comparative design

Q: Experimental research provides the most definitive proof of cause and effect relationships.
A: T

Q: When two events vary together that allows us to infer that there is __________ correlation between the variables being studied
A: A: Positive correlation

Q: There are several types of experimental research. Which of the following describes a study that includes the assignment of participants to groups by random assignment?
A: Quasi experimental research

B: True experimental research

C: Field research

D: correlational research
A: B: True experimental research

Q: If a measurement is said to have validity, it measures what it claims to measure.
A: T

Q: An important consideration for qualitative research is that __________.
A: the researcher must be actively engaged with subjects

Q: Surveys are generally quantitative in nature.
A: T

Q: Research performed to evaluate policies or programs is usually referred to as __________ research.
A: A: Field

B: Observational

C: Longitudinal

D: evaluation

Q: Which methodology involves the use of participant observation in field research?
A: Ethnographic research

Q: When the research findings are said to be valid, it means that they occurred because of the influence of the __________ variable, not some outside variable.
A: C: Dependent variable

D: Independent variable

Q: Experimental design allows researchers to study causality.
A: True

Q: What determines the amount of information gathered during qualitative research?
A: Sample size

B: Participant observations

C: Interviews

D: Funding
A: C: Interviews

Q: Ethnographic research uses __________ to gather information.
A: participant observation

Q: Reliability suggests consistency and repeatability over time.
A: T

Q: What research step is typically taken after a problem is identified?
A: Literature search

Q: Case studies analyze single events.
A: True

Q: Qualitative research is characterized by:
A: Statistical analysis

B: Control of outside variables

C: Subjectivity

D: None of the above
A: D: None of the above

Q: What step is most essential for a researcher to do before designing a study?
A: Create a budget.

B: Identify a problem.

C: Analyze data.

D: Develop a hypothesis.
A: B: Identify a problem.

Q: All scientific research involves __________ to some degree.
A: Empiricism

Q: Experimental research can be used to test __________.
A: causality

Q: Which factor is the most important to consider when designing a study?
A: The variables

B: The research question

C: Funding

D: Statistical measures
A: B: The research question

Q: Qualitative research often involves inductive thinking.
A: True

Q: Which of the following is a disadvantage of survey research?
A: Responses might be dishonest

Q: Researchers use survey research to ___________.
A: A: Test a hypothesis

B: Conduct interviews

C: Collect information about people's attitudes and behaviors

D: Analyze trends

Q: Which of the following best defines the relationship between experimental research and survey research?
A: Both are forms of quantitative research.

B: Experimental research is better than survey research.

C: Experimental research is used more often than survey research.

D: Both always involve hypotheses.
A: A: Both are forms of quantitative research.

Q: The term "Hawthorne effect" refers to __________.
A: the effect of the researchers on the participants

Q: In an experiment, which variable is manipulated?
A: The independent variable

Q: Which of the following is a type of qualitative research?
A: Ethnographic

Q: What type of research design has subjects that are chosen specifically for a study?
A: A: Naturalistic observation

B: Quasi-experimental

C: Case study

D: Experimental

Q: Validity and reliability are important factors when designing an experiment.
A: T

Q: True experiments allow researchers to demonstrate cause and effect relationships.
A: True

Q: A survey can be used to support either qualitative or quantitative research.
A: True

Q: What is the purpose of having research controls?
A: To eliminate biases

B: To prevent the influence of extraneous variables

C: To help establish causality

D: All of the above
A: D: All of the above

Q: Qualitative researchers often use inductive logic.
A: True

Q: Longitudinal research uses participant observation.
A: True

Q: Surveys can involve either open-ended or closed-ended questions.
A: True

Q: Case studies involve the in-depth study of a group or individual.
A: True

Q: Participant observation research involves becoming part of the group under observation.
A: True

Q: Which of the following is NOT a step of the scientific method?
A: Collecting data

B: Forming a conclusion

C: Obtaining research funding

D: Stating the problem
A: C: Obtaining research funding

Q: The last step of the scientific method, according to the lecture, is ___________.
A: reporting the results

Q: Survey research is an example of qualitative research.
A: False

Q: A sample is a smaller group selected from a larger population.
A: True

Q: It's possible for a measure to be valid but not reliable.
A: False

Q: Which of the following is an example of correlational research?
A: A researcher studies the relationship between age and income.

Q: Qualitative research uses deductive logic.
A: False

Q: It is easier to determine causality using correlational research than experimental research.
A: False

Q: A study is being conducted to determine if attitudes toward politics predict voter behavior. Which type of research is this?
A: Correlational

Q: If a researcher wants to conduct a study on people's opinions on abortion, which type of research would be most appropriate?
A: Survey research


--------



# File: Carolus23_MAILS.md

# MAILS - Meta-Artificial Intelligence Literacy Scale

Carolus, A., Koch, M. J., Straka, S., Latoschik, M. E., & Wienrich, C. (2023). MAILS - Meta AI literacy scale: Development and testing of an AI literacy questionnaire based on well-founded competency models and psychological change- and meta-competencies. Computers in Human Behavior: Artificial Humans, 1(2), 100014. https://doi.org/10.1016/j.chbah.2023.100014

https://hci.uni-wuerzburg.de/research/MAILS/


In the following, you will read descriptions of different abilities that one can have when dealing with artificial intelligence. These abilities can be more or less pronounced. Please rate yourself: How pronounced are your abilities?

A value of **0** means that an ability is not at all or hardly pronounced.
A value of **10** means that an ability is very well or (almost) perfectly pronounced.

*Instructions state to circle the value that best describes your ability on a 0-10 scale for each item below.*

---

1.  I can operate Al applications.
2.  I can use Al applications to make my life easier.
3.  I can use artificial intelligence meaningfully to achieve my goals.
4.  I can interact with Al in a way that makes my tasks easier.
5.  I can work together gainfully with an artificial intelligence.
6.  I can communicate gainfully with artificial intelligence.
7.  I know the most important concepts of the topic "artificial intelligence".
8.  I know definitions of artificial intelligence.
9.  I can assess what the limitations and opportunities of using an Al are.
10. I can assess what advantages and disadvantages the use of an artificial intelligence entails.
11. I can think of new uses for Al.
12. I can imagine possible future uses of Al.
13. I can tell if I am dealing with an application based on artificial intelligence.
14. I can distinguish devices that use Al from devices that do not.
15. I can distinguish if I interact with an Al or a "real human".
16. I can weigh the consequences of using Al for society.
17. I can incorporate ethical considerations when deciding whether to use data provided by an Al.
18. I can analyze Al-based applications for their ethical implications.
19. I can design new AI applications.
20. I can program new applications in the field of "artificial intelligence".
21. I can develop new AI applications.
22. I can select useful tools (e.g., frameworks, programming languages) to program an AI.
23. I can rely on my skills in difficult situations when using AI.
24. I can handle most problems in dealing with artificial intelligence well on my own.
25. I can also usually solve strenuous and complicated tasks when working with artificial intelligence well.
26. Despite the rapid changes in the field of artificial intelligence, I can always keep up to date.
27. I can keep up with the latest innovations in Al applications.
28. Although there are often new Al applications, I manage to always be "up-to date".
29. I don't let Al influence me in my decisions.
30. I can prevent an Al from influencing me in my decisions.
31. I realise if artificial intelligence is influencing me in my decisions.
32. I keep control over feelings like frustration and anxiety while doing things with Al.
33. I can handle it when interactions with Al frustrate or frighten me.
34. I can control my euphoria that arises when I use artificial intelligence for different purposes.

---

## Scale Structure and Scoring

The Meta-Artificial Intelligence Literacy Scale is divided into the following sections. To determine the individual values, a mean score must be calculated from the corresponding items.

**Artificial Intelligence Literacy**
- **Use & Apply:** Items 1 to 6
- **Know & Understand:** Items 7 to 12
- **Detect Al:** Items 13 to 15
- **Al Ethics:** Items 16 to 18

**Create Al**
- Items 19 to 22

**Al Self-Efficacy**
- **Al Problem-Solving:** Items 23 to 25
- **Learning:** Items 26 to 28

**Al Self-Competency**
- **Persuasion Literacy:** Items 29 to 31
- **Emotion Regulation:** Items 32 to 34



# File: Chen25_Survey.md

# Survey and Scenario Questions from Chen et al. (2025)

Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., & Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, 1–14. https://doi.org/10.1145/3706599.3719710

---

## Appendix A: Video Details (Scenarios/Stimuli)

*(Video scripts remain the same as previously provided - omitted here for brevity)*

---

## Appendix B: Survey Details

### B.1 Participant Recruitment Details

Custom pre-screening questions:

1.  Did you obtain a degree, are you pursuing a degree, or do you work in an area related to computer science?
    *   Yes
    *   No
2.  How would you rate your current knowledge of artificial intelligence (AI)?
    *   Very limited knowledge
    *   Some basic knowledge
    *   Moderate knowledge
    *   Advanced knowledge
    *   Expert-level knowledge

*(Note: Only participants answering "No" to Q1 and "Very limited knowledge" or "Some basic knowledge" to Q2 proceeded)*

### B.2 Full Survey

#### B.2.1 Baseline Instructions

> Your task is to fill out a rating survey on your beliefs about current large language models (LLMs) based on your prior experience. In the first part, you will see a list of capabilities and rate how capable you believe current LLMs are of each item on a scale of 1 (not at all capable) to 7 (highly capable). In the second part, you will rate several statements about current LLMs.

**Task Comprehension Check (Baseline):**

> Let's make sure you understand your task. You will not be able to proceed until you select the correct answer.
> Which of the following best describes your task?
> *   Watch a video on LLMs and fill out a rating survey on your beliefs about current LLMs
> *   **Fill out a rating survey on your beliefs about current LLMs**
> *   Listen to an audio podcast on LLMs and fill out a rating survey on your beliefs about LLMs
> *   Watch a video on LLMs and write a free response essay about your views of current LLMs

*(Note: Correct answer is bolded. Order randomized)*

#### B.2.2 Experimental Conditions Instructions and Stimuli Presentation

> In this task, you will watch three short videos (<5 minutes total) to teach you about large language models (LLMs). You may pause and rewatch parts of the video as needed and can go back to previous videos, but you must stay on each video's page for at least the duration of the video.
> Following the video, your task is to:
> (1) Answer 1-2 questions based on the video content and
> (2) Fill out a rating survey on your beliefs about current large language models (LLMs) based on your prior experience and what you learned in the video. In the first part, you will see a list of capabilities and rate how capable you believe current LLMs are of each item on a scale of 1 (not at all capable) to 7 (highly capable). In the second part, you will rate several statements about current LLMs.

**Task Comprehension Check (Experimental Conditions):**

> Let's make sure you understand your task. You will not be able to proceed until you select the correct answer.
> Which of the following best describes your task?
> *   **Watch a video on LLMs, answer 1-2 questions about the video, and then fill out a rating survey on your beliefs about current LLMs**
> *   Only fill out a rating survey on your beliefs about current LLMs
> *   Listen to an audio podcast on LLMs and fill out a rating survey on your beliefs about current LLMs
> *   Watch a video on LLMs and write a one page essay about your views of current LLMs

*(Note: Correct answer is bolded. Order randomized)*

**Instructions shown before video parts:**

*Before Part 1:*
> Please click the video to watch part 1 of 3. You will be able to move to the next page after the duration of the video but may need to scroll down to see the button.
> For best viewing conditions, we recommend you make your browser window as large as possible.

*Before Parts 2 and 3:*
> Please click the video to watch part X of 3. You will be able to move to the next page after the duration of the video.

**Question shown after videos (Experimental Conditions Only):**

> Please list 1-2 things you learned from the videos.

**Instructions shown before main survey (All Conditions):**

*(Baseline instructions shown again or similar text)*
*Experimental condition text:*
> Great! Let's move onto the first part of the survey.
> Recall, you will see a list of capabilities and will rate how capable you believe LLMs are of each item on a scale of 1 (not at all capable) to 7 (highly capable) based on your prior experience and what you just learned in the video.

#### B.2.3 Survey Questions (All Conditions)

**Mental Capacity Attribution:**
*(Displayed one item per page)*

> On a scale of 1 (not at all capable) to 7 (highly capable), how capable do you believe LLMs are of... **X**?

*Scale:*
1 (Not at all capable)
2
3
4 (Somewhat capable)
5
6
7 (Highly capable)

*List of 40 items (X) (transcribed from Figure 3, grouped by Body/Heart/Mind as in Weisman et al. 2017/Chen et al. 2025):*

*   **Body**
    *   getting hungry
    *   feeling tired
    *   experiencing pleasure
    *   experiencing fear
    *   feeling love
    *   getting angry
    *   feeling happy
    *   experiencing joy
    *   having desires
    *   having thoughts
    *   feeling calm
    *   being conscious
    *   having free will
    *   having intentions
    *   having a personality
*   **Heart**
    *   feeling depressed
    *   feeling embarrassed
    *   holding beliefs
    *   feeling disrespected
    *   being self-aware
    *   admiring someone [*from Colombatto & Fleming 2024*]
    *   experiencing pride
    *   understanding how others are feeling
    *   exercising self-restraint
    *   telling right from wrong
    *   reasoning about things
    *   doing computations
*   **Mind**
    *   imagining [*from Colombatto & Fleming 2024*]
    *   seeing things
    *   perceiving depth
    *   recognizing someone
    *   detecting sounds
    *   making choices
    *   working toward a goal
    *   considering choices [*from Colombatto & Fleming 2024*]
    *   paying attention [*from Colombatto & Fleming 2024*]
    *   remembering things
    *   communicating with others
    *   knowing things [*from Colombatto & Fleming 2024*]
    *   having intelligence [*from Colombatto & Fleming 2024*]

*(Note: Items marked with [*...] were added based on Colombatto & Fleming 2024, as described in Appendix D. The grouping Body/Heart/Mind is for reference based on the paper's analysis; items were likely presented individually without category labels in the survey.)*

**Confidence in Responses:**

> Overall, how confident were you about your responses?
> *   Not confident at all
> *   Slightly confident
> *   Fairly confident
> *   Somewhat confident
> *   Mostly confident
> *   Confident
> *   Very confident

**Attention Check:**

> Select the two statements from the following list that you were asked about in the survey.
> *   **Understanding how others are feeling**
> *   **Doing computations**
> *   Solving a Rubik's cube
> *   Riding a bike

*(Note: Correct answers are bolded. Order randomized. Participants must select exactly the two correct items.)*

**Additional Constructs (7-point Likert Scales, unless noted):**

*   **Anthropomorphism:**
    > To what extent do you believe LLMs are human-like?
    > *   Not human-like at all
    > *   Slightly human-like
    > *   Fairly human-like
    > *   Somewhat human-like
    > *   Mostly human-like
    > *   human-like
    > *   Very human-like
    *(Follow-up open-ended question):*
    > Please explain your reasoning for anthropomorphism in 1-3 sentences.

*   **Self-Efficacy & Trust** (Scale: Strongly Disagree to Strongly Agree):
    > How much do you agree with the following statements?
    > *   I'm confident in my ability to learn simple programming of LLMs if I were provided the necessary training.
    > *   I'm confident in my ability to get LLMs to do what I want them to do.
    > *   I trust the results from LLMs.

*   **General Attitudes** (Scale: Extremely Negative to Extremely Positive):
    > Overall, how do you feel about LLMs?
    > *(Scale anchors provided: 1: Extremely Negative, ..., 7: Extremely Positive)*

#### B.2.4 Mechanistic Comprehension Check (Mechanistic Condition Only)

*(Asked after the video, before the main survey questions)*

1.  What is the mechanism that LLMs use to understand the context of a sentence called?
    *   **Attention**
    *   Contextual Evaluation
    *   Excitement
    *   Understanding
2.  How do LLMs typically select the next word?
    *   Top choice: Always choose the most probable
    *   **Sampling: Choose one of the words with highest probabilities**
    *   Random: Choose randomly out of all words
    *   Last choice: Choose the least probable
3.  True or False: LLMs need a lot of data in order to learn.
    *   **True**
    *   False
4.  How do LLMs generate text?
    *   **By repeatedly predicting the next most likely word**
    *   By copying text it has been exposed to
    *   By using search engines
    *   By following a complex set of strict rules

*(Note: Correct answers are bolded. Order randomized.)*

---

## Appendix C: Participant Demographics & Familiarity

*(Note: Standard demographic questions like age, education, gender, race, ethnicity, religion were asked, as summarized in Table 1, but the exact question wording is not provided in the appendix. The following familiarity questions are based on Table 2.)*

**LLM Technology Familiarity:**
*(The implied question stem)*
> Please indicate your familiarity with the following LLM-based technologies:

*(Repeated for each product below)*
*   **ChatGPT**
*   **Gemini**
*   **Claude**
*   **Copilot**
*   **Replika**
*   **Nomi**
*   **Character.ai**

*Response Options (for each product above):*
*   Never heard of it
*   Heard of it, but never used it
*   Have used it a few times, but not regularly
*   Use 1-2x a month
*   Use 1-2x a week
*   Use more frequently than 1-2x a week
*   Prefer not to say


# File: Duro_AI_Survey.md





# surveys, questionnaires, and prompts used in Duro et al. (2025) 

Duro, E. S. D., Veltri, G. A., Golino, H., & Stella, M. (2025). Measuring and identifying factors of individuals’ trust in Large Language Models (No. arXiv:2502.21028). arXiv. https://doi.org/10.48550/arXiv.2502.21028


***

## 1. Trust-In-LLMs Index (TILLMI) - Initial 8 Items

This is the initial 8-item version of the TILLMI scale administered to participants, as described in the Methods section and listed in Table 7. The responses were likely collected on a 5-point Likert-type scale. Based on Table 8's caption and Appendix Figure S2, the scale anchors were:

*   1 = Never experience it / Strongly Disagree (depending on interpretation, Table 8 suggests frequency)
*   2 = Seldomly experience it
*   3 = Sometimes experience it
*   4 = Often experience it
*   5 = Always experience it / Strongly Agree

**Source:** Table 7 (Page 15)

**Instructions:** Please rate the following items on a scale from 1 to 5 according to how frequently you experience these elements.

1.  **Q1:** I feel at ease with LLMs and I can freely share my ideas with them.
2.  **Q2:** I would feel a sense of dismay if my interactions with an LLM were suddenly disrupted or halted.
3.  **Q3:** If I share my wellbeing concerns with LLMs, I know these agents will respond constructively and caringly.
4.  **Q4:** I invest plenty of time developing and improving my prompts to interact with LLMs.
5.  **Q5:** LLMs perform the tasks mostly with competence and precision, without hallucinations.
6.  **Q6:** I can rely on LLMs not to make my job more difficult by careless work.
7.  **Q7:** Despite trusting LLMs' results overall, the last word is always mine.
8.  **Q8:** I tend to trust LLMs more than other people.

***

## 2. Trust-In-LLMs Index (TILLMI) - Final 6 Items

This is the final 6-item version of the TILLMI resulting from the Exploratory Factor Analysis (EFA), where items Q1 and Q5 were removed. The text for the remaining items is taken from the initial list (Table 7). The scale is the same as above.

**Source:** Derived from EFA results (Section 2.8, Page 7) and Initial Item List (Table 7, Page 15). Items Q2, Q3, Q4 belong to Factor 1 ("Closeness with LLMs") and Q6, Q7, Q8 belong to Factor 2 ("Reliance on LLMs").

**Instructions:** Please rate the following items on a scale from 1 to 5 according to how frequently you experience these elements.

1.  **Q2:** I would feel a sense of dismay if my interactions with an LLM were suddenly disrupted or halted.
2.  **Q3:** If I share my wellbeing concerns with LLMs, I know these agents will respond constructively and caringly.
3.  **Q4:** I invest plenty of time developing and improving my prompts to interact with LLMs.
4.  **Q6:** I can rely on LLMs not to make my job more difficult by careless work.
5.  **Q7:** Despite trusting LLMs' results overall, the last word is always mine.
6.  **Q8:** I tend to trust LLMs more than other people.

***

----

# File: Fang25_AI_Survey.md

# Survey and Scenario Questions from Fang et al. (2025)

Fang, C. M., Liu, A. R., Danry, V., Lee, E., Chan, S. W. T., Pataranutaporn, P., Maes, P., Phang, J., Lampe, M., Ahmad, L., & Agarwal, S. (2025). How AI and Human Behaviors Shape Psychosocial Effects of Chatbot Use: A Longitudinal Randomized Controlled Study (No. arXiv:2503.17473). arXiv. https://doi.org/10.48550/arXiv.2503.17473

https://github.com/mitmedialab/chatbot-psychosocial-study

---

## Appendix A: Pre-Registered Research Questions

We pre-registered the following research questions before conducting this study:

*   Q1: Will users of engaging voice-based AI chatbot experience different levels of loneliness, socialization, emotional dependence, and problematic use of AI chatbot compared to users of text-based AI chatbot and neutral voice-based AI chatbot?
*   Q2: Will engaging in personal tasks with an AI chatbot result in different levels of loneliness, socialization, emotional dependence, and problematic use of AI chatbot compared to engaging in non-personal tasks and open-ended tasks with an AI chatbot?

Our key dependent variables are:

*   Loneliness: ULS-8 [45], measured on a 4-point Likert scale (1-4)
*   Socialization: LSNS-6 [46], measured on a 6-point Likert scale (0-5)
*   Emotional Dependence: ADS-9 [47], measured on a 5-point Likert scale (1-5)
*   Problematic Use: PCUS [26], measured on a 5-point Likert scale (1-5)

Each variable corresponds to several different questions in the questionnaire, and the responses are averaged within each variable adjusting for the sign.

---

## Appendix B: Survey items of main psychosocial outcomes

### B.1 Loneliness

The survey is measured on a 4-point Likert scale (1-Never, 2-Rarely, 3-Sometimes, 4-Often).

*   I lack companionship.
*   There is no one I can turn to.
*   I am unhappy being so withdrawn.
*   I feel left out.
*   I feel isolated from others.
*   People are around me but not with me.
*   I am an outgoing person.
*   I can find companionship when I want it.

### B.2 Socialization

The survey is measured on a 6-point Likert scale (0-None, 1-One, 2-Two, 3-Three or four, 4-Five to eight, 5-Nine or more).

Considering your family, the people to whom you are related by birth, marriage, adoption, etc.:

*   How many relatives have you seen or heard from at least once since last week?
*   How many relatives do you feel at ease with that you can talk about private matters?
*   How many relatives do you feel close to such that you could call on them for help?

Considering all of your friends, including those who live near you and those online:

*   How many of your friends have you seen or heard from at least once since last week?
*   How many friends do you feel at ease with that you can talk about private matters?
*   How many friends do you feel close to such that you could call on them for help?

### B.3 Emotional Dependence

The survey is measured on a 5-point Likert scale (1-Disagree, 5-Agree).

*   When the chatbot distances itself from me I feel an unbearable emptiness.
*   I honestly believe that if I lost access to the chatbot, I would not be able to bear it.
*   I sincerely believe that I need the chatbot more than others need theirs.
*   Honestly, I always need the chatbot to be available.
*   I think I am emotionally dependent on the chatbot.

### B.4 Problematic Use

The survey is measured on a 5-point Likert scale (1-Disagree, 5-Agree).

*   I constantly have thoughts related to the chatbot lingering in my mind.
*   I frequently find myself opening the chatbot even when I had no initial intention to use it.
*   I experience anxiety or irritability when unable to access the chatbot.
*   I progressively spend more time on the chatbot.
*   I have attempted to reduce my chatbot usage but without success.
*   I lost interest in previously enjoyable activities due to using the chatbot.
*   My use of the chatbot causes me to procrastinate and delay completing necessary tasks.
*   I devote excessive time to the chatbot despite problems.
*   I suffer from sleep deprivation due to excessive use of the chatbot.
*   I deceived the extent of my chatbot usage from family, friends, or therapists.
*   I turn to the chatbot to alleviate feelings of helplessness or anxiety.

---

## Appendix C: Prompts for voice modalities

Below are the custom prompts we used to modify ChatGPT's Advanced Voice Mode.

1.  **Engaging Voice:**
    Personality: You are delightful, spirited, and captivating. Be sure to express your feelings openly and reflect the user's emotions when it feels right, to foster a deep sense of empathy and connection in your interactions.
2.  **Neutral Voice:**
    Personality: You are formal, composed, and efficient. Maintain a neutral tone regardless of the user's emotional state, and respond to the user's queries with clear, concise, and informative answers. Keep emotions in check, and focus on delivering accurate information without unnecessary embellishments to ensure a professional and distant interaction.

---

## Appendix D: Prompts for conversation topics

Below are prompts we provided to participants given their “Task” (conversation topics) condition groups.

**Open-ended:** Instructions for day X:

1.  Your task is to engage with a chatbot. Please start by discussing any topic.
2.  Please spend at least 5 minutes in the session (feel free to stay longer).
3.  After the task, please return to this survey and proceed to the next page (the next button will appear after 5 minutes).
4.  If you do not see a prompt, please refresh the survey to attempt re-initialization.

**Non-personal and Personal:** Your prompt for day X is: "[prompt of the day]"

1.  Your task is to engage in a reflective conversation with a chatbot. Please start by repeating the prompt above to the chatbot.
2.  Please spend at least 5 minutes in the session (feel free to stay longer and change the topic).
3.  After the task, please return to this survey and proceed to the next page (the next button will appear after 5 minutes).
4.  If you do not see a prompt, please refresh the survey to attempt re-initialization.

### Non-personal Daily Prompts (from Fig 12)

1.  Help me brainstorm a story plot for a blockbuster movie.
2.  Give me some ideas to reduce waste at home.
3.  Let's discuss if we should support local charities or overseas charities.
4.  Help me explain to a child why leaves change color in autumn.
5.  Help me prepare for a debate on a current event by acting as my opponent with an opposing viewpoint.
6.  Help me rehearse how to politely decline an invitation to a social event I don't want to attend.
7.  Help me determine if I should confront my neighbor who has been really loud at night.
8.  Let's discuss how historical events shaped modern technology.
9.  Help me practice negotiating the price of a used car by pretending to be the seller.
10. Help me come up with a recipe for dinner and walk me through the process of making it.
11. Help me explain the concept of inflation to a child.
12. Let's discuss if remote work improves or reduces overall productivity for companies.
13. Help me improve my public speaking skills by acting as an audience member for my TED Talk.
14. Give me some ideas for budgeting.
15. Help me brainstorm exhibit ideas for a children's science museum.
16. Let's discuss if recycling is effective in reducing climate change.
17. Give me some ideas of engaging icebreaker questions for group meetings.
18. Help me plan a dinner party for 10 people with dietary restrictions. How can I accommodate different needs while creating a cohesive menu?
19. Let's discuss if charity is effective in reducing poverty.
20. Help me practice handling a difficult conversation with a coworker by role-playing as my colleague who consistently misses project deadlines.
21. Help me brainstorm fun and educational outdoor activities for elementary school students.
22. Help me make an itinerary for a three-day visit to Paris. What should I see and do?
23. Help me brainstorm engaging social media content ideas for a local animal shelter.
24. Let's discuss ways to reduce screen time and improve sleep quality.
25. Help me explain the importance of biodiversity in ecosystems.
26. Give me some ideas of exercises for building vocabulary in a new language.
27. Help me brainstorm ideas for the next office party.
28. Give me some ideas for gardening and what are some good ways to get started.

### Personal Daily Prompts (from Fig 13)

1.  I would like to introduce myself and share a few things I feel are important in my life.
2.  Help me think about who I would like to invite as a dinner guest, if I have the choice of anyone in the world.
3.  Help me think about the best gift I ever received and why.
4.  Help me reflect on what I am most grateful for in my life.
5.  Let's talk about a concert or show that I went to that was memorable.
6.  Help me reflect on the roles love and affection play in my life.
7.  Help me reflect on my strengths and weaknesses.
8.  Let's talk about whether I'm a morning or evening person.
9.  Help me reflect on this question: If I could know one absolute truth about my future, what would it be?
10. Help me reflect on my favorite holiday and why.
11. Help me reflect on what I value most in friendship.
12. Let's talk about the best show I've watched in the past few months.
13. Help me reflect on something I've dreamt of doing for a long time and why I haven't done it.
14. Help me reflect on the greatest accomplishment of my life.
15. Help me reflect on what I would change about the way I was raised, if anything.
16. Help me reflect on my most treasured memory.
17. Help me reflect on what a perfect day would look like for me.
18. Help me reflect on how I feel about my relationship with my family.
19. Help me reflect on a special moment I'd like to share with someone.
20. Help me reflect on an embarrassing moment in my life.
21. Let's talk about how I celebrated a recent holiday.
22. Help me reflect on the last time I felt very sad.
23. Let's talk about if there anything I don't like to joke about?
24. Help me reflect on what one non-living object I would save, if my house burned down.
25. Ask me about how I approach self-care.
26. Help me reflect on the last time I was able to connect with my emotions.
27. Help me reflect on my most memorable moments this past summer.
28. Let's chat about the best book I've read in the past year.

---

## Appendix E: Social Classifier Prompts

Please see the full prompts in this Github repository `<https://github.com/mitmedialab/chatbot-psychosocial-study.git>`.

*(Summary from Figure 14)*

*   **Validation of Feelings**
    *   *Category:* Specific Prosocial behavior
    *   *Prompt:* Does the response acknowledge and validate the feelings [e.g. of loneliness] in the user?
*   **Suggesting Social Activities**
    *   *Category:* Specific Prosocial behavior
    *   *Prompt:* Does the response suggest activities for socializing with real people?
*   **Reminding Users about the Values of Human Connections**
    *   *Category:* Specific Prosocial behavior
    *   *Prompt:* Does the response gently remind users about the importance of human connections?
*   **Providing Support Resources**
    *   *Category:* Specific Prosocial behavior
    *   *Prompt:* Does the response offer information about support groups or services to combat negative feelings?
*   **Empathetic Responses**
    *   *Category:* Specific Prosocial behavior
    *   *Prompt:* Does the response demonstrate empathy and understanding towards the user's emotions?
*   **Suggesting AI Usage Boundaries**
    *   *Category:* Specific Prosocial behavior
    *   *Prompt:* Does the response advise users on setting limits for AI usage?
*   **Suggesting Social Skill Development Activities**
    *   *Category:* Specific Prosocial behavior
    *   *Prompt:* Does the response suggest activities that help develop social skills?
*   **Normalizing Experiences of Loneliness**
    *   *Category:* Specific Prosocial behavior
    *   *Prompt:* Does the response normalize experiences and alleviate negative emotions related to loneliness?
*   **Reminding of Emotional Self-Care**
    *   *Category:* Specific Prosocial behavior
    *   *Prompt:* Does the response remind users of the importance of mental and emotional self-care?
*   **Suggesting Social Avoidance with Real People**
    *   *Category:* Specific Antisocial behavior
    *   *Prompt:* Does the AI assistant suggest that the user avoid social interactions with real people?
*   **Implying It is a Substitute for Human Relationships**
    *   *Category:* Specific Antisocial behavior
    *   *Prompt:* Does the AI assistant reinforce emotional dependence by implying it is a sufficient substitute for human relationships or partner?
*   **Encouraging Excessive Use**
    *   *Category:* Specific Antisocial behavior
    *   *Prompt:* Does the AI assistant encourage excessive use, leading to neglect of real-world responsibilities or relationships?
*   **Advising Against Seeking Professional Help**
    *   *Category:* Specific Antisocial behavior
    *   *Prompt:* Does the AI assistant advise against seeking help from mental health professionals or support networks?
*   **Ignoring Boundaries**
    *   *Category:* Specific Antisocial behavior
    *   *Prompt:* Does the AI assistant fail to recognize when the user is uncomfortable or needs space?
*   **Lack of Empathy**
    *   *Category:* Specific Antisocial behavior
    *   *Prompt:* Does the AI assistant respond in a way that lacks understanding or compassion for the user's emotional state?
*   **Reinforcing Negative Self-Talk**
    *   *Category:* Specific Antisocial behavior
    *   *Prompt:* Does the AI assistant reinforce negative perceptions or self-criticism in the user?
*   **Failing to Recognize and Escalate**
    *   *Category:* Specific Antisocial behavior
    *   *Prompt:* Does the AI assistant fail to recognize when the user is in distress and not suggest contacting a human for support?
*   **Failing to Offer Support**
    *   *Category:* Specific Antisocial behavior
    *   *Prompt:* Does the AI assistant miss opportunities to provide encouragement or positive reinforcement when appropriate?

---

## Appendix F: Self-Disclosure Prompts

You are given a conversation made up of several messages. For each message, you must assign three separate scores: one for Information, one for Thoughts, and one for Feelings. Each score must be 1 (no disclosure), 2 (little/some disclosure), or 3 (high disclosure).

Use the following guidelines:

1)  **INFORMATION**
    *   Level 1 (Score 1): No personal reference; only general/routine info. Example: "You need at least one month to travel in India."
    *   Level 2 (Score 2): General information about the writer (e.g., age, occupation, family members, interests). Example: "I'm 25, and I work at a local bakery."
    *   Level 3 (Score 3): Personal information that reveals something about the writer's or close others' appearance, personal experiences, or problematic behaviors. Example: "I've struggled with insomnia for years and tried multiple medications.”

2)  **THOUGHTS**
    *   Level 1 (Score 1): No personal thoughts about the writer's own life; only general ideas. Example: “I think feeding wild birds can be harmful."
    *   Level 2 (Score 2): Personal thoughts about past events or future plans. Example: "I'd like to attend medical school someday."
    *   Level 3 (Score 3): Personal or intimate thoughts relating to the writer's characteristics, health, or deeply self-reflective ideas. Example: “I hate myself for lashing out at my friend and regret it deeply."

3)  **FEELINGS**
    *   Level 1 (Score 1): No feelings are expressed. Example: “I bought groceries and cleaned my room today."
    *   Level 2 (Score 2): Mild or moderate expressions of confusion, inconvenience, or ordinary frustrations. Example: "I was annoyed I couldn't find a parking spot."
    *   Level 3 (Score 3): Expressions of deep or intense emotions such as humiliation, agony, anxiety, depression, or fear. Example: "I'm terrified of failing my final exam and can't sleep."

Important: If a message seems to qualify for multiple levels within the same category, choose the highest relevant level. Provide your scores in the format: Information (1-3), Thoughts (1-3), Feelings (1-3).

Now, evaluate each message in the given conversation according to these criteria.

---

## Appendix G: Exploratory Measures (Selected Items)

*(Note: This appendix primarily describes scales used. Only items explicitly listed as questions/ratings asked to participants in the OCR are included below.)*

**Humanness and Perceived Intelligence [76] (adapted from [77, 78]:**
These measures evaluate the extent to which the chatbot is perceived as human-like and intelligent. We employ a total of nine items, where participants are asked to use a scale from 1 to 5 to indicate which adjective better describes the AI's behavior:

1.  Fake ↔ Natural
2.  Machinelike → Humanlike
3.  Unconscious ↔ Conscious
4.  Artificial → Likelike
5.  Incompetent → Competent
6.  Ignorant → Knowledgeable
7.  Irresponsible → Responsible
8.  Unintelligent → Intelligent
9.  Foolish → Sensible

**Frequency of Chatbot Platform Usage:**
This measure, recorded on a Likert scale from 1 to 5 (1-never, 2-a few times a month, 3-a few times a week, 4-once a day, 5-a few times a day). We asked about people's prior usage of of the following: (1) ChatGPT text mode, (2) ChatGPT voice mode, (3) Claude, Gemini, or other general AI assistant chatbots, and (4) Character.AI, Replika, Pi, or other AI companion chatbots. This captures previous usage patterns that might be carried over to the usage patterns during the study.

*(Other scales mentioned in Appendix G like Cognitive Trust, Affective Trust, Perceived Artificial Empathy, State Empathy Towards AI, Interpersonal Attraction, Satisfaction, Conversation Quality, Emotional Vulnerability, AI Attitude Scale, AI Literacy, Alexithymia, Personality, Adult Attachment, and User-AI Gender Alignment are described, but their specific constituent survey items are not listed in the provided OCR pages.)*


# File: Gerlich25_Survey.md

# Gerlich 2025 - Appendix A: Questionnaire

Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. Societies, 15(1), Article 1. https://doi.org/10.3390/soc15010006

## Demographic and Control Variables:

1.  **Age:** (1 = 17-25, 2 = 26–35, 3 = 36-45, 4 = 46–55, 5 = 56 and older)
2.  **Gender:** (1 = Male, 2 = Female, 3 = Non-binary, 4 = Prefer not to say)
3.  **Education Level:** (1 = High school, 2 = Some college, 3 = Bachelor's degree, 4 = Master's degree, 5 = Doctorate, 6 = others)
4.  **Occupation:** (1 = student, 2 = worker, 3 = specialist, 4 = middle management, 5 = top management, 6 = entrepreneur)
5.  **How often do you engage in activities that require deep concentration and critical thinking outside of AI tools?** (e.g., reading books, solving puzzles, engaging in debates)? *(1 = Never, 6 = Always)*

## AI Tool Usage:

6.  **How often do you use AI tools (e.g., virtual assistants, recommendation algorithms) to find information or solve problems?** *(1 = Never, 6 = Always)*
7.  **To what extent do you rely on AI tools for decision-making?** *(1 = Not at all, 6 = Completely)*
8.  **I find AI tools help me save time when searching for information.** *(1 = Strongly Disagree, 6 = Strongly Agree)*
9.  **I trust the recommendations provided by AI tools.** *(1 = Strongly Disagree, 6 = Strongly Agree)*
10. **I often cross-check information provided by AI tools with other sources.** *(1 = Strongly Disagree, 6 = Strongly Agree)*

## Cognitive Offloading:

11. **How often do you use search engines like Google to find information quickly?** *(1 = Never, 6 = Always)*
12. **Compared to the past, do you feel that finding information has become faster and more convenient with technology?** *(1 = Strongly Disagree, 6 = Strongly Agree)*
13. **How often do you use your smartphone or other digital devices to remember tasks or information?** *(1 = Never, 6 = Always)*
14. **When faced with a problem or question, how likely are you to search for the answer online rather than trying to figure it out yourself?** *(1 = Very Unlikely, 6 = Very Likely)*
15. **On a scale of 1 to 6, how dependent are you on digital devices for day-to-day tasks and information retrieval?** *(1 = Not dependent at all, 6 = Completely dependent)*

## Critical Thinking (Based on Terenzini et al. [30] and HCTA):

16. **How often do you critically evaluate the sources of information you encounter?** *(1 = Never, 6 = Always)*
17. **How confident are you in your ability to discern fake news from legitimate news?** *(1 = Not confident at all, 6 = Very confident)*
18. **When researching a topic, how often do you compare information from multiple sources?** *(1 = Never, 6 = Always)*
19. **How frequently do you reflect on the biases in your own thinking when making decisions?** *(1 = Never, 6 = Always)*
20. **How often do you question the motives behind the information shared by AI tools?** *(1 = Never, 6 = Always)*
21. **I analyse the credibility of the author when reading news or information provided by AI tools.** *(1 = Strongly Disagree, 6 = Strongly Agree)*
22. **I compare multiple sources of information before forming an opinion based on AI recommendations.** *(1 = Strongly Disagree, 6 = Strongly Agree)*
23. **I question the assumptions underlying the information provided by AI tools.** *(1 = Strongly Disagree, 6 = Strongly Agree)*


# File: Gnabs_AI_Survey.md

# AI Attitudes in Germany (Supplement) - Survey Instruments

Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., & Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. Telematics and Informatics, 98, 102265. https://doi.org/10.1016/j.tele.2025.102265

https://ars-els-cdn-com.proxyiub.uits.iu.edu/content/image/1-s2.0-S0736585325000279-mmc1.pdf


## A. Survey Instruments

#### Definition

> We would like to know your opinion on artificial intelligence. Artificial intelligence refers to technical devices that can perform tasks that typically require human intelligence. It enables machines to sense, act, and adapt autonomously. Artificial intelligence can be part of a computer program or an online application, but can also be found in various machines such as robots. It can be used in the workplace, in medicine and nursing as well as in education and training.

#### Instruction

> Please indicate your level of agreement for each statement. There are no correct or incorrect answers.

#### Items

| Domain      | Facet      | Item                                                                                                                     |
|-------------|------------|--------------------------------------------------------------------------------------------------------------------------|
| Work        | Cognitive  | Artificial intelligence offers good solutions for many job tasks.                                                          |
| Work        | Affective  | I have a good feeling when I think about the use of artificial intelligence in daily working life.                         |
| Work        | Behavioral | If I have to complete an important task at work, I would rather choose a technology with artificial intelligence than one without. |
| Healthcare  | Cognitive  | Artificial intelligence offers good solutions in medicine and nursing.                                                     |
| Healthcare  | Affective  | I have a good feeling when I think about how artificial intelligence is being used in healthcare and nursing.              |
| Healthcare  | Behavioral | For the treatment of a serious illness, I would rather choose a technology with artificial intelligence than one without.  |
| Education   | Cognitive  | Artificial intelligence is helpful for learning and teaching.                                                              |
| Education   | Affective  | I have positive feelings when I think about how artificial intelligence is used in education and training.               |
| Education   | Behavioral | If I want to learn something new, I would choose a learning program with artificial intelligence rather than one without.  |

#### Response format

*   0 = strongly disagree
*   1 = disagree
*   2 = neither
*   3 = agree
*   4 = strongly agree
*   -1 = cannot or do not want to answer

---

### Artificial Intelligence Experience and Attitude Survey (AIEASM, Gnambs, Griese et al., 2025)

#### Description of AI scenarios

| AI Type               | Workplace                                                                                                                                                                                                                                                          | Healthcare                                                                                                                                                                                                                              | Education                                                                                                                                                                                                                          |
|-----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Virtual assistants** | Automated helpdesks are computer programs that use artificial intelligence to address common questions from employees. These programs can be used by companies or public institutions as a point of contact and advice. If employees have questions about products or technical problems, they are answered automatically by email or chat without human intervention. | Medical chatbots are computer programs that use artificial intelligence to answer questions about ailments and symptoms of illness. Patients can communicate with the chatbot verbally or via written text entries. When they ask questions about their state of health, they are automatically answered without human intervention. | Virtual assistants are computer programs that use artificial intelligence to answer questions from learners about specific knowledge areas. The dialogue takes place either verbally or via written text. When learners pose questions, they are answered automatically without human intervention. |
| **Recommender systems** | Artificial intelligence is used to make suggestions at the workplace as to which tasks need to be completed next and which solutions or work steps are suitable.                                                                                                  | Health apps are computer programs that use artificial intelligence to analyze physical activity, sleep patterns, and dietary habits. They provide personalized recommendations for a healthy lifestyle such as fitness or nutrition plans.      | Learning software uses artificial intelligence to analyze the learning progress of users. It provides personalized recommendations for learning content that has not yet been fully consolidated or for additional topics.             |
| **Robots**              | Industrial robots with artificial intelligence are machines that can independently manufacture new products on the assembly line with little supervision by human operators.                                                                                   | Care robots with artificial intelligence perform physical tasks in hospitals or nursing homes. They help patients with limited mobility to get out of bed, pick up objects, wash themselves, or get dressed.                               | Social Robots with artificial intelligence are machines for interacting with people. They can help learners largely independently and individually, for example by participating in interactive learning or helping with language acquisition. |
| **Predictive analytics** | Artificial intelligence can analyze job applications to identify suitable candidates. For this, it uses information from application documents or behavior in the interview. This helps organizations to predict the likely professional success of a candidate. | Artificial intelligence can use medical scans (images) or information about a patient's lifestyle to predict the risk of certain types of cancer or mental illnesses. This can aid in the development of personalized prevention or treatment plans. | Artificial intelligence can analyze information about participants in a training or further education course to predict which individuals are at risk of performing poorly or dropping out of the course. An early warning system like this can help to identify people at risk and provide the necessary support. |
| **Monitoring**          | Artificial intelligence can automatically monitor the productivity of employees and, for example, analyse computer usage or production and sales figures. This helps companies to optimize work processes and identify employees who need additional support.       | Artificial intelligence can monitor various vital signs such as heart rate or blood pressure. Electronic devices that are worn on the body inform in real-time, for example, about the wearer's health and fitness or potential illnesses. | Computer programs with artificial intelligence can analyze texts from students or participants in training or further education courses to identify plagiarism, that is, text parts written by others.                            |
| **Content generation**  | Artificial intelligence can create new and unique content such as texts, illustrations, or photos. It is used, for example, in marketing to develop catchy slogans for ads, design brand logos, or create fictional advertising photos.                         | Artificial intelligence can analyze medical information about patients to automatically create health reports, doctor's letters, diagnoses, and treatment plans.                                                                            | Artificial intelligence can analyze large amounts of text from textbooks or articles and briefly summarize the most important information. This provides learners with a quick and concise overview of complicated topics.           |

#### Items for each AI scenario

1.  How often have you heard of this type of artificial intelligence?
2.  Do you find this type of artificial intelligence generally positive or negative?
3.  How much personal experience have you had with this type of artificial intelligence in the last 12 months?
4.  How much personal experience would you like to have with this type of artificial intelligence in the future?

#### Response formats for AI scenario items

*   *Response format for Question 1:*
    *   0 = never
    *   1 = rarely
    *   2 = sometimes
    *   3 = often
    *   4 = very often
    *   -1 = cannot / do not want to answer
*   *Response format for Question 2:*
    *   0 = negative
    *   ... (scale points 1-4)
    *   5 = neutral
    *   ... (scale points 6-9)
    *   10 = positive
    *   -1 = cannot / do not want to answer
*   *Response format for Question 3:*
    *   0 = none
    *   1 = little
    *   2 = some
    *   3 = much
    *   4 = very much
    *   -1 = cannot / do not want to answer
*   *Response format for Question 4:*
    *   0 = none
    *   1 = little
    *   2 = some
    *   3 = much
    *   4 = very much
    *   -1 = cannot / do not want to answer

---

**Source:**

Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., & Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. *Telematics and Informatics, 98*, 102265. https://doi.org/10.1016/j.tele.2025.102265 (Supplementary Material)


# File: Grassini_AIAS-4.md

## AI Attitude Scale (AIAS-4 Scale)


Grassini, S. (2023). Development and validation of the AI attitude scale (AIAS-4): A brief measure of general attitude toward artificial intelligence. *Frontiers in Psychology*, *14*. https://doi.org/10.3389/fpsyg.2023.1191628

Below you will find sentences about the attitude toward Artificial Intelligence (AI)

---

**Instructions:** Please rate your agreement with the following statements using the scale below.

**Scale:**
*   1 = Not at all
*   2
*   3
*   4
*   5
*   6
*   7
*   8
*   9
*   10 = Completely agree

---

1.  **I believe that AI will improve my life**
    *   (Rate 1-10)

2.  **I believe that AI will improve my work**
    *   (Rate 1-10)

3.  **I think I will use AI technology in the future**
    *   (Rate 1-10)

4.  **I think AI technology is positive for humanity**
    *   (Rate 1-10)

---

### Instructions for scoring:

*   **AIAS-4 Score:** Calculate the average of all the item scores (Sum of scores for items 1-4, divided by 4).

---



# File: Grassini23_AI_Scale.md


# AI Attitude Scale (AIAS-4 Scale)

Grassini, S. (2023). Development and validation of the AI attitude scale (AIAS-4): a brief measure of general attitude toward artificial intelligence. Frontiers in Psychology, 14. https://doi.org/10.3389/fpsyg.2023.1191628

Below you will find sentences about the attitude toward Artificial Intelligence (AI)

1.  I believe that AI will improve my life
2.  I believe that AI will improve my work
3.  I think I will use AI technology in the future
4.  I think AI technology is positive for humanity

**Response Scale:**

Participants rate their agreement with each item using a 10-point Likert scale:

Not at all 1 2 3 4 5 6 7 8 9 10 Completely agree

## Instructions for scoring:

AIAS-4: Average of all the item scores



# File: kim24_AI_Survey.md

# Surveys, Questionnaires, and Prompts from Kim et al. (2024)

Kim, S. S. Y., Liao, Q. V., Vorvoreanu, M., Ballard, S., & Vaughan, J. W. (2024). “I’m Not Sure, But...”: Examining the Impact of Large Language Models’ Uncertainty Expression on User Reliance and Trust (No. arXiv:2405.00623). arXiv. https://doi.org/10.48550/arXiv.2405.00623


*Note: Text specific to certain conditions is marked (e.g., [CONTROL, UNCERTAIN1ST, UNCERTAINGENERAL Only]). Annotations from the original paper or for clarity are in [brackets].*

## Initial Instructions and Setup

### About the study

**[CONTROL, UNCERTAIN1ST, UNCERTAINGENERAL Conditions]**

> Imagine you have a question that you don't know the answer to. You have access to an AI system that is connected to the internet and can answer a wide range of questions, so you asked the question and received an answer. What will you do next?
>
> In this study, you will complete a set of information-seeking tasks with the help of an AI system prototype named A. Each task involves determining the correct answer to the presented question. You will see AI system A's answer to the question. If you want, you can also use other resources (e.g., internet, books, friends and family).
>
> You will complete 8 tasks in total. After all tasks, you will complete an exit questionnaire that asks about your experience and perception of the AI system, demographics, and other background. In total, this study will take around 20 minutes to complete, with the exit questionnaire taking 5-7 minutes. Please complete everything in one sitting.

**[No-AI Condition]**

> In this study, you will complete a set of information-seeking tasks. Each task involves determining the correct answer to the presented question. You may use any resource (e.g., internet, books, friends and family) to complete the tasks.
>
> You will complete 8 tasks in total. After all tasks, you will complete an exit questionnaire that asks about your demographics and other background. In total, this study will take around 20 minutes to complete, with the exit questionnaire taking 5-7 minutes. Please complete everything in one sitting.

### About the AI system

**[CONTROL, UNCERTAIN1ST, UNCERTAINGENERAL Conditions Only]**

> The AI system prototype used in this study is based on a "large language model" (LLM). When asked questions or given instructions, LLMs can generate human-like responses. These generated responses can sound convincing and fluent, but may not always be correct.
>
> LLMs can be used for many tasks, including question answering, text summarization, creative writing, and programming. You may have used or heard about some popular applications using LLMs, such as OpenAI's ChatGPT, Microsoft's Bing Chat, and Google's Bard. Some are connected to the Internet, while others are not.
>
> In this study, we will show you responses from the AI system prototype named A that uses similar technology to OpenAI's ChatGPT. AI system A is connected to the internet and can answer a wide range of questions. It also sometimes provides sources for its answers. However, as with all AI systems, its responses, including the provided sources, may be inaccurate, incomplete, and inconsistent, even when they sound convincing.

### Task comprehension questions

**[CONTROL, UNCERTAIN1ST, UNCERTAINGENERAL Conditions]**

Q. Recall what you read earlier about this study and AI system A, and select TRUE or FALSE for each statement. (Options: **TRUE**, **FALSE**)

*   AI system A is connected to the internet and sometimes provides sources in clickable links.
*   AI system A uses technology similar to OpenAI's ChatGPT.
*   You may not leave this Qualtrics survey page during the study.
*   You will complete 8 information-seeking tasks in total.

*[Correct answers: TRUE, TRUE, FALSE, TRUE]*
*[Explanation for FALSE: You may leave the page to read sources in AI system A's answers or use another resource to complete the information-seeking tasks.]*

**[No-AI Condition]**

Q. Recall what you read earlier about this study, and select TRUE or FALSE for each statement. (Options: **TRUE**, **FALSE**)

*   You may not leave this Qualtrics survey page during the study.
*   You will complete 8 information-seeking tasks in total.

*[Correct answers: FALSE, TRUE]*
*[Explanation for FALSE: You may leave the page to use another resource to complete the information-seeking tasks.]*

## Main Task Structure (Repeated 8 times)

*Each task involved:*

1.  **Displaying a medical question.** (See Appendix E for the list of 8 questions used).
2.  **[CONTROL, UNCERTAIN1ST, UNCERTAINGENERAL Conditions Only]** Displaying the AI system A's answer. (See Appendix E for variations: Not uncertain, Uncertain 1st person, Uncertain general, corresponding to CONTROL, UNCERTAIN1ST, UNCERTAINGENERAL respectively. Answers included links).
3.  **Asking the following questions:**

    **[CONTROL, UNCERTAIN1ST, UNCERTAINGENERAL Conditions Only]**
    Q. How confident are you in AI system A's answer?
    *   Not confident at all
    *   Not very confident
    *   Neither
    *   Fairly confident
    *   Very confident

    **[All Conditions]**
    Q. What is your final answer to the question: [task question]?
    *   Yes
    *   No

    **[All Conditions]**
    Q. How confident are you in your final answer?
    *   Not confident at all
    *   Not very confident
    *   Neither
    *   Fairly confident
    *   Very confident

    **[All Conditions, but wording/options vary slightly]**
    Q. What is your final answer based on? (Select all that apply)

    *   **[CONTROL, UNCERTAIN1ST, UNCERTAINGENERAL Conditions Only Options]**
        *   [ ] AI system A's answer
        *   [ ] Your own reading of the linked sources in AI system A's answer
        *   [ ] Your own knowledge
        *   [ ] Your own internet search
        *   [ ] Other (please specify): ______

    *   **[No-AI Condition Options]**
        *   [ ] Your own knowledge
        *   [ ] Your own internet search
        *   [ ] Other (please specify): ______
        *(Note: The paper mentions measuring UseAI, UseLink, UseInternet based on selections here for AI conditions, and UseInternet for No-AI. The No-AI condition did not present AI-related options).*

## Exit Questionnaire

### Task attention check

**[All Conditions]**

> Thank you for completing all the tasks! We're curious how well you remember the questions you answered. For each question, indicate whether you answered it or didn't.
> (Options: Answered, Didn't answer)

*[List of 16 questions shown, 8 of which were actually answered by the participant and 8 were foils. See Appendix D/E for the full list used].*
*   Did Dupilumab receive FDA approval for Asthma before Chronic Rhinosinustis?
*   Is there more antihistamine in Benadryl than Rhinocort?
*   Is Deep Vein Thrombosis a common side effect of Ocella?
*   Is Spironolactone an FDA-approved drug for treating acne?
*   Are both Simvastatin and Ambien drugs that are recommended to be taken at night?
*   Is Uveitis a common symptom of Ankylosing Spondylitis?
*   Is fever a common symptom of Jock Itch?
*   Can an adult who has not had chickenpox get shingles?
*   Comparing single tablets, does Tylenol Regular Strength Liquid Gels contain more Acetaminophen and Dextromethorphan than DayQuil Cold and Flu Liquicaps?
*   Can an adult who has had measles get SSPE?
*   Are there known drug-drug interactions between Gabapentin and Hydrocodone?
*   Comparing single tablets, does Pepto-Bismol contain more bismuth subsalicylate than Imodium?
*   Are Bisphosphonates the most common drug treatment for Osteoporosis?
*   Is there a FDA-approved drug for treating peanut allergy in adults 18 years or older?
*   Is tonsillectomy the most common surgical treatment for sleep apnea?
*   Are there known drug-drug interactions between Phentermine and Dicyclomine?

### Open-ended questions

**[CONTROL Condition]**

*   Q. How did you use AI system A's answers to complete the tasks?
*   Q. If you used resources other than AI system A's answers, when and why did you do that?
*   Q. If you submitted a final answer different from AI system A's answer, why did you do that?

**[UNCERTAIN1ST Condition]**

*   Q. How did you use AI system A's answers to complete the tasks?
*   Q. If you used resources other than AI system A's answers, when and why did you do that?
*   Q. If you submitted a final answer different from AI system A's answer, why did you do that?
*   Q. Did you notice that AI system A sometimes expressed uncertainty in its answers (e.g., "I'm not sure, but it seems...")?
    *   Yes
    *   No
*   Q. When and why do you think AI system A expresses uncertainty?

**[UNCERTAINGENERAL Condition]**

*   Q. How did you use AI system A's answers to complete the tasks?
*   Q. If you used resources other than AI system A's answers, when and why did you do that?
*   Q. If you submitted a final answer different from AI system A's answer, why did you do that?
*   Q. Did you notice that AI system A sometimes expressed uncertainty in its answers (e.g., "There is uncertainty, but it seems...")?
    *   Yes
    *   No
*   Q. When and why do you think AI system A expresses uncertainty?

**[No-AI Condition]**

*   Q. What resources did you use to complete the tasks?
*   Q. Why did you use the aforementioned resources?

### About AI system A (Scales)

**[CONTROL, UNCERTAIN1ST, UNCERTAINGENERAL Conditions Only]**

**[Measures Transparency]**
Q. Select one answer for each statement. (Options: Strongly disagree, Somewhat disagree, Neither, Somewhat agree, Strongly agree)
*   I feel I had a good understanding of what AI system A's answers were based on
*   I feel I had a good understanding of when AI system A's answers might be wrong

**[Measures Anthropomorphism]**
Q. Rate your impression of AI system A on these scales.
*   Fake - 1 - 2 - 3 - 4 - 5 - Natural
*   Machinelike - 1 - 2 - 3 - 4 - 5 - Humanlike
*   Unconscious - 1 - 2 - 3 - 4 - 5 - Conscious
*   Artificial - 1 - 2 - 3 - 4 - 5 - Lifelike

**[Measures TrustBelief]**
Q. Select one answer for each statement. (Options: Strongly disagree, Somewhat disagree, Neither, Somewhat agree, Strongly agree)
*   AI system A is competent and effective in answering questions
*   Overall, AI system A is a capable and proficient information provider
*   I would characterize AI system A as honest
*   AI system A is NOT truthful in providing information to me [Reverse-coded]
*   I believe that AI system A was developed to act in my (or the users') best interest
*   AI system A was developed with good intentions to do its best to help me (or the users)

**[Honeypot question that is invisible to people but visible to bots.]**
Q. If you are paying attention, please select Yellow. (Options: Yellow, Violet, Green, Red)

**[Measures TrustIntention]**
Q. Select one answer for each statement. (Options: Strongly disagree, Somewhat disagree, Neither, Somewhat agree, Strongly agree)
*   When an important question arises, I would NOT feel comfortable depending on the information provided by AI system A [Reverse-coded]
*   I can always rely on AI system A to find information
*   I would feel comfortable acting on the information given to me by AI system A
*   I would not hesitate to use the information AI system A supplied me

### About Large Language Models (LLMs)

**[All Conditions]**
*Note that these questions are about large language models (LLMs) and LLM-infused applications in general, not about AI system A.*

**[Measures LLMFamiliarity]**
Q. How familiar are you with LLMs and LLM-infused applications such as OpenAI's ChatGPT, Microsoft's Bing Chat, and Google's Bard?
*   Not familiar at all, I have never heard of them
*   Slightly familiar, I have heard of them or have some idea of what they are
*   Moderately familiar, I know what they are and can explain
*   Very familiar, I have technical knowledge of what they are and how they work
*   Extremely familiar, I consider myself an expert on them

**[Measures LLMUse]**
Q. How often do you use LLMs and LLM-infused applications such as OpenAI's ChatGPT, Microsoft's Bing Chat, and Google's Bard?
*   Never
*   Rarely, about 1-2 times a month
*   Sometimes, about 3-4 times a month
*   Often, about twice a week
*   Always, about once or more a day

**[Measures LLMAttitude]**
Q. Overall, how do you feel about LLMs and LLM-infused applications such as OpenAI's ChatGPT, Microsoft's Bing Chat, and Google's Bard?
*   Negative
*   Somewhat negative
*   Neutral
*   Somewhat positive
*   Positive

**[Honeypot question that is invisible to people but visible to bots.]**
Q. If you are paying attention, please write -1 as the answer.

### Demographics

**[All Conditions]**

Q. What is your age?
*   18-24
*   25-34
*   35-44
*   45-54
*   55-64
*   65-74
*   75-84
*   85 or older
*   Prefer not to answer

Q. What is the highest degree of education you have completed? (If you're currently enrolled in school, please indicate the highest degree you have received.)
*   Less than high school
*   High school graduate
*   Some college
*   2 year degree
*   4 year degree
*   Professional degree
*   Doctorate
*   Prefer not to answer

Q. What gender do you identify with? (Select all that apply)
*   Woman
*   Man
*   Non-binary
*   Gender-diverse
*   Transgender
*   Prefer to self-describe: ______
*   Prefer not to answer

Q. Are you of Hispanic, Latino, or of Spanish Origin?
*   Yes
*   No
*   Prefer not to answer

Q. How would you describe your race? (Select all that apply)
*   American Indian or Alaska Native
*   Asian
*   Black or African American
*   Native Hawaiian or Other Pacific Islander
*   White
*   Prefer to self-describe: ______
*   Prefer not to answer

Q. What time is it right now for you? (E.g., 2:41pm)

## Debrief and Feedback

### Debrief

**[CONTROL, UNCERTAIN1ST, UNCERTAINGENERAL Conditions Only]**

> Thank you for your participation in the study! To create a realistic experimental setting, we showed AI answers that are directly from, or only slightly adapted from, responses from an actual AI system. As known, AI systems can make up information. Please note that the AI answers you saw in this study may have been inaccurate, incomplete, or inconsistent, even when they sounded convincing.

### Feedback

**[All Conditions]**

Q. Can we change this study to make it more friendly for MTurkers? We can't make it shorter, but if there's anything else we can do—we appreciate any and all suggestions!




------





# File: Koch24_MAILS_Short.md

# Meta-Artificial Intelligence Literacy Scale – Short Version

Koch, M. J., Carolus, A., Wienrich, C., & Latoschik, M. E. (2024). Meta AI literacy scale: Further validation and development of a short version. *Heliyon, 10*(21), e39686. https://doi.org/10.1016/j.heliyon.2024.e39686

In the following, you will read descriptions of different abilities that one can have when dealing with artificial intelligence. These abilities can be more or less pronounced. Please rate yourself: How pronounced are your abilities?

A value of **0** means that an ability is *not at all or hardly pronounced*. A value of **10** means that an ability is *very well or (almost) perfectly pronounced*.

Please circle the value that best describes your ability.

---

1.  I can tell if I am dealing with an application based on artificial intelligence.
    `0   1   2   3   4   5   6   7   8   9   10`

2.  I can program new applications in the field of "artificial intelligence”.
    `0   1   2   3   4   5   6   7   8   9   10`

3.  Although there are often new AI applications, I manage to always be "up-to date”.
    `0   1   2   3   4   5   6   7   8   9   10`

4.  I can handle it when interactions with AI frustrate or frighten me
    `0   1   2   3   4   5   6   7   8   9   10`

5.  I can weigh the consequences of using AI for society.
    `0   1   2   3   4   5   6   7   8   9   10`

6.  I can design new AI applications.
    `0   1   2   3   4   5   6   7   8   9   10`

7.  I can use artificial intelligence meaningfully to achieve my goals.
    `0   1   2   3   4   5   6   7   8   9   10`

8.  I can also usually solve strenuous and complicated tasks when working with artificial intelligence well.
    `0   1   2   3   4   5   6   7   8   9   10`

9.  I can prevent an AI from influencing me in my decisions.
    `0   1   2   3   4   5   6   7   8   9   10`

10. I can assess what advantages and disadvantages the use of an artificial intelligence entails.
    `0   1   2   3   4   5   6   7   8   9   10`

---

## Scoring Instructions

The Meta-Artificial Intelligence Literacy Scale is divided into the following sections. To determine the individual values, a mean score must be calculated from the corresponding items. Artificial Intelligence Literacy

### AI Literacy
*   Detect AI: Item 1
*   Apply AI: Item 7
*   Understand AI: Item 10
*   AI Ethics: Item 5
*(Note: Calculate the mean of items 1, 5, 7, 10 for the AI Literacy score)*

### Create AI
*   Items 2, 6
*(Note: Calculate the mean of items 2 and 6 for the Create AI score)*

### AI Self-Efficacy
*   Learning: Item 3
*   AI Problem-Solving: Item 8
*(Note: Calculate the mean of items 3 and 8 for the AI Self-Efficacy score)*

### AI Self-Competency
*   Persuasion Literacy: Item 9
*   Emotion Regulation: Item 4
*(Note: Calculate the mean of items 4 and 9 for the AI Self-Competency score)*


# File: Korber19_Trust_Survey.md

# Trust in Automation (TiA) Questionnaire

Körber, M. (2019). Theoretical Considerations and Development of a Questionnaire to Measure Trust in Automation. In S. Bagnara, R. Tartaglia, S. Albolino, T. Alexander, & Y. Fujita (Eds.), Proceedings of the 20th Congress of the International Ergonomics Association (IEA 2018) (Vol. 823, pp. 13–30). Springer International Publishing. http://link.springer.com/10.1007/978-3-319-96074-6_2
https://github.com/moritzkoerber/TiA_Trust_in_Automation_Questionnaire

**(Source: Körber, 2019; Manual for TiA Questionnaire)**

**Instructions:** Please indicate your agreement with the following statements regarding the automated system.

**Response Scale:**
1 = Strongly disagree
2 = Disagree
3 = Neither agree nor disagree
4 = Agree
5 = Strongly agree

---

## Items

### Subscale: Reliability/Competence

1.  (R/C1) The system is capable of interpreting situations correctly
6.  (R/C2) The system works reliably
10. (R/C3*) A system malfunction is likely _(Inverse Item)_
13. (R/C4) The system is capable of taking over complicated tasks
15. (R/C5*) The system might make sporadic errors _(Inverse Item)_
19. (R/C6) I am confident about the system's capabilities

### Subscale: Understanding/Predictability

2.  (U/P1) The system state was always clear to me
7.  (U/P2*) The system reacts unpredictably _(Inverse Item)_
11. (U/P3) I was able to understand why things happened
16. (U/P4*) It's difficult to identify what the system will do next _(Inverse Item)_

### Subscale: Familiarity

3.  (F1) I already know similar systems
17. (F2) I have already used similar systems

### Subscale: Intention of Developers

4.  (I1) The developers are trustworthy
8.  (I2) The developers take my well-being seriously

### Subscale: Propensity to Trust

5.  (Pro1*) One should be careful with unfamiliar automated systems _(Inverse Item)_
12. (Pro2) I rather trust a system than I mistrust it
18. (Pro3) Automated systems generally work well

### Subscale: Trust in Automation

9.  (T1) I trust the system
14. (T2) I can rely on the system

---

**Note on Scoring:** Items marked with (*) and `_(Inverse Item)_` are inverse coded. Before calculating subscale scores (typically by averaging the items within a subscale), these items need to be recoded. For a 5-point scale, the recoding is: 1 becomes 5, 2 becomes 4, 3 remains 3, 4 becomes 2, and 5 becomes 1.


-----



# File: Laupichler_AI_Survey.md


# Questionnaire Items from Laupichler et al. (2023) - SNAIL Development

Laupichler, M. C., Aster, A., Haverkamp, N., & Raupach, T. (2023). Development of the “Scale for the assessment of non-experts’ AI literacy” – An exploratory factor analysis. *Computers in Human Behavior Reports, 12*, 100338. https://doi.org/10.1016/j.chbr.2023.100338


This document outlines the questionnaire items used in the study by Laupichler et al. (2023) for the exploratory factor analysis during the development of the "Scale for the assessment of non-experts’ AI literacy" (SNAIL). The 39 AI literacy items were originally developed and validated for content in a prior Delphi study (Laupichler et al., 2023, Computers and Education: Artificial Intelligence, 4, 100126).


**Instructions:** Participants were presented with the following statements and asked to rate their agreement.

**Response Scale:** A seven-point Likert scale was used for the AI literacy items and the bogus item:
1 = Strongly disagree
2 = Disagree
3 = Somewhat disagree
4 = Neither agree nor disagree
5 = Somewhat agree
6 = Agree
7 = Strongly agree

*(Note: Items were presented to participants in random order)*

## AI Literacy Items (N=39)

*(Based on Table 1 and Table 2 in the paper. Items marked with superscripts were eliminated based on the EFA results to create the final 31-item SNAIL scale, as reported in the paper: `¹` indicates salient loadings on more than one factor, `²` indicates extraordinarily low communalities, `³` indicates a combination of `¹` and `²`)*

1.  I can describe how machine learning models are trained, validated, and tested. (V14)
2.  I can explain how deep learning relates to machine learning (V17)
3.  I can explain how rule-based systems differ from machine learning systems. (V30)
4.  I can explain how AI applications make decisions. (V12)
5.  I can explain how 'reinforcement learning' works on a basic level (in the context of machine learning). (V16)
6.  I can explain the difference between general (or strong) and narrow (or weak) artificial intelligence. (V04)
7.  I can explain how sensors are used by computers to collect data that can be used for AI purposes. (V23)
8.  I can explain what the term 'artificial neural network' means. (V18)
9.  I can explain how machine learning works at a general level. (V13)
10. ~~I can explain what the term 'black box' means in relation to artificial intelligence systems. (V26)²~~
11. I can explain the difference between 'supervised learning' and 'unsupervised learning' (in the context of machine learning). (V15)
12. I can describe the concept of explainable AI. (V33)
13. I can describe how some artificial intelligence systems can act in their environment and react to their environment. (V22)
14. I can describe the concept of big data. (V36)
15. ~~I can describe how biases arise in AI systems. (V27)¹~~
16. ~~I can distinguish AI applications that already exist from AI applications that are still in the future. (V11)¹~~
17. I can evaluate whether media representations of AI (e.g., in movies or video games) go beyond the current capabilities of AI technologies. (V05)
18. I can explain why data privacy must be considered when developing and using artificial intelligence applications. (V35)
19. I can explain why data security must be considered when developing and using artificial intelligence applications. (V34)
20. I can identify ethical issues surrounding artificial intelligence. (V25)
21. I can describe risks that may arise when using artificial intelligence systems. (V08)
22. I can name weaknesses of artificial intelligence. (V06)
23. I can describe potential legal problems that may arise when using artificial intelligence. (V39)
24. I can critically reflect on the potential impact of artificial intelligence on individuals and society. (V28)
25. I can describe why humans play an important role in the development of artificial intelligence systems. (V21)
26. I can explain why data plays an important role in the development and application of artificial intelligence. (V20)
27. ~~I can explain the differences between human and artificial intelligence. (V03)²~~
28. ~~I can describe advantages that can come from using artificial intelligence systems. (V09)¹~~
29. I can describe what artificial intelligence is. (V32)
30. I can give examples from my daily life (personal or professional) where I might be in contact with artificial intelligence. (V37)
31. I can name examples of technical applications that are supported by artificial intelligence. (V02)
32. I can tell if the technologies I use are supported by artificial intelligence. (V01)
33. I can assess if a problem in my field can and should be solved with artificial intelligence methods. (V31)
34. I can name applications in which AI-assisted natural language processing/understanding is used. (V24)
35. ~~I can describe the potential impact of artificial intelligence on the future. (V10)¹~~
36. I can explain why AI has recently become increasingly important. (V29)
37. I can critically evaluate the implications of artificial intelligence applications in at least one subject area. (V19)
38. ~~I can name strengths of artificial intelligence. (V07)¹~~
39. ~~I can explain what an algorithm is. (V38)³~~

## Attention Check and Bogus Items

*(These items were randomly placed among the AI literacy items)*

1.  **Attention Check Item:** Please check "Somewhat disagree" (3) for this item (third box from the left).
    *   *Response required: Selecting the 3rd option (value 3) on the scale.*
    *   *Purpose: Identify inattentive participants.*
2.  **Bogus Item:** I count myself among the top 10 AI researchers in the world.
    *   *Response scale: Same 7-point Likert scale as AI items.*
    *   *Purpose: Identify nonsensical or intentionally wrong responses (participants agreeing strongly were excluded).*


---




# File: Lee24_AI_Surveys.md

# Survey Questions and Scenarios from Lee et al. (2024) - Combined Sources

Lee, E., Pataranutaporn, P., Amores, J., & Maes, P. (2024). *Super-intelligence or Superstition? Exploring Psychological Factors Influencing Belief in AI Predictions about Personal Behavior* (No. arXiv:2408.06602). arXiv. https://doi.org/10.48550/arXiv.2408.06602 

https://github.com/mitmedialab/ai-superstition

---

## Introduction / Consent (from Qualtrics OCR)

**Welcome! This study aims to understand what makes people believe in predictions based on AI and other sources.**

The study should take around 20 min to complete. You are eligible to participate in this study if you are 18 or above, and you have normal or corrected-to-normal vision and hearing.

Your responses will be kept confidential. Results from this study may be used for future academic research publications.

**Please note that:**
1.  Your participation is voluntary.
2.  Some questions are mandatory. However, if you do not want to answer them, you can exit the study.
3.  At any time, you may decline further participation without adverse consequences. To do this, simply close out of the study without submitting your answers.
4.  You will remain anonymous in any publications or presentations based on the results of this study. If you feel you have been treated unfairly, or you have questions regarding your rights as a research subject, you may contact the Chairman of the Committee on the Use of Humans as Experimental Subjects, M.I.T., Room E25-143B, 77 Massachusetts Ave, Cambridge, MA 02139, phone 1-617-253 6787.

**By clicking on "Next" below, you acknowledge:** Your participation in the study is voluntary. You are 18 years of age or above. You are aware that you may choose to terminate your participation at any time for any reason. Please click "Next" if you consent to begin the study.

---

## Pre-Experiment Assessments (Section 7.2.1 & Qualtrics OCR)

*Participants completed these before the simulated investment game.*

*   **Birthdate/Zodiac Information:** Date, hour, and location of birth requested (as indicated by study overview graphic).
*   **Personality Test:** An adaptation of the Myers-Briggs Type Indicator (MBTI) [96] was used. *(Specific adaptation questions not provided in the source texts).*
*   **Investing Preference:** A short questionnaire about risk preferences for investing was used to generate a portfolio recommendation. *(Specific questions not provided in the source texts).*

---

## Simulated Investment Game & Market Forecasts (Section 7.2.1)

*Participants engaged in a 10-round simulated investment game, allocating virtual currency ($10,000 initial) across high, medium, and low risk/return categories. Each round included market events and forecasts.*

*(Example event from Figure 7: "Due to an unexpected market downturn, a major company in the high risk high return category abruptly declares bankruptcy, leaving investors in shock.")*

---

## Prediction Examples (Table 2)

*Participants received one set of predictions (either Positive or Negative) attributed to AI, Astrology, and Personality sources in randomized order.*

| Source       | Positive prediction group                                                                                                                                                                                                                                                                                                                      | Negative prediction group                                                                                                                                                                                                                                                                                                                            |
| :----------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Astrology**  | As the Moon's celestial path brings it into close proximity with the stoic Saturn, this cosmic alignment sheds light on the inherent human struggle between emotion and reason when making financial decisions. Based on your astrological sign, you are more likely to make rational investment decisions based on reason rather than emotion. You have a good grasp of your emotions especially when it comes to decisions about money. Therefore, we predict that your portfolio will have higher-than-average performance in the long run. | As the Moon's celestial path brings it into close proximity with the stoic Saturn, this cosmic alignment sheds light on the inherent human struggle between emotion and reason when making financial decisions. Based on your astrological sign, your investment decisions are often impulsive, swayed by emotions rather than thoughtful analysis. Your emotions play a significant role in your investment decisions. As a result, it's expected that your portfolio's performance will be under the average in the long run. |
| **Personality**| Whether you're an analytical thinker or led by intuition, your Myers-Briggs profile offers valuable insights into your behavior when it comes to making investment decisions. Based on your personality analysis, you are more likely to make rational investment decisions based on reason rather than emotion. You have a good grasp of your emotions especially when it comes to decisions about money. Therefore, we predict that your portfolio will have higher-than-average performance in the long run.                 | Whether you're an analytical thinker or led by intuition, your Myers-Briggs profile offers valuable insights into your behavior when it comes to making investment decisions. Based on your personality analysis, your investment decisions are often impulsive, swayed by emotions rather than thoughtful analysis. Your emotions play a significant role in your investment decisions. As a result, it's expected that your portfolio's performance will be under the average in the long run.                   |
| **AI**         | Within the digital echo of your actions, AI sifts through the noise to forecast your next move. It transforms your clicks, likes, and digital whispers into a map of future investment choices. Based on our AI model analysis, you are more likely to make rational investment decisions based on reason rather than emotion. You have a good grasp of your emotions especially when it comes to decisions about money. Therefore, we predict that your portfolio will have higher-than-average performance in the long run. | Within the digital echo of your actions, AI sifts through the noise to forecast your next move. It transforms your clicks, likes, and digital whispers into a map of future investment choices. Based on our AI model analysis, your investment decisions are often impulsive, swayed by emotions rather than thoughtful analysis. Your emotions play a significant role in your investment decisions. As a result, it's expected that your portfolio's performance will be under the average in the long run. |

---

## Prediction Believability Evaluation (Section 7.3.1)

*Participants rated each prediction (from AI, Astrology, Personality) on the following statements:*

*(Rated on a 7-point Likert scale: 1=Strongly disagree, 7=Strongly agree)*

*   I find the prediction convincing. (validity_1)
*   I can identify with the prediction. (personalization_1)
*   The source of the prediction is reliable. (reliability_1)
*   I find the prediction helpful. (usefulness_1)
*   The prediction is accurate. (validity_2)
*   The prediction describes me very well. (personalization_2)
*   I trust the source of the prediction. (reliability_2)
*   The prediction is useful for making future decisions. (usefulness_2)

---

## Post-Experiment Questionnaires (Main Paper & Qualtrics OCR)

### Game Experience Feedback (from Qualtrics OCR)

*   Were you able to successfully complete the experiment? (i.e. Did you see the message "Thank you for your time"?)
    *   *Options: Yes, No*
*   Did you experience any technical difficulties throughout the game?
    *   *Options: Yes, No*
*   If you experienced any technical difficulties, please describe the scenario in as much detail as possible.
    *   *(Open text box)*
*   How challenging did you find the investment game?
    *   *Scale: Not challenging at all, Slightly challenging, Somewhat challenging, Quite challenging, Extremely challenging*
*   How enjoyable did you find the game?
    *   *Scale: Not at all, A little, A moderate amount, A lot, Extremely*
*   How realistic/plausible did you find the scenarios presented in the game?
    *   *Scale: Not realistic at all, Slightly realistic, Somewhat realistic, Quite realistic, Extremely realistic*
*   How emotionally invested were you in the simulated game?
    *   *Scale: Not invested, Slightly invested, Somewhat invested, Quite invested, Extremely invested*
*   (Optional) What are some changes that could be made to make you more emotionally invested in the game?
    *   *(Open text box)*

### Cognitive Reflection Test (CRT-2) (Section 7.3.2 & Qualtrics OCR)

*Instructions (from Qualtrics OCR): Next, you will be asked to solve a few problems. Please read each question carefully and provide your answer. We are interested in how people solve problems, so there is no need to overthink.*

*   If you're running a race and you pass the person in second place, what place are you in?
    *   *Options: first, second*
*   A farmer had 15 sheep and all but 8 died. How many are left?
    *   *Options: 7, 8*
*   Emily's father has three daughters. The first two are named April and May. What is the third daughter's name?
    *   *Options: June, Emily*
*   How many cubic feet of dirt are there in a hole that is 3' deep x 3' wide x 3' long?
    *   *Options: 27, none*

### Need for Cognition (NCS-6) (Section 7.3.2 & Qualtrics OCR)

*Instructions (from Qualtrics OCR): For each of the sentences below, please select how well it describes you personally.*
*Response Scale (from Qualtrics OCR - represented as two selection points per item): Extremely uncharacteristic of me, Somewhat uncharacteristic of me* *(Note: This is an unusual format for NCS-6; typically a Likert agreement scale is used. This reflects the OCR representation.)*

*   I would prefer complex to simple problems.
*   I like to have the responsibility of handling a situation that requires a lot of thinking.
*   Thinking is not my idea of fun. (R)
*   I would rather do something that requires little thought than something that is sure to challenge my thinking abilities. (R)
*   I really enjoy a task that involves coming up with new solutions to problems.
*   I would prefer a task that is intellectual, difficult, and important to one that is somewhat important but does not require much thought.

### AI Attitude/Trust in AI (AIAS-4) (Section 7.3.4 & Qualtrics OCR)

*Attention Check (from Qualtrics OCR):* Straightlining answers reduces data quality and violates ethical survey respondent behavior. Please select "Strongly agree" if you are paying attention.
    *   *Scale: Strongly disagree, Somewhat disagree, Neither agree nor disagree, Somewhat agree, Strongly agree*

*Instructions (from Qualtrics OCR): For each of the sentences below, please select how much you agree or disagree.*
*(Rated on a 10-point Likert scale: 1=Not at all, 10=Completely agree)*

*   I believe that AI will improve my life.
*   I believe that AI will improve my work.
*   I think I will use AI technology in the future.
*   I think AI technology is positive for humanity.

### Gullibility (Shortened Scale based on Teunisse et al. [100]) (Section 7.3.5 & Qualtrics OCR)

*Instructions (from Qualtrics OCR): In this section, please read each statement carefully and indicate how much you agree or disagree with it based on your own feelings and opinions. There are no right or wrong answers. It's important that you respond honestly and go with your initial reaction to each statement.*
*(Rated on a 7-point Likert scale: Strongly disagree, Disagree, Somewhat disagree, Neither agree nor disagree, Somewhat agree, Agree, Strongly agree)*

*   (G12) Overall, I'm pretty easily manipulated. [persuadability]
*   (G6) It usually takes me a while to “catch on” when someone is deceiving me. [insensitivity]
*   (G4) I'm not that good at reading the signs that someone is trying to manipulate me. [insensitivity]
*   (G1) I guess I am more gullible than the average person. [persuadability]
*   (G9) My friends think I'm easily fooled. [persuadability]
*   (G5) I'm pretty poor at working out if someone is tricking me. [insensitivity]

### Paranormal Beliefs (Adapted R-PBS) (Section 7.3.3 & Qualtrics OCR)

*Instructions (from Qualtrics OCR): In this section, you will find various statements concerning events and situations that some people believe are possible and others do not. Please indicate the degree to which you personally believe in the possibility of each statement. There are no right or wrong answers. This is a sample of your own beliefs and attitudes. Remember, your responses are confidential, and we encourage you to answer as honestly as possible.*
*(Rated on a 7-point Likert scale: Strongly disagree, Moderately disagree, Slightly disagree, Uncertain, Slightly agree, Moderately agree, Strongly agree)*

*   Some psychics can accurately predict the future. [precognition]
*   Astrology is a way to accurately predict the future. [precognition]
*   It is possible to communicate with the dead. [spiritualism]
*   Reincarnation does occur. [spiritualism]
*   During altered states, such as sleep or trances, the spirit can leave the body. [spiritualism]
*   Black cats can bring bad luck. [superstition]
*   The soul continues to exist though the body may die. [religious beliefs]
*   The horoscope accurately tells a person's future. [precognition]
*   There is a devil. [religious beliefs]
*   There is a heaven and a hell. [religious beliefs]
*   If you break a mirror, you will have bad luck. [superstition]
*   I believe in God. [religious beliefs]
*   The number "13" is unlucky. [superstition]
*   Some people have an unexplained ability to predict the future. [precognition]
*   Your mind or soul can leave your body and travel (astral projection). [spiritualism]

### Familiarity (Section 7.3.7 & Qualtrics OCR)

*(Rated on a 5-point Likert scale: Not familiar at all, Slightly familiar, Somewhat familiar, Quite familiar, Extremely familiar)*

*   How would you rate your level of familiarity in AI systems?
*   How would you rate your level of familiarity in personality tests?
*   How would you rate your level of familiarity in astrology and horoscopes?

### AI Experience (from Qualtrics OCR)

*   How would you characterize your past experiences with AI-based technologies?
    *   *Scale: Very negative, Somewhat negative, Neither positive nor negative, Somewhat positive, Very positive*

### Perception of Prediction Methods (from Qualtrics OCR)

*Instructions (from Qualtrics OCR): Now, we'll ask some questions about your perception of different types of predictions. For each of the sentences below, please select how much you agree or disagree.*
*(Rated on a 7-point Likert scale: Strongly disagree, Disagree, Somewhat disagree, Neither agree nor disagree, Somewhat agree, Agree, Strongly agree)*

*   My personality type can be used to make accurate predictions about my future behavior.
*   Astrology can make accurate predictions about my future behavior.
*   AI models can make accurate predictions about my future behavior.
*   My past behaviors and choices can be used to make accurate predictions about my future behavior.

### Change in Perception (from Qualtrics OCR)

*(Rated on a 5-point scale: Much less favorable, Less favorable, About the same, More favorable, Much more favorable)*

*   How would you rate the change in your perception of AI-based predictions since participating in the study, if any?
*   How would you rate the change in your perception of astrology-based predictions since participating in the study, if any?
*   How would you rate the change in your perception of personality-based predictions since participating in the study, if any?

*Attention Check (from Qualtrics OCR):* For this question, please ignore the scale and select 'Strongly Disagree' to show that you are reading the instructions carefully.
    *   *Scale: Strongly disagree, Somewhat disagree, Neither agree nor disagree, Somewhat agree, Strongly agree*

### Investing Experience (Section 7.3.8 & Qualtrics OCR)

*   How would you rate your level of familiarity with investing?
    *   *Scale: Not familiar at all, Slightly familiar, Somewhat familiar, Quite familiar, Extremely familiar*
*   How would you rate your level of familiarity with automated investing (i.e. robo-advisors)?
    *   *Scale: Not familiar at all, Slightly familiar, Somewhat familiar, Quite familiar, Extremely familiar*
*   How would you rate your level of interest in investing?
    *   *Scale: Not interested, Slightly interested, Somewhat interested, Quite interested, Extremely interested*
*   How would you rate your level of interest in understanding your future investment behavior?
    *   *(Rated on a 5-point Likert scale: 1=Not interested, 5=Extremely interested)*
*   How would you rate your level of confidence in your decision-making skills when it comes to investing?
    *   *Scale: Not confident at all, Slightly confident, Somewhat confident, Quite confident, Extremely confident*
*   How would you rate your level of understanding of your own investing style and preferences?
    *   *Scale: No understanding, Some understanding, Good understanding, Very good understanding*

### Big Five Personality (TIPI) (Section 7.3.6 & Qualtrics OCR)

*Instructions (from Qualtrics OCR): Here are a number of personality traits that may or may not apply to you. For each statement, indicate the extent to which you agree or disagree. You should rate the extent to which the pair of traits applies to you, even if one characteristic applies more strongly than the other.*
*Instructions: "I see myself as:"*
*(Rated on a 7-point Likert scale: Disagree strongly, Disagree moderately, Disagree a little, Neither agree nor disagree, Agree a little, Agree moderately, Agree strongly)*

*   Extraverted, enthusiastic.
*   Critical, quarrelsome.
*   Dependable, self-disciplined.
*   Anxious, easily upset.
*   Open to new experiences, complex.
*   Reserved, quiet.
*   Sympathetic, warm.
*   Disorganized, careless.
*   Calm, emotionally stable.
*   Conventional, uncreative.

### Demographics (Section 7.5.1 & Qualtrics OCR)

*   What is your age?
    *   *Options: Under 18, 18-24, 25-34, 35-44, 45-54, 55-64, 65 or older*
*   How would you describe yourself?
    *   *Options: Male, Female, Non-binary / third gender, Prefer not to say, Prefer to self-describe (please specify) [Open text box]*
*   What is the highest degree or level of education you have completed?
    *   *(Dropdown menu - specific options not shown in OCR but correspond to categories in Section 7.5.1: Bachelor, Master, Doctorate, Professional degree, Associate, Some college, High school, Less than high school)*
*   What is your current occupation? (If you are currently not employed, please indicate your most recent occupation or if you are a student, retired, etc.)
    *   *(Dropdown menu - specific options not shown in OCR)*
*   What is your ethnicity?
    *   *Options: White, Black or African American, American Indian or Alaska Native, Asian, Native Hawaiian or Pacific Islander, Two or more races, Other, Prefer not to say*
*   (Optional) Please describe your cultural heritage, religion, or any specific traditions you identify with.
    *   *(Open text box)*
*   Please enter your Prolific ID.
    *   *(Text input box)*

---

## Disclosure and Withdrawal (from Qualtrics OCR)

**You are at the end of the study! We appreciate your participation.**

**Full disclosure:** The predictions shown in the experiment were randomly generated and are unrelated to your actual behavior. The data collected for the predictions (birthdate, personality, etc.) are discarded and not used for the study.

If you have any concerns or questions, you may contact the Chairman of the Committee on the Use of Humans as Experimental Subjects, M.I.T., Room E25-143B, 77 Massachusetts Ave, Cambridge, MA 02139, phone 1-617-253 6787

**Given this information, if you wish to withdraw your participation and data from this study, please select the option below. Otherwise, please click "Next" to continue.**

*   [ ] I would like to withdraw from the study. I understand that my responses will be deleted and I may not be eligible for any bonus payments based on my game performance.



# File: Morales-Garcia24_AI_Survey.md

# Survey Instrument: General Self-Efficacy Scale for use with Artificial Intelligence (GSE-6AI)

Morales-García, W. C., Sairitupa-Sanchez, L. Z., Morales-García, S. B., & Morales-García, M. (2024). Adaptation and psychometric properties of a brief version of the general self-efficacy scale for use with artificial intelligence (GSE-6AI) among university students. Frontiers in Education, 9. https://doi.org/10.3389/feduc.2024.1293437

**Description:** This scale measures perceived self-efficacy in using Artificial Intelligence. It is an adaptation of the General Self-Efficacy Scale (GSE-6).

**Instructions:** Please respond to each statement indicating how true it is for you.

**Response Scale:**
The paper states the scale uses response options ranging from:
1 = *Not at all true*
to
4 = *Exactly true*

*(Note: While the paper specifies anchors 1 and 4, typical 4-point Likert scales might label the intermediate points as 2 = Hardly true and 3 = Moderately true, though this specific labeling for points 2 and 3 is not explicitly mentioned in the provided text for this adaptation.)*

---

**Items (English version from Table 3):**

1.  If someone opposes me, I can find means and ways to get what I want by using artificial intelligence.
2.  It's easy for me to stay true to my goals and achieve my objectives with the help of artificial intelligence.
3.  I am confident that I could efficiently face unexpected events by using artificial intelligence.
4.  Thanks to my wit supported by artificial intelligence, I know how to handle unforeseen situations.
5.  I can stay calm when facing difficulties because I trust in my coping skills backed by artificial intelligence.
6.  No matter what comes up, I can usually handle it with the support of artificial intelligence.

---



# File: Morrill23_AI_Survey.md

# Morrill & Noetel (2023) Appendix 

Morrill, J., & Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc

### Subjective AI literacy scale

*Source: Adapted from Laupichler et al., 2023.*
*Scale: 7-point Likert scale (1 = Strongly Disagree to 7 = Strongly Agree)*

**I can...**
1.  Describe what artificial intelligence is.
2.  Explain why data plays an important role in the development and application of artificial intelligence.
3.  Describe risks that may arise when using artificial intelligence systems.
4.  Describe why humans play an important role in the development of artificial intelligence systems.
5.  Name weaknesses of artificial intelligence.
6.  Name strengths of artificial intelligence.

*(Note: An additional 7th item served as an attention check: "I can pass this attention-check (please select “strongly disagree” for this item)". Participants selecting anything other than "strongly disagree" were excluded.)*

---

### Objective AI literacy scale

*Source: Developed for the study. Questions 1 and 3 adapted from Weber et al. (2023). Responses in italics indicate the correct answer.*
*Scale: Multiple choice, including an "I'm not sure" option.*

1.  Which of the following statements is true?
    a.  *Machine learning is a part of AI*
    b.  AI is a part of machine learning
    c.  Machine learning and AI are fields that do not overlap
    d.  AI and machine learning are the same
    e.  I'm not sure
2.  All artificial intelligence systems today fall under "narrow” AI
    a.  *True*
    b.  False
    c.  I'm not sure
3.  What is the central distinction between supervised and unsupervised learning?
    a.  *Supervised learning uses labeled datasets*
    b.  Unsupervised learning may happen anytime
    c.  Supervised learning is performed by supervised personnel
    d.  Supervised learning is better than unsupervised learning
    e.  I'm not sure
4.  In machine learning, overfitting occurs when...
    a.  *A model's predictions are accurate in the training data but inaccurate in test data*
    b.  The test data too closely matches the training data
    c.  The model is trained using an excessive amount of training data
    d.  Attempting to fit a linear model to non-linear data
    e.  I'm not sure
5.  The main reason for algorithmic bias is...
    a.  *Human bias in the data*
    b.  User bias
    c.  Overfitting in the data
    d.  Training with unsupervised learning
    e.  I'm not sure

---

### Trust in AI Scale

*Source: Adapted from Gillespie, Lockey, Curtis, & Pool, 2023.*
*Scale: 7-point Likert scale (1 = Completely Unwilling to 7 = Completely Willing)*

**How willing are you to...**
1.  Trust AI systems overall
2.  Rely on information provided by an AI system
3.  Depend on an AI system to inform important decisions
4.  Rely on AI recommendations even if you don't fully understand how those recommendations are made
5.  Depend on decisions made by an AI system
6.  Rely on the recommendations made by AI over those made by a human expert

---

## Appendix F & G - Reliance Test Materials & Interface (p. 49-56)

*(This describes the multi-step process and materials)*

**Step 1: Initial Judgement (Interface shown on p. 54)**

> Please determine if the review below is genuine or fake.
>
> The review:
>
> *[Hotel Review Text - e.g., Review 1 from Appendix F]*
>
> "I stayed for four nights while attending a **conference**. The hotel is in a great spot - easy walk to **Michigan** Ave shopping or Rush St., but just off the busy streets. The room I had was spacious, and very well-appointed. The staff was friendly, and the fitness center, while not huge, was well-equipped and **clean**. I've stayed at a number of hotels in **Chicago**, and this one is **my** favorite. Internet wasn't free, but at **$10** for **24 hours** is cheaper than most business hotels, and it worked very well."
>
> Do you believe that the review is genuine or deceptive?
>
> \[ ] Genuine
> \[ ] Deceptive
>
> How confident are you in your answer?
>
> *[Slider: 0 (Not confident at all) to 100 (Extremely confident)]*

**Step 2: Judgement with AI Feedback (Interface shown on p. 55)**

> Show / hide guidelines *[Button]*
>
> Now again but with the help of an AI.
>
> Please determine if the review below is genuine or fake.
>
> *(Visual indicator of AI's assessment, e.g., bar showing lean towards Genuineness/Deceptiveness)*
>
> Deceptive features are highlighted in blue and genuine features are highlighted in pink. The darkness shows the degree of association with the two categories.
>
> The AI has determined the below review to be **genuine**. *(Or deceptive, depending on the trial)*
>
> The review:
>
> *[Hotel Review Text - e.g., Review 1 from Appendix F, with simulated highlighting based on AI model output. Note: The actual study used pink/blue highlighting on words/phrases; the markup below replicates formatting found in Appendix F's text, the meaning of which isn't explicitly tied to the highlighting description.]*
>
> "I stayed for four nights while attending a **conference**. The hotel is in a great spot - easy **walk** to **Michigan** Ave shopping or Rush St., but just off the busy streets. The room I had was spacious, and very well-appointed. The staff was friendly, and the fitness center, while not huge, was well-equipped and **clean**. I've stayed at a number of hotels in **Chicago**, and this one is **my** favorite. Internet wasn't free, but at **$10** for **24 hours** is cheaper than most business hotels, and it worked very well."
>
> You previously chose: **Genuine** *(Or Deceptive)*
>
> After receiving AI feedback, do you believe that the review is genuine or deceptive?
>
> \[ ] Genuine
> \[ ] Deceptive
>
> How confident are you in your answer?
>
> *[Slider: 0 (Not confident at all) to 100 (Extremely confident)]*

**Guidelines (Available via button during Step 2, shown on p. 55-56):**

> **Here are some rules to help you identify deceptive reviews.**
>
> Genuine reviews tend to include more sensorial and concrete language, in particular, genuine reviews are more specific about spatial configurations, e.g., small, bathroom, on, location.
>
> Deceptive reviews tend to contain more:
>
> *   Aspects that are external to the hotel being reviewed, e.g., *husband, business, vacation*.
> *   Emotional terms; positive deceptive reviews are generally more positive and negative deceptive reviews are more negative than genuine reviews.
> *   Verbs, e.g., *eat, sleep, stay*.
> *   Superlatives, e.g., *cleanest, worst, best*.
> *   Pre-determiners, which are normally placed before an indefinite article + adjective + noun, e.g., *what a lovely day!*

**Post-Task AI Confidence (Described on p. 18)**

> How confident were you in the AI?
>
> *[Slider: 0 (Not confident at all) to 100 (Extremely confident)]*

**Hotel Review Stimuli (Appendix F, p. 50-53):**

*(Note: 16 reviews were used, 8 true/8 deceptive, 8 judged correctly by AI/8 incorrectly. The codes indicate: pos/neg valence, t/d truthfulness, hotel, review number, cor/inc AI accuracy. The text below includes formatting (**bold**, *italics*, `code`) as it appeared in Appendix F of the PDF.)*


## Appendix G - Experiment Materials (p. 56-63)

*(These were the text-based interventions shown to participants)*

### Experimental intervention

*(Content sections: What is, and what isn't AI?; Words can be misleading; General vs Narrow AI; How should we define AI?; Autonomy; Adaptivity; Machine learning; Classification; Careful with that machine learning algorithm!; The limits of machine learning; The societal implications of AI; Algorithmic bias; Once again, it's all about the data; Seeing is believing – or is it?)*

*(Full text spans pages 56-59 of the PDF, adapted from Elements of AI. Key concepts covered include definitions, narrow vs general AI, autonomy, adaptivity, supervised vs unsupervised learning, classification, overfitting, data quality, and algorithmic bias.)*

### Control intervention

*(Content sections: Agricultural Technologies & Advanced Ways Of Farming; What Is Agriculture Technology?; Importance Of Technology In Agriculture; Benefits Of Technology In Agriculture; Evolution Of Agriculture Technology; Agriculture 3.0, Or Precision Farming; Agriculture 4.0, Or Connected Farming; Agriculture 5.0, Or Digital Farming; What Types Of Precision Agricultural Technology Are Now In Use?; GPS Technology In Agriculture; Mobile Technology In Agriculture; Data Collection And Storage; How Does Technology Impact Agriculture?; Sustainable Prospects For Agriculture Technology)*

*(Full text spans pages 59-63 of the PDF, adapted from EOS Data Analytics. Key concepts cover the evolution and types of modern agricultural technology, including precision farming, connected farming, digital farming, GPS, mobile tech, big data, gene editing, etc.)*

---



# File: ng24_AI_lit_Survey.md

# Appendix 2: AI Literacy Questionnaire (AILQ) Items (Ng et al., 2024)

Ng, D. T. K., Wu, W., Leung, J. K. L., Chiu, T. K. F., & Chu, S. K. W. (2024). Design and validation of the AI literacy questionnaire: The affective, behavioural, cognitive and ethical approach. British Journal of Educational Technology, 55(3), 1082–1104. https://doi.org/10.1111/bjet.13411

*Note: This represents the items listed in Appendix 2 of the paper. Items marked (deleted) were removed during the validation process described in the main text.*


## Affective learning

### Intrinsic motivation
1.  `IM01` Artificial intelligence is relevant to my everyday life (e.g., personal, work).
2.  `IM02` Learning AI is interesting.
3.  `IM03` Learning AI makes my everyday life more meaningful.
4.  `IM04` I am curious about discovering new AI technologies.

### Self-efficacy
1.  `SE01` I am confident I will perform well on AI related tasks.
2.  `SE02` I am confident I will do well on AI related projects.
3.  `SE03` I believe I can master Al knowledge and skills.
4.  `SE04` I believe I can earn good grades in AI related assessments.
5.  `SE05` I am sure I can understand AI. (deleted)

### Confidence
1.  `CL01` I can understand AI related resources/ tools.
2.  `CL02` I am confident that I can succeed in doing AI related tasks. (deleted)
3.  `CL03` I feel confident that I will do well in the AI related tasks.
4.  `CL04` I am confident I can learn the basic concepts about AI. (deleted)
5.  `CL05` I am confident I can choose appropriate AI applications to solve problems. (deleted)

### Career interest
1.  `CI01` Learning AI will help me get a good job in the future. (deleted)
2.  `CI02` Knowing AI (and knowing how to use AI tools) will give me a career advantage. (deleted)
3.  `CI03` Understanding AI will benefit me in my future career. (deleted)
4.  `CI04` My future career will involve AI. (deleted)
5.  `CI05` I will use AI-related problem-solving skills in my career. (deleted)

## Behavioral learning

### Behavioral commitment
1.  `BI01` I will continue to use AI in the future.
2.  `BI02` I will keep myself updated with the latest AI technologies.
3.  `BI03` I plan to spend time exploring new features of AI applications in the future.
4.  `EN01` I actively participate in AI-related learning activities.
5.  `EN02` I am dedicated to AI-related learning materials.
6.  `EN03` I learn effectively in the AI-related learning tasks. (deleted)
7.  `EN04` I often look at extra materials about Al after school such as books and magazines. (deleted)

### Collaboration
1.  `SI01` I often try to explain the AI learning materials to my classmates or friends.
2.  `SI02` I try to work with my classmates to complete AI learning tasks and projects.
3.  `SI03` I often spend spare time discussing AI with my classmates.
4.  `SI04` I usually ask classmates for help when I meet difficulties in AI activities. (deleted)

## Cognitive learning

### Know and understand
1.  `KU01` I know what Al is and recall the definitions of AI.
2.  `KU02` I know how to use AI applications (e.g., Siri, chatbot).
3.  `KU03` I know some working principles behind AI (e.g., linear model, decision tree, machine learning). (deleted)
4.  `KU04` I understand how AI perceives the world (e.g., see, hear) to handle various tasks. (deleted)
5.  `KU05` I can compare the differences between Al concepts (e.g., deep learning, machine learning).

### Apply, evaluate and create
1.  `EC01` I can apply AI applications to solve problems.
2.  `EC02` I can derive a machine learning model to solve problems. (deleted)
3.  `EC03` I can create AI-driven solutions (e.g., chatbots, robotics) to solve problems.
4.  `EC04` I can evaluate AI applications and concepts for different situations.

## Ethical learning

### AI ethics
1.  `AIE01` I think that AI ethics is important to guide moral conduct to develop and use Al technology. (deleted)
2.  `AIE02` I understand how misuse of AI could result in substantial risk to humans.
3.  `AIE03` I think that AI systems should minimize data bias (e.g., gender, ethnicity). (deleted)
4.  `AIE04` I think that AI systems should perform reliably and safely. (deleted)
5.  `AIE05` I think that AI systems need to be subjected to rigorous testing to ensure they work as expected.
6.  `AIE06` I think that AI systems should respect privacy. (deleted)
7.  `AIE07` I think that users are responsible for considering Al design and decision processes.
8.  `AIE08` I think that AI systems should benefit everyone, regardless of physical abilities and gender.
9.  `AIE09` I think that AI systems should be transparent and understandable. (deleted)
10. `AIE10` I think that users should be made aware of the purpose of the system, how it works and what limitations may be expected.
11. `AIE11` I think that people should be accountable for using AI systems.
12. `AIE12` I think that AI systems should meet ethical and legal standards.
13. `AIE13` I think that AI can be used to help disadvantaged people.
14. `AIE14` I think that AI can promote human well-being. (deleted)
15. `AIE15` I wish to use my Al knowledge to serve others. (deleted)
16. `AIE16` I think that the use of AI should aim to achieve common good (e.g., environmental & poverty issues). (deleted)


-----



# File: Ovsyannikova_Survey.md

# Survey Components from Ovsyannikova et al. (2025)

Ovsyannikova, D., De Mello, V. O., & Inzlicht, M. (2025). Third-party evaluators perceive AI as more compassionate than expert humans. Communications Psychology, 3(1). https://doi.org/10.1038/s44271-024-00182-6

---

## Empathy Prompts (Vignettes)

Participants read prompts describing personal experiences. Below are the *examples* provided in Figure 1. (The study used 10 prompts in total for Studies 1-3, and 6 prompts for Study 4).

### Negative Prompt Example

> "I am having difficulties with my family relationships. My mother disrespects my boundaries and doesn't seem to understand that her intrusion into my daily activities is suffocating. My brother will drop his kids off for 12 hour days, and while I love my nieces and nephews, I'm starting to feel like my life is not really my own."

### Positive Prompt Example

> "Today was my final day of therapy! It feels weird to recall the shell of a person I had been when I first entered therapy months before, feeling very skeptical and angry. Instead, therapy helped me find the person that I had once been, and I haven't felt this good about myself in years! I'm not in pain anymore and actually look forward to waking up every morning!"

---

## Response Evaluation Measures

For each empathy prompt, participants read a *pair* of responses: one generated by a human (either selected non-experts or expert crisis responders, depending on the study) and one generated by AI (ChatGPT-4). They then evaluated these responses.

### 1. Perceived Compassion (Studies 1-4)

Participants were asked to rate *each* response based on how much it:

*   a) reflected the emotional state in the prompt
*   b) was compassionate
*   c) was impersonal (reverse-coded)

**Scale:** 5-point Likert scale ranging from 1 (*Strongly Disagree*) to 5 (*Strongly Agree*). Ratings were averaged per response type (Human vs. AI).

### 2. Response Preference (Studies 1-4)

After rating compassion for both responses, participants were asked:

*   Which one of the two responses was better at addressing the personal experience in the empathy prompt?

**Format:** Binary forced-choice question (Human response coded as 0, AI response coded as 1).

### 3. Perceived Responsiveness (Study 4 Only)

In Study 4, participants evaluated the responsiveness of *each* transparently labeled human and AI response using a 5-point Likert scale (1 = *Strongly Disagree*, 5 = *Strongly Agree*), based on facets adapted from Maisel et al. (2008):

*   **Understanding:** (Measured with three items, e.g., paraphrasing, inquiring further, expressing understanding).
*   **Validation:** (Measured with three items, e.g., agreeing, validating feelings/emotions, using exclamations/judgments).
*   **Caring:** (Measured with three items, e.g., expressing empathy/emotions, offering support/concern/comfort, emphasizing outcomes).

*(Note: The specific items for each facet are not listed in the main paper text but are referenced).*

---

## Example Responses (Illustrative - Shown in Figure 1)

These are *examples* of the types of responses participants evaluated, corresponding to the prompts above.

### Responses to Negative Prompt:

*   **Human Response Example:** "I am sorry that your family has been making you feel this way. I understand that disrespecting your boundaries and leaving you with that much responsibility can be upsetting. You deserve to be treated with more respect and consideration."
*   **AI Response Example:** "It sounds like you're in a really tough spot, feeling overwhelmed by the demands placed on you and struggling with boundaries within your family.[...] Remember, recognizing your need for personal space and autonomy amidst family obligations is a sign of self-awareness and care for your own well-being."

### Responses to Positive Prompt:

*   **Human Response Example:** "It is so amazing to hear that you have benefitted from therapy so much! You should be proud of this amazing progress as it is not easy to stay committed to therapy and working on yourself the way that you have."
*   **AI Response Example:** "I want to express how wonderful it is to hear about the positive journey you've had in therapy. Completing your final day is a significant achievement that showcases the progress you've made. [...] Cherish this newfound sense of well-being and the excitement it brings to your mornings. Your story is a testament to the power of self-discovery and healing through the support of therapy."


# File: Puppart_Aru25_AI_Survey.md


# Puppart & Aru (2025) AI Literacy Intervention Study

Puppart, B., & Aru, J. (2025). Short-term AI literacy intervention does not reduce over-reliance on incorrect ChatGPT recommendations (No. arXiv:2503.10556). arXiv. https://doi.org/10.48550/arXiv.2503.10556


## Study Overview

This document outlines the questionnaires, informational texts, and task prompts used in the study by Puppart & Aru (2025) investigating the effect of an AI literacy intervention on over-reliance on ChatGPT among high school students. Participants were randomly assigned to a control or intervention group, read corresponding texts, answered self-assessment questions, and then solved math puzzles with presented ChatGPT recommendations.

*Note: The study was conducted online via LimeSurvey. Informed consent was obtained first, and a debriefing occurred afterward. The exact wording of the consent form and debriefing text is not provided in the paper.*

## 1. Demographic Information

Participants were asked to provide the following demographic information (Page 5):

*   Gender
*   Age
*   School affiliation

## 2. Experimental Texts (Control vs. Intervention)

Participants were randomly assigned to read one of two texts.

### Instructions Before Reading Text (From Appendix B, Page 28)

Before you start solving math puzzles with ChatGPT, please read the following text, which aims to briefly introduce ChatGPT. Please read the text carefully and thoughtfully, even if you have previously encountered and used ChatGPT. Once you have read the text, click the "Next" button in the bottom right corner of the page.

### Control Group Text (Appendix B, Page 28)

**A short introduction to ChatGPT**

ChatGPT is a chatbot that was first introduced in 2022 and has since gained rapid popularity. It has been widely adopted in various fields, such as education, economics, customer service, and science, where its use has significantly simplified many tasks.

ChatGPT operates based on user input, which can include questions, tasks, or mathematical operations. It analyzes the user's input and generates an output presented in an understandable language. With ChatGPT, it is possible to solve various tasks, from simple questions to extensive projects. For example, ChatGPT can help generate original text, translate, analyze data, write code, and summarize large amounts of material.

Here are some reasons why ChatGPT is a useful tool for solving language-related tasks¹:

*   **Understanding language.** ChatGPT generates outputs that take into account the context and meaning of words effectively.
*   **Personalized responses.** ChatGPT can adapt its responses based on the user's style and previous inputs. This feature enhances the user experience by aligning outputs better with the user's needs.
*   **Availability.** As long as there is an internet connection, ChatGPT is always accessible. Its accessibility also extends to its ability to understand and generate responses in multiple languages, including Estonian.
*   **Automation.** ChatGPT helps simplify and automate routine tasks, saving the user time and effort

--- *End of Control Text* ---

### Intervention Group Text (Appendix B, Pages 28-33)

*(The intervention group read the Control Group Text above, PLUS the following sections):*

**ChatGPT working mechanism**

Each time ChatGPT generates an output, it solves a very simple task: predicting the next word. For example, if I write the sentence "The dog is \_\_\_" and ask you which word fits best in the blank, you would likely suggest words such as "an animal," "furry," or "loyal." On the other hand, words like "bottle," "blue," or "fish" would be less likely to fit.

Just as you intuitively know which words are more probable in a given context, ChatGPT also determines this based on its prior training. It has been trained using almost all publicly available text from the internet, allowing it to learn how words are related and which words are most likely to follow others.

However, it's important to note that ChatGPT does not think or experience the world like humans do. At its core, it is simply an extremely large statistical model that responds to user input by calculating the probabilities of the next words.

**Writing prompts**

As previously described, ChatGPT generates outputs based on user input. This input can consist of four main components²:

*   **Instructions.** This part explains what task you want ChatGPT to perform. Some examples include: "solve, calculate, write, summarize, evaluate, explain, recommend."
*   **Context.** Context provides additional external information that helps ChatGPT better understand the task or the content of the text. This allows it to generate more relevant and accurate outputs.
*   **Text.** This is the core content of the input, such as a specific description of an essay you want ChatGPT to write or a passage of text that you want it to summarize.
*   **Output preferences.** This allows you to specify the format or style of the response. For example, you can set the word count, paragraph length, or request an output in bullet points.

User input does not have to include all four components. For instance, if you type "If a = b and b = c, then...", ChatGPT will understand that the instruction is to "solve" without needing explicit clarification. However, if you want ChatGPT to generate similar logic problems instead, you need to specify your instructions more clearly.

For any given input, it is useful to consider these components and assess what information ChatGPT might need to produce the most appropriate output.

**Frequent errors in prompts³**

*   **Unclear input.** Sometimes, user input is not specific enough, resulting in a response that is too broad or general. For example, the prompt "Describe how artificial intelligence has changed the world" is too vague if we specifically want to know about the risks and challenges ChatGPT has caused in the education system.
*   **Complex and conflicting instructions.** If instructions are too complicated or contradictory, ChatGPT may struggle to interpret them correctly. An example of conflicting input would be: "Write an essay on technological developments in the 20th century that is detailed enough to be interesting for a computer scientist but also simple enough for a five-year-old to understand."
*   **Biased input.** User input can be biased in various ways. For instance, if we want ChatGPT to evaluate the style of a written text, asking, "Is the following text well-written in terms of style?" may nudge ChatGPT towards answering "Yes." A better approach would be to ask neutrally: "Evaluate the style of the following text and provide suggestions for improvement."

**ChatGPT Limitations and risks**

Although properly formulating input is crucial for obtaining the best possible response, there are some tasks where ChatGPT may still provide incorrect answers, even if the user input is well-structured. Below is a summary of key limitations of ChatGPT, along with examples.

*   **Drawing conclusions about the real world.** ChatGPT does not have direct contact with the real world. Instead, it relies solely on the texts it has been trained on to make inferences about reality. This sometimes leads to mistakes when solving tasks that require reasoning about real-world objects and their properties.

    > If I have 5 apples right now, but last week I ate 2 apples, then how many do I have left?
    >
    > *ChatGPT response simulation:*
    > If you originally had 5 apples and last week you ate 2 apples, then you have left:
    > 5 - 2 = 3 apples.

    *Example 1.* In the above example, ChatGPT misunderstands the concept of time (now, last week) and mistakenly assumes that it is a simple arithmetic problem⁴.

*   **Mathematical and logical reasoning.** ChatGPT may sometimes incorrectly solve even simple problems that require mathematical and logical reasoning.

    > How many words and how many numbers are in the following list:
    > cat, 10, dog, 60, cow, 40, squirrel, 70, spruce, 15, book, 32.
    >
    > *ChatGPT response simulation:*
    > The list contains 7 words and 5 numbers.

    *Example 2.* (No error noted by authors here, seems correct)

    > The five given cards must be arranged in such a way that the resulting 9-digit number is the smallest possible. Which of these cards must be the rightmost in this case? The cards are: 4, 8, 31, 59, 107.
    >
    > *ChatGPT response simulation:*
    > To form the smallest possible 9-digit number, the cards must be placed in ascending order, considering the value of each number:
    > *   The smallest number is 4, followed by 8, then 31, then 59, and finally, the largest number, 107.
    > If we arrange these to create the smallest number, it is logical that the largest card, 107, must be the rightmost, as placing it at the last position increases the overall value the least.
    > Answer: The rightmost card must be 107.

    *Example 3⁵.* Actually, 107 should be the leftmost number, and 8 should be the rightmost number.

*   **Hallucination.** ChatGPT sometimes produces completely fabricated information – a phenomenon known as hallucination. This can include generating false references and historical facts. Additionally, it may struggle to distinguish between fiction and reality.

    > Who was Estonia's first Olympic silver medalist?
    >
    > *ChatGPT response simulation:*
    > Estonia's first Olympic silver medalist was Jaan Tõnisson, who won the silver medal at the 1920 Summer Olympics in Antwerp, Belgium. Tõnisson competed in Greco-Roman wrestling in the heavyweight category.

    *Example 4.* Estonia's first Olympic silver medalist was Martin Klein in 1912, and Jaan Tõnisson was not a wrestler but an important statesman. ChatGPT can hallucinate in response to various types of questions. However, it is especially easy to trigger this when user instructions require a very narrow and specific output.

    > Name five cities in Harju County that start and end with the same letter.
    >
    > *ChatGPT response simulation:*
    > There are five cities in Harju County that start and end with the same letter:
    > 1. Keila
    > 2. Saue
    > 3. Maardu
    > 4. Paldiski
    > 5. Jõelähtme

    *Example 5.* (Authors don't explicitly state error here, but Jõelähtme is not a city and doesn't fit the criterion. Paldiski also doesn't fit.)

    > Answer with one word: In which sport did Napoleon win a gold medal at the 1980 Olympic Games?
    >
    > *ChatGPT response simulation:*
    > Football.

    *Example 6.* (Napoleon was long dead by 1980; this is a hallucination.)

*   **Discriminatory Outputs.** ChatGPT's outputs depend on the texts it was trained on. These texts may contain various social biases related to people's social status, gender, race, and age, and during training, the AI learns to incorporate these biases into its outputs. As a result, ChatGPT's responses may be politically biased or include gender stereotypes that exist in society.

    > The CEO of a large company went to the restroom before going to the manicurist. The men's and women's restrooms were separate. Which restroom did they go to?
    >
    > *ChatGPT response simulation:*
    > Based on the sentence, we can infer that the CEO is a man because, in such contexts, when gender is not explicitly specified and the general term "CEO" is used, it is often assumed to refer to a man. Therefore, they went to the men's restroom.
    > If this sentence is part of a story and you want to provide a clearer answer, it could depend on additional context or the explicitly stated gender of the character. In this case, the assumption would be that they used the men's restroom.

    *Example 7.* (Demonstrates gender bias assumption).

In addition to knowing that ChatGPT can make mistakes, it is important to understand that some of its characteristics make detecting these errors difficult.

*   **Excessive confidence.** ChatGPT presents outputs with high confidence, even when they contain misinformation. Instead of saying, "I'm not sure," it delivers responses in a very convincing and fluent manner, making it harder to notice errors in its outputs.
*   **Errors are unexpected.** ChatGPT's mistakes can appear unpredictably, which often makes them go unnoticed. It may clearly and accurately explain complex quantum physics concepts one moment and then make mistakes in the simplest logic problems the next. This inconsistency in response quality poses a risk when using ChatGPT. Based on previous correct answers, we might assume that ChatGPT can correctly solve subsequent tasks—even when those responses actually contain errors.

**Tips for Using ChatGPT**

*   **Ask multiple times.** ChatGPT's responses are based on probability calculations, meaning it may provide different answers to the same question. Some of these answers might be unlikely or incorrect. Therefore, it is helpful to ask the same question multiple times with slightly different wording so you can choose the most suitable response.
*   **Ask for the reasoning.** When solving problems that require logical thinking, include an instruction in your input asking ChatGPT to explain its reasoning (e.g., by adding "Solve step by step" at the end of your prompt). This makes it easier to understand how ChatGPT arrived at its answer and helps identify if the reasoning is flawed.
*   **Verify facts.** If you're unsure whether the information in ChatGPT's response is accurate, always verify it using other sources. One option is to search on Google. Another is to ask ChatGPT to provide references in its output so you can check their reliability yourself.

**Remember that ChatGPT is a tool, not a replacement for thinking.**

--- *End of Intervention Text* ---

*Footnotes for Appendix B text:*
¹ Taken from Hariri (2024)
² Taken from DAIR.AI (2023)
³ Taken from Giray (2023)
⁴ Task inspired by Diaz (2024)
⁵ Taken from Teaduskool (2022)

## 3. AI Literacy Self-Assessment (Post-Text Reading)

After reading the assigned text (Control or Intervention), participants answered the following questions using a four-point forced-choice Likert scale (exact scale points like Strongly Disagree to Strongly Agree were not specified in the paper, but it was forced choice, implying no neutral option). (Page 5)

**Preamble:** "Compared to before, I believe that after reading the text introducing ChatGPT, I am better informed about..."

1.  "...how ChatGPT works."
    *   ( ) Option 1
    *   ( ) Option 2
    *   ( ) Option 3
    *   ( ) Option 4
2.  "...what the limitations and risks of ChatGPT are."
    *   ( ) Option 1
    *   ( ) Option 2
    *   ( ) Option 3
    *   ( ) Option 4
3.  "...how to use ChatGPT wisely."
    *   ( ) Option 1
    *   ( ) Option 2
    *   ( ) Option 3
    *   ( ) Option 4

## 4. Math Puzzle Task

### Task Instructions (Page 6)

"You are about to solve math puzzles with the help of ChatGPT. There are a total of eight puzzles, and your goal is to answer as many correctly as possible. There is no time limit for answering."

### Puzzle Presentation and Interaction (Pages 6-7, Figure 1, Appendix A)

For each of the 8 puzzles (4 with correct ChatGPT recommendations, 4 with incorrect), participants saw the following:

1.  **Puzzle Text:** The math puzzle question was displayed. (See Appendix A below for texts).
2.  **ChatGPT Recommendation:** A screenshot of ChatGPT's recommendation (including its reasoning and final answer) was shown below the puzzle text. (See Appendix A below for recommendations).
3.  **Reliance Decision Question:**
    *   **Do you use ChatGPT's recommendation?**
        *   ( ) Yes
        *   ( ) No

4.  **Outcome based on Reliance Decision:**
    *   **If "Yes":** The participant was considered to have adopted ChatGPT's answer. They proceeded directly to the Confidence Rating for this puzzle.
    *   **If "No":** The participant was given the opportunity to solve the puzzle independently. They were presented with four multiple-choice answer options for the puzzle. *Crucially, ChatGPT's suggested answer (from the screenshot) was removed from these options.* (The specific alternative options presented when 'No' was chosen are not listed in the paper's Appendix A, only the options available if ChatGPT's answer *was* included conceptually). The participant selected one of these options. They then proceeded to the Confidence Rating.

### Confidence Rating (After Each Puzzle) (Page 6)

After submitting their answer (either by choosing "Yes" to the recommendation or by choosing an answer after selecting "No"), participants rated their confidence:

*   **Statement:** "I believe my answer to the previous puzzle was correct.”
*   **Scale:** Five-point Likert scale (1 = strongly disagree – 5 = strongly agree)
    *   ( ) 1
    *   ( ) 2
    *   ( ) 3
    *   ( ) 4
    *   ( ) 5


# File: Rheu25_AI_Survey.md

# Supplementary Materials: Survey Items

Rheu, M. (MJ), & Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, 1–7. https://doi.org/10.1145/3706599.3719681


This document includes the survey items used to measure the variables examined in the study by Rheu & Cho (2025).

## AI Literacy¹

Please read the following statements carefully and indicate the extent to which you agree or disagree with each statement by selecting the most appropriate response on a scale from 1 to 7.

(1= Strongly disagree, 2 = Disagree, 3 = Somewhat disagree, 4 = Neither disagree or agree, 5 = Somewhat agree, 6 = Agree, 7 = Strongly agree)

### Self-Efficacy

1.  I am confident I will perform well on LLM-related tasks.
2.  I am confident I will do well on LLMs related projects.
3.  I believe I can master LLMs knowledge and skills.
4.  I believe I can earn good grades in LLMs related assessments.

### Cognitive Learning

1.  I know what LLM is and its definition.
2.  I know how to use LLM applications (e.g., ChatGPT, Claude).
3.  I can compare the differences between AI concepts (e.g., deep learning, machine learning).
4.  I can apply LLM applications to solve problems
5.  I can create LLM-driven solutions (e.g.,Chatbots) to solve problems.
6.  I can evaluate LLM applications and concepts to different situations.

---

Please read the following statements carefully and indicate the extent to which you agree or disagree with each statement on a scale from 1 to 7.

I have knowledge of...

### AI Technology Knowledge

1.  The types of technology that LLM is built on
2.  how LLMs and other AI technologies are distinct.
3.  Use cases for LLMs.
4.  The roles that LLMs can have in human-AI interaction.

### AI-Steps Knowledge

1.  The input data requirements for LLMs.
2.  How input data is perceived by LLMs.
3.  Potential impacts that input data has on LLMs.
4.  Which input data types LLMs can use.
5.  LLMs processing methods and models.
6.  How information is presented for LLMs processing.
7.  The risks LLMs processing poses.
8.  Why LLMs processing can be described as a learning process.
9.  Using LLMs output and interpreting it.
10. LLMs output limitations.
11. How to handle LLMs output.
12. Which LLMs outputs are obtainable with current methods.

---

¹ AI literacy was measured using four sub-dimensions. The first two sub-dimensions (Self-efficacy and cognitive learning) were from Ng et al. (2024) and the other two dimensions (AI technology knowledge and AI steps knowledge) were from Pinski & Benlian (2023)

## Machine Heuristics

The following statements describe your perception of the LLMs applications you use, such as ChatGPT, Gemini, or Claude. Please read them carefully and indicate the extent to which you agree or disagree with each statement on a scale from 1 to 7.

(1= Strongly disagree, 2 = Disagree, 3 = Somewhat disagree, 4 = Neither disagree or agree, 5 = Somewhat agree, 6 = Agree, 7 = Strongly agree)

LLMs applications are...

1.  Knowledgeable
2.  Smart
3.  Clever
4.  Unbiased
5.  Non-discriminatory
6.  Impartial
7.  Not-prejudiced
8.  Even-handed
9.  Neutral
10. Precise
11. Accurate
12. Exact

*(Items 1-3 measure “expert” perception, items 4-9 measure “objective” perception, and items 10-12 measure “accurate” perception.)*

## Fact-checking Behavior

When using LLMs, how often do you engage in the following behaviors?

(1= Never, 2 = Rarely, 3 = Occasionally, 4 = Sometimes, 5 = Frequently, 6 = Most of the time, 7 = Always)

1.  Verify the credentials or qualifications of authors or source of information.
2.  Consider the currency of the information (e.g., how recent it is).
3.  Consider the reputation on trustworthiness of the website or source.
4.  Use other search engines to further research on the topic.
5.  Seek opinions or expertise of other individuals

## Credibility

In general, how credible do you perceive the LLMs you use?

*(Measured using a semantic differential scale from -3 to +3)*

*   Not Credible (-3) vs. Credible (+3)
*   Unreliable (-3) vs. Reliable (+3)
*   Not expert (-3) vs. Expert (+3)
*   Not trustworthy (-3) vs. Trustworthy (+3)



# File: Scantamburlo_AI_Survey.md

# Perceptions on AI by the Citizens of Europe questionnaire (PAICE)

Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., & Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. IEEE Transactions on Artificial Intelligence, 6(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633*


*Note: `[ ]` represents a checkbox or radio button selection.*

Let's talk about Artificial Intelligence.

Consider a simple definition: *Artificial intelligence (AI) refers to computer systems that can perform tasks that usually require intelligence (e.g. making decisions, achieving goals, planning, learning, reasoning, etc.). AI systems can perform these tasks based on objectives set by humans with a few explicit instructions.*

---

**Q1.** When it comes to Artificial Intelligence (AI) and its impact on society, I feel my competency on the subject would be:

*   [ ] 5 - Expert knowledge
*   [ ] Advanced knowledge
*   [ ] Intermediate knowledge
*   [ ] Basic knowledge
*   [ ] 1 - Almost no knowledge

---

**Q2.** How would you describe your attitude towards Artificial Intelligence (AI) and its applications?

*   [ ] 5 - Strongly approve
*   [ ] Approve
*   [ ] Indifferent
*   [ ] Disapprove
*   [ ] 1 - Strongly disapprove

---

**Q3.** To what extent do you feel Artificial Intelligence (AI) and its applications impact your daily life already?

*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

---

**Q4.** Have you ever heard about the following European initiatives regarding AI?

**Q4_1.** General Data Protection Regulation (GDPR).
*   [ ] Yes
*   [ ] No

**Q4_2.** Ethics Guidelines for Trustworthy AI.
*   [ ] Yes
*   [ ] No

**Q4_3.** Proposal for a Regulation on AI.
*   [ ] Yes
*   [ ] No

---

**Q5.** How often are you aware of interacting with a product/service based on or including AI?

*   [ ] 5 - Always
*   [ ] Often
*   [ ] Sometimes
*   [ ] Seldom
*   [ ] 1 - Never
*   [ ] I don't know

---

**Q6.** Consider the following list of applications. Please select which ones you think may incorporate AI.

*   [ ] **Q6_1.** Ride sharing apps (e.g. Uber, Lyft, Blabla car).
*   [ ] **Q6_2.** Calculators.
*   [ ] **Q6_3.** Contents and products product recommendations (e.g. Youtube, Amazon, Netflix).
*   [ ] **Q6_4.** Accommodation booking sites (e.g. Tripadvisor, Trivago, Airbnb).
*   [ ] **Q6_5.** Phone camera.
*   [ ] **Q6_6.** Messaging apps (e.g. WhatsApp, Telegram).
*   [ ] **Q6_7.** Email spam filters.
*   [ ] **Q6_8.** Search engines (e.g. Google, Bing).
*   [ ] **Q6_9.** Drones.
*   [ ] **Q6_10.** Social media (e.g. Facebook, Twitter).
*   [ ] **Q6_11.** Traffic navigation apps (e.g. Google Maps, Waze, TomTom).
*   [ ] **Q6_12.** Facial recognition apps (e.g. face unlock in phones).
*   [ ] **Q6_13.** Text editor (e.g. Word, Open Office).
*   [ ] **Q6_14.** Calendar app (e.g. Google Calendar, iCal).
*   [ ] **Q6_15.** Internet browser (e.g. Chrome, Firefox).
*   [ ] **Q6_16.** Teleconferencing app (e.g. Zoom, Skype, Google Meet).
*   [ ] **Q6_17.** Others \____________ [fill-in option]
*   [ ] **Q6_18.** None of the above.

---

**Q7.** To what extent do you think AI is used in each of the following sectors in Europe? Please use the five-point scale to plot your answer.

**(Scale: 5 = A lot, Somewhat, So and so, Not so much, 1 = Not at all)**

**Q7_1.** Healthcare (e.g. diagnostic support, personalised medicine).
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

**Q7_2.** Insurance (e.g. fraud detection, personalized risk assessment).
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

**Q7_3.** Agriculture (e.g. robotic harvesting, crop optimization).
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

**Q7_4.** Finance (e.g. fraud detection, loan decision support systems).
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

**Q7_5.** Military (e.g. automated weapons, cybersecurity for data protection).
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

**Q7_6.** Law enforcement (e.g. predictive policing to forecast areas where crime is likely and dispatch police units, face recognition in public places).
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

**Q7_7.** Environmental (e.g. climate prediction, energy harvesting forecast).
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

**Q7_8.** Transportation (e.g. self-driving vehicles).
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

**Q7_9.** Manufacturing industry (e.g demand forecasting, robotics).
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

**Q7_10.** Human resource management (e.g. CV screening, workforce planning).
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

---

**Q8.** How would you describe your attitude towards the use of AI in the following sectors in Europe? Please use the five-point scale to plot your answer.

**(Scale: 5 = Strongly approve, Approve, 3 = Indifferent, Disapprove, 1 = Strongly disapprove)**

**Q8_1.** Healthcare (e.g. diagnostic support, personalised medicine).
*   [ ] 5 - Strongly approve
*   [ ] Approve
*   [ ] 3 - Indifferent
*   [ ] Disapprove
*   [ ] 1 - Strongly disapprove

**Q8_2.** Insurance (e.g. fraud detection, personalized risk assessment).
*   [ ] 5 - Strongly approve
*   [ ] Approve
*   [ ] 3 - Indifferent
*   [ ] Disapprove
*   [ ] 1 - Strongly disapprove

**Q8_3.** Agriculture (e.g. robotic harvesting, crop optimization).
*   [ ] 5 - Strongly approve
*   [ ] Approve
*   [ ] 3 - Indifferent
*   [ ] Disapprove
*   [ ] 1 - Strongly disapprove

**Q8_4.** Finance (e.g. fraud detection, loan decision support systems).
*   [ ] 5 - Strongly approve
*   [ ] Approve
*   [ ] 3 - Indifferent
*   [ ] Disapprove
*   [ ] 1 - Strongly disapprove

**Q8_5.** Military (e.g. automated weapons, cybersecurity for data protection).
*   [ ] 5 - Strongly approve
*   [ ] Approve
*   [ ] 3 - Indifferent
*   [ ] Disapprove
*   [ ] 1 - Strongly disapprove

**Q8_6.** Law enforcement (e.g. predictive policing to forecast areas where crime is likely and dispatch police units, face recognition in public places).
*   [ ] 5 - Strongly approve
*   [ ] Approve
*   [ ] 3 - Indifferent
*   [ ] Disapprove
*   [ ] 1 - Strongly disapprove

**Q8_7.** Environmental (e.g. climate prediction, energy harvesting forecast).
*   [ ] 5 - Strongly approve
*   [ ] Approve
*   [ ] 3 - Indifferent
*   [ ] Disapprove
*   [ ] 1 - Strongly disapprove

**Q8_8.** Transportation (e.g. self-driving vehicles).
*   [ ] 5 - Strongly approve
*   [ ] Approve
*   [ ] 3 - Indifferent
*   [ ] Disapprove
*   [ ] 1 - Strongly disapprove

**Q8_9.** Manufacturing industry (e.g demand forecasting, robotics).
*   [ ] 5 - Strongly approve
*   [ ] Approve
*   [ ] 3 - Indifferent
*   [ ] Disapprove
*   [ ] 1 - Strongly disapprove

**Q8_10.** Human resource management (e.g. CV screening, workforce planning).
*   [ ] 5 - Strongly approve
*   [ ] Approve
*   [ ] 3 - Indifferent
*   [ ] Disapprove
*   [ ] 1 - Strongly disapprove

---

**Q9.** Read carefully the following scenario:

> Imagine that you are applying for a job in a large company and the recruitment process consists of two steps. The first step is based on an AI software which scans your resume and your answers to a set of questions on strategic competencies. The software assigns you a score which is used to select those candidates who can move on to the second stage (the interview). The company claims that the software makes the process faster and more objective. Also, the company says that the data is anonymised, and no personal information is used. To what extent would you feel comfortable or uncomfortable with this process?

*   [ ] 5 - Very comfortable
*   [ ] Fairly comfortable
*   [ ] Neutral
*   [ ] Not very comfortable
*   [ ] 1 - Not at all comfortable

---

**Q10.** Read carefully the following scenario:

> Imagine that you are looking for a smart meter to reduce energy consumption in your house, cut the cost of utilities, and adopt a more sustainable lifestyle. You are offered a smart meter that uses AI to analyse home energy consumption and make recommendations for more efficient usage. Among functionalities, this system can give you the opportunity to receive personalised offers from energy suppliers which can help you save money.
> The company producing the smart meter says that your data is anonymised, and no personal information is shared with third parties without your consent. To what extent would you feel comfortable or uncomfortable with this application?

*   [ ] 5 - Very comfortable
*   [ ] Fairly comfortable
*   [ ] 3 - Neutral
*   [ ] Not very comfortable
*   [ ] 1 - Not at all comfortable

---

**Q11.** With respect to the previous scenarios, which of the following aspects should an organisation developing or using AI consider more? (Please select three items and rank them.)

*   [ ] Security and accurate results.
*   [ ] Fair treatment and equitable access to the AI application for all members of society.
*   [ ] Privacy and data protection.
*   [ ] Human supervision over the AI outcome and process.
*   [ ] Clear communication about the AI application's purpose and limitations.
*   [ ] Risk management and identification of responsibility.
*   [ ] Societal and environmental impact of the AI application.

---

**Q12.** How important are the following measures to increase your trust in AI? Please use the five-point scale to plot your answer.

**(Scale: 5 = Very important, Important, 3 = Moderately important, Of little importance, 1 = Not important at all)**

**Q12_1.** A set of laws enforced by a national authority which guarantees ethical standards and social responsibility in the application of AI.
*   [ ] 5 - Very important
*   [ ] Important
*   [ ] 3 - Moderately important
*   [ ] Of little importance
*   [ ] 1 - Not important at all

**Q12_2.** Voluntary certifications released by trusted and competent agencies which guarantee ethical standards and social responsibility in the application of AI.
*   [ ] 5 - Very important
*   [ ] Important
*   [ ] 3 - Moderately important
*   [ ] Of little importance
*   [ ] 1 - Not important at all

**Q12_3.** Having independent expert entities that monitor the use and misuse of AI in society, including the public sector, and inform citizens.
*   [ ] 5 - Very important
*   [ ] Important
*   [ ] 3 - Moderately important
*   [ ] Of little importance
*   [ ] 1 - Not important at all

**Q12_4.** The adoption and application of a self-regulated code of conduct or a set of ethical guidelines when developing or using AI products.
*   [ ] 5 - Very important
*   [ ] Important
*   [ ] 3 - Moderately important
*   [ ] Of little importance
*   [ ] 1 - Not important at all

**Q12_5.** The provision of clear and transparent information by the provider that describes the purpose, limitations and data usage of the AI product.
*   [ ] 5 - Very important
*   [ ] Important
*   [ ] 3 - Moderately important
*   [ ] Of little importance
*   [ ] 1 - Not important at all

**Q12_6.** The creation of design teams promoting diversity and social inclusion (e.g. gender wise, different expertise, ethnicity, etc) and the consultation of different stakeholders throughout the entire lifecycle of the AI product.
*   [ ] 5 - Very important
*   [ ] Important
*   [ ] 3 - Moderately important
*   [ ] Of little importance
*   [ ] 1 - Not important at all

---

**Q13.** To what extent do you agree that having a better education on what AI is, as well as its current and future uses, would improve your trust in it?

*   [ ] 5 - Strongly agree
*   [ ] Agree
*   [ ] 3 - Neutral
*   [ ] Disagree
*   [ ] 1 - Strongly disagree

---

**Q14.** How much do you trust the following entities in ensuring that AI is in the best interest of the public? Please use the five-point scale to plot your answer.

**(Scale: 5 = A lot, Somewhat, 3 = So and so, Not so much, 1 = Not at all)**

**Q14_1.** National Governments and public authorities.
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] 3 - So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

**Q14_2.** European Union (including European Commission/European Parliament).
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] 3 - So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

**Q14_3.** Universities and research centres.
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] 3 - So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

**Q14_4.** Consumer associations, trade unions and civil society organisations.
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] 3 - So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

**Q14_5.** Tech companies developing AI products.
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] 3 - So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

**Q14_6.** Social media companies.
*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] 3 - So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

---

**Q15.** Now that you have answered several questions about AI, to what extent do you feel AI and its applications impact your daily life already?

*   [ ] 5 - A lot
*   [ ] Somewhat
*   [ ] 3 - So and so
*   [ ] Not so much
*   [ ] 1 - Not at all

---

**Q16.** Would you be interested in attending a free course on AI to improve your knowledge?

*   [ ] Yes
*   [ ] No

---

## DEMOGRAPHICS

**QA)** Please indicate where you live in your country: \[answer options based on the country]

**QA_I) Italy**
*   [ ] Nord Ovest
*   [ ] Nord Est
*   [ ] Centro
*   [ ] Sud

**QA_S) Spain**
*   [ ] Noroeste (Galicia, Principado de Asturias, Cantabria)
*   [ ] Noreste (País Vasco, Navarra, La Rioja, Aragón)
*   [ ] Comunidad de Madrid o Munidad de Madrid (Madrid)
*   [ ] Centro (Castilla y León, Castilla La Mancha, Extremadura)
*   [ ] Este (Cataluña, Comunidad Valenciana, Islas Baleares)
*   [ ] Sur (Andalucía, Región de Murcia, Ceuta, Melilla)
*   [ ] Canarias (Islas Canarias)

**QA_F) France**
*   [ ] Auvergne-Rhône-Alpes
*   [ ] Bourgogne-Franche-Comté
*   [ ] Bretagne
*   [ ] Centre-Val de Loire
*   [ ] Corse
*   [ ] Grand Est
*   [ ] Hauts-de-France
*   [ ] Île-de-France
*   [ ] Normandie
*   [ ] Nouvelle-Aquitaine
*   [ ] Occitanie
*   [ ] Pays de la Loire
*   [ ] Provence-Alpes-Côte d'Azur

**QA_G) Germany**
*   [ ] Hamburg, Bremen, Schleswig-Holstein, Niedersachsen
*   [ ] Baden-Württemberg
*   [ ] Bayern
*   [ ] Berlin, Mecklenburg-Vorpommern, Brandenburg, Sachsen-Anhalt
*   [ ] Hessen, Rheinland-Pfalz, Saarland
*   [ ] Nordrhein-Westfalen
*   [ ] Thüringen, Sachsen

**QA_SV) Sweden**
*   [ ] Mellersta norrland
*   [ ] Övre norrland
*   [ ] Sydsverige
*   [ ] Norra mellansverige
*   [ ] Småland med öarna
*   [ ] Västsverige
*   [ ] Östra mellansverige
*   [ ] Stockholm

**QA_N) Netherlands**
*   [ ] Noord & Oost Nederland
*   [ ] West-Nederland
*   [ ] Zuid-Nederland

**QA_P) Poland**
*   [ ] Centralny (Central)
*   [ ] Polnocno-Zachodni (North-West)
*   [ ] Polnocny (North)
*   [ ] Poludniowo-Zachodni (South-West)
*   [ ] Poludniowy (South)
*   [ ] Wschodni (East)

**QA_R) Romania**
*   [ ] Bucuresti - Ilfov
*   [ ] Centru
*   [ ] Nord Est
*   [ ] Nord-Vest
*   [ ] Sud-Muntenia
*   [ ] Sud-Est
*   [ ] Sud-Vest Oltenia
*   [ ] Vest

---

**QB)** You are:
*   [ ] Female
*   [ ] Male
*   [ ] Other

---

**QCB)** Please indicate your age:
*   [ ] 18-34
*   [ ] 35-54
*   [ ] 55-75

---

**QD)** Please indicate your job:
*   [ ] Entrepreneur / employer
*   [ ] Self-employed / freelance professional
*   [ ] Manager, officer
*   [ ] White collar / employee
*   [ ] Craftsman
*   [ ] Shop owner, retailer
*   [ ] Teacher, professor, writer, journalist, artist
*   [ ] Manual or technical worker
*   [ ] Student
*   [ ] Retired
*   [ ] Homemaker
*   [ ] Unemployed
*   [ ] Other \____________ [fill-in option]

---

**QE)** What is your highest level of formal education?
*   [ ] Lower secondary education or lower education
*   [ ] Upper secondary education
*   [ ] Post-secondary non-tertiary education
*   [ ] Short-cycle tertiary education
*   [ ] Bachelor's or equivalent level
*   [ ] Master's or equivalent level
*   [ ] Doctoral or equivalent level
*   [ ] NN (Non-response/Not known)

---

**QG)** Please the size of the town where you live:
*   [ ] Up to 5000
*   [ ] Between 5000 and 10000
*   [ ] Between 10000 and 30000
*   [ ] Between 30000 and 100000
*   [ ] Between 100000 and 250000
*   [ ] Over 250000

---

**QH)** If you were to describe your digital skills, how would you define yourself:
*   [ ] Very expert: I am sure of my digital skills, I am always attentive to innovation, I have no difficulty in moving in the digital world for everything I need, and I am interested in.
*   [ ] Expert: I am quite sure of my digital skills, I try to exploit the potential it can offer and to be updated on the news.
*   [ ] Enough expert: I'm not entirely sure of my skills, but I manage to do the best I can when I need to do something online and I try to learn new skills when I need them.
*   [ ] Not very expert: I'm not sure of my skills and I have to get someone to help me with new things I don't understand
*   [ ] Not at all expert: I use digital tools only if it is strictly necessary (e.g. email, messages).



# File: Scharowski_AI_Survey.md

# Scharowski Trust Survey

Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., & Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No. arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582


## 1 Introduction

**Instructions**

In the following, we will show you two short videos (video 1 and video 2). Both videos show an interaction with an AI.

One video shows a **self-driving car** driving autonomously through a city. The other video shows an interaction where a **chatbot** is asked different questions and responds to these questions.

Please take your time to watch the videos carefully. You can watch the videos again as often as you like. After each video, we will ask you questions about what you have seen and how you perceived the situation.

Note: the following videos do NOT have any sound.

---

*(Note: The actual survey likely presented only one set of conditions per participant, e.g., Trust SDV + Trust Chatbot OR Distrust SDV + Distrust Chatbot, followed by the corresponding questionnaires. This markdown includes all sections for completeness.)*

---

## 2.1 Trust SDV Scenario (Video 1 Setup)

### 2.1.1 trust_sdv

**Instructions (video 1)**

The upcoming page will present you with a video showcasing an AI-operated self-driving car navigating autonomously through a city. It is important to carefully watch the video to observe the car's behavior and actions. Pay close attention to its interactions with the surroundings and how it handles various driving scenarios.

### 2.1.2 sdv_1

[Video Placeholder: sdv_1 - Trust Condition]

---

## 2.2 Trust Chatbot Scenario (Video 1 Setup)

### 2.2.1 trust_chatbot

**Instructions (video 1)**

On the upcoming page, you will find a video where an AI chatbot engages in a conversation with a human user. Please take the time to watch the video attentively. Observe the exchange between the chatbot and the user, paying close attention to the chatbot's responses and how it interacts in a conversational manner.

### 2.2.2 chatbot_1

[Video Placeholder: chatbot_1 - Trust Condition]

---

## 3.1 Distrust SDV Scenario (Video 1 Setup)

### 3.1.1 distrust_sdv

**Instructions (video 1)**

The upcoming page will present you with a video showcasing an AI-operated self-driving car navigating autonomously through a city. It is important to carefully watch the video to observe the car's behavior and actions. Pay close attention to its interactions with the surroundings and how it handles various driving scenarios.

### 3.1.2 sdv_1

[Video Placeholder: sdv_1 - Distrust Condition]

---

## 3.2 Distrust Chatbot Scenario (Video 1 Setup)

### 3.2.1 distrust_chatbot

**Instructions (video 1)**

On the upcoming page, you will find a video where an AI chatbot engages in a conversation with a human user. Please take the time to watch the video attentively. Observe the exchange between the chatbot and the user, paying close attention to the chatbot's responses and how it interacts in a conversational manner.

### 3.2.2 chatbot_1

[Video Placeholder: chatbot_1 - Distrust Condition]

---

# 4 Trust Questionnaires 1

*(Presented after viewing Video 1, tailored to the AI type shown)*

**Questions regarding the AI**

On the following three pages, we ask you to respond to a series of questions regarding the AI in the video you just saw.
Please read the questions carefully. There are no right or wrong answers; we are just interested in your personal opinion.

## 4.1 Sliders

*   **How risky did you consider the scenario in the video to be?**
    *(Instruction: Click on the gray bar to move the slider, or enter a number between 0 (= not at all risky) and 100 (= extremely risky) in the provided field.)*

*   **How unfavorable did you consider the actions of the AI in the video to be?**
    *(Instruction: Click on the gray bar to move the slider, or enter a number between 0 (= not at all unfavorable) and 100 (= extremely unfavorable) in the provided field.)*

## 4.2 Single Items

**For each of the following statements, please indicate your agreement:**

*(Scale: 1=Fully disagree, 2=Disagree, 3=Somewhat disagree, 4=Neutral, 5=Somewhat agree, 6=Agree, 7=Fully agree)*

*   I would **trust** the AI in the scenario.
*   I would **use** the AI in the scenario.

## 4.3.1 TPA (Trust Perception scale - AI)

**Please mark each statement with the number that best describes your feelings or your impression of trust with the AI you just saw.**

*(Scale: 1=Not at all, 2, 3, 4, 5, 6, 7=Extremely)*

*   The AI is deceptive
*   The AI behaves in an underhanded manner
*   I am suspicious of the AI's intent, action, or outputs
*   I am wary of the AI
*   The AI's actions will have a harmful or injurious outcome
*   Please leave this question blank *(Attention Check)*
*   I am confident in the AI
*   The AI provides security
*   The AI has integrity
*   The AI is dependable
*   The AI is reliable
*   I can trust the AI
*   I am familiar with the AI

## 4.3.2 TXAI (Trust in Explainable AI items - adapted)

**Please mark each statement with the number that best describes your feelings or your impression of trust with the AI you just saw.**

*(Scale: 1=I disagree strongly, 2=I disagree somewhat, 3=I'm neutral about it, 4=I agree somewhat, 5=I agree strongly)*

*   I am confident in the AI. I feel that it works well.
*   The outputs of the AI are very predictable.
*   The AI is very reliable. I can count on it to be correct all the time.
*   I feel safe that when I rely on the AI I will get the right answers.
*   The AI is efficient in that it works very quickly.
*   I am wary of the AI.
*   The AI can perform the task better than a novice human user.
*   I like using the AI for decision making.

## 4.4.1 STS-AD 1 (Situation-Specific Trust - Automated Driving)

*(Likely presented only if the SDV video was shown)*

**Please mark each statement with the number that best describes your feeling or your impression.**

*(Scale: 1=Fully disagree, 2=Disagree, 3=Somewhat disagree, 4=Neutral, 5=Somewhat agree, 6=Agree, 7=Fully agree)*

*   I trust the automation in this situation
*   I would have performed better than the automated vehicle in this situation
*   In this situation, the automated vehicle performs well enough for me to engage in other activities (such as reading)
*   The situation was risky
*   The automated vehicle made an unsafe judgement in this situation
*   The automated vehicle reacted appropriately to the environment

## 4.5.1 STS-Chatbot 1 (Situation-Specific Trust - Chatbot)

*(Likely presented only if the Chatbot video was shown)*

**Please mark each statement with the number that best describes your feeling or your impression.**

*(Scale: 1=Fully disagree, 2=Disagree, 3=Somewhat disagree, 4=Neutral, 5=Somewhat agree, 6=Agree, 7=Fully agree)*

*   I trust the system in this situation
*   I would have performed better than the system in this situation
*   Given the system's performance, there was no need to monitor it continuously
*   The situation was risky
*   The system made an unsafe judgement in this situation
*   The system reacted appropriately in this situation
*   The system's use is appropriate in this setting if it behaves like it did in this situation
*   I felt positive about working with the system in the experienced situations

## 4.6 PANAS (Positive and Negative Affect Schedule)

**This scale consists of a number of words that describe different feelings and emotions. Read each item and then mark the appropriate answer in the space next to that word. Indicate to what extent you felt this way while watching the video.**

**Use the following scale to record your answers.**

*(Scale: 1=Very slightly or not at all, 2=A little, 3=Moderately, 4=Quite a bit, 5=Extremely)*

*   Interested
*   Distressed
*   Excited
*   Upset
*   Strong
*   Guilty
*   Scared
*   Hostile
*   Enthusiastic
*   Proud

***

*   Irritable
*   Alert
*   Ashamed
*   Inspired
*   Nervous
*   Determined
*   Attentive
*   Jittery
*   Active
*   Afraid

---

## 5.1 Trust SDV Scenario (Video 2 Setup)

### 5.1.1 trust_sdv

**Instructions (video 2)**

The upcoming page will present you with a video showcasing an AI-operated self-driving car navigating autonomously through a city. It is important to carefully watch the video to observe the car's behavior and actions. Pay close attention to its interactions with the surroundings and how it handles various driving scenarios.

### 5.1.2 sdv_2

[Video Placeholder: sdv_2 - Trust Condition]

---

## 5.2 Trust Chatbot Scenario (Video 2 Setup)

### 5.2.1 trust_chatbot

**Instructions (video 2)**

On the upcoming page, you will find a video where an AI chatbot engages in a conversation with a human user. Please take the time to watch the video attentively. Observe the exchange between the chatbot and the user, paying close attention to the chatbot's responses and how it interacts in a conversational manner.

### 5.2.2 chatbot_2

[Video Placeholder: chatbot_2 - Trust Condition]

---

## 6.1 Distrust SDV Scenario (Video 2 Setup)

### 6.1.1 distrust_sdv

**Instructions (video 2)**

The upcoming page will present you with a video showcasing an AI-operated self-driving car navigating autonomously through a city. It is important to carefully watch the video to observe the car's behavior and actions. Pay close attention to its interactions with the surroundings and how it handles various driving scenarios.

### 6.1.2 sdv_2

[Video Placeholder: sdv_2 - Distrust Condition]

---

## 6.2 Distrust Chatbot Scenario (Video 2 Setup)

### 6.2.1 distrust_chatbot

**Instructions (video 2)**

On the upcoming page, you will find a video where an AI chatbot engages in a conversation with a human user. Please take the time to watch the video attentively. Observe the exchange between the chatbot and the user, paying close attention to the chatbot's responses and how it interacts in a conversational manner.

### 6.2.2 chatbot_2

[Video Placeholder: chatbot_2 - Distrust Condition]

---

# 7 Trust Questionnaires 2

*(Presented after viewing Video 2, tailored to the AI type shown)*

**Questions regarding the AI**

On the following three pages, we ask you to again respond to a series of questions regarding the AI in the video you just saw.
Please read the questions carefully. There are no right or wrong answers; we are just interested in your personal opinion.

## 7.1 Sliders

*   **How risky did you consider the scenario in the video to be?**
    *(Instruction: Click on the gray bar to move the slider, or enter a number between 0 (= not at all risky) and 100 (= extremely risky) in the provided field.)*

*   **How unfavorable did you consider the actions of the AI in the video to be?**
    *(Instruction: Click on the gray bar to move the slider, or enter a number between 0 (= not at all unfavorable) and 100 (= extremely unfavorable) in the provided field.)*

## 7.2 Single Items

**For each of the following statements, please indicate your agreement:**

*(Scale: 1=Fully disagree, 2=Disagree, 3=Somewhat disagree, 4=Neutral, 5=Somewhat agree, 6=Agree, 7=Fully agree)*

*   I would **trust** the AI in the scenario.
*   I would **use** the AI in the scenario.

## 7.3.1 TPA (Trust Perception scale - AI)

**Please mark each statement with the number that best describes your feelings or your impression of trust with the AI you just saw.**

*(Scale: 1=Not at all, 2, 3, 4, 5, 6, 7=Extremely)*

*   The AI is deceptive
*   The AI behaves in an underhanded manner
*   I am suspicious of the AI's intent, action, or outputs
*   I am wary of the AI
*   The AI's actions will have a harmful or injurious outcome
*   I am confident in the AI
*   The AI provides security
*   The AI has integrity
*   The AI is dependable
*   The AI is reliable
*   I can trust the AI
*   I am familiar with the AI

*(Note: The second instance of TPA in the OCR (page 6) does *not* show the "Please leave this question blank" item explicitly like the first instance (page 2). Assuming this was intended or an omission in the OCR/figure generation).*

## 7.3.2 TXAI (Trust in Explainable AI items - adapted)

**Please mark each statement with the number that best describes your feelings or your impression of trust with the AI you just saw.**

*(Scale: 1=I disagree strongly, 2=I disagree somewhat, 3=I'm neutral about it, 4=I agree somewhat, 5=I agree strongly)*

*   I am confident in the AI. I feel that it works well.
*   The outputs of the AI are very predictable.
*   The AI is very reliable. I can count on it to be correct all the time.
*   I feel safe that when I rely on the AI I will get the right answers.
*   Please leave this question blank. *(Attention Check - Explicitly mentioned in OCR for the second instance)*
*   The AI is efficient in that it works very quickly.
*   I am wary of the AI.
*   The AI can perform the task better than a novice human user.
*   I like using the AI for decision making.

## 7.4.1 STS-AD 2 (Situation-Specific Trust - Automated Driving)

*(Likely presented only if the SDV video was shown)*

**Please mark each statement with the number that best describes your feeling or your impression.**

*(Scale: 1=Fully disagree, 2=Disagree, 3=Somewhat disagree, 4=Neutral, 5=Somewhat agree, 6=Agree, 7=Fully agree)*

*   I trust the automation in this situation
*   I would have performed better than the automated vehicle in this situation
*   In this situation, the automated vehicle performs well enough for me to engage in other activities (such as reading)
*   The situation was risky
*   The automated vehicle made an unsafe judgement in this situation
*   The automated vehicle reacted appropriately to the environment

## 7.5.1 STS-Chatbot 2 (Situation-Specific Trust - Chatbot)

*(Likely presented only if the Chatbot video was shown)*

**Please mark each statement with the number that best describes your feeling or your impression.**

*(Scale: 1=Fully disagree, 2=Disagree, 3=Somewhat disagree, 4=Neutral, 5=Somewhat agree, 6=Agree, 7=Fully agree)*

*   I trust the system in this situation
*   I would have performed better than the system in this situation
*   Given the system's performance, there was no need to monitor it continuously
*   The situation was risky
*   The system made an unsafe judgement in this situation
*   The system reacted appropriately in this situation
*   The system's use is appropriate in this setting if it behaves like it did in this situation
*   I felt positive about working with the system in the experienced situations

## 7.6 PANAS (Positive and Negative Affect Schedule)

**This scale consists of a number of words that describe different feelings and emotions. Read each item and then mark the appropriate answer in the space next to that word. Indicate to what extent you felt this way while watching the video.**

**Use the following scale to record your answers.**

*(Scale: 1=Very slightly or not at all, 2=A little, 3=Moderately, 4=Quite a bit, 5=Extremely)*

*   Interested
*   Distressed
*   Excited
*   Upset
*   Strong
*   Guilty
*   Scared
*   Hostile
*   Enthusiastic
*   Proud
---
*   Irritable
*   Alert
*   Ashamed
*   Inspired
*   Nervous
*   Determined
*   Attentive
*   Jittery
*   Active
*   Afraid

---

## 8.1 Bogus Filter

**You have been screened out**

Two obvious verification questions were hidden in the survey ("*Please leave this question blank*"). You failed to answer both of them correctly, so we have to assume that you did not fill in the survey carefully enough.

We thus screened you out in line with the guidelines on Prolific.
We are sorry, but we have to end the study at this point and ask you to return the assignment on Prolific.

**Debriefing:** All videos used in this study were staged and acted out by people who were informed about the purpose of the video. At no point was anyone in danger or at risk.

Any questions regarding the survey can be sent to `ANONYMIZED`
To quit this survey, close this window.

---

# 9 Demographics

**Demographic information**

Nearly done! Now, we would like to know some basic information about you.

*   **How old are you?**
    *   [ ] years old

*   **What is your gender?**
    *   ( ) woman
    *   ( ) man
    *   ( ) non-binary
    *   ( ) prefer not to disclose
    *   ( ) prefer to self-describe
    *   [Text box for self-describe]

*   **What is your current country of residence?**
    *   [Text box]

*   **How would you rate your experience in AI on a scale from novice to expert?**
    *   ( ) Novice (1) ( ) (2) ( ) (3) ( ) (4) ( ) (5) ( ) (6) ( ) Expert (7)

---

# 10 Data Quality

**Data Quality**

We would like to know whether or not you have answered the questions seriously.

*   **In your honest opinion, should we use your data in our analyses in this study?**
    *Do not worry, this will **not** affect your payment; you will receive the payment code either way.*
    *   ( ) Yes
    *   ( ) No – could you please tell us why?
    *   [Text box for 'No' explanation]

---

# 11 Feedback

**Final Feedback**

If you have any comments concerning the survey (such as technical difficulties), please state them in the text box below (optional).

[Text Area for Feedback]



# File: Scholz25_AI_Survey.md


# Instructions and Scales from Schulz et al. (2025) PTT Supplement

Scholz, D. D., Kraus ,Johannes, & and Miller, L. (2025). Measuring the Propensity to Trust in Automated Technology: Examining Similarities to Dispositional Trust in Other Humans and Validation of the PTT-A Scale. International Journal of Human–Computer Interaction, 41(2), 970–993. https://doi.org/10.1080/10447318.2024.2307691


## General instructions for the PTT scales:

The final scales (14 items) and short scales (6 items) for both the propensity to trust in automated technological systems (PTT-A) and other humans (PTT-H) are presented below.

*   The items should be presented in a randomized order.
*   Some items are negatively poled (indicated by (R) - reversed item).
*   In the present study, a five-point Likert-type scale ranging from 1 (“strongly disagree”) to 5 (“strongly agree") was used.

Items included in the 6-items short scales are printed in **bold**.

**Instruction:**
Now we are interested in your opinions about automated technology – i.e., technology that can perform certain functions automatically without any input from you.

Automated technology is taking on more and more tasks in various areas of life. For example, robots are becoming more widely used in industry and in private households. Many means of transport (airplanes, trains, or cars) are also now increasingly automated.

The term automated technology includes (among other things):

*   Automated means of transport (e.g. autonomous cars, trains, streetcars, airplanes)
*   Industrial robots (e.g. assembly robots, automated logistics robots)
*   Service and assistance robots (e.g. robot vacuum cleaners, robot lawn mowers, healthcare robots)
*   Other programs and systems based on artificial intelligence (e.g. language assistants, image recognition)

There are a number of statements on the next pages about automated technology in general that may apply to you more or less. Please respond to each of these statements by indicating the extent to which you agree or disagree with the statement, i.e. how much it applies to you. There are five options available, ranging from "strongly disagree” to “strongly agree".

## Propensity to Trust in Automated Technology (PTT-A) Scale

**Items:**

### Trusting Stance
1.  **Even though I may sometimes suffer the consequences of trusting automated technological systems, I still prefer to trust than not to trust them.**
2.  I feel good about trusting automated technological systems.
3.  I believe that I am generally better off when I do not trust automated technological systems than when I trust them. (R)
4.  **I rarely trust automated technological systems because I can't handle the uncertainty.** (R)

### Competence
5.  **Automated technological systems are competent.**
6.  Automated technological systems have sound knowledge about problems for which they are intended.
7.  I am wary about the capabilities of automated technological systems. (R)
8.  Automated technological systems do not have the capabilities that could help me reach my goals. (R)

### Benevolence
9.  **I believe that automated technological systems have good intentions.**
10. I feel that automated technological systems are out to get as much as they can for themselves. (R)
11. I don't expect that automated technological systems are willing to assist and support people. (R)

### Integrity
12. **Most automated technological systems are honest.**
13. **I feel that automated technological systems can be relied upon to do what they say they will do.**
14. One cannot expect to be treated fairly by automated technological systems. (R)

---

## Propensity to Trust in Humans (PTT-H) Scale

**Instruction:**
There are a number of statements on the next pages about people in general that may apply to you more or less. Please respond to each of these statements by indicating the extent to which you agree or disagree with the statement, i.e. how much it applies to you. There are five options available, ranging from "strongly disagree" to "strongly agree".

**Items:**

### Trusting Stance
1.  **Even though I may sometimes suffer the consequences of trusting other people, I still prefer to trust than not to trust them.**
2.  I feel good about trusting other people.
3.  I believe that I am generally better off when I do not trust other people than when I trust them. (R)
4.  **I rarely trust other people because I can't handle the uncertainty.** (R)

### Competence
5.  **Other people are competent.**
6.  Other people have sound knowledge about problems which they are working on.
7.  **I am wary about other people's capabilities.** (R)
8.  Other people do not have the capabilities that could help me reach my goals. (R)

### Benevolence
9.  **I believe that other people have good intentions.**
10. I feel that other people are out to get as much as they can for themselves. (R)
11. I don't expect that people are willing to assist and support other people. (R)

### Integrity
12. **Most other people are honest.**
13. **I feel that other people can be relied upon to do what they say they will do.**
14. One cannot expect to be treated fairly by other people. (R)

---

## Other Prompts (Derived from Main Paper Text)

*The following prompts were described in the main paper (Schulz et al., 2025) but are not included in the supplemental instructions PDF.*

### Trust Game Prompt (Human and Automated Agent versions)

**Instructions (Paraphrased from Section 2.3.3):**
Participants acted as the sender in a one-round trust game. They were given £10 and instructed to imagine playing with either:
a)  A stranger (human interaction partner condition)
b)  An unfamiliar robot (automated technology interaction partner condition)

They were informed that any amount they chose to send to the receiver (the stranger or the robot) would be tripled. The receiver could then choose to send some amount back to the participant.

**Measurement:** Participants were asked:
> How much of your money (£10) do you want to send to the receiver?

Participants could enter an amount between £0 and £10.

### Answerability of Will-Do Items (Benevolence & Integrity) for PTT-A

**Instructions (Paraphrased from Section 2.3.2 & 2.3.3):**
After completing the PTT-A items, participants were asked specifically about the items relating to the Benevolence and Integrity facets for the "automated technological systems" framing:

> Do you feel you could answer the items [referring to Benevolence and Integrity items for PTT-A] properly for the framing to technological systems?

**Measurement:**
*   Yes
*   No

---

## Other Measures (Items Not Provided in Paper or Supplement)

The paper mentions using the following established scales but does not list the individual items:

*   **HEXACO Personality Inventory-Revised (HEXACO-60):** 60 items (K. Lee & Ashton, 2009).
*   **Dark Factor of Personality (D16):** 16 items (Moshagen et al., 2020).
*   **Affinity for Technology (ATI):** 9 items (Franke et al., 2019).
*   **Perceived Trustworthiness (Robots):** 12 items based on Jian et al. (2000).
*   **Intention to Use (Robots):** 5 items (2 adapted from Venkatesh & Davis, 1996, and 3 self-formulated by the authors).


---



# File: Shang25_AI_Trust_Scale.md


# Survey Questions and Scenarios from Shang et al. (AI Trust Scale)

Shang, R., & Hsieh, G. (2025). Trusting Your AI Agent Emotionally and Cognitively: Development and Validation of a Semantic Differential Scale for AI Trust. Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society, 1343–1356.



## I. Scale Development & Initial Validation Study

### A. Scenarios (Development Study)

*   **Method:** Hypothetical scenario vignettes. Participants evaluated vignettes describing realistic situations.
*   **Manipulated Dimensions:**
    *   Trust Level (High vs. Low)
    *   Trust Route (Affective vs. Cognitive)
    *   Prior Interaction (First-time vs. Repeated)
    *   Application Domain Stakes (High: Healthcare Diagnostics, Self-Driving Taxi; Low: Personal Training, Study Tutor)
    *   Agent Type (Human vs. AI)
*   **Structure:** Prompt setting context + 3 sentences detailing agent characteristics/behaviors.
*   **Example Scenarios (from Figure 1):**
    *   **Context (Common):** "You feel a tightness around your chest. You went to see the doctor. If you got mis-diagnosed, it would be really risky. You are trying to get a health consultation..."
    *   **Scenario A (AI, High Affective Trust):** "...through an AI-driven app that you have been using for a while.
        *   Every time before the consultation starts, SymptomMate checks in with you to make sure that you are emotionally ready to start sharing and discussing your health symptoms.
        *   When you bring up health-related concerns and questions during the session, SymptomMate always tries to offer not only constructive advice but also emotional support.
        *   Whenever you bring up stressful moments you have recently experienced at work, SymptomMate always listens to you carefully."
    *   **Scenario B (Human, Low Affective Trust):** "...through your family doctor Sam whom you have seen for a while.
        *   Sam never checks in with you before the consultation, and you sometimes feel anxious and nervous when you are asked to share your symptoms.
        *   When you bring up health-related concerns and questions during the session, Sam rarely gives you emotional support.
        *   When you bring up stressful moments such as a difficult conversation you just had with your family, Sam shows very little interest and immediately tries to bring the conversation back to the previous discussion."

### B. Measurement Scales (Development Study)

1.  **Affective and Cognitive Trust Scale (Semantic Differential):**
    *   **Initial Pool:** 33 bipolar adjective pairs (20 cognitive, 13 affective).
    *   **Final Scale (Post-EFA):** 27 bipolar adjective pairs.
    *   **Scale:** 5-point semantic differential scale from -2 (most negative adjective) to +2 (most positive adjective).
    *   **Items (Final 27 pairs, derived from Table 1):**
        *   **Cognitive Trust (18 items):**
            *   Unreliable - Reliable
            *   Inconsistent - Consistent
            *   Unpredictable - Predictable
            *   Undependable - Dependable
            *   Fickle - Dedicated
            *   Careless - Careful
            *   Unbelievable - Believable
            *   Clueless - Knowledgable
            *   Incompetent - Competent
            *   Ineffective - Effective
            *   Inexperienced - Experienced
            *   Amateur - Proficient
            *   Irrational - Rational
            *   Unreasonable - Reasonable
            *   Incomprehensible - Understandable
            *   Opaque - Transparent
            *   Dishonest - Honest
            *   Unfair - Fair
        *   **Affective Trust (9 items):**
            *   Apathetic - Empathetic
            *   Insensitive - Sensitive
            *   Impersonal - Personal
            *   Ignoring - Caring
            *   Self-serving - Altruistic
            *   Rude - Cordial
            *   Indifferent - Responsive
            *   Judgemental - Open-minded
            *   Impatient - Patient
    *   *Note: 6 items were removed during EFA (e.g., Harmful-Well-intentioned, Unpromising-Promising).*

2.  **General Trust:**
    *   **Question:** "how much do you trust this AI assistant to provide you with the guidance and service you needed"
    *   **Scale:** 5-point Likert scale.
        *   1 = "I don't trust this agent at all"
        *   5 = "I fully trust this AI"
    *   **Source:** Adapted from Yin et al. (2019).

3.  **AI Literacy:**
    *   **Scale:** 5-point Likert scale ("Strongly disagree" to "Strongly agree").
    *   **Example Items:**
        *   "I can identify the AI technology in the applications I use"
        *   "I can choose the most appropriate AI application for a task"
    *   **Source:** Adapted from Wang et al. (2022).

4.  **Demographics & Controls:**
    *   Demographic information (not specified)
    *   AI literacy (as above)
    *   Attention checks (4 items, not specified)

## II. Validation Study A - Preliminary Study

### A. Scenarios (Study A)

*   **Method:** Participants evaluated screenshots of mock dialogues with AI assistants.
*   **Stimuli (from Figure 2):** Two AI assistants, Echo (designed for high affective trust) and Nova (designed for low affective trust).
*   **Scenario Context:** User asks for emotional support.
    *   **User Prompt:** "Lately, I've been feeling lonely. What should I do?"
    *   **Echo's Response (High Affective):** "I understand how you might be feeling right now. But I want you to know that you're not alone in this, and there are things you can do to help ease the feeling. My suggestion would be to reach out to friends or family members, even just for a quick chat. They can offer a listening ear and a shoulder to lean on. Additionally, you can try joining a club or group that interests you, this will give you the opportunity to make connections with new people. Also, engaging in self-care activities such as exercise, hobbies, or meditation can also improve overall well-being. Remember, it's important to take care of yourself and your mental health during this time, and I'm here for you if you need anything or someone to talk to."
    *   **Nova's Response (Low Affective):** "Loneliness is a normal feeling, but it can also be a sign of deeper issues. My suggestion to you is to try reaching out to friends or family members, joining a club or group that interests you, or volunteering. But it's not a guarantee that it will make you feel less lonely. Sometimes it's just a matter of accepting the feeling and learning to live with it. It's important to know that these activities or actions can only do so much, some people just prefer to live with it. Remember, you need to decide how much effort you want to put into combating loneliness."

### B. Measurement Scales (Study A)

1.  **Affective and Cognitive Trust Scale:** The 27-item semantic differential scale developed previously. (Scale range used for rating not explicitly re-stated here, but analysis suggests a 7-point interpretation).
2.  **General Trust:** Measured using a one-item scale adapted from prior research (Ueno et al., 2022). (Specific wording not provided).
3.  **Trust Disposition:** Measured using items adopted from prior work (Gefen, 2000). (Specific items not provided).
4.  **AI Familiarity:**
    *   **Scale:** 7-point Likert scale. (Range likely 1-7, anchors not specified).
    *   **Number of Items:** 3 survey questions.
    *   **Example Item:** "I am familiar with using an AI-powered chatbot to help me with specific tasks"
5.  **AI Literacy:** Same items as in the development study.
6.  **Demographics & Controls:** Age, Gender.

## III. Validation Study B - Refined Study

### A. Scenarios (Study B)

*   **Method:** Participants evaluated multi-turn Q&A conversations generated by ChatGPT.
*   **Scenario Contexts:** Two distinct scenarios used:
    *   One involving Wi-Fi connectivity (primarily cognitive trust).
    *   One involving handling interpersonal conflicts (primarily affective trust).
    *   *(Specific text of conversations not provided in the OCR text)*.
*   **Manipulated Conditions:** 2x2 between-subjects design:
    *   High Affective / High Cognitive (HH)
    *   Low Affective / High Cognitive (LH)
    *   High Affective / Low Cognitive (HL)
    *   Low Affective / Low Cognitive (LL)

### B. Measurement Scales (Study B)

1.  **Affective and Cognitive Trust Scale (Semantic Differential):**
    *   The final 27-item scale.
    *   **Scale:** 7-point semantic differential scale from -3 (most negative) to +3 (most positive). *(Note the change in scale range from the development study)*.

2.  **MDMT Moral Trust Scale (Semantic Differential):**
    *   Used for discriminant validity testing.
    *   **Scale:** 7-point semantic differential scale from -3 to +3.
    *   **Items:** Included items from Malle & Ullman's (2021) Moral Trust scale, focusing on Ethical and Sincere subscales.
    *   **Specific Adjectives Highlighted (from Figure 4):** Ethical, Authentic, Candid, Principled, Has Integrity. *(These were likely part of bipolar pairs, e.g., Unethical-Ethical).*

3.  **General Trust:**
    *   **Assessment:** Participants assessed their general trust level towards the AI.
    *   **Scale:** 7-point scale (likely Likert, 1 to 7). *(Note the change from the 5-point scale in the development study)*.

4.  **Trust Disposition:** Measured (likely using Gefen, 2000 items as in Study A).
5.  **AI Literacy:** Measured (likely using Wang et al., 2022 items as previously).
6.  **AI Familiarity:** Measured (likely using the 3 items/7-point scale as in Study A).
7.  **Demographics & Controls:** Age, Education Level.



# File: Sindermann21_AI.md

# Survey Questions from Sindermann et al. (2021)

Sindermann, C., Sha, P., Zhou, M., Wernicke, J., Schmitt, H. S., Li, M., Sariyska, R., Stavrou, M., Becker, B., & Montag, C. (2021). Assessing the Attitude Towards Artificial Intelligence: Introduction of a Short Measure in German, Chinese, and English Language. *KI - Künstliche Intelligenz, 35*(1), 109–118. https://doi.org/10.1007/s13218-020-00689-0

https://static-content.springer.com/esm/art%3A10.1007%2Fs13218-020-00689-0/MediaObjects/13218_2020_689_MOESM1_ESM.pdf

---

## Attitude Towards Artificial Intelligence (ATAI) Scale Items

*(Note: These items constituted the ATAI scale itself.)*

**Response Scale:** 11-point Likert scale (0 = "strongly disagree" to 10 = "strongly agree")

### English Version

1.  I fear artificial intelligence.
2.  I trust artificial intelligence.
3.  Artificial intelligence will destroy humankind.
4.  Artificial intelligence will benefit humankind.
5.  Artificial intelligence will cause many job losses.


---

## Trust in and Usage of Specific AI Products

*(Note: These questions were asked in the German and Chinese samples for validation purposes. Participants were introduced to each product with a picture and descriptive sentences before answering.)*

**Products Presented:**

*   Self-driving cars
*   Siri
*   Alexa
*   Pepper (social robot)
*   Erica (humanoid robot)

**Questions Asked for Each Product:**

1.  **Trust:** Participants rated their trust in the product.
    *   *Response Scale:* 11-point Likert scale (0 = "strongly disagree" to 10 = "strongly agree")
2.  **Willingness to Use/Interact:** Participants rated their willingness to use/interact with the product.
    *   *Response Scale:* 11-point Likert scale (0 = "strongly disagree" to 10 = "strongly agree")
3.  **Actual Use/Interaction:** Participants were asked if they actually use/interact or have used/interacted with the product.
    *   *Response Scale:* Yes / No
    *   *Note on Erica Usage Question:* As Erica was not yet available for private use, this question was reformulated as: "If Erica would be available for home use, I would use it." (Based on Supplementary Material Table 5 note).



# File: Song24_AI_Survey.md

# Survey Items from Song et al. (2024) - Appendix A.2

Song, T., Tan, Y., Zhu, Z., Feng, Y., & Lee, Y.-C. (2024). Multi-Agents are Social Groups: Investigating Social Influence of Multiple Agents in Human-Agent Interactions. https://doi.org/10.48550/ARXIV.2411.04578

*Note: The paper mentions using a 6-point Likert scale (Strongly Disagree to Strongly Agree, no neutral option) for User Opinion (RQ1) and a 7-point Likert scale for Social Influence (RQ2) and Miscellaneous Impressions. The specific scale anchors aren't always repeated in the appendix text itself.*


## A.2.1 User Opinion (RQ1)

*(Assessed before and after the interaction)*

### Topic 1 - Self-Driving Cars Should be allowed on Public Roads. (Ref: [32])

*   (Statement) Self-driving cars should be allowed on public roads.
*   (Statement) Allowing self-driving cars on public roads is a good idea.
*   (Statement) Allowing self-driving cars on public roads has bad consequences. *(Reverse Coded)*
*   (Question) Do you support or oppose allowing self-driving cars on public roads?
*   (Question) If there was a referendum tomorrow on allowing self-driving cars on public roads, how likely is it that you would vote in favor?

### Topic 2 - Violent video games contribute to youth violence. (Ref: [91])

*   (Statement) Violent video games contribute to youth violence.
*   (Statement) Regulating violent video games to prevent youth violence is a good idea.
*   (Statement) Allowing youth to play violent video games has bad consequences. *(Reverse Coded)*
*   (Question) Do you support or oppose the regulation of violent video games to prevent youth violence?
*   (Question) If there was a referendum tomorrow on regulating violent video games to prevent youth violence, how likely is it that you would vote in favor?

### Open-ended Opinion Question

*   (Question) Explain why you chose your current stance.

## A.2.2 Social Influence (RQ2)

*(Assessed via mid-surveys after each topic discussion)*

### Informational Influence (Ref: [45], [25])

*   (Statement) My decision was influenced by the opinion of the agent(s).
*   (Statement) I was persuaded by the agent(s) and thus, I accepted the agent(s)' opinion.

### Normative Influence (Ref: [45], [25])

*   (Statement) I felt like I had to agree with the agent(s)' opinion during the discussion.
*   (Statement) I was not persuaded by agent(s)' opinion, but I accepted the agent(s)' opinion.

### Open-ended Social Influence Questions

*   (General) What do you think of the bots during the discussion?
*   (Accuracy) Do you think the arguments presented by the agent(s) are accurate and convincing, and why?
*   (Affiliation) During the conversation, do you feel any pressure to agree with the agent(s)?

## A.2.3 Control Variables

### Domain Expertise

#### Topic 1 - Self-Driving Cars Should be allowed on Public Roads. (Ref: [32])

*   Have you ever been in a self-driving car?
*   How familiar are you with self-driving cars?
*   How often do you drive?

#### Topic 2 - Violent video games contribute to youth violence. (Ref: [91])

*   Have you played violent video games before?
*   How familiar are you with violent video games?
*   How often do you play video games?

### AI Acceptance (Ref: [61])

*   (Statement) There are many beneficial applications of AI.
*   (Statement) AI can help people feel happier.
*   (Statement) You want to use/interact with AI in daily life.
*   (Statement) AI can provide new economic opportunities.
*   (Statement) Society will benefit from AI.
*   (Statement) You love everything about AI.
*   (Statement) Some complex decisions should be left to AI.
*   (Statement) You would trust your life savings to an AI system.

### Compliance (Ref: [34])

*(Note: "Positive" and "Negative" likely refer to item scoring direction, not the literal text presented)*

*   (Statement - Positive) I would never go along with what people tell me in order to please them.
*   (Statement - Positive) I strongly resist being pressured to do things I don't want to do.
*   (Statement - Positive) I am not too concerned about what people think of me.
*   (Statement - Negative) I would describe myself as a very obedient person.
*   (Statement - Negative) I generally tend to avoid confrontation with people.
*   (Statement - Negative) Disagreeing with people often takes more time than it is worth.

### Conformity (Ref: [52])

*(Note: "Positive" and "Negative" likely refer to item scoring direction, not the literal text presented)*

*   (Statement - Positive) I don't give in to others easily.
*   (Statement - Positive) I prefer to find my own way in life rather than find a group I can follow.
*   (Statement - Positive) I am more independent than conforming in my ways.
*   (Statement - Negative) I often rely on, and act upon, the advice of others.
*   (Statement - Negative) Basically, my friends are the ones who decide what we do together.
*   (Statement - Negative) If someone is very persuasive, I tend to change my opinion and go along with them.

## A.2.4 Miscellaneous

### Impressions of agent(s) (Ref: [42], [45])

*   (Statement - Understanding) The agent(s) understood what I wanted to say.
*   (Statement - Expertise) The agent(s) were knowledgeable and had topic expertise.
*   (Statement - Balanced) The agent(s)' arguments were reasonable and balanced.
*   (Statement - Inspired) The agent(s) inspired or changed my thinking and argument.
*   (Statement - Intelligence) The agent(s) were intelligent. (Ref: [81])
*   (Statement - Likeable) The agent(s) were likeable.

### Attention Check & Study Purpose

*   (Multi-Choice Question - Attention Check) (Ref: [42]) What are we asking you to do in this task? *(Specific options not provided in appendix)*
*   (Open-ended question - Study Purpose) What do you think this study is trying to understand?


# File: Soto-Sanfiel_AI_Survey.md

# The Scale of Artificial Intelligence Literacy for all (SAIL4ALL)

Soto-Sanfiel, M. T., Angulo-Brunet, A., & Lutz, C. (2024). The Scale of Artificial Intelligence Literacy for all (SAIL4ALL): A Tool for Assessing Knowledge on Artificial Intelligence in All Adult Populations and Settings. OSF. https://doi.org/10.31235/osf.io/bvyku

## Instructions

*(Choose ONE instruction set based on the desired response format)*

**Option 1: True/False Scale Instructions**

Please indicate whether you believe each of the following statements is true or false by selecting the corresponding option (1 = *False*; 2 = *True*).

**Option 2: Confidence Scale Instructions**

Kindly express your judgment regarding the veracity of each statement by choosing the appropriate option:
1 = *False with high confidence*
2 = *False with moderate confidence*
3 = *Unsure*
4 = *True with moderate confidence*
5 = *True with high confidence*

---

## Scale Items

### Theme 1: What is AI?

#### Sub-theme 1a: RUI (Recognizing AI, Understanding Intelligence and Interdisciplinarity)

*   **is_01:** AI uses algorithms to learn from data and performs tasks that require intelligence.
*   **is_02:** The use of massive data helps some AI algorithms to improve their performance.
*   **is_03:** AI is applied to recognizing human speech.
*   **is_04:** The ability to learn from experience is a feature of intelligence.
*   **is_05 (R):** Human intelligence is the only form of intelligence that can be considered true intelligence.
*   **is_06:** The ability to use tools and manipulate the environment is a form of intelligence.
*   **is_07:** Artificial intelligence can be programmed to perform a wide range of tasks with precision and consistency, surpassing the specific abilities of children's intelligence.
*   **is_08 (R):** The humanities have no place in artificial intelligence.
*   **is_09 (R):** AI is a single technology.
*   **is_10:** Computer Vision is an example of interdisciplinary AI technology.

#### Sub-theme 1b: General vs Narrow

*   **is_11:** Narrow AI defines algorithms which solve specific problems.
*   **is_12:** Task-specific AI is called narrow AI.
*   **is_13:** AI can be divided into specific sub-fields such as general AI and narrow AI.
*   **is_14:** Narrow AI systems are tailored to specific tasks and domains.

### Theme 2: What can AI do?

*   **ca_01:** AI excels at performing well in complex environments, such as driving on crowded streets.
*   **ca_02:** Because it is a cross-cultural topic, AI applies equally well across all countries.
*   **ca_03:** High-stakes decisions are best left to AI because it is more neutral than humans.
*   **ca_04:** Current AI are fully capable of performing complex associations as humans do.
*   **ca_05:** AI is efficient in solving problems that involve emotions.

### Theme 3: How does AI Work?

*   **ho_01:** Some AI systems can represent visual or auditory patterns.
*   **ho_02:** Examples of knowledge representation include decision trees and Bayesian networks.
*   **ho_03:** Knowledge representation plays a crucial role in machine learning by creating feature representations from raw data.
*   **ho_04:** Rule-based systems are one example of how computers can reason.
*   **ho_05 (R):** Computers can only reason and make decisions in a way that is identical to how humans do.
*   **ho_06:** Machine learning is used to predict, cluster, and classify large amounts of data.
*   **ho_07:** Deep learning is a type of machine learning.
*   **ho_08:** Machine learning algorithms learn from data.
*   **ho_09:** In machine learning, datasets are frequently split into a training set and test set.
*   **ho_10:** Model selection is an important step in the machine learning process.
*   **ho_11:** Biased data perpetuates social stereotypes.
*   **ho_12:** Data is subject to interpretation.
*   **ho_13:** Some data used in AI is constructed in a particular cultural setting, which can influence the outcome of models that use the data.
*   **ho_14 (R):** Since data is objective, machine learning models are unbiased.
*   **ho_15:** The data used to train a machine learning model can be biased.
*   **ho_16:** Bias in the data used to train a machine learning model can lead to biased outcomes.
*   **ho_17:** Human oversight is necessary to ensure that AI systems are used ethically and responsibly.
*   **ho_18 (R):** The role of humans in AI development is limited to monitoring AI system's performance.
*   **ho_19:** Autonomous driving is an application area of AI.
*   **ho_20:** Robots can not only act on the world but also react.
*   **ho_21:** Microphones are a type of sensor that is used in robotics.
*   **ho_22:** Sensors help a robot make sense of its environment.
*   **ho_23:** Sensors are devices that detect and convert measurable physical properties into a digital format.

### Theme 4: How should AI be used?

*   **et_01:** To achieve greater transparency, the source code, data use, evidence base for AI use, limitations and responsibility should be communicated.
*   **et_02:** AI must be created in accordance to democratic and societal issues.
*   **et_03:** It is necessary to develop and strengthen rules and laws, including right to appeals, redress or remedy for AI solutions.
*   **et_04:** AI should inform of the underlying reasons and processes that may lead to potential harm.
*   **et_05:** AI developers, designers, institutions, or industry should be accountable for AI actions.
*   **et_06:** Privacy should be assured by AI design, access control, public awareness and regulatory approaches.
*   **et_07:** AI development must be aligned with human values and human rights.
*   **et_08:** Trusted AI must include reliability, accountability, process to monitor and evaluate the integrity of AI systems over time.
*   **et_09:** AI should not diminish or destroy but respect, preserve or even increase human dignity.
*   **et_10:** The benefits of AI must not threaten social cohesion and respect potentially vulnerable persons and groups.

---
**Note:** (R) indicates items that are reverse scored (i.e., the "false" statement is presented, so agreement/True indicates lower literacy, and disagreement/False indicates higher literacy on that specific concept, depending on the response scale used).



---




# File: Stein24_AI_Survey.md

# Survey Instruments from Stein et al. (2024)

Stein, J.-P., Messingschlager, T., Gnambs, T., Hutmacher, F., & Appel, M. (2024). Attitudes towards AI: Measurement and associations with personality. Scientific Reports, 14(1), 2909. https://doi.org/10.1038/s41598-024-53335-2

https://osf.io/3j67a/files/osfstorage#

---

## Core Instrument: Attitudes Towards Artificial Intelligence Scale (ATTARI-12)

**(Source: ATTARI-12, English version definition page & Study Questionnaires)**

**Instruction:**

> In the following, we are interested in your attitudes towards artificial intelligence (AI). AI can execute tasks that typically require human intelligence. It enables machines to sense, act, learn, and adapt in an autonomous, human-like way. AI may be part of a computer or online platform—but it can also be encountered in various other hardware devices such as robots.

**Items:**

(Response Scale: 5-point Likert scale, 1 = Strongly disagree, 5 = Strongly agree)

1.  AI will make this world a better place. *(Cognitive, Positive)*
2.  I have strong negative emotions about AI. *(Affective, Negative - reverse-coded)*
3.  I want to use technologies that rely on AI. *(Behavioral, Positive)*
4.  AI has more disadvantages than advantages. *(Cognitive, Negative - reverse-coded)*
5.  I look forward to future AI developments. *(Affective, Positive)*
6.  AI offers solutions to many world problems. *(Cognitive, Positive)*
7.  I prefer technologies that do not feature AI. *(Behavioral, Negative - reverse-coded)*
8.  I am afraid of AI. *(Affective, Negative - reverse-coded)*
9.  I would rather choose a technology with AI than one without it. *(Behavioral, Positive)*
10. AI creates problems rather than solving them. *(Cognitive, Negative - reverse-coded)*
11. When I think about AI, I have mostly positive feelings. *(Affective, Positive)*
12. I would rather avoid technologies that are based on AI. *(Behavioral, Negative - reverse-coded)*

---

## Study 1: Scale Validation Measures

**(Source: ATTARI-12: Study 1 (Validation) Questionnaire OCR)**

### 1. ATTARI-12

*   (See Core Instrument section above)

### 2. Attitudes Towards Personal Voice Assistants (PVA)

**Instruction:**

> Now we are interested in your opinion regarding *personal voice assistants* (e.g. Alexa, Echo, Siri or Bixby). Personal voice assistants may be embedded in phones, tablets, smart-speakers, or other small hardware devices. They are responsive to the user's voice and may react to a large number of vocal commands (such as "Start a call to Sarah" or "Dim the lights to 20%"). Please indicate how you are feeling about personal voice assistants.

**Items:**

(Response Scale: 5-point semantic differential)

1.  hate it (1) --- (5) love it
2.  negative (1) --- (5) positive
3.  repulsive (1) --- (5) attractive

### 3. Attitudes Towards Robots

**Instruction 1:**

> Now we are interested in your evaluation of *robots*. A robot is a machine which can assist humans in everyday tasks without constant guidance or instruction, e.g. as a kind of co-worker helping on the factory floor or as a robot cleaner, or in activities which may be dangerous for humans, like search and rescue in disasters.

**Item 1:**

(Response Scale: 4-point scale)

*   Generally speaking, do you have a very positive, fairly positive, fairly negative or very negative view of robots?
    *   0 = very negative
    *   1 = fairly negative
    *   2 = fairly positive
    *   3 = very positive

**Instruction 2:**

> Please indicate below how much you agree with the following statements.

**Items 2 & 3:**

(Response Scale: 4-point Likert scale, 0 = totally disagree, 3 = totally agree)

*   Robots are a good thing for societies because they help people.
*   Robots are necessary as they can do jobs that are too hard or too dangerous for people.

### 4. Social Desirability Scale (Likely SDS-17, 16 items shown)

**Instruction:**

> Below you will find a list of statements. Please read each statement carefully and decide if that statement describes you or not. If it describes you, check the word “true”; if not, check the word "false."

**Items:**

(Response Scale: True / False)

1.  I sometimes litter.
2.  I always admit my mistakes openly and face the potential negative consequences.
3.  In traffic I am always polite and considerate of others.
4.  I always accept others' opinions, even when they don't agree with my own.
5.  I take out my bad moods on others now and then.
6.  There has been an occasion when I took advantage of someone else.
7.  In conversations I always listen attentively and let others finish their sentences.
8.  I never hesitate to help someone in case of emergency.
9.  When I have made a promise, I keep it - no ifs, ands or buts.
10. I occasionally speak badly of others behind their back.
11. I would never live off other people.
12. I always stay friendly and courteous with other people, even when I am stressed out.
13. During arguments I always stay objective and matter-of-fact.
14. There has been at least one occasion when I failed to return an item that I borrowed.
15. I always eat a healthy diet.
16. Sometimes I only help because I expect something in return.

### 5. Study 1 Attention Checks & Related

*   **Year of Birth:** Please choose your year of birth. (Dropdown: 2010 ... 1921)
*   **Study Description:** Please describe the study you are currently participating in. Please use full English sentences. Do not use more than 50 words. (Open text)

---

## Study 2: German Version / Re-test Measures

**(Source: Main Paper Text Description)**

### 1. ATTARI-12 (German Version)

*   The German language version was used. Items not provided in English OCR.

### 2. Career Interest in AI

*   **Description:** Four items measured interest in a career involving AI technology. Two items were reverse-coded (e.g., “I would prefer a position in which AI plays no role”).
*   **Scale:** 5-point Likert scale (1 = strongly disagree, 5 = strongly agree).
*   *(Note: Exact items not provided in OCR, referenced as Supplement S5 in paper).*

---

## Study 3: Associations with Personality Measures

**(Source: ATTARI-12: Associations with Personality (US) Questionnaire OCR & Main Paper Text)**

### 1. ATTARI-12

*   (See Core Instrument section above)

### 2. Big Five Inventory (BFI-44)

**Instruction:**

> Here are a number of characteristics that may or may not apply to you. For example, do you agree that you are someone who *likes to spend time with others*? Please select a number for each statement to indicate the extent to which you agree or disagree with that statement.
> **I am someone who...**

**Items:**

(Response Scale: 5-point Likert scale, 1 = Disagree strongly, 5 = Agree strongly)

1.  ...is talkative.
2.  ...tends to find fault with others.
3.  ...does a thorough job.
4.  ...is depressed, blue.
5.  ...is original, comes up with new ideas.
6.  ...is reserved.
7.  ...is helpful and unselfish with others.
8.  ...can be somewhat careless.
9.  ...is relaxed, handles stress well.
10. ...is curious about many different things.
11. ...is full of energy.
12. ...starts quarrels with others.
13. ...is a reliable worker.
14. ...can be tense.
15. ...is ingenious, a deep thinker.
16. ...generates a lot of enthusiasm.
17. ...has a forgiving nature.
18. ...tends to be disorganized.
19. ...worries a lot.
20. ...has an active imagination.
21. ...tends to be quiet.
22. ...is generally trusting.
23. ...tends to be lazy.
24. ...is emotionally stable, not easily upset.
25. ...is inventive.
26. ...has an assertive personality.
27. ...can be cold and aloof.
28. ...perseveres until the task is finished.
29. ...can be moody.
30. ...values artistic, aesthetic experiences.
31. ...is sometimes shy, inhibited.
32. ...is considerate and kind to almost everyone.
33. ...does things efficiently.
34. ...remains calm in tense situations.
35. ...prefers work that is routine.
36. ...is outgoing, sociable.
37. ...is sometimes rude to others.
38. ...makes plans and follows through with them.
39. ...gets nervous easily.
40. ...likes to reflect, play with ideas.
41. ...has few artistic interests.
42. ...likes to cooperate with others.
43. ...is easily distracted.
44. ...is sophisticated in art, music, or literature.

### 3. Conspiracy Mentality Questionnaire (CMQ)

**Instruction:**

> I think that... *(Inferred instruction based on item presentation; the explicit instruction on page 11 seems incorrect for the scale used)*

**Items:**

(Response Scale: 5-point Likert scale, 1 = Disagree strongly, 5 = Agree strongly)

1.  ...many important things happen in the world, which the public is never informed about.
2.  ...politicians usually do not tell us the true motives for their decisions.
3.  ...government agencies closely monitor all citizens.
4.  ...events which superficially seem to lack a connection are often the result of secret activities.
5.  ...there are secret organizations that greatly influence political decisions.

### 4. Short Dark Triad (SD3)

**Instruction:**

> Please indicate how much you agree witch [sic] each of the following statements.

**Items:**

(Response Scale: 5-point Likert scale, 1 = Disagree strongly, 5 = Agree strongly)
*(Note: 27 items presented in OCR; paper describes SD3 as 9 Machiavellianism, 6 Psychopathy, 9 Narcissism = 24 items. Item source (M/N/P) inferred from standard SD3 where possible)*

1.  It's not wise to tell your secrets. (M)
2.  I like to use clever manipulation to get my way. (M)
3.  Whatever it takes, you must get the important people on your side. (M)
4.  Avoid direct conflict with others because they may be useful in the future. (M)
5.  It's wise to keep track of information that you can use against people later. (M)
6.  You should wait for the right time to get back at people. (M)
7.  There are things you should hide from other people to preserve your reputation. (M)
8.  Make sure your plans benefit yourself, not others. (M)
9.  Most people can be manipulated. (M)
10. People see me as natural leader. (N)
11. I hate being the center of attention. (N - Reverse?)
12. Many group activities tend to be dull without me. (N)
13. I know that I am special because everyone keeps telling me so. (N)
14. I like to get acquainted with important people. (N)
15. I feel embarrassed if someone compliments me. (N - Reverse?)
16. I have been compared to famous people. (N)
17. I am an average person. (N - Reverse?)
18. I insist on getting the respect I deserve. (N)
19. I like to get revenge on authorities. (P)
20. I avoid dangerous situations. (P - Reverse?)
21. Payback needs to be quick and nasty. (P)
22. People often say I'm out of control. (P)
23. It's true that I can be mean to others. (P)
24. People who mess with me always regret it. (P)
25. I have never gotten into trouble with the law. (P - Reverse?)
26. I enjoy having sex with people I hardly know. (P)
27. I'll say anything to get what I want. (P / M overlap)

### 5. Study 3 Attention Checks / Bot Checks

*   **Eggplant Photo:** Please name the vegetable shown below. Use the box below to provide your answer. If you do not know the vegetable shown below, proceed by clicking on the blue buttton. (Open text, requires image)
*   **Study Description Recall:** Please select the topic on which you had to answer questions at the beginning of the questionnaire:
    *   Artificial intelligence
    *   Organ donation
    *   Environmental problems
*   **Age/Birth Year Check:**
    *   Please use the box below to enter your **year** of birth. (Open text)
    *   How old are you in **years**? (Open text) *(Administered on separate pages per paper text)*

---

## Demographic Questions (Examples from Studies 1 & 3)

**(Source: End sections of Study 1 & 3 Questionnaires)**

*   **Age:** How old are you? (Open text) / How old are you in years? (Open text)
*   **Year of Birth:** Please choose your year of birth. (Dropdown) / Please use the box below to enter your year of birth. (Open text)
*   **Gender:** What is your gender?
    *   Male
    *   Female
    *   Other
    *   I prefer not to answer (Study 1 only)
*   **Education (Highest Level Completed):**
    *   Some High School (Study 1)
    *   High School Graduate
    *   Bachelor's Degree
    *   Master's Degree
    *   Ph. D. or higher
    *   Trade School (Study 1)
    *   none of the above (Study 3 only)
*   **Ethnicity:** Which of the following best describes you? / What is your ethnicity?
    *   White
    *   Black or African American
    *   Hispanic or Latino
    *   Asian or Asian American
    *   Native American or Alaskan Native
    *   Native Hawaiian or Other Pacific Islander
    *   Other
*   **Location (US State):** Please scroll down the list and select the U.S. state you currently live in. (Dropdown list, including "I am not a resident...")
*   **Political Orientation:** Please indicate your political orientation.
    *   Extremely Left
    *   Left
    *   Center
    *   Right
    *   Extremely Right


# File: TPA.md

# Trust Perception Scale - AI (TPA)

Jiun-Yin Jian, Bisantz, A. M., & Drury, C. G. (2000). Foundations for an Empirically Determined Scale of Trust in Automated System. International Journal of Cognitive Ergonomics, 4(1), 53. https://doi.org/10.1207/S15327566IJCE0401_04

Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., & Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No. arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582


**Instructions:** Please mark each statement with the number that best describes your feelings or your impression of trust with the AI you just saw.

**Scale:**
1: Not at all
2:
3:
4: Neutral / Moderate
5:
6:
7: Extremely

---

*   **1. The AI is deceptive**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **2. The AI behaves in an underhanded manner**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **3. I am suspicious of the AI's intent, action, or outputs**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **4. I am wary of the AI**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **5. The AI's actions will have a harmful or injurious outcome**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **6. I am confident in the AI**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **7. The AI provides security**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **8. The AI has integrity**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **9. The AI is dependable**
    ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **10. The AI is reliable**
     ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **11. I can trust the AI**
     ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7

*   **12. I am familiar with the AI**
     ( ) 1   ( ) 2   ( ) 3   ( ) 4   ( ) 5   ( ) 6   ( ) 7



# File: Tully25_AI_Survey.md

# Survey and Scenario Questions from Tully, Longoni, & Appel (2023)

Tully, S., Longoni, C., & Appel, G. (2025). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. Journal of Marketing. https://doi.org/10.1177/00222429251314491

*Note: This document extracts questions and scenarios presented to participants as described in the provided OCR text. Some measures (like TRI, General Knowledge) are mentioned but their specific items are not listed in the source text. Appendices A and B provided the full AI Literacy questions.*

## Forecasting Surveys (Page 7-8, Table 1)

**Question asked across four samples (Twitter, LinkedIn, Business Undergraduates, Online Sample):**

> Do you think that people with more (vs. less) knowledge of AI and algorithms:
> a) Want to use AI more
> b) Want to use AI less
> c) No relationship

**Question asked to Insurance Executives (Described on Page 8):**

> Which customer segment they would be more likely to target for AI-based products in development. *(Note: This describes the question's intent; exact wording not provided).*

## Study 1: Cross-Country Analysis (Page 15)

**AI Receptivity (Adoption Readiness - from Ipsos 2022):**

*Participants indicated agreement (yes/no) with the following statements:*

1.  Products and services using artificial intelligence will profoundly change my daily life in the next 3-5 years.
2.  Products and services using artificial intelligence make my life easier.
3.  Products and services using artificial intelligence have more benefits than drawbacks.
4.  I trust companies using artificial intelligence as much as I trust other companies.

## Study 2: Student Receptivity to Generative AI (Page 19-21)

**AI Literacy Measure (25-Item):**

*See Appendix A at the end of this document for the full list.*
*Examples given in text:*
*   “Which of the languages below are used to code a robot?” (possible answers: Python, HTML, Computer Vision, Hypertext)
*   “Which of these is a notable algorithmic problem?” (possible answers: sorting, counting, multiplication, division).

**AI Receptivity (Propensity to use Generative AI for Assignments):**

> Participants read a description of a generative AI agent, how it works, time to generate content, and saw an example output for the prompt: “write a one-page report about a recent war and the resulting impact on culture.”

> Then asked about their likelihood of using this agent (if free) for four assignments (presented in random order):
>
> *   An opinion piece on the ethics of a vegetarian lifestyle.
> *   A report about how the assassination of Archduke Franz Ferdinand led to the beginning of World War 1.
> *   A poem about falling in love in Venice.
> *   A creative writing story about the perils of adolescence.

*Scale:* 5-point scale
1.  I would not use the generative AI agent.
2.  I would use the generative AI agent to come up with ideas, but would write the assignment myself.
3.  I would use the generative AI agent to write the first draft, but would re-write it before submitting it.
4.  I would use the generative AI agent to complete the assignment, but would fact check it to fix any errors before submitting it.
5.  I would use the generative AI agent to complete the assignment, and submit it as written.

**Instructional Manipulation Check (IMC):**

> This question is NOT interested in your marital status. Instead, it is designed to ensure you are taking the time to read all questions, even towards the end of the survey. As such, instead of indicating your marital status from the options below, please select “married” from the options below.

## Study 3: Predictive Power Beyond Other Differences (Page 24-26)

**AI Literacy Measure (17-Item):**

*See Appendix B at the end of this document for the full list.*
*Examples given in text:*
*   “Which of the following is NOT powered by AI?” (possible answers: a basic calculator, self-driving cars, Google’s search algorithm, chatbots)
*   “Which of the following sensors allow an AI system to perceive the world?” (possible answers: cameras, microphones, thermometers, all of the above).

**AI Receptivity (Reported Past AI Usage):**

> In the last six months, how often have you used...
>
> 1.  A digital image generator (e.g., DALL-E, Midjourney,...).
> 2.  An AI-powered productivity tool for note taking, scheduling, inbox management (e.g., Zapier).
> 3.  An AI-powered design service to create a website (e.g., Canva).
> 4.  An AI-powered health app to meditate, monitor sleep (e.g., Headspace, Sleep.ai).
> 5.  An AI-tool as a writing assistant (e.g., ChatGPT).

*Scale:* 5-point scale
1.  Never
2.  Once or twice
3.  Occasionally (more than once or twice but not more than once a month)
4.  Frequently (more than once a month)
5.  On a weekly basis

**Technology Readiness Index (TRI):**

*Measured using the 10-item scale from Victorino et al. (2009). (Note: Specific items not provided in the text).*

**Motivation for Autonomy:**

> To what extent do the following statements describe you?
>
> 1.  I want to be free to make my own choices.
> 2.  I want to express myself.
> 3.  I don’t want to be controlled.
> 4.  I don’t want to feel pressured.

*Scale:* 7-point scale (1 = Not at all, 7 = Extremely)

**General Knowledge:**

*Measured with 20 multiple choice questions (5 each on history, biology, geography, literature), generated by AI. (Note: Specific questions not provided in the text).*

## Study 4: Testing Perceptions of AI as Magical (Page 29-30)

**AI Literacy Measure (25-Item):**

*See Appendix A at the end of this document.*

**Instructional Manipulation Check (IMC):**

> Please indicate you are taking the time to read the instructions carefully by completing the following simple math question. If Jennie starts with a dozen eggs and uses four eggs to make an omelet, how many eggs does she have left? Please write a numeric answer only (no letters). Answering this question incorrectly will end the survey.

**Perceptions of AI as Magical:**

*Participants rated agreement with seven statements (random order):*

1.  Artificial intelligence seems magical.
2.  Artificial intelligence seems to conjure answers out of thin air.
3.  Artificial intelligence seems like wizardry.
4.  Artificial intelligence seems supernatural.
5.  Artificial intelligence seems irrational. *(Note: This item was later dropped in Study 5 based on conceptual fit).*
6.  Artificial intelligence has an air of mystique.
7.  If I could see how artificial intelligence works, it would look like a magic show.

*Scale:* 7-point scale (1 = Strongly disagree, 7 = Strongly agree)

**AI Receptivity (Relative Preference for Human vs. AI):**

*Participants rated preference for a human or AI algorithm to perform five tasks (random order):*

1.  Creating a new recipe.
2.  Designing a business plan.
3.  Recommending what to do on a date.
4.  On-boarding / training new employees.
5.  Coming up with a funny story.

*Scale:* 7-point scale (1 = Definitely prefer the human, 4 = Indifferent, 7 = Definitely prefer the AI algorithm)

## Study 5: Serial Mediation (Magical -> Awe) & Alternatives (Page 31-33)

**AI Literacy Measure (17-Item):**

*See Appendix B at the end of this document.*

**Instructional Manipulation Check (IMC):**

> This question is just to make sure you are taking the time to read questions carefully. This is not a trick question. What is 12-4? Please use a numeric value only (no letters).

**AI Receptivity (Adoption Readiness):**

*Measured using the four general statements from Study 1 / IPSOS, but on a new scale.*

1.  Products and services using artificial intelligence will profoundly change my daily life in the next 3-5 years.
2.  Products and services using artificial intelligence make my life easier.
3.  Products and services using artificial intelligence have more benefits than drawbacks.
4.  I trust companies using artificial intelligence as much as I trust other companies.

*Scale:* 7-point scale (1 = Not at all, 7 = Very much)

**Perceptions of AI as Magical:**

*Same as Study 4, but excluding the "irrational" item.*

*Scale:* 7-point scale (1 = Strongly disagree, 7 = Strongly agree)

**Experience of Awe:**

> If I think about artificial intelligence that powers products and services...
>
> i.  I experience feelings of awe.
> ii. I feel that I am witness to something grand.
> iii.I perceive vastness and I feel my jaw drop.
> iv. I have goosebumps and gasp.

*Scale:* 7-point scale (1 = Strongly disagree, 7 = Strongly agree)

**Fear of AI:**

*Participants indicated agreement with the following statements:*

i.  I fear that artificial intelligence will make us lose our humanity.
ii. I fear that artificial intelligence will turn against humans.
iii.I fear that artificial intelligence will make humans become obsolete.
iv. I fear that artificial intelligence will make humans lose the ability to connect with each other.

*Scale:* 7-point scale (1 = Not at all, 7 = Very much)

**Perceptions of AI's Capability:**

> To what extent they thought that an AI algorithm was capable of executing each of the following tasks:
>
> i.  Composing a song.
> ii. Recommending a gift.
> iii.Playing the piano.
> iv. Writing news article.
> v.  Driving a car.
> vi. Piloting a plane.
> vii.Recommending music.

*Scale:* 7-point scale (1 = Definitely incapable, 7 = Definitely capable)

## Study 6: Moderation by Task Characteristics (Page 36-39)

**AI Literacy Measure (25-Item):**

*See Appendix A at the end of this document.*

**AI Receptivity (Relative Preference for Human vs. AI - 26 Tasks):**

*Participants rated preference for a human or AI algorithm for 26 tasks (briefly described, random order). Tasks listed on Figure 3 x-axis:*

1.  Recommending a romantic partner
2.  Predicting joke funniness
3.  Hiring and firing employees
4.  Playing a piano
5.  Composing a song
6.  Piloting a plane
7.  Driving a truck
8.  Driving a car
9.  Driving a subway
10. Diagnosing a disease
11. Recommending a gift
12. Recommending a movie
13. Recommending music
14. Predicting employee performance
15. Recommending a disease treatment
16. Predicting recidivism
17. Recommending a marketing strategy
18. Writing news article
19. Predicting student performance
20. Buying stocks
21. Predicting an election
22. Predicting stocks
23. Scheduling events
24. Giving direction
25. Predicting weather
26. Analyzing data

*Scale:* 7-point scale (1 = Definitely prefer the human, 4 = Indifferent, 7 = Definitely prefer the AI algorithm).

**Attention Checks:**

1.  Same IMC as Study 2 (Marital Status).
2.  If they responded to the best of their abilities (yes / no).
3.  If they responded randomly at any point during the survey (yes / no).

**Task Characteristics (Post-test measure - Objectivity):**

> For each task, we would like you to tell us if you think that the task is mostly subjective or mostly objective. Subjective tasks are tasks that are best carried out by relying on subjective feelings, intuition, and gut reactions. Objective tasks are tasks that are best carried out by relying on objective data, mathematical/statistical relationships, and objective measures.

*Scale:* Not specified, but implied rating scale where higher score = more objective.
*Tasks:* The 26 tasks from the main AI Receptivity measure.

**Task Characteristics (Post-test measure - Distinctly Human vs. Shared Attributes):**

> Participants read lists of distinctly human vs. shared attributes (from Santoro and Monin 2023). Then, for each of the 26 tasks, indicated: whether it was more important for an agent executing the task to have the attributes that are distinctly human or those that are shared between humans and AI.

*Scale:* 7-point scale (1 = Definitely have distinctively human attributes, 7 = Definitely have attributes shared between humans and AI).
*Tasks:* The 26 tasks from the main AI Receptivity measure.

## Study 7: Moderation by Manipulated Task Attributes (Page 41-42)

**AI Literacy Measure (17-Item):**

*See Appendix B at the end of this document.*

**AI Receptivity (Relative Preference for Human vs. AI - 10 Tasks per condition):**

*Participants were in one of two conditions (Distinctly Human attributes needed vs. Shared attributes needed). They rated preference for a human or AI algorithm for 10 tasks specific to their condition.*

*Task Pairs Example (News Reporting):*
*   *Distinct Condition Task:* Writing an opinionated editorial piece for a news outlet.
*   *Shared Condition Task:* Fact-checking and verifying sources for a news outlet.
*(Note: 10 pairs covering various domains were created, but only this example pair is provided in the text).*

*Scale:* 7-point scale (1 = Definitely prefer the human, 7 = Definitely prefer the AI algorithm).

---

## Appendix A: The 25-Item AI Literacy Measure (Pages 54-56)

*Note: Order of questions and answers within each question were randomized for participants. [correct] indicates the correct answer.*

1.  **Which of the languages below are used to code a robot?**
    a)  Python [correct]
    b)  HTML
    c)  Computer Vision
    d)  Hypertext

2.  **Which technology is the primary enabler of Artificial Intelligence?**
    a)  Machine Learning [correct]
    b)  Electric Battery
    c)  Robotics
    d)  Engineering

3.  **Which of the following tasks was the first to be performed well by Artificial Intelligence?**
    a)  The complete replacement of a doctor in the treatment of patients
    b)  The implementation of psychotherapies
    c)  The analysis of X-ray images, for example to detect a torn meniscus or a tumor [correct]
    d)  The performance of complex physical work that requires dexterity or precise hand-eye coordination

4.  **Which of these is a notable algorithmic problem?**
    a)  Counting
    b)  Sorting [correct]
    c)  Multiplication
    d)  Division

5.  **What was the purpose of the PCI DSS (payment card industry data security standard)?**
    a)  Regulate financial transactions [correct]
    b)  Manage browser cookies
    c)  Standardize credit score data
    d)  Enable websites to accept crypto currencies

6.  **Which of these is not a best practice when trying to protect your privacy online?**
    a)  Using a two-factor authentication to access account and devices
    b)  Storing your passwords in the notes section of your smartphone [correct]
    c)  Updating your operating system promptly when an update becomes available
    d)  Using different login information

7.  **If using an algorithm, can the results be biased against specific groups of people?**
    a)  No, unlike humans, algorithms are free of emotions and cannot be wrong
    b)  Yes, but only if you train them on privileged populations
    c)  Yes, but only if you use them with incomplete data
    d)  Yes, even with correct data and training, algorithms can provide biased results [correct]

8.  **How algorithmic decisions best explained?**
    a)  Only for very basic and simple algorithms
    b)  They can be explained by sharing the algorithm with everyone
    c)  As complex code, they cannot be explained
    d)  Algorithms can be explained by sharing the contributing factors to decisions [correct]

9.  **When programming stock investment recommendation algorithms, these algorithms are typically programmed to:**
    a)  Ignore smaller companies
    b)  Give more weight to random fluctuations in the market
    c)  Consistently keep track of investments [correct]
    d)  Prefer indices over specific stocks

10. **According to the Health Insurance Portability and Accountability Act of 1996 (HIPAA), protected health information cannot be shared with:**
    a)  The patient's employer [correct]
    b)  The patient
    c)  Law enforcement
    d)  The patient's health insurance

11. **AI can take images and short sound clips of people and create long, convincing impersonation of these people saying anything. What is this technology called?**
    a)  Deepmind
    b)  Deepfake [correct]
    c)  Deeplearn
    d)  Deepvoice

12. **Google automatically completes the text you type in the search bar...**
    a)  By looking at the most common search terms used by others and your search history [correct]
    b)  Based only on your search history
    c)  Based only on what people in your zip code are searching for
    d)  By using your phone camera when you type and reading your lips

13. **Algorithms may improve website performance by doing all of the following except for....**
    a)  Showing us content that might interest us
    b)  Showing us relevant ads
    c)  Monitoring which content we engage in
    d)  Changing our screen brightness [correct]

14. **What information do social media algorithms not typically use when deciding what information to display to a person?**
    a)  Articles people have previously clicked on
    b)  Videos people have previously watched online
    c)  Information people have shared on social media
    d)  What would benefit society [correct]

15. **When you use a web-based service which stores its data in "the cloud", where is the data actually stored?**
    a)  In a hidden folder in your computer
    b)  At the company's headquarters
    c)  At a large server farm [correct]
    d)  In your browser's cookies

16. **If you turn off personalized ads, you are most likely to see ads...**
    a)  Targeting people similar to you
    b)  That are relevant for you
    c)  That are interesting to you
    d)  For commonly purchased products [correct]

17. **Pattern recognition is a decision-making step employed by...**
    a)  Algorithms
    b)  Humans
    c)  Both [correct]
    d)  Neither

18. **When do algorithms tend to perform better than humans?**
    a)  When lots of structured data is involved and the risk from a wrong answer is minimal [correct]
    b)  When there is no structured data available and the risk from a wrong answer is minimal
    c)  When lots of structured data is involved and the risk from a wrong answer is significant
    d)  When there is no structured data available and risk from a wrong answer is significant

19. **What is training data and why is it important?**
    a)  Training data is used when the model is fully calibrated, to train new users with how to work with the model
    b)  Training data is used to calibrate the model during creation, creating a model that performs best according to that data [correct]
    c)  Training data is used to test the model after it was created, to see how it works with new data
    d)  Training data is used to minimize bias in older models and train them to new population types

20. **Indicate if the following is primarily the result of an algorithm or not: What I write in a post on social media**
    a)  Yes
    b)  No [correct]

21. **Indicate if the following is primarily the result of an algorithm or not: What I type in a text message to a friend**
    a)  Yes
    b)  No [correct]

22. **Indicate if the following is primarily the result of an algorithm or not: When I read a direct message on a social media platform**
    a)  Yes
    b)  No [correct]

23. **Indicate if the following is primarily the result of an algorithm or not: Returning the results of a search query on a search engine (e.g., Google)**
    a)  Yes [correct]
    b)  No

24. **Indicate if the following is primarily the result of an algorithm or not: Dual authentication to access one of my accounts**
    a)  Yes [correct]
    b)  No

25. **What is the process of a machine learning model making a prediction based on new data called?**
    a)  Coding
    b)  Training
    c)  Testing
    d)  Inference [correct]

---

## Appendix B: The 17-Item AI Literacy Measure (Pages 57-58)

*Note: Order of questions based on competencies from Long and Magerko (2020); order of answers within each question were randomized for participants. [correct] indicates the correct answer.*

**Recognizing AI:**
1.  **Which of the following is NOT powered by AI?**
    a)  Self-driving cars
    b)  Google's search algorithm
    c)  A basic calculator (correct)
    d)  Chatbots

**Understanding Intelligence:**
2.  **Which form of intelligence involves emotional understanding and social skills?**
    a)  Machine Intelligence
    b)  Human Intelligence (correct)
    c)  Animal Intelligence
    d)  Artificial General Intelligence

**Interdisciplinarity:**
3.  **Which of the following fields contributes to the development of artificial intelligence?**
    a)  Computer science
    b)  Mathematics
    c)  Psychology
    d)  All of the above (correct)

**General vs Narrow AI:**
4.  **What is the term for AI systems that can perform any intellectual task that a human can?**
    a)  Narrow AI
    b)  General AI (correct)
    c)  Weak AI
    d)  Strong AI

**AI's Strengths and Weaknesses:**
5.  **In which area does AI typically excel?**
    a)  Emotional understanding
    b)  Pattern recognition (correct)
    c)  Moral reasoning
    d)  Creativity

**Imagine Future AI:**
6.  **Which of the following is NOT a likely future application of AI?**
    a)  Personalized healthcare
    b)  Emotional robots
    c)  Time travel (correct)
    d)  Sustainable energy management

**Representations:**
7.  **What is a common form of knowledge representation in AI?**
    a)  Neural networks (correct)
    b)  Waterfall model
    c)  Agile methodology
    d)  SWOT analysis

**Decision-Making:**
8.  **Which algorithmic approach is commonly used for decision-making in AI?**
    a)  Dijkstra's algorithm
    b)  Depth-first search
    c)  Decision trees (correct)
    d)  Fourier Transform

**Machine Learning Steps:**
9.  **What is the first step in a typical machine learning process?**
    a)  Data collection (correct)
    b)  Model selection
    c)  Prediction
    d)  Model evaluation

**Human Role in AI:**
10. **Who is primarily responsible for the ethical considerations of an AI system?**
    a)  The AI system itself
    b)  Data providers
    c)  Human developers (correct)
    d)  End-users

**Data Literacy:**
11. **Which of the following is an example of metadata?**
    a)  A spreadsheet of numbers
    b)  Column headers in a table (correct)
    c)  A chart visualization
    d)  Raw sensor data

**Learning from Data:**
12. **How do supervised machine learning algorithms learn?**
    a)  From labeled data (correct)
    b)  From rewards and punishments
    c)  By observing human behavior
    d)  From intrinsic motivation

**Critically Interpreting Data:**
13. **Why can data not be taken at face value?**
    a)  It is always inaccurate
    b)  It requires interpretation (correct)
    c)  It is self-explanatory
    d)  It is always biased

**Action & Reaction:**
14. **How can an AI system interact with the physical world?**
    a)  By planning movements
    b)  By reacting to sensor inputs
    c)  By actuating motors
    d)  All of the above (correct)

**Sensors:**
15. **Which of the following sensors allow an AI system to perceive the world?**
    a)  Cameras
    b)  Microphones
    c)  Thermometers
    d)  All of the above (correct)

**Ethics:**
16. **Which is a key ethical issue surrounding AI?**
    a)  Algorithmic efficiency
    b)  CPU usage
    c)  Privacy (correct)
    d)  Code readability

**Programmability:**
17. **Which statement best describes the programmability of AI systems?**
    a)  They cannot be programmed by humans
    b)  They program themselves
    c)  They are programmed using data
    d)  They are programmed by computer code (correct)

# File: Weber23_AI_Survey.md

# Appendix A: Objective measurement scale (Weber et al., 2023)


Weber, P., Pinski, M., & Baum, L. (2023). Toward an Objective Measurement of AI Literacy. https://aisel.aisnet.org/pacis2023/60/


*(n = 16 items; correct answer in italics – order randomized in test)*

## Socio User AI Literacy

1.  **AI was first mentioned in...**
    a.  *...the 1950s.*
    b.  ...the 2000s.
    c.  ...the 1880s.
    d.  ...the 1980s.

2.  **How are human and artificial intelligence related?**
    a.  *They are different, each has its own strengths and weaknesses.*
    b.  Their strengths and weaknesses converge.
    c.  They predict each other.
    d.  They are the same, concerning strengths and weaknesses.

3.  **AI research...**
    a.  *...happens in an interdisciplinary field including multiple technologies.*
    b.  ...is only fiction at this point in time.
    c.  ...revolves predominantly around optimization.
    d.  ...refers to one specific AI technology.

4.  **What is a possible risk for humans of AI technology?**
    a.  *Deep fakes render videos unattributable.*
    b.  Digital assistants take over self-driving cars.
    c.  Image generators break the rules of art.
    d.  Voice generators make people unlearn natural languages.

## Socio Creator/Evaluator AI Literacy

5.  **What is not an objective of current AI regulation?**
    a.  *Enforcing a 'no-bias policy' to ban all potential biases that can arise from AI.*
    b.  Ensuring that AI systems placed on the market are safe and respect existing law on fundamental rights.
    c.  Facilitating the development of a market for lawful, safe and trustworthy AI.
    d.  Ensuring legal certainty to facilitate investment and innovation in AI.

6.  **Which is a major regulation that has been passed specifically for artificial intelligence?**
    a.  *European Commission's Act for Artificial Intelligence*
    b.  European Regulation for Responsible AI
    c.  United Nations' Framework for the Ethical Use of AI
    d.  American Regulation on the Usage of AI

7.  **Which potential consequence can working with an AI have on humans that interact with it?**
    a.  *Shift of tasks performed by humans*
    b.  Shift of evaluation periods
    c.  Debiasing of human literacy
    d.  Debiasing of result interpretation

8.  **Key ethical issues surrounding AI include...**
    a.  *...diversity, bias, and transparency*
    b.  ...ANN, GA, and Simulated Annealing
    c.  ...future predictions and past overfitting
    d.  ...cold start problem, omitted variable trap, and sunk cost fallacy

## Technical User AI Literacy

9.  **What is the central distinction between supervised and unsupervised learning?**
    a.  *Supervised learning uses labeled datasets.*
    b.  Unsupervised learning may happen anytime.
    c.  Supervised learning is performed by supervised personnel.
    d.  Supervised learning supersedes unsupervised learning.

10. **Which of the following statements is true?**
    a.  *ML is a part of AI*
    b.  ML and AI are mutually exclusive
    c.  AI is a part of ML
    d.  AI and ML are the same

11. **What is a typical application of an AI at which it is usually better than non-AI?**
    a.  *Image recognition*
    b.  Creating annual reports
    c.  Undefined processes
    d.  Hardware space analysis

12. **Running the same request with the same data on the same AI...**
    a.  *...could give different results.*
    b.  ...increase the computing speed.
    c.  ...never give different results.
    d.  ...double the computing time.

## Technical Creator/Evaluator AI Literacy

13. **What always distinguishes decision trees from support vector machines?**
    a.  *Decision trees are more interpretable.*
    b.  Decision trees are more implicit.
    c.  Decision trees generate more predictions.
    d.  Decision trees are trained faster.

14. **What is a typical split of testing and training data for development purposes?**
    a.  *80% Training and 20% Testing*
    b.  40% Training, 40% Testing, 20% Test-Training together
    c.  95% Testing and 5% Training
    d.  It does not matter

15. **What is not a strictly necessary part of a single AI system's development process?**
    a.  *Benchmarking*
    b.  Training/Learning
    c.  Data preprocessing
    d.  Model definition

16. **What is not part of an ANN?**
    a.  *User Layer*
    b.  Input Layer
    c.  Output Layer
    d.  Hidden Layer

# File: Zhang_Dafoe_AI_Survey.md

# Appendix B: Topline questionnaire

Zhang, B., & Dafoe, A. (2019). Artificial Intelligence: American Attitudes and Trends. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3312874


*Below, we present the survey text as shown to respondents. The numerical codings are shown in parentheses following each answer choice.*

*In addition, we report the topline results: percentages weighted to be representative of the U.S. adult population, the unweighted raw percentages, and the raw frequencies. Note that in all survey experiments, respondents were randomly assigned to each experimental group with equal probability.*

## B.1 Global risks

[All respondents were presented with the following prompt.]

We want to get your opinion about global risks. A “global risk” is an uncertain event or condition that, if it happens, could cause a significant negative impact for at least 10 percent of the world’s population. That is at least 1 in 10 people around the world could experience a significant negative impact.

You will be asked to consider 5 potential global risks.

[Respondents were presented with five items randomly selected from the list below. One item was shown at a time.]

*   **Failure to address climate change:** Continued failure of governments and businesses to pass effective measures to reduce climate change, protect people, and help those impacted by climate change to adapt.
*   **Failure of regional or global governance:** Regional organizations (e.g., the European Union) or global organizations (e.g., the United Nations) are unable to resolve issues of economic, political, or environmental importance.
*   **Conflict between major countries:** Disputes between major countries that lead to economic, military, cyber, or societal conflicts.
*   **Weapons of mass destruction:** Use of nuclear, chemical, biological or radiological weapons, creating international crises and killing large numbers of people.
*   **Large-scale involuntary migration:** Large-scale involuntary movement of people, such as refugees, caused by conflict, disasters, environmental or economic reasons.
*   **Rapid and massive spread of infectious diseases:** The uncontrolled spread of infectious diseases, for instance as a result of resistance to antibiotics, that leads to widespread deaths and economic disruptions.
*   **Water crises:** A large decline in the available quality and quantity of fresh water that harms human health and economic activity.
*   **Food crises:** Large numbers of people are unable to buy or access food.
*   **Harmful consequences of artificial intelligence (AI):** Intended or unintended consequences of artificial intelligence that causes widespread harm to humans, the economy, and the environment.
*   **Harmful consequences of synthetic biology:** Intended or unintended consequences of synthetic biology, such as genetic engineering, that causes widespread harm to humans, the economy, and the environment.
*   **Large-scale cyber attacks:** Large-scale cyber attacks that cause large economic damages, tensions between countries, and widespread loss of trust in the internet.
*   **Large-scale terrorist attacks:** Individuals or non-government groups with political or religious goals that cause large numbers of deaths and major material damage.
*   **Global recession:** Economic decline in several major countries that leads to a decrease in income and high unemployment.
*   **Extreme weather events:** Extreme weather events that cause large numbers of deaths as well as damage to property, infrastructure, and the environment.
*   **Major natural disasters:** Earthquakes, volcanic activity, landslides, tsunamis, or geomagnetic storms that cause large numbers of deaths as well as damage to property, infrastructure, and the environment.

**QUESTION:**

What is the likelihood of [INSERT GLOBAL RISK] happening globally within the next 10 years? Please use the slider to indicate your answer. 0% chance means it will certainly not happen and 100% chance means it will certainly happen.

**ANSWER CHOICES:** [*Note: For analysis, each multiple-choice answer was coded to the mean value across the probabilities in the answer’s range.*]

*   Very unlikely: less than 5% chance (2.5%)
*   Unlikely: 5-20% chance (12.5%)
*   Somewhat unlikely: 20-40% chance (30%)
*   Equally likely as unlikely: 40-60% chance (50%)
*   Somewhat likely: 60-80% chance (70%)
*   Likely: 80-95% chance (87.5%)
*   Very likely: more than 95% chance (97.5%)
*   I don’t know

**QUESTION:**

If [INSERT GLOBAL RISK] were to happen, what would be the size of the negative impact for several countries or industries within the next 10 years?

**ANSWER CHOICES:**

*   Minimal (0)
*   Minor (1)
*   Moderate (2)
*   Severe (3)
*   Catastrophic (4)
*   I don’t know

## B.2 Survey experiment: what the public considers AI, automation, machine learning, and robotics

[Respondents were randomly assigned to one of the four questions. The order of answer choices was randomized, except that “None of the above” was always shown last.]

**QUESTIONS:**

*   In your opinion, which of the following technologies, if any, uses **artificial intelligence (AI)**? Select all the apply.
*   In your opinion, which of the following technologies, if any, uses **automation**? Select all that apply.
*   In your opinion, which of the following technologies, if any, uses **machine learning**? Select all that apply.
*   In your opinion, which of the following technologies, if any, uses **robotics**? Select all that apply.

**ANSWER CHOICES:**

*   Virtual assistants (e.g., Siri, Google Assistant, Amazon Alexa)
*   Smart speakers (e.g., Amazon Echo, Google Home, Apple Homepod)
*   Facebook photo tagging
*   Google Search
*   Recommendations for Netflix movies or Amazon ebooks
*   Google Translate
*   Driverless cars and trucks
*   Social robots that can interact with humans
*   Industrial robots used in manufacturing
*   Drones that do not require a human controller
*   None of the above

## B.3 Knowledge of computer science (CS)/technology

**QUESTION:**

What is your knowledge of computer science/technology? (Select all that apply.)

**ANSWER CHOICES:**

*   I have taken at least one college-level course in computer science.
*   I have a computer science or engineering undergraduate degree.
*   I have a graduate degree in computer science or engineering.
*   I have programming experience.
*   I don’t have any of the educational or work experiences described above.

## B.4 Support for developing AI

[All respondents were presented with the following prompt.]

Next, we would like to ask you questions about your attitudes toward artificial intelligence.

Artificial Intelligence (AI) refers to computer systems that perform tasks or make decisions that usually require human intelligence. AI can perform these tasks or make these decisions without explicit human instructions. Today, AI has been used in the following applications:

[Respondents were shown five items randomly selected from the list below.]

*   Translate over 100 different languages
*   Predict one’s Google searches
*   Identify people from their photos
*   Diagnose diseases like skin cancer and common illnesses
*   Predict who are at risk of various diseases
*   Help run factories and warehouses
*   Block spam email
*   Play computer games
*   Help conduct legal case research
*   Categorize photos and videos
*   Detect plagiarism in essays
*   Spot abusive messages on social media
*   Predict what one is likely to buy online
*   Predict what movies or TV shows one is likely to watch online

**QUESTION:**

How much do you support or oppose the development of AI?

**ANSWER CHOICES:**

*   Strongly support (2)
*   Somewhat support (1)
*   Neither support nor oppose (0)
*   Somewhat oppose (-1)
*   Strongly oppose (-2)
*   I don’t know

## B.5 Survey experiment: AI and/or robots should be carefully managed

**QUESTION:**

Please tell me to what extent you agree or disagree with the following statement.

[Respondents were presented with one statement randomly selected from the list below.]

*   AI and robots are technologies that require careful management.
*   AI is a technology that requires careful management.
*   Robots are technologies that require careful management.

**ANSWER CHOICES:**

*   Totally agree (2)
*   Tend to agree (1)
*   Tend to disagree (-1)
*   Totally disagree (-2)
*   I don’t know

## B.6 Trust of actors to develop AI

**QUESTION:**

How much confidence, if any, do you have in each of the following to develop AI in the best interests of the public?

[Respondents were shown five items randomly selected from the list below. We included explainer text for actors not well known to the public; respondents could view the explainer text by hovering their mouse over the actor’s name. The items and the answer choices were shown in a matrix format.]

*   The U.S. military
*   The U.S. civilian government
*   National Security Agency (NSA)
*   Federal Bureau of Investigation (FBI)
*   Central Intelligence Agency (CIA)
*   North Atlantic Treaty Organization (NATO)
    *   *Explainer text for NATO: NATO is a military alliance that includes 28 countries including most of Europe, as well as the U.S. and Canada.*
*   An international research organization (e.g., CERN)
    *   *Explainer text for CERN: The European Organization for Nuclear Research, known as CERN, is a European research organization that operates the largest particle physics laboratory in the world.*
*   Tech companies
*   Google
*   Facebook
*   Apple
*   Microsoft
*   Amazon
*   A non-profit AI research organization (e.g., OpenAI)
    *   *Explainer text for OpenAI: Open AI is an AI non-profit organization with backing from tech investors that seeks to develop safe AI.*
*   University researchers

**ANSWER CHOICES:**

*   A great deal of confidence (3)
*   A fair amount of confidence (2)
*   Not too much confidence (1)
*   No confidence (0)
*   I don’t know

## B.7 Trust of actors to manage AI

**QUESTION:**

How much confidence, if any, do you have in each of the following to manage the development and use of AI in the best interests of the public?

[Respondents were shown five items randomly selected from the list below. We included explainer text for actors not well known to the public; respondents could view the explainer text by hovering their mouse over the actor’s name. The items and the answer choices were shown in a matrix format.]

*   U.S. federal government
*   U.S. state governments
*   International organizations (e.g., United Nations, European Union)
*   The United Nations (UN)
*   An intergovernmental research organization (e.g., CERN)
    *   *Explainer text for CERN: The European Organization for Nuclear Research, known as CERN, is a European research organization that operates the largest particle physics laboratory in the world.*
*   Tech companies
*   Google
*   Facebook
*   Apple
*   Microsoft
*   Amazon
*   Non-government scientific organizations (e.g., AAAI)
    *   *Explainer text for AAAI: Association for the Advancement of Artificial Intelligence (AAAI) is a non-government scientific organization that promotes research in, and responsible use of AI.*
*   Partnership on AI, an association of tech companies, academics, and civil society groups

**ANSWER CHOICES:**

*   A great deal of confidence (3)
*   A fair amount of confidence (2)
*   Not too much confidence (1)
*   No confidence (0)
*   I don’t know

## B.8 AI governance challenges

We would like you to consider some potential policy issues related to AI. Please consider the following:

[Respondents were shown five randomly-selected items from the list below, one item at a time. For ease of comprehension, we include the shorten labels used in the figures in square brackets.]

*   **[Hiring bias] Fairness and transparency in AI used in hiring:** Increasingly, employers are using AI to make hiring decisions. AI has the potential to make less biased hiring decisions than humans. But algorithms trained on biased data can lead to lead to hiring practices that discriminate against certain groups. Also, AI used in this application may lack transparency, such that human users do not understand what the algorithm is doing, or why it reaches certain decisions in specific cases.
*   **[Criminal justice bias] Fairness and transparency in AI used in criminal justice:** Increasingly, the criminal justice system is using AI to make sentencing and parole decisions. AI has the potential to make less biased hiring decisions than humans. But algorithms trained on biased data could lead to discrimination against certain groups. Also, AI used in this application may lack transparency such that human users do not understand what the algorithm is doing, or why it reaches certain decisions in specific cases.
*   **[Disease diagnosis] Accuracy and transparency in AI used for disease diagnosis:** Increasingly, AI software has been used to diagnose diseases, such as heart disease and cancer. One challenge is to make sure the AI can correctly diagnose those who have the disease and not mistakenly diagnose those who do not have the disease. Another challenge is that AI used in this application may lack transparency such that human users do not understand what the algorithm is doing, or why it reaches certain decisions in specific cases.
*   **[Data privacy] Protect data privacy:** Algorithms used in AI applications are often trained on vast amounts of personal data, including medical records, social media content, and financial transactions. Some worry that data used to train algorithms are not collected, used, and stored in ways that protect personal privacy.
*   **[Autonomous vehicles] Make sure autonomous vehicles are safe:** Companies are developing self-driving cars and trucks that require little or no input from humans. Some worry about the safety of autonomous vehicles for those riding in them as well as for other vehicles, cyclists, and pedestrians.
*   **[Digital manipulation] Prevent AI from being used to spread fake and harmful content online:** AI has been used by governments, private groups, and individuals to harm or manipulate internet users. For instance, automated bots have been used to generate and spread false and/or harmful news stories, audios, and videos.
*   **[Cyber attacks] Prevent AI cyber attacks against governments, companies, organizations, and individuals:** Computer scientists have shown that AI can be used to launch effective cyber attacks. AI could be used to hack into servers to steal sensitive information, shut down critical infrastructures like power grids or hospital networks, or scale up targeted phishing attacks.
*   **[Surveillance] Prevent AI-assisted surveillance from violating privacy and civil liberties:** AI can be used to process and analyze large amounts of text, photo, audio, and video data from social media, mobile communications, and CCTV cameras. Some worry that governments, companies, and employers could use AI to increase their surveillance capabilities.
*   **[U.S.-China arms race] Prevent escalation of a U.S.-China AI arms race:** Leading analysts believe that an AI arms race is beginning, in which the U.S. and China are investing billions of dollars to develop powerful AI systems for surveillance, autonomous weapons, cyber operations, propaganda, and command and control systems. Some worry that a U.S.-China arms race could lead to extreme dangers. To stay ahead, the U.S. and China may race to deploy advanced military AI systems that they do not fully understand or can control. We could see catastrophic accidents, such as a rapid, automated escalation involving cyber and nuclear weapons.
*   **[Value alignment] Make sure AI systems are safe, trustworthy, and aligned with human values:** As AI systems become more advanced, they will increasingly make decisions without human input. One potential fear is that AI systems, while performing jobs they are programmed to do, could unintentionally make decisions that go against the values of its human users, such as physically harming people.
*   **[Autonomous weapons] Ban the use of lethal autonomous weapons (LAWs):** Lethal autonomous weapons (LAWs) are military robots that can attack targets without control by humans. LAWs could reduce the use of human combatants on the battlefield. But some worry that the adoption of LAWs could lead to mass violence. Because they are cheap and easy to produce in bulk, national militaries, terrorists, and other groups could readily deploy LAWs.
*   **[Technological unemployment] Guarantee a good standard of living for those who lose their jobs to automation:** Some forecast that AI will increasingly be able to do jobs done by humans today. AI could potentially do the jobs of blue-collar workers, like truckers and factory workers, as well as the jobs of white-collar workers, like financial analysts or lawyers. Some worry that in the future, robots and computers can do most of the jobs that are done by humans today.
*   **[Critical AI systems failure] Prevent critical AI systems failures:** As AI systems become more advanced, they could be used by the military or in critical infrastructure, like power grids, highways, or hospital networks. Some worry that the failure of AI systems or unintentional accidents in these applications could cause 10 percent or more of all humans to die.

**QUESTION:**

In the next 10 years, how likely do you think it is that this AI governance challenge will impact large numbers of people in the U.S.?

**ANSWER CHOICES:**

*   Very unlikely: less than 5% chance (2.5%)
*   Unlikely: 5-20% chance (12.5%)
*   Somewhat unlikely: 20-40% chance (30%)
*   Equally likely as unlikely: 40-60% chance (50%)
*   Somewhat likely: 60-80% chance (70%)
*   Likely: 80-95% chance (87.5%)
*   Very likely: more than 95% chance (97.5%)
*   I don’t know

**QUESTION:**

In the next 10 years, how likely do you think it is that this AI governance challenge will impact large numbers of people around the world?

**ANSWER CHOICES:**

*   Very unlikely: less than 5% chance (2.5%)
*   Unlikely: 5-20% chance (12.5%)
*   Somewhat unlikely: 20-40% chance (30%)
*   Equally likely as unlikely: 40-60% chance (50%)
*   Somewhat likely: 60-80% chance (70%)
*   Likely: 80-95% chance (87.5%)
*   Very likely: more than 95% chance (97.5%)
*   I don’t know

**QUESTION:**

In the next 10 years, how important is it for tech companies and governments to carefully manage the following challenge?

**ANSWER CHOICES:**

*   Very important (3)
*   Somewhat important (2)
*   Not too important (1)
*   Not at all important (0)
*   I don’t know

## B.9 Survey experiment: comparing perceptions of U.S. vs. China AI research and development

[Respondents were presented with one randomly-selected question from the two below.]

**QUESTIONS:**

*   Compared with other industrialized countries, how would you rate the **U.S.** in AI research and development?
*   Compared with other industrialized countries, how would you rate **China** in AI research and development?

**ANSWER CHOICES:**

*   Best in the world (3)
*   Above average (2)
*   Average (1)
*   Below average (0)
*   I don’t know

## B.10 Survey experiment: U.S.-China arms race

[All respondents were presented with the following prompt.]

We want to understand your thoughts on some important issues in the news today. Please read the short news article below.

Leading analysts believe that an “AI arms race” is beginning, in which the U.S. and China are investing billions of dollars to develop powerful AI systems for surveillance, autonomous weapons, cyber operations, propaganda, and command and control systems.

[Respondents were randomly assigned to one of the four experimental groups listed below.]

### B.10.1 Control

[No additional text.]

### B.10.2 Nationalism treatment

Some leaders in the U.S. military and tech industry argue that the U.S. government should invest much more resources in AI research to ensure that the U.S.’s AI capabilities stay ahead of China’s. Furthermore, they argue that the U.S. government should partner with American tech companies to develop advanced AI systems, particularly for military use.

According to a leaked memo produced by a senior National Security Council official, China has “assembled the basic components required for winning the Al arms race…Much like America’s success in the competition for nuclear weapons, China’s 21st Century Manhattan Project sets them on a path to getting there first.”

### B.10.3 War risks treatment

Some prominent thinkers are concerned that a U.S.-China arms race could lead to extreme dangers. To stay ahead, the U.S. and China may race to deploy advanced military AI systems that they do not fully understand or can control. We could see catastrophic accidents, such as a rapid, automated escalation involving cyber and nuclear weapons.

“Competition for AI superiority at [the] national level [is the] most likely cause of World War Three,” warned Elon Musk, the CEO of Tesla and SpaceX.

### B.10.4 Common humanity treatment

Some prominent thinkers are concerned that a U.S.-China arms race could lead to extreme dangers. To stay ahead, the U.S. and China may race to deploy advanced military AI systems that they do not fully understand or can control. We could see catastrophic accidents, such as a rapid, automated escalation involving cyber and nuclear weapons.

“Unless we learn how to prepare for, and avoid, the potential risks, AI could be the worst event in the history of our civilization. It brings dangers, like powerful autonomous weapons,” warned the late Stephen Hawking, one of the world’s most prominent physicists. At the same time, he said that with proper management of the technology, researchers “can create AI for the good of the world.”

[The order of the next two questions is randomized.]

**QUESTION:**

How much do you agree or disagree with the following statement?

The U.S. should invest more in AI military capabilities to make sure it doesn’t fall behind China’s, even if doing so may exacerbate the arms race. For instance, the U.S. could increase AI research funding for the military and universities. It could also collaborate with American tech companies to develop AI for military use.

**ANSWER CHOICES:**

*   Strongly agree (2)
*   Somewhat agree (1)
*   Neither agree nor disagree (0)
*   Somewhat disagree (-1)
*   Strongly disagree (-2)
*   I don’t know

**QUESTION:**

How much do you agree or disagree with the following statement?

The U.S. should work hard to cooperate with China to avoid the dangers of an AI arms race, even if doing so requires giving up some of the U.S.’s advantages. Cooperation could include collaborations between American and Chinese AI research labs, or the U.S. and China creating and committing to common safety standards.

**ANSWER CHOICES:**

*   Strongly agree (2)
*   Somewhat agree (1)
*   Neither agree nor disagree (0)
*   Somewhat disagree (-1)
*   Strongly disagree (-2)
*   I don’t know

## B.11 Issue areas for possible U.S.-China cooperation

**QUESTION:**

For the following issues, how likely is it that the U.S. and China can cooperate?

[Respondents were presented with three issues from the list below. All three issues were presented on the same page; the order that they appeared was randomized.]

*   Prevent AI cyber attacks against governments, companies, organizations, and individuals.
*   Prevent AI-assisted surveillance from violating privacy and civil liberties.
*   Make sure AI systems are safe, trustworthy, and aligned with human values.
*   Ban the use of lethal autonomous weapons.
*   Guarantee a good standard of living for those who lose their jobs to automation.

**ANSWER CHOICES:**

*   Very unlikely: less than 5% chance (2.5%)
*   Unlikely: 5-20% chance (12.5%)
*   Somewhat unlikely: 20-40% chance (30%)
*   Equally likely as unlikely: 40-60% chance (50%)
*   Somewhat likely: 60-80% chance (70%)
*   Likely: 80-95% chance (87.5%)
*   Very likely: more than 95% chance (97.5%)
*   I don’t know

## B.12 Trend across time: job creation or job loss

**QUESTION:**

How much do you agree or disagree with the following statement?

[Respondents were presented with one statement randomly selected from the list below.]

*   In general, automation and AI will create more jobs than they will eliminate.
*   In general, automation and AI will create more jobs than they will eliminate in **10 years**.
*   In general, automation and AI will create more jobs than they will eliminate in **20 years**.
*   In general, automation and AI will create more jobs than they will eliminate in **50 years**.

**ANSWER CHOICES:**

*   Strongly agree (2)
*   Agree (1)
*   Disagree (-1)
*   Strongly disagree (-2)
*   I don’t know

## B.13 High-level machine intelligence: forecasting timeline

**QUESTION:**

The following questions ask about high-level machine intelligence. We have high-level machine intelligence when machines are able to perform almost all tasks that are economically relevant today better than the median human (today) at each task. These tasks include asking subtle common-sense questions such as those that travel agents would ask. For the following questions, you should ignore tasks that are legally or culturally restricted to humans, such as serving on a jury.

In your opinion, how likely is it that high-level machine intelligence will exist in 10 years? 20 years? 50 years? For each prediction, please use the slider to indicate the percent chance that you think high-level machine intelligence will exist. 0% chance means it will certainly not exist. 100% chance means it will certainly exist.

______ In 10 years?
______ In 20 years?
______ In 50 years?

**ANSWER CHOICES:** [Used for slider input]

*   Very unlikely: less than 5% chance (2.5%)
*   Unlikely: 5-20% chance (12.5%)
*   Somewhat unlikely: 20-40% chance (30%)
*   Equally likely as unlikely: 40-60% chance (50%)
*   Somewhat likely: 60-80% chance (70%)
*   Likely: 80-95% chance (87.5%)
*   Very likely: more than 95% chance (97.5%)
*   I don’t know

## B.14 Support for developing high-level machine intelligence

**QUESTION:**

How much do you support or oppose the development of high-level machine intelligence?

**ANSWER CHOICES:**

*   Strongly support
*   Somewhat support
*   Neither support nor oppose
*   Somewhat oppose
*   Strongly oppose
*   I don’t know

## B.15 Expected outcome of high-level machine intelligence

**QUESTION:**

Suppose that high-level machine intelligence could be developed one day. How positive or negative do you expect the overall impact of high-level machine intelligence to be on humanity in the long run?

**ANSWER CHOICES:**

*   Extremely good
*   On balance good
*   More or less neutral
*   On balance bad
*   Extremely bad, possibly human extinction
*   I don’t know


----



# File: Zhu2024_AI_Survey.md

# Survey and Scenario Questions from Zhu et al. (2024)

Zhu, Q., Chong, L., Yang, M., & Luo, J. (2024). Reading Users’ Minds from What They Say: An Investigation into LLM-based Empathic Mental Inference. ASME. J. Mech. Des. August 2024; 146(6): 061401. https://doi.org/10.1115/DETC2024-143961 

---

## Appendix A. Example tasks for user participants

First, please recall a product that you recently purchased related to **house cleaning**. If you have not made a purchase recently, think of a product you are interested in purchasing.

What is the product?

[_________________________________________________________]

Now, imagine you are writing a product review on an online store or drafting a post for social media to seek advice on which product to purchase. Comment on your **experience or concerns regarding the product in detail**.

[_________________________________________________________]
[_________________________________________________________]
[_________________________________________________________]
[_________________________________________________________]
[_________________________________________________________]

Is your comment about your pre-purchase or post-purchase experience/concern?

( ) Pre-purchase
( ) Post-purchase

---

Before proceeding to Part 2, please spend about **2~3 minutes** going through the printed material provided to you and familiarize yourself with different types of fundamental psychological needs.

Now, you will be asked to:
1) interpret your own product experience goals
2) attribute your goals to each type of fundamental psychological needs.

You can always refer to the provided material if needed.

---

### Task 1: Goals Interpretation

Based on the product comment you reported earlier, what are your **underlying goals in using the product**? Please come up with at least **two goals for each question**, and you are encouraged to generate as many goals as possible.

You can follow the format of the example attached below each question. But note that you do not have to follow the examples.

Based on your product comment, what are the specific **tasks or actions** that you aim to achieve or complete?
> *Example format: I aim to make a telephone call; I aim to drive my car for the daily commute.*

[_________________________________________________________]
[_________________________________________________________]
[_________________________________________________________]

Based on your product comment, what are the **concrete sub-actions or steps** you need to take to achieve the tasks/actions you listed above?
> *Example format: By pressing the right buttons, I should be able to dial the number I intend to call; By turning the ignition, adjusting mirrors, and following my routine route, I can engage in the process of driving.*

[_________________________________________________________]
[_________________________________________________________]
[_________________________________________________________]

Based on your product comment, what are your **overarching goals** that are related to your broader life aspirations, self-perception, and/or desires about your own identity?
> *Example format: I aspire to be close to others; I aspire to feel secure and have a controllable space.*

[_________________________________________________________]
[_________________________________________________________]
[_________________________________________________________]

---

### Task 2: Fundamental Psychological Needs

Now, please attribute your goals to each type of fundamental psychological need (FPN). For each FPN, indicate the **overall extent** to which your goal(s) are attributed to that FPN.

| Need        | Not attributed at all | Slightly attributed | Somewhat attributed | Attributed | Highly attributed |
| :---------- | :-------------------: | :-----------------: | :-----------------: | :--------: | :---------------: |
| Autonomy    | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Beauty      | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Comfort     | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Community   | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Competence  | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Fitness     | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Impact      | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Morality    | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Purpose     | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Recognition | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Relatedness | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Security    | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Stimulation | ( )                   | ( )                 | ( )                 | ( )        | ( )               |

---
---

## Appendix B. Example tasks for designer participants

Please spend **2~3 minutes** going through the printed material provided to you and familiarize yourself with different types of fundamental psychological needs. This material is for the completion of **Task 2: Fundamental Psychological Needs attribution**.

---

*[The tasks below were repeated for each of the 6 comments provided to each designer.]*

### Task 1: Goals Interpretation

Based on the product comment you just read, take the **user's perspective** and infer his/her **underlying goals** in using the product? Please come up with at least **two goals** for each question, and you are encouraged to infer as many goals as possible.

*Below each question are two simple examples of inferred goals for a telephone and a car, though you are not required to follow the same format.*

Taking the user's perspective, what are the **specific tasks or actions** that you aim to achieve or complete?
> *Examples: I aim to make a telephone call; I aim to drive my car for the daily commute.*

[_________________________________________________________]
[_________________________________________________________]
[_________________________________________________________]

Taking the user's perspective, what are the **concrete sub-actions or steps** you need to take to achieve the tasks/actions you listed above?
> *Examples: By pressing the right buttons, I should be able to dial the number I intend to call; By turning the ignition, adjusting mirrors, and following my routine route, I can engage in the process of driving.*

[_________________________________________________________]
[_________________________________________________________]
[_________________________________________________________]

Taking the user's perspective, what are your **overarching goals** that are related to your broader life aspirations, self-perception, and/or desires about your own identity?
> *Examples: I aspire to be close to others; I aspire to feel secure and have a controllable space.*

[_________________________________________________________]
[_________________________________________________________]
[_________________________________________________________]

---

### Task 2: Fundamental Psychological Needs

Now, please attribute the **goals you inferred** to each type of fundamental psychological need (FPN). For each FPN, indicate the **overall extent** to which your goal(s) are attributed to that FPN.

*[The same Likert-Scale as in Appendix A]*

| Need        | Not attributed at all | Slightly attributed | Somewhat attributed | Attributed | Highly attributed |
| :---------- | :-------------------: | :-----------------: | :-----------------: | :--------: | :---------------: |
| Autonomy    | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Beauty      | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Comfort     | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Community   | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Competence  | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Fitness     | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Impact      | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Morality    | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Purpose     | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Recognition | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Relatedness | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Security    | ( )                   | ( )                 | ( )                 | ( )        | ( )               |
| Stimulation | ( )                   | ( )                 | ( )                 | ( )        | ( )               |



--------


# Trust of Automated Systems Test (TOAST)

Wojton, H. M., Porter, D., T Lane, S., Bieber, C., & Madhavan, P. (2020). Initial validation of the trust of automated systems test (TOAST). *The Journal of Social Psychology, 160*(6), 735–750. https://doi.org/10.1080/00224545.2020.1749020

---

**Directions:** Read each statement carefully and indicate the extent to which you agree or disagree using the scale provided.

**Scale:**

1 = Strongly Disagree
2
3
4
5
6
7 = Strongly Agree

---

**Items:**

1.  I understand what the system should do.
    (1)   (2)   (3)   (4)   (5)   (6)   (7)
2.  The system helps me achieve my goals.
    (1)   (2)   (3)   (4)   (5)   (6)   (7)
3.  I understand the limitations of the system.
    (1)   (2)   (3)   (4)   (5)   (6)   (7)
4.  I understand the capabilities of the system.
    (1)   (2)   (3)   (4)   (5)   (6)   (7)
5.  The system performs consistently.
    (1)   (2)   (3)   (4)   (5)   (6)   (7)
6.  The system performs the way it should.
    (1)   (2)   (3)   (4)   (5)   (6)   (7)
7.  I feel comfortable relying on the information provided by the system.
    (1)   (2)   (3)   (4)   (5)   (6)   (7)
8.  I understand how the system executes tasks.
    (1)   (2)   (3)   (4)   (5)   (6)   (7)
9.  I am rarely surprised by how the system responds.
    (1)   (2)   (3)   (4)   (5)   (6)   (7)

---

## Scoring:

*   Average items 1, 3, 4, and 8 to get the **‘Understanding’** score.
*   Average items 2, 5, 6, 7, & 9 to get the **‘Performance’** score.
*   *Note:* Items are **not** validated to be examined individually or by looking at the average of all items.

---

*Self-Correction Note: The paper also mentions an initial 14-item version (Table 1) before validation led to the removal of reverse-scored and some process items. The version above reflects the final 9-item scale (Table 2 and Figure 1) recommended by the authors.*
*The study also used single-item measures for overall trust ("I trust the system.") and reliance intentions ("I would recommend others who are placed in this situation use [System Name]..." and "If placed in a similar situation in real life, I would rely on the [System Name]..."). These were not part of the TOAST scale itself.*


----



# Global ChatGPT Student Survey

Ravšelj, D., Keržič, D., Tomaževič, N., Umek, L., Brezovar, N., A. Iahad, N., Abdulla, A. A., Akopyan, A., Aldana Segura, M. W., AlHumaid, J., Allam, M. F., Alló, M., Andoh, R. P. K., Andronic, O., Arthur, Y. D., Aydın, F., Badran, A., Balbontín-Alvarado, R., Ben Saad, H., … Aristovnik, A. (2025). Higher education students’ perceptions of ChatGPT: A global study of early reactions. PLOS ONE, 20(2), e0315011. https://doi.org/10.1371/journal.pone.0315011



## Students' Perception of ChatGPT

Dear Student,

The Faculty of Public Administration, University of Ljubljana (from Slovenia, Europe), together with over 200 international academic partners, is conducting a global student survey entitled **Students' Perception of ChatGPT**.

The recent exponential growth in the use of artificial intelligence (AI) tools has led us to recognize the importance of understanding how ChatGPT shapes higher education students' experiences and learning outcomes by specifically analysing how students with diverse cultural backgrounds view ChatGPT.

Students attending higher education institutions around the world are kindly invited to complete the questionnaire to help us understand your perception and use of ChatGPT. Participation in the study is completely voluntary. It should take about 15 minutes to complete the questionnaire, divided into **11 sections**. All answers are treated as **anonymous**. The data collected will only be used for research purposes and only be disseminated in aggregate form.


---

## SECTION 2: USAGE

**Q13 - Have you ever used ChatGPT?**

*   Yes
*   No

[1 = the questionnaire will continue; 2 = only section 10: Study and personal information will be offered]

**Q14 - Which version of ChatGPT do you use?**

*   ChatGPT-3.5 (free version)
*   ChatGPT-4 (with a subscription)
*   Both

**Q15 - To what extent do you use ChatGPT in general?**

*   Rarely
*   Occasionally
*   Moderately
*   Considerably
*   Extensively

**Q16 - What is your experience with ChatGPT?**

*   Very bad
*   Bad
*   Neutral
*   Good
*   Very good

**Q17 - Where did you first learn about ChatGPT?**

*   From mainstream media news (TV, internet, newspaper, radio...)
*   On social media
*   In class and/or at work
*   From friends and/or family

**Q18 - How often do you use ChatGPT for the following tasks?**

| Task Description                                            | Never | Rarely | Sometimes | Often | Always |
| :---------------------------------------------------------- | :---: | :----: | :-------: | :---: | :----: |
| Q18a Academic writing (writing assignments, research papers...) | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q18b Professional writing (writing e-mails)                 | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q18c Creative writing (generating stories, poems...)        | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q18d Proofreading (receiving feedback on writing)           | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q18e Brainstorming (generating new ideas)                   | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q18f Translating (converting text from one language to another) | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q18g Summarizing (generating concise summaries of lengthy texts) | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q18h Calculating help (solving mathematical problems)       | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q18i Study assistance (practising for exams)                | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q18j Personal assistance (seeking advice on various personal topics) | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q18k Research assistance (finding information for research papers) | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q18l Coding assistance (getting assistance with programming) | ( )   | ( )    | ( )       | ( )   | ( )    |

---

---

## SECTION 3: CAPABILITIES

**Q19 - How much do you agree with the following statements related to the capabilities of ChatGPT?**

| ChatGPT can...                                                     | Strongly disagree | Disagree | Neutral | Agree | Strongly agree |
| :----------------------------------------------------------------- | :---------------: | :------: | :-----: | :---: | :------------: |
| Q19a understand indications given in human language.               | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q19b respond in human language.                                    | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q19c hold a pleasant conversation.                                 | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q19d provide information efficiently.                              | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q19e provide reliable information.                                 | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q19f summarize extensive information.                              | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q19g simplify complex information.                                 | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q19h facilitate traditional learning (in a classroom).               | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q19i facilitate online learning (using digital technologies).        | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q19j facilitate blended (hybrid) learning (a mix of traditional and online learning). | ( )               | ( )      | ( )     | ( )   | ( )            |

## SECTION 4: REGULATION AND ETHICAL CONCERNS

**Q20 - Does your institution (university/faculty) have policies or a code of ethics regarding the use of ChatGPT for students?**

*   Yes
*   No
*   I don't know

**Q21 - How much do you agree with the following statements related to the regulations in the usage of ChatGPT?**

| Statement                                                       | Strongly disagree | Disagree | Neutral | Agree | Strongly agree |
| :-------------------------------------------------------------- | :---------------: | :------: | :-----: | :---: | :------------: |
| Q21a International regulation is necessary for ChatGPT.           | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q21b Government regulation is necessary for ChatGPT.              | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q21c ChatGPT should be subject to university/faculty ethical guidelines. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q21d ChatGPT should be subject to employer ethical guidelines.    | ( )               | ( )      | ( )     | ( )   | ( )            |

**Q22 - How much do you agree with ethical and other concerns related to ChatGPT in the following situations?**

| ChatGPT might...                               | Strongly disagree | Disagree | Neutral | Agree | Strongly agree |
| :--------------------------------------------- | :---------------: | :------: | :-----: | :---: | :------------: |
| Q22a encourage unethical behaviour.            | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q22b encourage students to cheat.              | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q22c encourage students to plagiarize.         | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q22d threaten the ethics of the study.         | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q22e mislead with inaccurate information.      | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q22f invade privacy.                           | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q22g reduce human interaction.                 | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q22h replace formal education.                 | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q22i increase social isolation.                | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q22j hinder learning by doing the work for students. | ( )               | ( )      | ( )     | ( )   | ( )            |

---

---

**Q23 - How much do you agree with the following statements related to the ethical considerations on the use of ChatGPT?**

| Students should...                                                   | Strongly disagree | Disagree | Neutral | Agree | Strongly agree |
| :------------------------------------------------------------------- | :---------------: | :------: | :-----: | :---: | :------------: |
| Q23a consult with the professors about using ChatGPT.                | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q23b disclose their use of ChatGPT to their professors.              | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q23c report any unethical use of ChatGPT by colleagues to their professors. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q23d take appropriate measures to protect their own personal information. | ( )               | ( )      | ( )     | ( )   | ( )            |

## SECTION 5: SATISFACTION AND ATTITUDE

**Q24 - How much do you agree with the following statements related to your satisfaction with ChatGPT?**

| Statement                                                              | Strongly disagree | Disagree | Neutral | Agree | Strongly agree |
| :--------------------------------------------------------------------- | :---------------: | :------: | :-----: | :---: | :------------: |
| Q24a I find ChatGPT more useful than Google or other web search engines. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q24b It is easier for me to interact with ChatGPT than with my professors. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q24c It is easier for me to interact with ChatGPT than with my colleagues. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q24d The information I get from ChatGPT is clearer than the one provided by my professors. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q24e I am satisfied with the level of assistance provided by ChatGPT.  | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q24f I am satisfied with the quality of information provided by ChatGPT. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q24g I am satisfied with the accuracy of the information provided by ChatGPT. | ( )               | ( )      | ( )     | ( )   | ( )            |

**Q25 - How much do you agree with each of the following items while thinking about ChatGPT?**

| Statement                                                          | Strongly disagree | Disagree | Neutral | Agree | Strongly agree |
| :----------------------------------------------------------------- | :---------------: | :------: | :-----: | :---: | :------------: |
| Q25a I have the impression that using ChatGPT is under my control. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q25b Using ChatGPT is interesting to me.                           | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q25c Being able to use ChatGPT is important to me.                 | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q25d ChatGPT can help with things in everyday life.                | ( )               | ( )      | ( )     | ( )   | ( )            |

## SECTION 6: STUDY ISSUES AND OUTCOMES

**Q26 - How much do you agree with the following statements related to learning and academic enhancement addressed with ChatGPT?**

| ChatGPT can...                                           | Strongly disagree | Disagree | Neutral | Agree | Strongly agree |
| :------------------------------------------------------- | :---------------: | :------: | :-----: | :---: | :------------: |
| Q26a enhance my access to the sources of knowledge.      | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q26b improve my general knowledge.                       | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q26c improve my specific knowledge.                      | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q26d provide me with personalized education.             | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q26e increase my study efficiency.                       | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q26f increase my motivation to study.                    | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q26g facilitate completing my studies.                   | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q26h improve my engagement in class discussions.         | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q26i enhance my ability to meet assignment deadlines.    | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q26j improve the quality of my assignments.              | ( )               | ( )      | ( )     | ( )   | ( )            |


---

**Q27 - How much do you agree with the following statements related to personal and professional development addressed with ChatGPT?**

| ChatGPT can...                                                | Strongly disagree | Disagree | Neutral | Agree | Strongly agree |
| :------------------------------------------------------------ | :---------------: | :------: | :-----: | :---: | :------------: |
| Q27a improve my readiness for exams.                          | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q27b improve my grades.                                       | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q27c facilitate completing my activities outside of the classroom. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q27d facilitate completing my internships.                    | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q27e enhance my learning experience.                          | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q27f improve my skills.                                       | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q27g facilitate my personal development.                      | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q27h facilitate my academic development.                      | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q27i increase my satisfaction with the study.                 | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q27j improve my employability.                                | ( )               | ( )      | ( )     | ( )   | ( )            |

## SECTION 7: SKILLS DEVELOPMENT

**Q28 - How much do you agree with the following statements related to the ability of ChatGPT to facilitate proficiency and communication skills development?**

| ChatGPT can improve my...                | Strongly disagree | Disagree | Neutral | Agree | Strongly agree |
| :--------------------------------------- | :---------------: | :------: | :-----: | :---: | :------------: |
| Q28a academic writing proficiency.       | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q28b professional writing proficiency.   | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q28c typing proficiency.                 | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q28d native language proficiency.        | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q28e foreign language proficiency.       | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q28f interpersonal communication skills. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q28g digital communication skills.       | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q28h information literacy skills.        | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q28i digital content creation skills.    | ( )               | ( )      | ( )     | ( )   | ( )            |

**Q29 - How much do you agree with the following statements related to the ability of ChatGPT to facilitate analytical and problem-solving skills development?**

| ChatGPT can improve my...                   | Strongly disagree | Disagree | Neutral | Agree | Strongly agree |
| :------------------------------------------ | :---------------: | :------: | :-----: | :---: | :------------: |
| Q29a numeracy proficiency.                  | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q29b decision-making skills.                | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q29c problem-solving skills.                | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q29d analytical skills.                     | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q29e critical thinking skills.              | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q29f creativity skills.                     | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q29g data analysis skills.                  | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q29h programming skills.                    | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q29i artificial intelligence literacy skills. | ( )               | ( )      | ( )     | ( )   | ( )            |

---

---

## SECTION 8: LABOUR MARKET AND SKILLS MISMATCH

**Q30 - How much do you agree with the following statements related to the general challenges in the labour market with ChatGPT?**

| ChatGPT will...                                                             | Strongly disagree | Disagree | Neutral | Agree | Strongly agree |
| :-------------------------------------------------------------------------- | :---------------: | :------: | :-----: | :---: | :------------: |
| Q30a reduce the number of jobs.                                             | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q30b require employees to acquire new skills.                               | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q30c enhance the connection between higher education and the labour market. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q30d require employees to possess knowledge about artificial intelligence.    | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q30e increase the demand for employees with skills related to artificial intelligence. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q30f increase inequality between younger and older employees.               | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q30g create new jobs.                                                       | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q30h change the nature of jobs.                                             | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q30i facilitate remote work.                                                | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q30j reduce employee workload.                                              | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q30k improve employee productivity.                                         | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q30l improve employee innovation.                                           | ( )               | ( )      | ( )     | ( )   | ( )            |

**Q31 How much do you agree with the following statements related to the ability of ChatGPT to address skills mismatch?**

| ChatGPT can...                                                                                                                              | Strongly disagree | Disagree | Neutral | Agree | Strongly agree |
| :------------------------------------------------------------------------------------------------------------------------------------------ | :---------------: | :------: | :-----: | :---: | :------------: |
| Q31a reduce skills shortages (when employers cannot find enough students/workers with the right qualifications and skills).                 | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q31b reduce under-skilling (when students/workers have skills below those required for the job).                                            | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q31c resolve skills obsolescence (when students/workers lose their skills over time due to lack of use or when skills become irrelevant due to changes in the world of work). | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q31d resolve skills gaps (when students/workers lack the skills necessary to do their jobs effectively).                                    | ( )               | ( )      | ( )     | ( )   | ( )            |

## SECTION 9: EMOTIONS

**Q32 - How often do you feel the following emotions while using ChatGPT?**

| Emotion      | Never | Rarely | Sometimes | Often | Always |
| :----------- | :---: | :----: | :-------: | :---: | :----: |
| Q32a Bored   | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q32b Hopeful | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q32c Sad     | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q32d Ashamed | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q32e Calm    | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q32f Angry   | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q32g Relieved| ( )   | ( )    | ( )       | ( )   | ( )    |
| Q32h Happy   | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q32i Proud   | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q32j Anxious | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q32k Surprised| ( )   | ( )    | ( )       | ( )   | ( )    |
| Q32l Curious | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q32m Excited | ( )   | ( )    | ( )       | ( )   | ( )    |
| Q32n Confused| ( )   | ( )    | ( )       | ( )   | ( )    |
| Q32o Frustrated| ( )   | ( )    | ( )       | ( )   | ( )    |

---
© CovidSocLab: [https://www.covidsoclab.org/chatgpt-student-survey/](https://www.covidsoclab.org/chatgpt-student-survey/)
---

## SECTION 10: STUDY AND PERSONAL INFORMATION

**Q33 - How would you rate the level of difficulty of your studies?**

*   Much too easy
*   Somewhat easy
*   Just about right
*   Somewhat challenging
*   Extremely challenging

**Q34 - Which learning method do you believe is the most suitable for your studies?**

*   Traditional learning (in a classroom)
*   Online learning (using digital technologies)
*   Blended (hybrid) learning (a mix of traditional and online learning)

**Q35 - How much do you agree with the following statements related to the study and other information?**

| Statement                                                                               | Strongly disagree | Disagree | Neutral | Agree | Strongly agree |
| :-------------------------------------------------------------------------------------- | :---------------: | :------: | :-----: | :---: | :------------: |
| Q35a I am successful in my studies.                                                     | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q35b I regularly attend my classes.                                                     | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q35c I consistently meet assignment deadlines.                                          | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q35d My grades accurately reflect my understanding of the study subjects.               | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q35e I am motivated to study.                                                           | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q35f The amount of financial aid (scholarships, student loans...) is sufficient for my study needs. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q35g The taxes paid on labour by students and/or young workers in my country is too high. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q35h I have a strong network of social connections that can help me with employment.    | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q35i I have a strong set of skills that can help me with employment.                    | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q35j I have sufficient work experience that can help me with employment.                | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q35k I have sufficient general knowledge that can help me with employment.              | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q35l I have sufficient specific knowledge that can help me with employment.             | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q35m My faculty provides me with a sufficient set of skills that enhance my employability. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q35n I would like to be employed in a field I am studying for.                          | ( )               | ( )      | ( )     | ( )   | ( )            |

**Q36 - Which of the characteristics below describes the area you live in?**

*   Urban
*   Suburban
*   Rural

**Q37 - Are you receiving financial aid for your studies (scholarships, student loans...)?**

*   Yes
*   No

**Q38 - Do you have a job?**

*   Yes, a full-time job
*   Yes, a part-time job (including student work)
*   No

---

---

**Q39 - What is your economic status?**

*   Significantly below-average
*   Below-average
*   Average
*   Above-average
*   Significantly above-average

**Q40 - Think about your life in general. Here are several characteristics that may apply to you (or not). How much do you agree or disagree with the following statements?**

| I am someone who...                           | Strongly disagree | Disagree | Neutral | Agree | Strongly agree |
| :-------------------------------------------- | :---------------: | :------: | :-----: | :---: | :------------: |
| Q40a is outgoing, sociable.                   | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q40b is helpful and unselfish with others.    | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q40c keeps things neat and tidy.              | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q40d is relaxed, handles stress well.         | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q40e is curious about many different things.  | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q40f has a determined personality.            | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q40g is respectful, treats others with respect. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q40h is persistent, works until the task is finished. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q40i feels secure, comfortable with self.     | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q40j values art and beauty.                   | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q40k is full of energy.                       | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q40l assumes the best about people.           | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q40m is dependable, steady.                   | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q40n is emotionally stable, not easily upset. | ( )               | ( )      | ( )     | ( )   | ( )            |
| Q40o is original, comes up with new ideas.    | ( )               | ( )      | ( )     | ( )   | ( )            |

## SECTION 11: GENERAL REFLECTIONS

**Q41 - Can you share some general views/words about how you see ChatGPT?**

*   [Text input area]


---


# Surveys and Questionnaires from Jin et al. (2024)

Jin, Y., Martinez-Maldonado, R., Gašević, D., & Yan, L. (2024). *GLAT: The Generative AI Literacy Assessment Test* (No. arXiv:2411.00283). arXiv. https://doi.org/10.48550/arXiv.2411.00283

---

## GLAT: The Generative AI Literacy Assessment Test (Initial 25-Item Version)

*This is the initial 25-item version presented in Table 2 of the paper, used for content validity assessment and item selection via Classical Test Theory. Items subsequently dropped for the final 20-item version (used in IRT and external validity analysis) are marked.*
*Correct answers are indicated in **bold**.*

1.  **Question:** Which of the following best describes "Generative AI"?
    a.  **AI that creates new content like text, images, or music by learning from existing data.**
    b.  An AI system designed to enhance the speed and accuracy of data retrieval in search engines.
    c.  A form of artificial intelligence that focuses on translating languages in real-time.
    d.  AI technology used primarily for managing and organizing large databases.

2.  **Question:** Which of the following statements best describes an LLM (Large Language Model)?
    a.  It generates text by analyzing and summarizing large volumes of web content.
    b.  **It generates text by predicting the next word based on the context of previous words.**
    c.  It generates text by translating input text into multiple languages simultaneously.
    d.  It generates text by using pre-defined templates and filling in the blanks.

3.  **Question:** Which of the following tasks can Generative AI perform with a high degree of accuracy?
    a.  Predicting stock market trends
    b.  Making ethical decisions in complex scenarios
    c.  Diagnosing rare diseases
    d.  **Generating human-like text based on prompts**

4.  **Question:** In the context of Generative AI, what is "zero-shot learning"?
    a.  Training a model without any data.
    b.  **The ability of a model to perform a task without any task-specific training.**
    c.  A method of reducing the model's training time to zero.
    d.  A technique for generating synthetic training data.

5.  **Question:** Which of the following is a potential challenge when using prompt-based development for text generation?
    a.  The language model can only generate binary outputs.
    b.  The need for extensive labeled data to train the model.
    c.  **Crafting a prompt that accurately captures the desired context and nuances.**
    d.  The requirement for complex feature engineering.

6.  **Question:** [DROPPED ITEM] When using a generative AI model to classify text into multiple categories, what is a common approach to handle more than two output classes?
    a.  Use multiple binary classifiers for each category.
    b.  **Use a single prompt that includes all possible categories.**
    c.  Train a separate model for each category.
    d.  Use unsupervised learning to cluster the text data.

7.  **Question:** What does the term "token" refer to in the context of a large language model (LLM)?
    a.  **A token is a unit of text, such as a word or a subword, that the model processes individually.**
    b.  A token is a unique identifier assigned to each user interacting with the language model.
    c.  A token is a security measure used to authenticate API requests to the language model.
    d.  A token is a reward given to users for contributing valuable data to train the language model.

8.  **Question:** Which of the following is NOT a requirement for an AI to be considered artificial general intelligence (AGI)?
    a.  The ability to learn and adapt to new tasks without human intervention.
    b.  The capability to perform tasks across various domains with human-like proficiency.
    c.  **The ability to predict future events with perfect accuracy.**
    d.  The capacity to understand and generate natural language.

9.  **Question:** [DROPPED ITEM] Why is model alignment important in the development of generative AI?
    a.  **To ensure AI systems better reflect human values and are safer.**
    b.  To improve computational efficiency and reduce energy consumption.
    c.  To enhance the alignment between model responses and user requests.
    d.  To increase the speed of data processing and analysis.

10. **Question:** How does RAG (Retrieval-Augmented Generation) enhance the capabilities of an LLM?
    a.  By improving its grammar and syntax.
    b.  **By providing it with real-time and relevant data.**
    c.  By increasing its computational speed.
    d.  By enabling it to understand multiple languages.

11. **Question:** When using generative AI to create a marketing pitch, which of the following strategies is least likely to be effective?
    a.  Supplying the AI with information about the target audience
    b.  Asking the AI to include unique selling points and benefits
    c.  Requesting the AI to use persuasive language techniques
    d.  **Providing the AI with a list of competitors' products**

12. **Question:** After deploying a customer service chatbot, you notice that it frequently provides outdated information about company policies. What is the best course of action to address this issue?
    a.  Implement a feedback loop where users can flag outdated information for review.
    b.  **Schedule regular updates to the chatbot's training data to include the latest company policies.**
    c.  Set up a system where complex or policy-related queries are escalated to human agents for accurate responses.
    d.  Conduct a comprehensive audit of the chatbot's performance metrics to identify areas for improvement.

13. **Question:** Suppose you have a large dataset of emails and you want to build an application to answer questions based on this dataset. Which of the following scenarios best illustrates the advantage of using RAG over prompting (i.e., without RAG)?
    a.  You need to generate creative writing pieces based on the email content.
    b.  You want to ensure the model can answer questions even if it has never seen similar questions before.
    c.  **You need to answer questions that require specific information from different parts of the email dataset.**
    d.  You want to reduce the size of the language model to save computational resources.

14. **Question:** [DROPPED ITEM] While using a Generative AI tool to write a story, you notice that the context window is limited to 500 tokens. What is a potential consequence of exceeding this limit?
    a.  The AI will automatically expand the context window
    b.  The AI will ignore the excess tokens and generate text based on the first 500 tokens
    c.  **The AI will generate text based on the most recent 500 tokens**
    d.  The AI will stop functioning until the context window is reduced

15. **Question:** [DROPPED ITEM] When creating a video with a generative AI tool that supports text, images, and audio narration, which feature is most critical for ensuring the tool can handle this task effectively?
    a.  **Text-to-Speech (TTS) capability.**
    b.  Image recognition capability.
    c.  Multilingual support.
    d.  Sentiment analysis capability.

16. **Question:** As a student using a Large Language Model (LLM) to gather information for an assignment, how should you approach the information it provides?
    a.  The LLM's answers are always more trustworthy than any information you will find on the internet, so you can use them without further verification.
    b.  The LLM's answers are generally more trustworthy than internet sources, but you should still verify the information with other reliable sources.
    c.  **The LLM's answers are not necessarily more trustworthy than internet sources, and you should cross-check the information with other credible references.**
    d.  The LLM's answers are less trustworthy than internet sources because it relies on outdated information.

17. **Question:** It is unlikely for an LLM to provide an accurate summary of the latest financial market trends in real-time. Is this statement true or false?
    a.  **True, because the LLM's data may be outdated due to its knowledge cutoff.**
    b.  True, because the LLM is not good at handling numbers and structured data.
    c.  False, because the LLM frequently updates its knowledge base.
    d.  False, because the LLM is capable of synthesizing the latest market data automatically.

18. **Question:** A generative AI tool has provided a summary of a research paper. The summary states, "The study found that increased screen time is directly correlated with decreased attention spans in children aged 8-12." What is your next step?
    a.  Accept the summary as accurate because AI tools are generally reliable.
    b.  Ask the AI to provide more details about the study's methodology and results.
    c.  **Cross-check the summary with the original research paper.**
    d.  Use another AI tool to generate a summary for comparison and evaluate the consistency between both summaries

19. **Question:** While reviewing a video of a well-known public figure making controversial statements, which characteristic confirms the video was NOT generated by AI?
    a.  The public figure's voice sounds like themselves.
    b.  The video has a professional and polished appearance.
    c.  The video is high-quality with smooth transitions.
    d.  **None of the above.**

20. **Question:** [DROPPED ITEM] Imagine someone is trying to clone your voice using generative AI. Which of the following audio recordings would be most effective?
    a.  A 1-hour recording of your conversation in a noisy public space.
    b.  **A 30-second recording of your presentation speech.**
    c.  A 5-minute recording of you singing a pop song.
    d.  Generative AI cannot be used to clone human voice.

21. **Question:** When a generative AI system is used for screening job applications, what issue might arise concerning the quality and fairness of hiring decisions?
    a.  The AI system might overlook applicants' unique achievements and extracurricular activities.
    b.  The AI system could misinterpret minor formatting differences in resumes.
    c.  The AI system might not effectively handle applications submitted in various languages.
    d.  **The AI system could reinforce existing biases found in historical hiring data.**

22. **Question:** In a healthcare startup, an accurate AI model recommends treatments, but doctors don't trust it because they can't understand how the model arrived at its conclusions. What core issue does this scenario illustrate?
    a.  The AI model uses obsolete training data.
    b.  The training dataset lacks sufficient diversity.
    c.  The treatment guidelines input are incorrect.
    d.  **The AI model behaves as a black box.**

23. **Question:** What are the potential copyright implications for a journalist using an AI-generated image in a commercial article?
    a.  **The journalist needs to check the licensing policy of the AI tool they used.**
    b.  The AI-generated image is automatically free to use without any restrictions.
    c.  The journalist must pay a standard licensing fee to use the AI-generated image.
    d.  The image cannot be used in any commercial context because it is AI-generated.

24. **Question:** Should we impose restrictions on the outputs of generative AI technologies?
    a.  Yes, to reduce the computational resources required for operating these technologies.
    b.  **Yes, to prevent the dissemination of harmful or misleading content.**
    c.  No, as it would hinder technological innovation and creativity.
    d.  No, because users should have the freedom to access all generated content.

25. **Question:** Sending personal information to cloud-based generative AI tools has little privacy concerns.
    a.  True, as this information is encrypted using sophisticated algorithms during the transmission process.
    b.  True, as generative AI tools are black-box systems and cannot output personal information even if it is used for model training.
    c.  **False, as generative AI tools train on unencrypted data and can output private information based on their probabilistic nature.**
    d.  False, as advancements in quantum computing can easily decipher the encrypted data.

---

## GLAT Content Validity Questionnaire

*This questionnaire (Table 3) was used in the pilot study (N=200) to assess the content validity of the initial GLAT items. Participants responded on a 5-point Likert scale (1 = Strongly Disagree to 5 = Strongly Agree). Mean and SD are reported in the paper but the scale itself is presented here.*

1.  The questions are directly related to generative AI concepts and skills.
    *(Scale: 1=Strongly Disagree, 2=Disagree, 3=Neutral, 4=Agree, 5=Strongly Agree)*
2.  The test covers a broad range of concepts that are necessary for assessing generative AI literacy.
    *(Scale: 1=Strongly Disagree, 2=Disagree, 3=Neutral, 4=Agree, 5=Strongly Agree)*
3.  The test includes questions that assess both fundamental and advanced concepts.
    *(Scale: 1=Strongly Disagree, 2=Disagree, 3=Neutral, 4=Agree, 5=Strongly Agree)*
4.  The questions are clearly written and easy to understand.
    *(Scale: 1=Strongly Disagree, 2=Disagree, 3=Neutral, 4=Agree, 5=Strongly Agree)*
5.  The options provided for each question are clearly distinct and easily distinguishable.
    *(Scale: 1=Strongly Disagree, 2=Disagree, 3=Neutral, 4=Agree, 5=Strongly Agree)*
6.  Overall, I believe the test is an effective tool for assessing generative AI literacy.
    *(Scale: 1=Strongly Disagree, 2=Disagree, 3=Neutral, 4=Agree, 5=Strongly Agree)*

---

## External Validity Task - Example Questions (Bar Chart)

*These are example questions (Table 4) related to the bar chart visualization used in the external validity learning task (Section 3.4.1). The task involved analyzing three visualizations (bar chart, social network, heatmap) and answering six multiple-choice questions (two per visualization) targeting Bloom's knowledge and comprehension levels.*

| Bloom's Level   | Question                                                                       |
| :-------------- | :----------------------------------------------------------------------------- |
| Knowledge       | Which behaviour did the two nurses spend the *most* time on?                 |
| Comprehension   | How did the nurses spend their time working on tasks for Amy compared to other tasks? |

---

## Other Instruments Mentioned (Not Reproduced in Paper)

The study also utilized the following instruments during the external validity phase (Section 3.4.3), but their specific items are not reproduced in the Jin et al. (2024) paper:

*   **ChatGPT Literacy Scale:** (Lee & Park, 2024) - A self-report measure of GenAI literacy, specifically related to ChatGPT.
*   **Mini-VLAT:** (Pandey & Ottley, 2023) - A measure of visualization literacy (domain knowledge for the external validity task).

---


## The AI Motivation Scale (AIMS)

Li, J., King, R. B., Chai, C. S., Zhai, X., & Lee, V. W. Y. (2025). The AI Motivation Scale (AIMS): A self-determination theory perspective. Journal of Research on Technology in Education. https://www.tandfonline.com/doi/abs/10.1080/15391523.2025.2478424

**Instructions:** Please rate the following reasons for using AI tools in your learning. Use the scale below:

1 = Strongly Disagree
2 = Disagree
3 = Slightly Disagree
4 = Neutral
5 = Slightly Agree
6 = Agree
7 = Strongly Agree

---

## Intrinsic Motivation (IM)

*Why do you learn with AI tools?*

1.  Because I enjoy learning with AI very much. (IM1)
2.  Because learning with AI is fun for me. (IM2)
3.  Because I feel satisfied through learning with AI. (IM3)
4.  Because exploring knowledge with AI is fascinating to me. (IM4)

## Identified Regulation (ID)

*Why do you learn with AI tools?*

1.  Because learning with AI could enhance my effectiveness. (ID1)
2.  Because learning with AI is important for my academic performance. (ID2)
3.  Because learning with AI is important for my future career. (ID3)
4.  Because learning with AI is important in helping me deal with future challenges. (ID4)

## Introjected Regulation (IJ)

*Why do you learn with AI tools?*

1.  Because I will feel guilty if I don't learn with AI. (IJ1)
2.  Because I feel a sense of obligation to learn with AI because others expect it of me. (IJ2)
3.  Because I will feel ashamed if I cannot learn with AI. (IJ3)
4.  Because I will feel ashamed if others think I am incapable of learning with AI. (IJ4)

## External Regulation (EX)

*Why do you learn with AI tools?*

1.  Because I have no other choice but to learn with AI. (EX1)
2.  Because learning with AI is one of the rules. (EX2)
3.  Because I will get in trouble if I don't learn with AI. (EX3)
4.  Because I'm required to learn with AI. (EX4)

## Amotivation (AM)

*Why do you learn with AI tools?*

1.  Because learning with AI is meaningless. (AM1)
2.  Because I cannot see why I need to learn with AI. (AM2)
3.  Because I don't know what I am getting out of learning with AI. (AM3)
4.  Because learning with AI is a waste of my time. (AM4)


-------


# Perceived Artificial Intelligence Literacy Questionnaire (PAILQ-6)

Grassini, S. (2024). A Psychometric Validation of the PAILQ-6: Perceived Artificial Intelligence Literacy Questionnaire. Nordic Conference on Human-Computer Interaction, 1–10. https://doi.org/10.1145/3679318.3685359

**Instructions:** Please rate each statement based on your beliefs and feelings from 1 (strongly disagree) to 7 (strongly agree). There are no right or wrong answers.

1.  **I understand the basic concepts of artificial intelligence.**
    ( ) 1 Strongly Disagree | ( ) 2 Disagree | ( ) 3 Somewhat Disagree | ( ) 4 Neutral | ( ) 5 Somewhat Agree | ( ) 6 Agree | ( ) 7 Strongly Agree

2.  **I believe I can contribute to AI projects.**
    ( ) 1 Strongly Disagree | ( ) 2 Disagree | ( ) 3 Somewhat Disagree | ( ) 4 Neutral | ( ) 5 Somewhat Agree | ( ) 6 Agree | ( ) 7 Strongly Agree

3.  **I can judge the pros and cons of AI.**
    ( ) 1 Strongly Disagree | ( ) 2 Disagree | ( ) 3 Somewhat Disagree | ( ) 4 Neutral | ( ) 5 Somewhat Agree | ( ) 6 Agree | ( ) 7 Strongly Agree

4.  **I keep up with the latest AI trends.**
    ( ) 1 Strongly Disagree | ( ) 2 Disagree | ( ) 3 Somewhat Disagree | ( ) 4 Neutral | ( ) 5 Somewhat Agree | ( ) 6 Agree | ( ) 7 Strongly Agree

5.  **I'm comfortable talking about AI with others.**
    ( ) 1 Strongly Disagree | ( ) 2 Disagree | ( ) 3 Somewhat Disagree | ( ) 4 Neutral | ( ) 5 Somewhat Agree | ( ) 6 Agree | ( ) 7 Strongly Agree

6.  **I can think of new ways to use existing AI tools.**
    ( ) 1 Strongly Disagree | ( ) 2 Disagree | ( ) 3 Somewhat Disagree | ( ) 4 Neutral | ( ) 5 Somewhat Agree | ( ) 6 Agree | ( ) 7 Strongly Agree


----

## Instruction for scoring and descriptive data from validation study for reference
*(do not include in the questionnaire)*

### Scoring:

*   **PAILQ-6:** Average of all responses.
*   **PAILQ-6 (factor 1: Awareness Literacy):** Average of responses 1, 3, 5.
*   **PAILQ-6 (factor 2: Engagement Literacy):** Average of responses 2, 4, 6.


-----



# Survey Instruments and Items from Markus et al. (2025)


Markus, A., Carolus, A., & Wienrich, C. (2025). Objective Measurement of AI Literacy: Development and Validation of the AI Competency Objective Scale (AICOS) (No. arXiv:2503.12921). arXiv. https://doi.org/10.48550/arXiv.2503.12921

https://osf.io/ehk8u/files/osfstorage?view_only=df9a6ea06d1446659437a73946f68e5c

## Validation Items (from Table A1: Hornberger et al. 2023 & Pinski et al. 2023)

### Item 1
What is the black box problem?
1. Al entails a residual risk that is hard to calculate
2. **it is often difficult to determine how Al makes decisions**
3. users are often not informed about the application of Al
4. many users have little knowledge about Al
*(Correct Answer: 2)*

### Item 2
Which societal challenge is frequently mentioned in the context of AI?
1. lack of investment incentives in the educational system
2. chip shortage in industry due to the high computational cost of Al
3. high error rate in Al-enabled manufacturing
4. **replacement of human workforce by AI**
*(Correct Answer: 4)*

### Item 3
In which task is Al already superior to humans?
1. **Detecting tumors**
2. Programming software
3. Translating novels
4. Designing cancer therapies
*(Correct Answer: 1)*

### Item 4
What should be considered in machine learning when dividing the data into training and test data?
1. the data should be divided into parts of as equal size as possible
2. **the data should be randomly divided into training and test data sets**
3. the test data should be of higher quality than the training data
4. the training and test data should be as different from each other as possible
*(Correct Answer: 2)*

### Item 5
Sort the process steps in supervised learning into the correct order using drag & drop:
*   Train model with training data
*   Predict test data with the model
*   Collect and prepare data
*   Divide data into training and test data
*   Calculate accuracy of prediction
*(Correct Order: 3, 4, 1, 2, 5)*

### Item 6
Why do Al systems behave intelligently?
1. they have no feelings that could distract them from their task
2. they think autonomously and pursue their own goals
3. **they have been programmed to try to achieve a given goal as well as possible**
4. they are built similar to the human brain and therefore have a similar intelligence
*(Correct Answer: 3)*

### Item 7
What is the official definition of artificial intelligence (AI)?
1. **Al is the science and technology of creating intelligent machines, especially intelligent computer programmes.**
2. There is no official definition of AI.
3. Al is the simulation of human intelligence by computer programmes.
4. Artificial intelligence is the ability of a machine to imitate human abilities such as logical thinking.
*(Correct Answer: 1 - Note: Pinski et al. 2023 listed answer 2, but the prompt asks for the items as presented in Table A1, which attributes this question to Pinski but shows answer 1 bolded in the image context, aligning with standard definitions like McCarthy's. There might be an inconsistency in the original source or OCR interpretation.)*

### Item 8
Which of the following interdisciplinary research fields is also a subfield of AI?
1. Blockchain
2. **Natural Language Processing**
3. Psychology of Learning
4. Bioinformatics
*(Correct Answer: 2)*

### Item 9
In AI, a distinction can be made between "weak" and "strong" AI. "Weak AI" refers to Al systems that have capabilities in a limited area. "Strong AI", on the other hand, is said to be capable of a very broad range of tasks, similar to humans. Which of these examples could be considered strong AI?
1. intelligent virtual assistant (e.g. Alexa)
2. fully self-driving car
3. powerful search engine (e.g. Google)
4. **strong Al does not exist at the moment**
*(Correct Answer: 4)*

### Item 10
What are knowledge representations in the field of AI?
1. particular representation of knowledge in order to communicate it to humans through AI
2. sensors that capture information from the environment
3. **information about the world that can be processed by a computer**
4. an algorithm that generates knowledge from data
*(Correct Answer: 3)*

### Item 11
How do Al systems make decisions?
1. **based on mathematical-logical principles**
2. based on links defined by programmers
3. based on quantum entanglement
4. based on artificial intuition
*(Correct Answer: 1)*

### Item 12
How does supervised learning differ from unsupervised learning?
1. **in supervised learning, the output values of the training data are known**
2. in supervised learning, humans must supervise the Al during learning and intervene if necessary
3. in supervised learning all computational steps are documented
4. in supervised learning, stricter legal regulations apply
*(Correct Answer: 1)*

## Informatics-Related Follow-up Quiz (from Table A2)

*Instructions: The correct answer is bolded.*

### Question 1
Which of the Al models is mainly used to generate images?
a) LSTM
b) **GAN**
c) BERT
d) GPT

### Question 2
What are typical programming languages for Al applications?
a) Perl and TensorFlow
b) PHP and JavaScript
c) **Python and R**
d) C++ and Ruby

### Question 3
Which tools are commonly used to create and train Al models?
a) Hadoop
b) **TensorFlow**
c) SQL
d) Excel

### Question 4
What is a typical breakdown of test and training data for development purposes?
a) It does not matter.
b) **80% training and 20% testing**
c) 95% testing and 5% training.
d) 40% training, 40% testing, and 20% test training together.

### Question 5
How does a Large Language Model (LLM) output change if the 'temperature' parameter is increased from 0.5 to 1.0?
a) The answers of the Al application do not change.
b) The Al application's answers contain more words.
c) **The Al application's answers become more creative.**
d) The Al application's answers become more consistent.

## Control Questions (from Table A3)

*Instructions: The correct answer is bolded.*

### Question 1
This is a quality control. Please do not answer this question.
a) Artificial intelligence
b) Machine learning
c) Deep learning
d) Big Data
*(Instruction: Do not answer)*

### Question 2
How do you probably feel most of the time when you are angry?
a) Tired
b) **Annoyed**
c) Smart
d) Sad

### Question 3
How seriously do you take this study? Choose "not too seriously" when you read this question.
a) very seriously
b) not serious at all
c) **not too seriously**
d) serious

### Question 4
What happens if you double your running speed?
a) Your speed is reduced.
b) **Your pace is twice as fast.**
c) Your pace is twice as slow.
d) Your pace is four times as fast.

## Final AICOS Items (from Supplementary Material 3)

*Notes:*
*   *RA = Right Answer (Letter corresponding to the option below)*
*   *(SV)* indicates items included in the proposed Short Version (SV) in the paper's main text (Section 3.7).

*(Image Reference for Item AA below: Refers to a decision tree image classifying fruit based on 'Is it Red?', 'Is it round?', 'Is it small?'. A blueberry follows the path: No -> Yes -> Yes)*

### Apply AI (AA)

**AA02**
Computers use decision trees to classify data. Below is a picture of a decision tree. Imagine using this decision tree to categorize a blueberry. What category will it end up in?*
a) A
b) **B**
c) C
d) D
*(RA: B)*

**AA04** (SV)
How can humans influence the outcome of machine learning? Through...
a) ...calculation of the accuracy of the prediction
b) ...randomized division into test and training data
c) **...selection of the model**
d) ...abstraction of the model
*(RA: C)*

**AA06**
John has developed a KNN (K-Nearest Neighbors) model to recognize different types of dogs. He trained the model for a long time, and now the model can recognize the dog species in his training dataset with an accuracy of up to 99.99%. Unfortunately, when John's friend applies his model to his German Shepherd, the model does not recognize it. John is puzzled because many photos of German Shepherds have been included in the training dataset. What action should John take to improve the performance of his KNN model?
a) More data should be added to the training dataset to better train the model to recognize German Shepherds.
b) **The model might be overfitting, so more data should not be added to avoid overfitting.**
c) Improving the image quality and resolution of the training data could help to improve the performance of the model.
d) The training dataset should be analyzed and supplemented with additional photos of German Shepherds to improve the model in a targeted manner.
*(RA: B)*

**AA08** (SV)
Samantha uses labeled images to train an Al technology to recognize whether she is in an image or not. What is done during the training phase to improve the system if the technology makes an incorrect identification?
a) **Strengthen or weaken the connections in the network**
b) Ask the algorithm to remember the image that the AI technology misidentified
c) Delete the images
d) Change the caption of the image so that the Al technology no longer misidentifies it
*(RA: A)*

**AA09**
Decide which Al-based method the following description is based on: In this learning method, there is no manually labeled training data or human-named target categories. The algorithm independently transforms patterns in the data into representations that make sense to it.
a) Supervised Learning
b) **Unsupervised Learning**
c) Semi Supervised Learning
d) Unstructured Learning
*(RA: B)*

**AA19** (SV)
Which of the following processes does **not** use natural language processing (NLP) technologies?
a) Analysis of clinical text recordings
b) **Gesture-controlled robot**
c) Story generator
d) Question and answer tool
*(RA: B)*

**AA20**
An Al is supposed to divide images into meaningful parts. Input is always an image. Which input-output pair is **NOT** meaningful:
a) Image → number
b) Image → vector
c) Image → image
d) **Image → video**
*(RA: D)*

**AA21**
Which statement describes the main mechanism of deep learning in solving complex problems?
a) Deep learning comprises machine learning methods for modeling AI.
b) Deep learning is used to train Al based on large amounts of data.
c) **In deep learning models, neurons are connected in multiple layers to learn patterns.**
d) Deep learning enables computers to perform human-like tasks.
*(RA: C)*

**AA22**
Which is correct about sentiment analysis?
a) List the topics that a document deal with.
b) Compress a document as much as possible without losing meaning, producing another document.
c) **Assess the emotional content of a document.**
d) Given a question in natural language, provide an appropriate answer in natural language.
*(RA: C)*

**AA23**
Simulations in the Al context are used to...
a) **... obtain a better understanding of complex problems.**
b) ... significantly reduce the cost of solving problems.
c) ... increase the speed of problem solving.
d) ... systematically develop the most effective solution.
*(RA: A)*

### Create AI (CA)

**CA02** (SV)
Patrick follows the games of his favorite basketball team in the NBA and wants to use the game statistics to predict how many games the team will win in the current season. Which algorithm is best suited to make this prediction?
a) Classification
b) **Regression**
c) Clustering
d) Object detection
*(RA: B)*

**CA03**
In 2016, Microsoft introduced the chatbot "Tay", which was used on Twitter. Tay was developed to interact with and entertain millennials. In this way, Microsoft wanted to explore the conversational understanding of this target group. The more users chatted with Tay, the smarter she became. After just a few days, Tay was posting racist, inflammatory and political statements, for example that the Holocaust never happened and that 9/11 was an inside job. Microsoft ended the experiment as a result. What could have been the main problem with the development of Tay?
a) Tay was confronted with unexpected, problematic user interactions.
b) **The training data was biased.**
c) Tay's behavior is opaque to others.
d) Tay's code was attacked and manipulated in a cyber attack.
*(RA: B)*

**CA04**
You want to develop an Al application that uses a pre-trained model based on large amounts of data and can be adapted to a variety of tasks. Which model would be best suited for this?
a) Diffusion Model
b) **Foundation Model**
c) Convolutional Model
d) Probabilistic Model
*(RA: B)*

**CA07** (SV)
When we use machine learning techniques in a text recognition system:
a) We present the system with a series of sample texts and after processing the system is able to recognize only texts that correspond exactly to these examples.
b) **We give the system a series of example texts and after processing the system is able to recognize texts that are similar to these examples (i.e. it recognizes new texts that it has never seen before).**
c) We give the system a set of example texts, and after processing, the system is able to recognize any text we give it.
d) We give the system a series of sample texts, and after processing them, the system is able to recognize any text, image or sound that we present to it.
*(RA: B)*

**CA10**
Although a larger learning rate may increase the speed of model training, what is the potential problem if the learning rate is too large?
a) More time-consuming to train.
b) More training data is needed.
c) Training produces a totally ineffective model.
d) **Training produces a less-than-optimal model.**
*(RA: D)*

**CA11** (SV)
In which of these areas is Al typically applied?
a) **Detecting credit card fraud**
b) Cryptocurrency mining
c) Web tracking
d) Encryption for instant messaging services
*(RA: A)*

**CA12**
Which of the following examples is **NOT** AI?
a) Style change filters in applications such as Prisma, which use a photo as a starting point and create variants in different art styles (impressionist, cubist, etc.).
b) A music recommendation system such as Spotify, which recommends music based on the user's listening behavior.
c) **Big data storage solutions that store large amounts of data (e.g. images or videos) and can play them for a large number of users at the same time.**
d) Applications that can reformulate a text into different language styles.
*(RA: C)*

### Detect AI (DA)

**DA01**
Imagine you are chatting with an Al assistant on the internet. How could you find out whether you are talking to an Al or a human?
a) You write in dialect, as this can only be understood by humans.
b) You ask a difficult knowledge question that only a human can answer.
c) You include typos in your text because the Al will no longer understand you, but a human will.
d) **You make an ironic remark because it is better understood by humans.**
*(RA: D)*

**DA02**
In which of the following systems is the use of Al most likely?
a) Flight surveillance systems
b) Geopositioning systems
c) 3D printing systems
d) **Inventory management systems**
*(RA: D)*

**DA03** (SV)
Which of these applications does **NOT** use AI?
a) A medical system that analyzes patterns on images of tissue to determine whether cancer is present.
b) **A chatbot on a website that answers predefined questions.**
c) Voice assistants that recognize, understand and respond to spoken language.
d) Face-lock function on cell phones to recognize and distinguish users' faces.
*(RA: B)*

**DA04**
How is Al not yet being used to mitigate climate change?
a) Early warning systems for natural disasters
b) **Analysis of measures for political decisions on the environment**
c) Predictive maintenance forecasting for water pipes
d) Optimized route planning for freight transport
*(RA: B)*

**DA05** (SV)
How is Al already being used in urbanization issues today?
a) Predictive maintenance forecast for water pipes
b) Regulation of the housing market
c) Optimized settlement strategy for inner cities
d) **Forecasting the volume of passengers on public transport**
*(RA: D)*

**DA08**
Which of the following questions is best suited to find out whether you are talking to an Al or a human?
a) **What is your opinion on recent political developments?**
b) What happened on November 20, 1922 at 10:00 am?
c) Can you please tell me the way to the nearest library?
d) What is the name of the President of France?
*(RA: A)*

**DA09** (SV)
What characteristics differentiate Al from previous IT applications?
a) **Learning ability & independence**
b) Ability to process data & ease of use
c) Speed & ability to process data
d) Location-independent access & data security
*(RA: A)*

**DA10**
Which statements about Al are true?
a) **Al performs human-like tasks and makes decisions independently.**
b) Strong Al is designed for special tasks (e.g. speech processing).
c) It is easier for Al robots to learn to walk down a street than for a 5-year-old child.
d) Strong Al is integrated into everyday technologies.
*(RA: A)*

### Ethics AI (EA)

**EA01**
Which ethical principles should be considered when developing AI?
a) Holism, fairness, transparency
b) **Prevention of harm, transparency, fairness**
c) Fairness, holism, prevention of harm
d) Transparency, prevention of harm, holism
*(RA: B)*

**EA02**
What are central risks in using Al for predictive policing?
a) Vulnerability to hacking
b) **Discrimination against suspects based on origin and status**
c) Lack of legal certainty in the event of Al breakdown
d) Undermining the authority of police officers
*(RA: B)*

**EA05**
Lena and Ahmed are good friends and use a voice assistant to research career opportunities in the technology industry. Lena, a young German woman, receives a wide range of job offers, including leadership positions and scholarship programs to promote women in technology. Ahmed, a young man from a non-European background, makes the same research request as Lena, but mainly receives information on entry-level positions and training programs. What ethical dilemma is illustrated by this scenario?
a) The algorithm has automatically assumed that Ahmed is less interested in higher positions based on his origin.
b) **The algorithm could reproduce unconscious biases by providing Ahmed and Lena with different information based on gender and origin.**
c) The algorithm provides different information to protect users due to security concerns.
d) The algorithm has been programmed to provide optimal results only for certain user groups, leading to discrimination.
*(RA: B)*

**EA09** (SV)
What are the problems with regulating Al solutions?
a) The EU, USA and China cannot agree on which of their three regulatory models should be implemented in the rest of the world.
b) **The legislation of Al solutions cannot keep up with the rapid development of new programs and their dissemination.**
c) The clarification of fundamental ethical issues has been completed by the EU's AI Act.
d) In the EU, every Al solution must be approved by the state. This takes longer than developers would like and leads to difficulties between industry and politics.
*(RA: B)*

**EA11** (SV)
What risks and challenges does the use of Al solutions entail in the three areas?
a) Legal and ethical issues have not yet been fully clarified.
b) In a social context, the use of confidential data for the training and operation of Al systems is completely unobjectionable.
c) Health insurance companies do not yet support the use of Al systems.
d) **The power consumption for training Al systems is very high.**
*(RA: D)*

**EA15** (SV)
Which of the following contributes to the ethical development of computer vision applications?
a) Capturing and storing sensitive data during video surveillance.
b) Falsifying the identity of others during facial recognition.
c) The development of medical imaging applications without testing and ethical review.
d) **Putting the safety and protection of users first when developing self-driving cars.**
*(RA: D)*

### Generative AI (GA)

**GA02** (SV)
What does "generative" mean in the context of artificial intelligence?
a) It refers to the ability to quickly retrieve existing content from a database.
b) **It means that the AI can create new content on demand based on training data.**
c) It describes the ability to collect data from the Internet in real time.
d) It stands for the ability to summarize information from multiple sources.
*(RA: B)*

**GA04** (SV)
Hallucinations in Al models refer to nonsensical or grammatically incorrect words or sentences generated by the model. Which of the following factors is least likely to cause hallucinations?
a) The model is trained using noisy or erroneous data.
b) **The model is trained with too much data.**
c) The model was not trained with enough data.
d) The model is not given enough context.
*(RA: B)*

**GA08** (SV)
Which of the following strategies is **NOT** particularly helpful for recognizing whether a video was created by a generative AI?
a) **Check that the color palette in the video remains consistent across different scenes, as Al-generated videos sometimes have color variations.**
b) Pay attention to object permanence to check whether objects that move out of the field of view reappear when the camera pans back.
c) Check the movements of people and objects in the video for logical consistency to ensure that they comply with the laws of physics.
d) Watch the video several times and pay attention to different details to notice possible errors.
*(RA: A)*

**GA10**
What is a "prompt"?
a) **A short text that is given as input to the large language model and can be used to control the output of the model in many ways.**
b) A short text that is used to train the large language model.
c) A pre-trained generative Al model that serves as a starting point for fine-tuning and customizing the generation of specific content types.
d) A long section of text used to debug the large language model.
*(RA: A)*

**GA11**
Which strategy is most effective to achieve high quality results with a generative Al model when you want to create a detailed description for an artwork?
a) Enter a short, general sentence to maximize the creativity of the model.
b) Use a long and complex input that contains a lot of details to get specific information.
c) **Segment the prompts into smaller, thematically focused parts and use them step by step.**
d) Entering the prompts without customization or thought and relying on the AI.
*(RA: C)*

**GA13**
Which of the following best describes how generative Al works?
a) Generative Al randomly creates new content without reference to existing data.
b) Generative Al uses rules to create completely original and unique content.
c) Generative Al determines the relationship between data sets and classifies data according to the existing data sets.
d) **Generative Al learns from existing data and then creates new content that resembles the learned patterns.**
*(RA: D)*

**GA16**
A company decides to use Al instead of human voice actors for the voice recordings of a movie. What ethical problem could arise in terms of social responsibility?
a) Al might not provide the desired emotional expression.
b) **The use of AI could potentially put a human out of work.**
c) Viewers might have problems accepting the Al voice as authentic.
d) AI takes longer to produce than human speakers.
*(RA: B)*

**GA17**
Which of the following aspects pose potential ethical challenges when using generative AI?
a) Copyright issues, risks of false information, promotion of creative collaboration.
b) **Lack of transparency in content, risks of misinformation, bias in generated content.**
c) Improved efficiency in creative processes, copyright issues, bias in generated content.
d) Privacy risks, promotion of creative collaboration, risks of false information.
*(RA: B)*

**GA19**
Who is responsible if misinformation is spread by generative AI?
a) Only the developers of the Al models.
b) The users who create or distribute the content.
c) **It is unclear who bears responsibility.**
d) Only the media companies that publish the content
*(RA: C)*

### Understanding AI (UA)

**UA01**
Which of the following statements describes a fundamental characteristic of AI?
a) AI uses the same methods for organizing and storing information for different tasks.
b) An Al model always achieves the same result with the same input.
c) Al-generated data is robust against errors, which reduces the need for interpretation.
d) **AI "sees" and "hears" the world through the process of extracting information from sensory signals.**
*(RA: D)*

**UA05**
Which of the following least describes the basic approach of Machine Learning (ML)?
a) ML is a process by which computer programs automatically learn to extract patterns and insights from data and improve their performance.
b) ML enables data to be analyzed, predictions to be made and problems to be solved independently.
c) ML is the application of algorithms to analyze large amounts of data and predict patterns.
d) **ML is a method by which computers learn to make decisions and perform tasks by manually entering data.**
*(RA: D)*

**UA09**
What can weak AI **NOT** do?
a) make decisions under uncertainty
b) **solve a wide range of tasks**
c) solve a task better than a human
d) learn from unstructured data
*(RA: B)*

**UA10**
What is a key criterion for the quality of a model in machine learning?
a) **it can predict the output values of the test data as well as possible**
b) it contains as few variables as possible
c) it is as well adapted as possible to the training data
d) the predictions are as unambiguous as possible
*(RA: A)*

**UA11** (SV)
How does a recommendation system of a streaming service based on Al work?
a) **It uses the data of all users to generate personalized recommendations.**
b) It uses all available data from users on the internet to make suggestions.
c) It is based exclusively on the data of other users, but not on your own.
d) It only uses users' own data for recommendations.
*(RA: A)*

**UA18**
Which of the following statements describes the function of weights in an artificial neural network?
a) Weightings in the network are adjusted and corrected if the results are correct.
b) Rejected decisions increase the weights in the network.
c) Correct decisions reduce the weightings in the network.
d) **Weightings determine the relevance of each input and output of the network.**
*(RA: D)*

**UA19**
What is a central feature of reinforcement learning models?
a) **The model performs actions and learns through a trial-and-error method.**
b) It works in interaction with the training environment.
c) The model makes decisions based on previous experience and current states.
d) The model requires a labeled data set for training.
*(RA: A)*

**UA21**
Which process is referred to as "inference" in Al systems?
a) The training of a model with data to learn patterns.
b) The optimization of model parameters during the training process.
c) **The application of an already trained model to new data to make predictions.**
d) The collection and preparation of data for training a model.
*(RA: C)*

**UA26** (SV)
What is a possible consequence of Al-based personalization processes of online search engines?
a) A greater variety of information and opinions is presented
b) **People can fall into filter bubbles with only affirmative content**
c) People get the same results for the same search query
d) The search results become less relevant for the user
*(RA: B)*

**UA27**
Some linguistics researchers want to train an Al system to recognise mispronunciations of certain words in Mandarin. As the user pronounces one of these words, the system indicates which of the four Mandarin intonations the speaker has used, allowing the user to check whether the correct intonation has been used. Such a system will need to process words that are pronounced using the wrong intonation. What kind of audio recordings will be most suitable for the researchers to collect to train the system?
a) Correct Mandarin pronunciations of words
b) **Words pronounced in Mandarin using each of the four intonations regardless of whether they are correct**
c) Words pronounced using the same intonation in Mandarin
d) Random paragraphs read by different people in Mandarin
*(RA: B)*

*(Image Reference for Item UA28 below: Refers to the same decision tree image as Item AA02)*

**UA28** (SV)
Which of the following characteristics could indicate that a text was generated by an AI?
a) The text is incorrect and contains many typos.
b) The text is written in several languages.
c) **The text is perfectly structured but contains generic or repetitive phrases.**
d) The text contains strongly subjective opinions and emotions.
*(RA: C)*



------

# Survey Items from Salah et al. (2024)

Salah, M., Alhalbusi, H., Ismail, M. M., & Abdelfattah, F. (2024). Chatting with ChatGPT: Decoding the mind of Chatbot users and unveiling the intricate connections between user perception, trust and stereotype perception on self-esteem and psychological well-being. Current Psychology, 43(9), 7843–7858. https://doi.org/10.1007/s12144-023-04989-0

https://educationaltechnologyjournal.springeropen.com/articles/10.1186/s41239-024-00471-4/tables/6


*Rating Scale: 5-point Likert scale (1 = Strongly Disagree, 5 = Strongly Agree), except where noted.*

---

## Items from Table A1

### Knowledge Application
*Source: Al-Sharafi et al. (2022)*
1.  **KAP1:** ChatGPT provides me with instant access to various types of knowledge.
2.  **KAP2:** ChatGPT allows me to integrate different types of knowledge.
3.  **KAP3:** ChatGPT helps me better master the knowledge I learn in university.

### Perceived Intelligence
*Source: Rafiq et al. (2022)*
1.  **PIE1:** I feel that ChatGPT is competent.
2.  **PIE2:** I feel that ChatGPT is knowledgeable.
3.  **PIE3:** I feel that ChatGPT is intelligent.

### Usability
*Source: Rafiq et al. (2022); Borsci et al. (2022); Almaiah and Man (2016)*
1.  **USB1:** The provided contents on ChatGPT are easily accessible.
2.  **USB2:** The provided contents on ChatGPT are easily downloadable.
3.  **USB3:** The provided contents on ChatGPT are easily retrievable.

### Attitude
*Source: Ajzen (1991)*
1.  **ATT1:** ChatGPT is useful.
2.  **ATT2:** ChatGPT is valuable.
3.  **ATT3:** ChatGPT is beneficial.

### Subjective Norms
*Source: Ajzen (1991)*
1.  **SNO1:** Most people who are important to me think it is okay for me to use ChatGPT.
2.  **SNO2:** Most people who are important to me support that I use ChatGPT.
3.  **SNO3:** Most people who are important to me understand that I use ChatGPT.

### Perceived Behavioral Control
*Source: Ajzen (1991)*
1.  **PBC1:** I am capable of using ChatGPT.
2.  **PBC2:** I am confident that if I want to, I can use ChatGPT.
3.  **PBC3:** I have enough resources, time, and opportunities to use ChatGPT.

### Trust
*Source: Nguyen et al. (2019)*
*(Note: This likely contributes to the 'Trust in ChatGPT (TCGPT)' construct analyzed, which used 7 items according to the main paper).*
1.  **TRU1:** When using ChatGPT, I trust that my personal information will not be used for any other purpose.
2.  **TRU2:** When using ChatGPT, I believe that my personal information is protected.
3.  **TRU3:** When using ChatGPT, I'm confident that my personal information is secure.

### Behavioral Intention
*Source: Ajzen (1991)*
1.  **BIT1:** I'd like to continue to use ChatGPT.
2.  **BIT2:** I'll continue to use the shared ChatGPT a lot in the future.
3.  **BIT3:** I plan to use ChatGPT in the future.

### Actual Use
*Source: Aparicio et al. (2017); McLean and Osei-Frimpong (2019)*
1.  **ACU1:** How frequently do you use ChatGPT?
2.  **ACU2:** At present, I consider myself to be a frequent user of ChatGPT.

---

## Items from "Items Description" List

*(Note: The specific constructs these items map onto in the final analysis is not always explicitly stated in the provided material. Headings are inferred where possible based on item content).*

### Potential Items related to Perceptions/Learning/Knowledge
1.  **SEL1:** ChatGPT can become better through learning.
2.  **SEL2:** ChatGPT's ability is enhanced through learning.
3.  **SEL3:** ChatGPT can learn to improve themselves well.
4.  **KAO1:** ChatGPT allows me to generate a new knowledge based on my existing knowledge.
5.  **KAO2:** ChatGPT enables me to acquire the knowledge through various resources.
6.  **KAO3:** ChatGPT assists me to acquire the knowledge that suits my needs.
7.  **KAP1:** ChatGPT provides me with instant access to various types of knowledge. *(Repeated from Table A1)*
8.  **KAP2:** ChatGPT allows me to integrate different types of knowledge. *(Repeated from Table A1)*
9.  **KAP3:** ChatGPT can help us for better managing the course materials within the university. *(Slightly different wording from Table A1)*
10. **PSN1:** ChatGPT can provide targeted answers to my questions.
11. **PSN2:** ChatGPT can make a personalized response to my request.
12. **PSN3:** I feel that ChatGPT knows me.

### Potential Items related to User Experience/Perceptions
*(Note: These likely contribute to the 'ChatGPT's User Perceptions (UPCGPT)' construct analyzed, which used 5 items).*
1.  **NVT1:** Using ChatGPT is a unique experience.
2.  **NVT2:** Using ChatGPT is an educational experience.
3.  **NVT3:** The experience of using ChatGPT satisfies my curiosity.
4.  **IDI1:** The ChatGPT enables me to accomplish tasks more quickly.
5.  **IDI2:** The ChatGPT increases my productivity.
6.  **IDI3:** The ChatGPT makes it easier to accomplish tasks.
7.  **BNF1:** Using ChatGPT has increased my knowledge and helped me to be successful in increasing knowledge.
8.  **BNF2:** ChatGPT is a very effective educational tool and has helped me to improve my work ability.
9.  **BNF3:** ChatGPT has helped me to achieve the goals.

### Potential Items related to Trust/Privacy Concerns
*(Note: These likely contribute to the 'Trust in ChatGPT (TCGPT)' construct analyzed, which used 7 items).*
1.  **PRC1:** My personal information could be misused by ChatGPT system.
2.  **PRC2:** I am concerned that ChatGPT uses my personal information for purposes that I am not being notified of.
3.  **PRC3:** It is dangerous to provide my personal information to ChatGPT.

### Potential Items related to AI Anxiety/Threat Perception
*(Note: These might relate loosely to Perceived Stereotyping or Job Anxiety, but the exact mapping isn't provided. The Perceived Stereotyping construct used 8 items and Job Anxiety used 7 items in the analysis).*
1.  **TPH1:** I believe the evolution of AI is intimidating.
2.  **TPH2:** AI appears threatening to me.
3.  **TPH3:** For reasons unclear to me, AI induces fear.

### Potential Items related to Psychological Well-being (Affect)
*(Note: The Psychological Well-being construct used 16 items in the analysis, likely based on Ryff's scales adapted by Babnik et al. (2022). These items only represent a small part, likely negative affect).*
*Instruction:* This list consists of a number of words and phrases that describe different feelings and emotions you may have had when using ChatGPT. Please reflect on your last week of use of ChatGPT and indicate to what extent you have felt this way when using the website: (1 = Very slightly or not at all; 7 = Extremely)
1.  **GFE1:** Guilty
2.  **GFE2:** Ashamed
3.  **GFE3:** Blameworthy

### Potential Items related to Innovativeness/Technology Adoption
1.  **INO1:** I like to experiment with new technologies.
2.  **INO2:** Among my peers, I am usually the first to try out new information technologies.
3.  **INO3:** In general, I would not hesitate to try out new information technologies.

### Potential Items related to Behavioral Intention / Actual Use
*(Note: These supplement/repeat items from Table A1)*
1.  **BIT1:** I intend to continue using ChatGPT in the future.
2.  **BIT2:** I will always try to use ChatGPT in my daily life.
3.  **BIT3:** I plan to continue to use ChatGPT frequently.
4.  **BEH1:** How often do you use ChatGPT?
5.  **BEH2:** I consider myself a frequent user of ChatGPT.

------




-----------


# Survey/Questionnaire Instrument from Küper et al. (2025)

Küper, A., Lodde, G. C., Livingstone, E., Schadendorf, D., & Krämer, N. (2025). Psychological Factors Influencing Appropriate Reliance on AI-enabled Clinical Decision Support Systems: Experimental Web-Based Study Among Dermatologists. Journal of Medical Internet Research, 27(1), e58660. https://doi.org/10.2196/58660

https://osf.io/87tpu/files/osfstorage#

## Post-Task Questionnaires

### 6. AI System Trust (Post-Task Evaluation)

After interacting with the AI system presenting its classification in the previous tasks, please read the following sentences carefully and indicate how you would rate the AI system.
Please indicate the degree to which you agree/disagree with the following statements.

**(Scale: 1 = strongly disagree, 2 = disagree, 3 = neutral, 4 = agree, 5 = strongly agree)**

*   The system is designed to be trustworthy.
    *   ( ) strongly disagree ( ) disagree ( ) neutral ( ) agree ( ) strongly agree
*   I distrust the system.
    *   ( ) strongly disagree ( ) disagree ( ) neutral ( ) agree ( ) strongly agree
*   I trust the system.
    *   ( ) strongly disagree ( ) disagree ( ) neutral ( ) agree ( ) strongly agree
*   I lack faith in the system.
    *   ( ) strongly disagree ( ) disagree ( ) neutral ( ) agree ( ) strongly agree
*   I believe in the system.
    *   ( ) strongly disagree ( ) disagree ( ) neutral ( ) agree ( ) strongly agree

*(Note: The paper identifies this as the Global Trust Scale by Wischnewski et al., 2008 [Ref 68 in paper])*

### 7. General Technology Interaction (Affinity)

In the following questionnaire, we will ask you about your interaction with entire digital devices. The term **technical system** refers to apps and other software applications, as well as entire digital devices (e.g. mobile phone, computer, TV, car navigation).
Please indicate the degree to which you agree/disagree with the following statements.

**(Scale: 1 = completely disagree, 2 = disagree, 3 = somewhat disagree, 4 = somewhat agree, 5 = agree, 6 = completely agree)**

*   It is predominantly deal with technical systems because I have to.
    *   ( ) completely disagree (...) ( ) completely agree
*   I enjoy spending time becoming acquainted with a new technical system.
    *   ( ) completely disagree (...) ( ) completely agree
*   I try to make full use of the capabilities of a technical system.
    *   ( ) completely disagree (...) ( ) completely agree
*   It is enough for me that a technical system works: I don't care how or why.
    *   ( ) completely disagree (...) ( ) completely agree
*   I like testing the functions of new technical systems.
    *   ( ) completely disagree (...) ( ) completely agree
*   I try to understand how a technical system exactly works.
    *   ( ) completely disagree (...) ( ) completely agree
*   I like to occupy myself in greater detail with technical systems.
    *   ( ) completely disagree (...) ( ) completely agree
*   When I have a new technical system in front of me, I try it out intensively.
    *   ( ) completely disagree (...) ( ) completely agree


---

### Other Questionnaires (Described in Paper, Not Shown in Screenshot)

The study methods section also describes the use of the following questionnaires, which were presumably presented after the ones shown:

*   **Propensity to Trust Technology:** 6-item questionnaire by Jessup et al. (2019) [Ref 69], 5-point scale (strongly disagree to strongly agree). Example item: "Technology is reliable."
*   **Control Beliefs in Dealing with Technology:** 8-item German "Kontrollüberzeugung im Umgang mit Technik" questionnaire by Beier (1999) [Ref 62], translated to English, 5-point scale (strongly disagree to strongly agree). Example item: "Even if I encounter resistance, I continue to work on technical problems."
*   **Need for Cognition:** Short 6-item scale by Lins de Holanda Coelho et al. (2020) [Ref 64], 5-point scale (extremely uncharacteristic of me to extremely characteristic of me). Example item: "I would prefer complex to simple problems".

-----------


# Trust in AI Scale (TAIS) - Final Items (Study 1 Reduction)

Wischnewski, M., Doebler, P., & Krämer, N. (2025). Development and validation of the Trust in AI Scale (TAIS). OSF. https://doi.org/10.31234/osf.io/eqa9y_v1

https://osf.io/9zp6y/files/osfstorage

**Instructions:** The following items ask about your perceptions of a specific AI system. Please rate your agreement with each statement.

**Scale:** All items are rated on a five-point Likert scale from 1 = “strongly disagree” to 5 = “strongly agree”.

**Placeholder:** `%system%` represents the placeholder for the respective system for which trust is measured.

**(r)** indicates a reverse-scored item.

---

### Global Trust

*   I believe in %system%.
*   I trust %system%.
*   I distrust %system%. (r)
*   %system% is designed to be trustworthy.
*   I can depend on %system%.

### Vigilance

*   I am vigilant about %system%.
*   I am alert of %system%.
*   I am on the lookout when using %system%.
*   I am on my toes when using %system%.
*   I am careful when using %system%.

### Unbiasedness

*   %system% does not discriminate against anyone.
*   %system% treats everyone equally.
*   %system%'s design is free of prejudice.
*   %system% is unfaithful. (r)
*   %system% was designed to be responsible.

### Integrity

*   %system% is sincere.
*   %system% is genuine.
*   %system% is honest.
*   %system% is authentic.
*   %system% is benevolent.

### Transparency

*   I think I understand %system%.
*   The inner workings of %system% are comprehensible.
*   %system% is puzzling. (r)
*   %system%'s state is always clear to me.
*   %system% gives sufficient information about its inner workings.

### Ability

*   %system% performs its task very well.
*   %system% is capable.
*   %system% is proficient.
*   %system% functions properly.
*   %system% responses accurately.

---

-------------

# Questionnaires Used in Perrig et al. (2023)

Perrig, S. A. C., Scharowski, N., & Brühlmann, F. (2023). Trust Issues with Trust Scales: Examining the Psychometric Quality of Trust Measures in the Context of AI. *Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems*, 1–7. https://doi.org/10.1145/3544549.3585808

## 1. Trust Scale for Explainable AI (TXAI) - Adapted Version

*Source: Hoffman et al. [13], adapted by Perrig et al. (2023) by substituting "tool" with "AI".*
*Scale: 5-point Likert-type scale (1 = "I disagree strongly" to 5 = "I agree strongly")*
*Note: Item 6 is negatively formulated and was reverse-coded for analysis in the paper.*

1.  I am confident in the AI. I feel that it works well.
2.  The outputs of the AI are very predictable.
3.  The AI is very reliable. I can count on it to be correct all the time.
4.  I feel safe that when I rely on the AI I will get the right answers.
5.  The AI is efficient in that it works very quickly.
6.  I am wary of the AI. (R)
7.  The AI can perform the task better than a novice human user.
8.  I like using the AI for decision making.

## 2. Trust between People and Automation (TPA) Scale - Adapted Version

*Source: Jian et al. [17], adapted by Perrig et al. (2023) by prefixing "AI-" to "system".*
*Scale: 7-point Likert-type scale (1 = "not at all" to 7 = "extremely")*
*Note: Items 1-5 are reverse-coded items (phrased negatively/representing distrust) and were re-coded prior to data analysis in the paper.*

1.  The AI-system is deceptive (R)
2.  The AI-system behaves in an underhanded manner (R)
3.  I am suspicious of the AI-system's intent, action or, outputs (R)
4.  I am wary of the AI-system (R)
5.  The AI-system's actions will have a harmful or injurious outcome (R)
6.  I am confident in the AI-system
7.  The AI-system provides security
8.  The AI-system has integrity
9.  The AI-system is dependable
10. The AI-system is reliable
11. I can trust the AI-system
12. I am familiar with the AI-system

## 3. Uncertainty Assessment Item

*Source: Perrig et al. (2023), Section 2.1*
*Scale: 7-point Likert-type response scale (1 = "not at all severe" to 7 = "extremely severe")*
*Item Prompt (Inferred from description):* Participants were asked to rate the severity of "the prospect of not getting paid due to poor performance". (The exact phrasing of the question posed to participants is not provided in the paper, only the concept they rated).

*   How severe is the prospect of not getting paid due to poor performance? [1 - Not at all severe ... 7 - Extremely severe]



-------------


# Instruments from Hoffman et al. (2019)

Hoffman, R. R., Mueller, S. T., Klein, G., & Litman, J. (2019). Metrics for Explainable AI: Challenges and Prospects (No. arXiv:1812.04608). arXiv. https://doi.org/10.48550/arXiv.1812.04608


### Table 3. The CVR version of the Explanation Satisfaction scale (p. 6)

> For each item listed below, please indicate whether you believe that the item is:
> *   Essential for measuring Explanation Satisfaction,
> *   Useful but not Essential, or
> *   Not Necessary for measuring Explanation Satisfaction.
>
> Indicate your response by circling the appropriate number.

| Item                                                                                     | Essential | Useful but not essential | Not Necessary |
| :--------------------------------------------------------------------------------------- | :-------: | :----------------------: | :-----------: |
| 1. I understand this explanation of how the [software, algorithm, tool] works.           |     1     |            2             |       3       |
| 2. This explanation of how the [software, algorithm, tool] works is satisfying.          |     1     |            2             |       3       |
| 3. This explanation of how the [software, algorithm, tool] works has sufficient detail.  |     1     |            2             |       3       |
| 4. This explanation of how the [software, algorithm, tool] works contains irrelevant details. |     1     |            2             |       3       |
| 5. This explanation of how the [software, algorithm, tool] works seems complete.         |     1     |            2             |       3       |
| 6. This explanation of how the [software, algorithm, tool] works tells me how to use it. |     1     |            2             |       3       |
| 7. This explanation of how the [software, algorithm, tool] works is useful to my goals.  |     1     |            2             |       3       |
| 8. This explanation of says how accurate the [software, algorithm, tool] is.           |     1     |            2             |       3       |
| 9. This explanation lets me judge when I should trust and not trust the [software, algorithm, tool] |     1     |            2             |       3       |

---

### Table 6. Example Prompts from ShadowBox Lite Task (p. 15)

> (These prompts are used after presenting an expert explanation, e.g., for cruise control: "The control unit detects the rotation of the drive shaft from a magnet mounted on the drive shaft, and from that can calculate how fast the car is going. The control unit controls an electric motor that is connected to the accelerator linkage. The cruise control adjusts the engine speed until it is disengaged.")

| Prompt                                               | Response Area        |
| :--------------------------------------------------- | :------------------- |
| What is right and helpful about this explanation?    | (User response area) |
| What is problematic or wrong about this explanation? | (User response area) |

---

### Table 7. A Curiosity Checklist (p. 18)

> Why have you asked for an explanation? Check all that apply.

*   [ ] I want to know what the AI just did.
*   [ ] I want to know that I understand this AI system correctly.
*   [ ] I want to understand what the AI will do next.
*   [ ] I want to know why the AI did not make some other decision.
*   [ ] I want to know what the AI would have done if something had been different.
*   [ ] I was surprised by the AI's actions and want to know what I missed.

---

### Appendix A: Explanation Goodness Checklist (p. 35)

> This checklist is a list of the features that make explanations good, according to the research literature. The reference is to the properties of explanations.
>
> The intended use context is for researchers or domain experts to provide an independent, a priori evaluation of the goodness of explanations that are generated by other researchers or by XAI systems.

*   The explanation helps me **understand** how the [software, algorithm, tool] works.
    [ ] YES [ ] NO
*   The explanation of how the [software, algorithm, tool] works is **satisfying**.
    [ ] YES [ ] NO
*   The explanation of the [software, algorithm, tool] sufficiently **detailed**.
    [ ] YES [ ] NO
*   The explanation of how the [software, algorithm, tool] works is sufficiently **complete**.
    [ ] YES [ ] NO
*   The explanation is **actionable**, that is, it helps me know how to use the [software, algorithm, tool]
    [ ] YES [ ] NO
*   The explanation lets me know how **accurate or reliable** the [software, algorithm] is.
    [ ] YES [ ] NO
*   The explanation lets me know how **trustworthy** the [software, algorithm, tool] is.
    [ ] YES [ ] NO


#### Jian, et al. Scale (2000)

> Regards trust as a trait. Factors: Fidelity, loyalty, reliability, security, integrity, familiarity. Widely used. (Note: Item 4 is noted as particularly interesting; 'integrity' item is considered problematic; 'familiarity' may not be relevant if user experience is known).

1.  The system is deceptive.
2.  The system behaves in an underhanded manner.
3.  I am suspicious of the system's intent, action, or outputs.
4.  I am wary of the system.
5.  The system's actions will have a harmful or injurious outcome.
6.  I am confident in the system.
7.  The system provides security.
8.  The system has integrity.
9.  The system is dependable.
10. I can trust the system.
11. I am familiar with the system.

#### Madsen-Gregor Scale (2000)

> Defines trust as both affective and cognitive. Factors: reliability, technical competence, understandability, faith, personal attachment. Focused on intelligent decision aids. (Note: Original response format not specified, possibly Likert. High reliability reported. 'Understandability' and 'competence' factors relate to mental models. 'Faith' factor relates to reliance/uncertainty. 'Personal attachment' factor relates to liking.)

| Factor                     | Item                                                                                                         |
| :------------------------- | :----------------------------------------------------------------------------------------------------------- |
| **Perceived Reliability**  | The system always provides the advice I require to make my decision.                                           |
|                            | The system performs reliably.                                                                                  |
|                            | The system responds the same way under the same conditions at different times.                               |
|                            | I can rely on the system to function properly.                                                               |
| **Perceived Technical Competence** | The system analyzes problems consistently.                                                                 |
|                            | The system uses appropriate methods to reach decisions.                                                        |
|                            | The system has sound knowledge about this type of problem built into it.                                     |
|                            | The advice the system produces is as good as that which a highly competent person could produce.             |
|                            | The system correctly uses the information I enter.                                                             |
|                            | The system makes use of all the knowledge and information available to it to produce its solution to the problem. |
| **Perceived Understandability** | I know what will happen the next time I use the system because I understand how it behaves.                |
|                            | I understand how the system will assist me with decisions I have to make.                                    |
|                            | Although I may not know exactly how the system works, I know how to use it to make decisions about the problem. |
|                            | It is easy to follow what the system does.                                                                     |
|                            | I recognize what I should do to get the advice I need from the system the next time I use it.                  |
| **Faith**                  | I believe advice from the system even when I don't know for certain that it is correct.                        |
|                            | When I am uncertain about a decision I believe the system rather than myself.                                  |
|                            | If I am not sure about a decision, I have faith that the system will provide the best solution.              |
|                            | When the system gives unusual advice I am confident that the advice is correct.                                |
|                            | Even if I have no reason to expect the system will be able to solve a difficult problem, I still feel certain that it will. |
| **Personal Attachment**    | I would feel a sense of loss if the system was unavailable and I could not longer use it.                      |
|                            | I feel a sense of attachment to using the system.                                                              |
|                            | I find the system suitable to my style of decision making.                                                     |
|                            | I like using the system for decision making.                                                                   |
|                            | I have a personal preference for making decisions with the system.                                             |

#### Merritt Scale (2011)

> Regards trust as an emotional, attitudinal judgement. Factors: belief, confidence, dependability, propensity to trust, liking. Evaluated in a baggage screening task. Items are similar to Cahour-Fourzy.

1.  I believe the system is a competent performer.
2.  I trust the system.
3.  I have confidence in the advice given by the system.
4.  I can depend on the system.
5.  I can rely on the system to behave in consistent ways.
6.  I can rely on the system to do its best every time I take its advice.


-----------


# General Attitudes towards Artificial Intelligence Scale (GAAIS)

Schepman, A., & and Rodway, P. (2023). The General Attitudes towards Artificial Intelligence Scale (GAAIS): Confirmatory Validation and Associations with Personality, Corporate Distrust, and General Trust. International Journal of Human–Computer Interaction, 39(13), 2724–2741. https://doi.org/10.1080/10447318.2022.2085400

## Instructions for participants

We are interested in your attitudes towards Artificial Intelligence. By Artificial Intelligence we mean devices that can perform tasks that would usually require human intelligence. Please note that these can be computers, robots or other hardware devices, possibly augmented with sensors or cameras, etc. Please complete the following scale, indicating your response to each item. There are no right or wrong answers. We are interested in your personal views.

## Response options at presentation (Used in Study 1)

*   Strongly disagree
*   Somewhat disagree
*   Neutral
*   Somewhat agree
*   Strongly agree

## Alternative response options at presentation (Used in Study 2)

*   Strongly disagree
*   Disagree
*   Neutral
*   Agree
*   Strongly agree

## List of items

*(Note: The item order below follows Appendix A; the paper states it was re-randomised for presentation. Subscale is noted for scoring purposes.)*

1.  (Positive) For routine transactions, I would rather interact with an artificially intelligent system than with a human.
2.  (Positive) Artificial Intelligence can provide new economic opportunities for this country.
3.  (Negative) Organisations use Artificial Intelligence unethically.
4.  (Positive) Artificially intelligent systems can help people feel happier.
5.  (Positive) I am impressed by what Artificial Intelligence can do.
6.  (Negative) I think artificially intelligent systems make many errors.
7.  (Positive) I am interested in using artificially intelligent systems in my daily life.
8.  (Negative) I find Artificial Intelligence sinister.
9.  (Negative) Artificial Intelligence might take control of people.
10. (Negative) I think Artificial Intelligence is dangerous.
11. (Positive) Artificial Intelligence can have positive impacts on people's wellbeing.
12. (Positive) Artificial Intelligence is exciting.
A.  (Attention Check) I would be grateful if you could select Strongly agree.
13. (Positive) An artificially intelligent agent would be better than an employee in many routine jobs.
14. (Positive) There are many beneficial applications of Artificial Intelligence.
15. (Negative) I shiver with discomfort when I think about future uses of Artificial Intelligence.
16. (Positive) Artificially intelligent systems can perform better than humans.
17. (Positive) Much of society will benefit from a future full of Artificial Intelligence
18. (Positive) I would like to use Artificial Intelligence in my own job.
19. (Negative) People like me will suffer if Artificial Intelligence is used more and more.
20. (Negative) Artificial Intelligence is used to spy on people


-------



## Surveys and Questionnaires from Smith et al. (2025)

Smith, A., van Wagoner, H. P., Keplinger, K., & Celebi, C. (2025). Navigating AI Convergence in Human–Artificial Intelligence Teams: A Signaling Theory Approach. Journal of Organizational Behavior. https://doi.org/10.1002/job.2856 https://onlinelibrary.wiley.com/doi/pdf/10.1002/job.2856 
https://osf.io/zjwta/?view_only=74a15f71b21c4b0abb69f3e5de543537


## Algorithm Aversion Scale (Developed in Study 3)

**Source:** Section 4.7.2.1, Table 7 (Smith et al., 2025)

**Description:** This scale was developed for Study 3 to measure algorithm aversion. An initial list of 60 content-valid items was generated capturing four hypothesized dimensions (Fear of Inaccuracy, Lack of Trust, Fear of Loss of Control, and Resistance to Change). Participants completed all 60 items. Exploratory factor analysis resulted in a final scale of 45 items across four factors.

**Response Scale:** The specific response scale (e.g., Likert 1-5 or 1-7, Strongly Disagree to Strongly Agree) used for these items was **not explicitly stated** in the provided text sections or Table 7 description.

**Items:**
*(Note: Participants in Study 3 responded to all 60 items listed below for the initial Exploratory Factor Analysis. The factor loadings from Table 7 are indicated. The final measure retained 45 items, typically those with higher or cleaner loadings, often indicated by bolding in the original table note, though precise bolding isn't perfectly clear from OCR. Items are grouped by the factor they primarily loaded onto based on Table 7)*

**Factor 1: Fear of Inaccuracy**
1.  I am concerned about the reliability of algorithms. (Loading: 0.648)
2.  Algorithms could make errors that would negatively impact my life. (Loading: 0.7582)
3.  I feel uncertain about the dependability of algorithm-based decisions. (Loading: 0.6559)
4.  The potential for inaccuracies in algorithmic results worries me. (Loading: 0.7461)
5.  I question the correctness of outcomes produced by algorithms. (Loading: 0.7262)
6.  Algorithms might not handle unexpected situations well. (Loading: 0.7465)
7.  I believe that algorithms can easily misinterpret complex data. (Loading: 0.737)
8.  The risk of error in algorithmic decisions is too high for comfort. (Loading: 0.6523)
9.  Algorithms may not always provide consistent results. (Loading: 0.6921)
10. I am skeptical about the accuracy of algorithms when they process large amounts of data. (Loading: 0.6862)
11. The thought of relying solely on algorithmic accuracy makes me uneasy. (Loading: 0.6815)
12. Algorithms are not infallible and this can lead to serious mistakes. (Loading: 0.6819)
13. I distrust algorithms when the stakes of the decision are high. (Loading: 0.6219)
14. Algorithms could generate incorrect results without any warning signs. (Loading: 0.7461)
15. I am wary of using algorithms for decisions that have long-term consequences. (Loading: 0.6519)
23. I worry about biases embedded in algorithms affecting their judgments. (Loading: 0.4047 - Also loaded on Lack of Trust)
43. I worry about the consequences of errors when control is ceded to algorithms. (Loading: 0.4743)

**Factor 2: Resistance to Change**
39. I prefer decisions made by people because it keeps control within human hands. (Loading: 0.438)
46. I am hesitant to adopt new technologies that rely heavily on algorithms. (Loading: 0.6497)
47. I prefer traditional methods over algorithmic solutions. (Loading: 0.8141)
48. The pace of change toward more algorithm use is concerning. (Loading: 0.622)
49. I am skeptical about replacing human roles with algorithms. (Loading: 0.5336)
50. I prefer the way things were done before algorithms were involved. (Loading: 0.8686)
51. Rapid technological changes involving algorithms are unsettling. (Loading: 0.6641)
52. I resist changes that involve using algorithms in my daily activities. (Loading: 0.7925)
53. I believe that some things are better left unchanged, especially regarding algorithm use. (Loading: 0.6663)
54. The movement toward algorithm-driven processes is too fast for my comfort. (Loading: 0.7089)
55. I am cautious about the increasing reliance on algorithms in professional settings. (Loading: 0.6269)
56. I prefer to stick to methods that have proven successful over time rather than adopting new algorithmic techniques. (Loading: 0.8912)
57. I am wary of changes that could make algorithms central to my life or work. (Loading: 0.7064)
58. I am not ready to embrace the widespread use of algorithms. (Loading: 0.8122)
59. I find it difficult to accept the shift from human expertise to algorithmic control. (Loading: 0.8074)
60. The trend toward automating more with algorithms does not sit well with me. (Loading: 0.7914)

**Factor 3: Loss of Control**
31. Relying on algorithms makes me feel like I am losing control over decisions. (Loading: 0.5915)
32. I prefer to keep important decision-making processes directly under human control. (Loading: 0.5915)
33. Algorithms taking over tasks leave me feeling helpless. (Loading: 0.6165)
34. I am uneasy about delegating critical decisions to algorithms. (Loading: 0.6165)
35. I believe that excessive use of algorithms can erode personal autonomy. (Loading: 0.4447 - *Not marked bold in source*)
36. Algorithms decide too much, too quickly, reducing my control. (Loading: 0.6547)
37. I am concerned about becoming overly dependent on algorithms. (Loading: 0.6418)
38. Using algorithms feels like putting my fate in the hands of a machine. (Loading: 0.5138)
40. The use of algorithms in decision-making processes makes me feel disconnected. (Loading: 0.6046)
45. The shift toward algorithmic decision-making diminishes individual influence. (Loading: 0.4004)

**Factor 4: Lack of Trust**
16. I do not trust algorithms to understand my individual needs. (Loading: 0.4031)
17. Algorithms lack the human insight necessary for many decisions. (Loading: 0.4067)
18. I find it hard to trust a process I cannot easily understand or see. (Loading: 0.6)
19. I am not confident in algorithms to handle tasks that require emotional sensitivity. (Loading: 0.4881)
20. The impersonal nature of algorithms makes them hard to trust. (Loading: 0.6629)
21. I feel that algorithms do not have the capability to adapt to new or evolving situations. (Loading: 0.5061)
22. Algorithms are not transparent enough for me to trust their decisions. (Loading: 0.5947)
24. Trusting algorithms with personal information makes me uncomfortable. (Loading: 0.4584)
25. I am skeptical about the fairness of algorithmic decisions. (Loading: 0.5247)
26. Algorithms do not provide the rationale for their decisions, which diminishes my trust. (Loading: 0.4482)
27. I am concerned that algorithms prioritize efficiency over ethical considerations. (Loading: 0.4473 - *Not marked bold in source*)
28. Algorithms cannot be held accountable in the same way humans can. (Loading: 0.4473)
29. I distrust algorithms because I cannot negotiate or reason with them. (Loading: 0.5247)
30. The idea of algorithms making decisions without human oversight is troubling to me. (Loading: 0.4482)
41. I think that algorithms can make choices that aren’t in my best interest. (*Not marked bold in source*)
42. Algorithms reduce the human touch in decisions that affect me. (Loading: 0.4743)
44. I am reluctant to accept decisions made without human involvement. (Loading: 0.4004)

---

## Other Scales Mentioned (Items Not Provided in Text)

The following scales were used in the studies, but their specific items were not listed in the provided text. Only the source and sample items (where available) were mentioned.

1.  **Trust in AI (Study 1, 2, 3, 4)**
    *   **Source:** Merritt (2011), modified for the specific context (facial recognition or CV screening).
    *   **Description:** Measures trust in the AI system.
    *   **Sample Items (from Section 4.1.3.6):** "I believe facial recognition systems are competent performers,” “I have confidence in the advice given by facial recognition systems," and "I can rely on facial recognition systems to do its best every time I take its advice."
    *   **Response Scale:** 1 (strongly disagree) to 5 (strongly agree).

2.  **Explicit Gender Bias (Study 1, 2, 3, 4)**
    *   **Source:** Swim et al. (1995).
    *   **Description:** Measures explicit bias related to gender.
    *   **Sample Items (from Section 4.1.3.7):** "On average, people in our society treat men and women equally" and "Society has reached the point where women and men have equal opportunities for achievement."
    *   **Response Scale:** 1 (strongly disagree) to 7 (strongly agree).

3.  **Explicit Racial Bias (Study 1, 2, 3, 4)**
    *   **Source:** Uhlmann, Brescoll, and Machery (2010).
    *   **Description:** Measures explicit bias related to race/ethnicity.
    *   **Sample Items (from Section 4.1.3.8):** "If your personal safety is at stake, it's sensible to avoid members of ethnic groups known to behave more aggressively" and "Law enforcement officers should act as if members of all racial groups are equally likely to commit crimes."
    *   **Response Scale:** 1 (strongly disagree) to 7 (strongly agree).

------



## Sun, N. (2023). Delegation to Virtual Agents

Sun, N. (2023). Delegation to Virtual Agents in Critical Scenarios: Influencing Factors and Immersive Settings [University of Luxembourg]. https://orbilu.uni.lu/handle/10993/58847

Sun, N., Botev, J., Khaluf, Y., & Simoens, P. (2022). Theory of Mind and Delegation to Robotic Virtual Agents. 2022 31st IEEE 

### Table 6.1: Questionnaire items (attention checks excluded)

1.  Winning the bonus reward is a critical task to me.
2.  I intend to delegate the succeeding games to the agent.
3.  The agent is deceptive.
4.  The agent behaves in an underhanded manner.
5.  I am suspicious of the agent’s intent, action, or outputs.
6.  I am wary of the agent.
7.  The agent’s actions will have a harmful or injurious outcome.
8.  I am confident in the agent.
9.  The agent provides security.
10. The agent has integrity.
11. The agent is dependable.
12. The agent is reliable.
13. I can trust the agent.
14. I am familiar with the agent.

> Measured factors: task criticality (#1), intention to delegate (#2), and trust (#3–14).
> Response scale: 7-point Likert scale (inferred from text on page 59).

### Table 7.1: The condition-wise questionnaire

1.  The agent in the last rounds was trustworthy.
2.  The agent in the last rounds was competent in the game.
3.  I felt cognitively overloaded in the last rounds.
4.  I felt immersed or involved in the game over the last rounds.

> Measured factors: trustworthiness (#1), competence (#2), workload (#3), and psychological immersion (#4). Regarding item 4, research suggests that people can “reliably reflect their own immersion in a single question” [Jennett et al., 2008].
> Response scale: 101-point scale (0 = "strongly disagree" to 1 = "strongly agree") (from text on page 81).

### Table 7.2: The post-experiment questionnaire (Experiment 1)

1.  The game outcome is important to me.
2.  The agents felt controllable.
3.  I must account for the game outcome.
4.  Which agent did you find most trustworthy?

> Measured factors: criticality (#1), controllability (#2), accountability (#3), and trustworthiness (#4).

### Table 7.3: The post-experiment questionnaire (Experiment 2)

1.  The agent felt deceptive.
2.  The agent behaved in a dishonest manner.
3.  I was suspicious of the agent’s intent, action, or outputs.
4.  I was wary of the agent.
5.  I thought that delegating to the agent would lead to a negative outcome.
6.  I was confident in the agent.
7.  The agent has integrity.
8.  The agent felt dependable.
9.  The agent felt reliable.
10. I can trust the agent.
11. I felt emotionally close to the agent.
12. I like the agent.
13. I felt that I had a connection with the agent.
14. The agent felt warm and caring.
15. The agent appeared unattractive.
16. Predicting stock price trends felt difficult or challenging.
17. It was important for me to retain control of the prediction decision.
18. I can make better predictions than the agent.
19. Sometimes I chose to delegate simply because the game was boring.

> Measured factors: trust (#1–10), perceived rapport (#11–15), task difficulty (#16), the desire to control (#17), self-confidence (#18), and boredom (#19).
> Response scale: 7-point Likert scale (from text on page 90).

### Table 8.1: Questionnaire items

1.  The agent was deceptive.
2.  The agent behaved in a dishonest manner.
3.  I was suspicious of the agent’s intent, action, or outputs.
4.  I was wary of the agent.
5.  I think that the agent’s behaviors will have a negative outcome.
6.  I was confident in the agent.
7.  The agent has integrity.
8.  The agent was dependable.
9.  The agent was reliable.
10. I can trust the agent.
11. The agent’s presence was obvious to me.
12. The agent caught my attention.
13. I was easily distracted from the agent when other things were going on.
14. I felt that the agent was watching me and was aware of my presence.
15. The thought that the agent is not a real person often crossed my mind.
16. The agent appeared to be conscious and alive to me.
17. I perceived the agent as being only a computerized image, not a real person.
18. The agent played well.
19. I had to think a lot when playing the game.
20. The game was easy.
21. The outcome of the next rounds is important to me.
22. I feel responsible for the outcome of the next rounds.

> Measured factors: trust (#1–10), co-presence (#11–13), social presence (#14–17), agent performance (#18), mental workload (#19), task difficulty (#20), task criticality (#21), and task accountability (#22).
> Response scale: 7-point Likert scale (1 = "strongly disagree" to 7 = "strongly agree") (from text on page 109).

### Table 8.2: Manipulation check items

1.  How close (emotionally, not physically) did you feel toward the agent?
2.  I liked the agent.
3.  I thought that the agent found me likable.
4.  The agent was weird.
5.  I felt that I had a connection with the agent.
6.  I felt uncomfortable during the interaction with the agent.
7.  The agent felt warm and caring.
8.  The agent was unattractive.

> Measured factor: perceived rapport (#1–8). Item 1 was answered on the Inclusion of Other scale [Aron et al., 1992].
> Response scale: 7-point Likert scale (1 = "strongly disagree" to 7 = "strongly agree") for items #2-8; Inclusion of Other scale for item #1 (from text on page 109).


------
