


# Summary Report of AI-Related Survey Instruments

This report organizes and summarizes various survey instruments related to Artificial Intelligence (AI), drawing from the provided list of references and associated details. The instruments are categorized based on their primary focus.

---

## 1. AI Literacy Scales

Instruments designed to measure knowledge, understanding, skills, and competencies related to AI.

### 1.1. MAILS - Meta-Artificial Intelligence Literacy Scale
* **Reference:** Carolus, A., Koch, M. J., Straka, S., Latoschik, M. E., & Wienrich, C. (2023). MAILS - Meta AI literacy scale: Development and testing of an AI literacy questionnaire based on well-founded competency models and psychological change- and meta-competencies. *Computers in Human Behavior: Artificial Humans, 1*(2), 100014. https://doi.org/10.1016/j.chbah.2023.100014
* **Description:** A comprehensive scale measuring AI literacy based on competency models and psychological meta-competencies.
* **Constructs:** AI Literacy (Use & Apply, Know & Understand, Detect AI, AI Ethics), Create AI, AI Self-Efficacy (Problem-Solving, Learning), AI Self-Competency (Persuasion Literacy, Emotion Regulation).
* **Details:** 34 items rated on an 11-point scale (0-10).
* **Link:** https://hci.uni-wuerzburg.de/research/MAILS/

### 1.2. MAILS - Short Version
* **Reference:** Koch, M. J., Carolus, A., Wienrich, C., & Latoschik, M. E. (2024). Meta AI literacy scale: Further validation and development of a short version. *Heliyon, 10*(21), e39686. https://doi.org/10.1016/j.heliyon.2024.e39686
* **Description:** A validated short form of the MAILS.
* **Constructs:** AI Literacy (Detect, Apply, Understand, Ethics), Create AI, AI Self-Efficacy (Learning, Problem-Solving), AI Self-Competency (Persuasion Literacy, Emotion Regulation).
* **Details:** 10 items rated on an 11-point scale (0-10). 

### 1.3. Tully, Longoni, & Appel (2023) AI Literacy Measure (25-Item)
* **Reference:** Tully, S., Longoni, C., & Appel, G. (2023). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. OSF. https://doi.org/10.31234/osf.io/t9u8g (Used in Studies 2, 4, 6)
* **Description:** Measures objective AI literacy through multiple-choice questions covering various AI concepts.
* **Details:** 25 multiple-choice questions. Full items available in Appendix A of the source file (`Tully25_AI_Survey.md`).

### 1.4. Tully, Longoni, & Appel (2023) AI Literacy Measure (17-Item)
* **Reference:** Tully, S., Longoni, C., & Appel, G. (2023). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. OSF. https://doi.org/10.31234/osf.io/t9u8g (Used in Studies 3, 5, 7)
* **Description:** A shorter version measuring objective AI literacy through multiple-choice questions, structured by competencies from Long and Magerko (2020).
* **Details:** 17 multiple-choice questions. Full items available in Appendix B of the source file (`Tully25_AI_Survey.md`).

### 1.5. Rheu & Cho (2025) AI Literacy Measure
* **Reference:** Rheu, M. (MJ), & Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–7. https://doi.org/10.1145/3706599.3719681
* **Description:** Combines items from Ng et al. (2024) and Pinski & Benlian (2023) to measure AI literacy in college students using LLMs.
* **Constructs:** Self-Efficacy, Cognitive Learning, AI Technology Knowledge, AI-Steps Knowledge.
* **Details:** Items rated on a 7-point Likert scale (Strongly disagree to Strongly agree). 

### 1.6. AI Literacy Questionnaire (AILQ)
* **Reference:** Ng, D. T. K., Wu, W., Leung, J. K. L., Chiu, T. K. F., & Chu, S. K. W. (2024). Design and validation of the AI literacy questionnaire: The affective, behavioural, cognitive and ethical approach. *British Journal of Educational Technology, 55*(3), 1082–1104. https://doi.org/10.1111/bjet.13411
* **Description:** Measures AI literacy across affective, behavioral, cognitive, and ethical dimensions.
* **Constructs:** Affective (Intrinsic Motivation, Self-Efficacy, Confidence), Behavioral (Commitment, Collaboration), Cognitive (Know & Understand, Apply/Evaluate/Create), Ethical (AI Ethics).
* **Details:** Developed with an initial pool of items, validated version likely uses a subset. Response scale typically Likert-type. 

### 1.7. Weber et al. (2023) Objective Measurement Scale
* **Reference:** Weber, P., Pinski, M., & Baum, L. (2023). Toward an Objective Measurement of AI Literacy. *PACIS 2023 Proceedings*. https://aisel.aisnet.org/pacis2023/60/
* **Description:** Measures objective AI literacy using multiple-choice questions covering socio-user, socio-creator/evaluator, technical-user, and technical-creator/evaluator aspects.
* **Details:** 16 multiple-choice questions. 

### 1.8. Scale for the assessment of non-experts’ AI literacy (SNAIL)
* **Reference:** Laupichler, M. C., Aster, A., Haverkamp, N., & Raupach, T. (2023). Development of the “Scale for the assessment of non-experts’ AI literacy” – An exploratory factor analysis. *Computers in Human Behavior Reports, 12*, 100338. https://doi.org/10.1016/j.chbr.2023.100338
* **Description:** Measures self-perceived AI literacy among non-experts. Developed via Delphi study and EFA.
* **Details:** Final scale has 31 items (reduced from 39) rated on a 7-point Likert scale (Strongly disagree to Strongly agree). Initial 39 items available in the source file (`Laupichler_AI_Survey.md`).

### 1.9. Morrill & Noetel (2023) Subjective AI Literacy Scale
* **Reference:** Morrill, J., & Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc
* **Description:** A brief subjective measure of AI literacy adapted from Laupichler et al. (2023).
* **Details:** 6 items rated on a 7-point Likert scale (Strongly disagree to Strongly agree), plus an attention check. Items available in the source file (`Morrill23_AI_Survey.md`).

### 1.10. Morrill & Noetel (2023) Objective AI Literacy Scale
* **Reference:** Morrill, J., & Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc
* **Description:** A brief objective measure of AI literacy developed for the study, partly adapted from Weber et al. (2023).
* **Details:** 5 multiple-choice questions with an "I'm not sure" option. Items available in the source file (`Morrill23_AI_Survey.md`).

### 1.11. The Scale of Artificial Intelligence Literacy for all (SAIL4ALL)
* **Reference:** Soto-Sanfiel, M. T., Angulo-Brunet, A., & Lutz, C. (2024). The Scale of Artificial Intelligence Literacy for all (SAIL4ALL): A Tool for Assessing Knowledge on Artificial Intelligence in All Adult Populations and Settings. OSF. https://doi.org/10.31235/osf.io/bvyku
* **Description:** Assesses AI knowledge suitable for diverse adult populations, covering fundamental concepts, capabilities, mechanisms, and ethics.
* **Themes:** What is AI? (Recognizing/Understanding, General/Narrow), What can AI do?, How does AI Work? (Representation, Reasoning, Learning, Data, Human Role, Action/Reaction, Sensors), How should AI be used? (Ethics).
* **Details:** 59 items. Can be used with True/False or a 5-point confidence scale. Full items available in the source file (`Soto-Sanfiel_AI_Survey.md`).

### 1.12. Puppart & Aru (2025) AI Literacy Self-Assessment
* **Reference:** Puppart, B., & Aru, J. (2025). Short-term AI literacy intervention does not reduce over-reliance on incorrect ChatGPT recommendations (No. arXiv:2503.10556). arXiv. https://doi.org/10.48550/arXiv.2503.10556
* **Description:** A brief self-assessment used post-intervention to gauge perceived changes in understanding of ChatGPT's workings, limitations/risks, and wise usage.
* **Details:** 3 items rated on a 4-point forced-choice Likert scale. Items available in the source file (`Puppart_Aru25_AI_Survey.md`).

---

## 2. AI Attitude Scales

Instruments measuring general feelings, beliefs, and evaluations towards AI.

### 2.1. Attitude Towards Artificial Intelligence (ATAI) Scale
* **Reference:** Sindermann, C., Sha, P., Zhou, M., Wernicke, J., Schmitt, H. S., Li, M., Sariyska, R., Stavrou, M., Becker, B., & Montag, C. (2021). Assessing the Attitude Towards Artificial Intelligence: Introduction of a Short Measure in German, Chinese, and English Language. *KI - Künstliche Intelligenz, 35*(1), 109–118. https://doi.org/10.1007/s13218-020-00689-0
* **Description:** A brief scale measuring general attitude towards AI, focusing on fear, trust, and perceived impact (benefit/destruction, job losses).
* **Details:** 5 items rated on an 11-point Likert scale (0-10). 

### 2.2. AI Attitude Scale (AIAS-4)
* **Reference:** Grassini, S. (2023). Development and validation of the AI attitude scale (AIAS-4): a brief measure of general attitude toward artificial intelligence. *Frontiers in Psychology, 14*. https://doi.org/10.3389/fpsyg.2023.1191628
* **Description:** A very brief measure of general positive attitude toward AI.
* **Details:** 4 items rated on a 10-point Likert scale (1-10). 

### 2.3. Attitudes Towards Artificial Intelligence Scale (ATTARI-12)
* **Reference:** Stein, J.-P., Messingschlager, T., Gnambs, T., Hutmacher, F., & Appel, M. (2024). Attitudes towards AI: Measurement and associations with personality. *Scientific Reports, 14*(1), 2909. https://doi.org/10.1038/s41598-024-53335-2
* **Description:** Measures attitudes towards AI across cognitive, affective, and behavioral dimensions, balanced for positive and negative valence.
* **Constructs:** Cognitive (Positive/Negative), Affective (Positive/Negative), Behavioral (Positive/Negative).
* **Details:** 12 items rated on a 5-point Likert scale (Strongly disagree to Strongly agree). Items available in the source file (`Stein24_AI_Survey.md`).

### 2.4. Gnambs et al. (2025) Domain-Specific AI Attitudes
* **Reference:** Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., & Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. *Telematics and Informatics, 98*, 102265. https://doi.org/10.1016/j.tele.2025.102265
* **Description:** Measures cognitive, affective, and behavioral attitudes towards AI within specific domains (Work, Healthcare, Education).
* **Details:** 9 items (3 per domain) rated on a 5-point scale (0-4), plus a "cannot answer" option. Items available in the source file (`Gnabs_AI_Survey.md`).

### 2.5. Perceptions on AI by the Citizens of Europe questionnaire (PAICE) - Attitude Items
* **Reference:** Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., & Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. *IEEE Transactions on Artificial Intelligence, 6*(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633
* **Description:** Includes items assessing general attitude towards AI (Q2) and attitudes towards AI use in specific sectors (Q8: Healthcare, Insurance, Agriculture, Finance, Military, Law Enforcement, Environmental, Transportation, Manufacturing, HR).
* **Details:** Items rated on 5-point scales (Strongly disapprove to Strongly approve). Full questionnaire available in the source file (`Scantamburlo_AI_Survey.md`).

### 2.6. Zhang & Dafoe (2019) Support for Developing AI
* **Reference:** Zhang, B., & Dafoe, A. (2019). Artificial Intelligence: American Attitudes and Trends. *SSRN Electronic Journal*. https://doi.org/10.2139/ssrn.3312874
* **Description:** Measures general support or opposition to the development of AI after presenting examples of AI applications.
* **Details:** 1 item rated on a 5-point scale (Strongly oppose to Strongly support), plus "I don't know". Item available in the source file (`Zhang_Dafoe_AI_Survey.md`).

---

## 3. AI Trust & Reliance Scales

Instruments measuring trust, confidence, and reliance on AI systems or automation in general.

### 3.1. Scale of Trust in Automated Systems (Jian, Bisantz, & Drury, 2000) / Trust Perception Scale - AI (TPA)
* **Reference:** Jian, J.-Y., Bisantz, A. M., & Drury, C. G. (2000). Foundations for an Empirically Determined Scale of Trust in Automated System. *International Journal of Cognitive Ergonomics, 4*(1), 53–71. https://doi.org/10.1207/S15327566IJCE0401_04 (Also used/cited in Adams et al., 2003; Scharowski et al., 2025)
* **Description:** A widely used scale measuring trust in automated systems, often adapted for AI contexts (as TPA). Assesses aspects like deceptiveness, suspicion, confidence, integrity, dependability, reliability, and familiarity.
* **Details:** 12 items rated on a 7-point scale (Not at all to Extremely).

### 3.2. Shang et al. (2025) Affective and Cognitive Trust Scale
* **Reference:** Shang, R., & Hsieh, G. (2025). Trusting Your AI Agent Emotionally and Cognitively: Development and Validation of a Semantic Differential Scale for AI Trust. *Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society*, 1343–1356.
* **Description:** A semantic differential scale designed to measure distinct cognitive (reliability, competence, understandability, integrity) and affective (empathy, sensitivity, care, altruism, responsiveness, etc.) dimensions of trust in AI agents.
* **Constructs:** Cognitive Trust (18 items), Affective Trust (9 items).
* **Details:** 27 bipolar adjective pairs rated on a 7-point semantic differential scale (-3 to +3). Items available in the source file (`Shang25_AI_Trust_Scale.md`).

### 3.3. Trust in Automation (TiA) Questionnaire
* **Reference:** Körber, M. (2019). Theoretical Considerations and Development of a Questionnaire to Measure Trust in Automation. In S. Bagnara, et al. (Eds.), *Proceedings of the 20th Congress of the International Ergonomics Association (IEA 2018)* (Vol. 823, pp. 13–30). Springer. http://link.springer.com/10.1007/978-3-319-96074-6_2
* **Description:** Measures trust in automation based on theoretical considerations, including reliability/competence, understanding/predictability, familiarity, intention of developers, and propensity to trust.
* **Constructs:** Reliability/Competence, Understanding/Predictability, Familiarity, Intention of Developers, Propensity to Trust, Trust in Automation.
* **Details:** 19 items rated on a 5-point Likert scale (Strongly disagree to Strongly agree), with some reverse-coded. 

### 3.4. Propensity to Trust in Automated Technology (PTT-A) Scale
* **Reference:** Scholz, D. D., Kraus, J., & Miller, L. (2025). Measuring the Propensity to Trust in Automated Technology: Examining Similarities to Dispositional Trust in Other Humans and Validation of the PTT-A Scale. *International Journal of Human–Computer Interaction, 41*(2), 970–993. https://doi.org/10.1080/10447318.2024.2307691
* **Description:** Measures an individual's general tendency (disposition) to trust automated technology, mirroring scales for trust in humans. Includes a short form.
* **Constructs:** Trusting Stance, Competence, Benevolence, Integrity.
* **Details:** 14 items (6 bolded for short scale) rated on a 5-point Likert scale (Strongly disagree to Strongly agree), with some reverse-coded. 

### 3.5. Trust-In-LLMs Index (TILLMI)
* **Reference:** Duro, E. S. D., Veltri, G. A., Golino, H., & Stella, M. (2025). Measuring and identifying factors of individuals’ trust in Large Language Models (No. arXiv:2502.21028). arXiv. https://doi.org/10.48550/arXiv.2502.21028
* **Description:** Measures trust specifically in Large Language Models (LLMs), focusing on closeness/ease of sharing and reliance/competence.
* **Constructs:** Closeness with LLMs, Reliance on LLMs.
* **Details:** Final scale has 6 items (reduced from 8) rated on a 5-point frequency scale (Never experience it to Always experience it). Items available in the source file (`Duro_AI_Survey.md`).

### 3.6. Morrill & Noetel (2023) Trust in AI Scale
* **Reference:** Morrill, J., & Noetel, M. (2023). A short-form AI literacy intervention can reduce over-reliance on AI. OSF. https://doi.org/10.31234/osf.io/hv9qc
* **Description:** Measures willingness to trust, rely on, and depend on AI systems, adapted from Gillespie et al. (2023).
* **Details:** 6 items rated on a 7-point Likert scale (Completely Unwilling to Completely Willing). Items available in the source file (`Morrill23_AI_Survey.md`).

### 3.7. Kim et al. (2024) Trust Beliefs & Intentions
* **Reference:** Kim, S. S. Y., Liao, Q. V., Vorvoreanu, M., Ballard, S., & Vaughan, J. W. (2024). “I’m Not Sure, But...”: Examining the Impact of Large Language Models’ Uncertainty Expression on User Reliance and Trust (No. arXiv:2405.00623). arXiv. https://doi.org/10.48550/arXiv.2405.00623
* **Description:** Measures trust beliefs (competence, honesty, benevolence) and trust intentions (reliance, comfort acting on info) towards a specific AI system experienced in a task.
* **Constructs:** TrustBelief, TrustIntention.
* **Details:** 10 items (6 belief, 4 intention) rated on a 5-point Likert scale (Strongly disagree to Strongly agree), some reverse-coded.

### 3.8. Scharowski et al. (2025) Single Trust/Use Items
* **Reference:** Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., & Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No. arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582
* **Description:** Simple, direct measures of trust and willingness to use an AI after observing it in a specific scenario (Self-Driving Vehicle or Chatbot).
* **Details:** 2 items ("I would trust...", "I would use...") rated on a 7-point Likert scale (Fully disagree to Fully agree). 

### 3.9. Scharowski et al. (2025) Situation-Specific Trust Scales (STS-AD / STS-Chatbot)
* **Reference:** Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., & Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No. arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582
* **Description:** Measures trust and evaluation of AI performance within the specific context of the observed scenario (Self-Driving Vehicle or Chatbot). Includes comparative judgment (vs. self), perceived safety, and appropriateness.
* **Details:** 6 items for STS-AD, 8 items for STS-Chatbot, rated on a 7-point Likert scale (Fully disagree to Fully agree). 

### 3.10. Trust in Explainable AI (TXAI) Items (Adapted by Scharowski et al., 2025)
* **Reference:** Scharowski, N., Perrig, S. A. C., Aeschbach, L. F., Felten, N. von, Opwis, K., Wintersberger, P., & Brühlmann, F. (2025). To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI (No. arXiv:2403.00582). arXiv. https://doi.org/10.48550/arXiv.2403.00582 (Adapted from original source, likely related to explainability literature).
* **Description:** Measures confidence, predictability, reliability, safety, efficiency, wariness, perceived competence (vs. novice human), and liking for decision-making regarding an observed AI.
* **Details:** 8 items rated on a 5-point Likert scale (I disagree strongly to I agree strongly). 

### 3.11. PAICE Questionnaire - Trust Items
* **Reference:** Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., & Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. *IEEE Transactions on Artificial Intelligence, 6*(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633
* **Description:** Includes items assessing the importance of various measures (laws, certifications, monitoring, codes of conduct, transparency, diverse teams) for increasing trust in AI (Q12), and trust in different entities (governments, EU, universities, CSOs, tech companies, social media) to ensure AI serves public interest (Q14).
* **Details:** Items rated on 5-point scales (Not important at all to Very important; Not at all to A lot). Full questionnaire available in the source file (`Scantamburlo_AI_Survey.md`).

### 3.12. Gerlich (2025) AI Trust Item
* **Reference:** Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. *Societies, 15*(1), Article 1. https://doi.org/10.3390/soc15010006
* **Description:** Includes a single item assessing trust in recommendations provided by AI tools.
* **Details:** Item 9: "I trust the recommendations provided by AI tools." Rated on a 6-point Likert scale (Strongly Disagree to Strongly Agree). 

### 3.13. Madsen & Gregor (2000) Human-Computer Trust Instrument
* **Reference:** Madsen, M., & Gregor, S. (2000). Measuring Human-Computer Trust. *Proceedings of the 11th Australasian Conference on Information Systems*. (As cited/used in Adams et al., 2003).
* **Description:** Measures trust in computer systems (potentially applicable to AI) across dimensions of reliability, technical competence, understandability, faith, and personal attachment.
* **Constructs:** Perceived Reliability, Perceived Technical Competence, Perceived Understandability, Faith, Personal Attachment.
* **Details:** 25 items (5 per construct). Original response scale not specified in the Adams et al. 

### 3.14. SHAPE Automation Trust Index (SATI v0.3)
* **Reference:** Goillau, P., Kelly, M., Boardman, J., & Jeannot, E. (2001). *SHAPE Automation Trust Index (SATI v0.3)*. Eurocontrol Experimental Centre. (As cited/used in Adams et al., 2003).
* **Description:** A two-part index assessing trust and confidence in a simulated automated system before and after interaction, including reasons for trust/confidence levels.
* **Details:** Includes rating scales (Bad-OK-Good, None-OK-Full confidence), Yes/No trust question, and open-ended reasons. Administered pre- and post-simulation. 
---

## 4. AI Perception & Experience Scales

Instruments measuring how AI is perceived, user experiences, and related psychological constructs.

### 4.1. Chen et al. (2025) Mental Capacity Attribution
* **Reference:** Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., & Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–14. https://doi.org/10.1145/3706599.3719710
* **Description:** Measures the extent to which people attribute various mental capacities (related to Body, Heart, Mind) to LLMs. Based on Weisman et al. (2017) with additions.
* **Details:** 40 items rated on a 7-point capability scale (Not at all capable to Highly capable). 

### 4.2. Chen et al. (2025) Anthropomorphism Measure
* **Reference:** Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., & Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–14. https://doi.org/10.1145/3706599.3719710
* **Description:** Measures perceived human-likeness of LLMs.
* **Details:** 1 item rated on a 7-point scale (Not human-like at all to Very human-like), plus an open-ended explanation. 
### 4.3. Kim et al. (2024) Anthropomorphism Measure
* **Reference:** Kim, S. S. Y., Liao, Q. V., Vorvoreanu, M., Ballard, S., & Vaughan, J. W. (2024). “I’m Not Sure, But...”: Examining the Impact of Large Language Models’ Uncertainty Expression on User Reliance and Trust (No. arXiv:2405.00623). arXiv. https://doi.org/10.48550/arXiv.2405.00623
* **Description:** Measures impression of an AI system using semantic differential scales related to human-likeness.
* **Details:** 4 bipolar adjective pairs (Fake-Natural, Machinelike-Humanlike, Unconscious-Conscious, Artificial-Lifelike) rated on a 5-point scale. 

### 4.4. General Self-Efficacy Scale for use with Artificial Intelligence (GSE-6AI)
* **Reference:** Morales-García, W. C., Sairitupa-Sanchez, L. Z., Morales-García, S. B., & Morales-García, M. (2024). Adaptation and psychometric properties of a brief version of the general self-efficacy scale for use with artificial intelligence (GSE-6AI) among university students. *Frontiers in Education, 9*. https://doi.org/10.3389/feduc.2024.1293437
* **Description:** Measures perceived self-efficacy in using AI, adapted from the general self-efficacy scale.
* **Details:** 6 items rated on a 4-point scale (Not at all true to Exactly true).

### 4.5. Chen et al. (2025) Self-Efficacy Items
* **Reference:** Chen, A., Kim, S. S. Y., Dharmasiri, A., Russakovsky, O., & Fan, J. E. (2025). Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–14. https://doi.org/10.1145/3706599.3719710
* **Description:** Includes items measuring confidence in learning to program LLMs and getting LLMs to perform desired tasks.
* **Details:** 2 items rated on a 7-point Likert scale (Strongly Disagree to Strongly Agree). 

### 4.6. Gnambs et al. (2025) AI Experience & Familiarity
* **Reference:** Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., & Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. *Telematics and Informatics, 98*, 102265. https://doi.org/10.1016/j.tele.2025.102265
* **Description:** Assesses familiarity (how often heard of) and past 12-month experience with specific AI scenarios/types (virtual assistants, recommender systems, robots, predictive analytics, monitoring, content generation) across different domains (workplace, healthcare, education).
* **Details:** Questions rated on 5-point scales (0-4). 

### 4.7. PAICE Questionnaire - Awareness & Competency Items
* **Reference:** Scantamburlo, T., Cortés, A., Foffano, F., Barrué, C., Distefano, V., Pham, L., & Fabris, A. (2025). Artificial Intelligence Across Europe: A Study on Awareness, Attitude and Trust. *IEEE Transactions on Artificial Intelligence, 6*(2), 477–490. https://doi.org/10.1109/TAI.2024.3461633
* **Description:** Includes items assessing self-rated competency on AI (Q1), perceived impact on daily life (Q3, Q15), awareness of European AI initiatives (Q4), awareness of interacting with AI (Q5), and identification of AI in common applications (Q6).
* **Details:** Various scales (5-point Likert, Yes/No, Multiple Choice). 

### 4.8. Lee et al. (2024) Prediction Believability Evaluation
* **Reference:** Lee, E., Pataranutaporn, P., Amores, J., & Maes, P. (2024). *Super-intelligence or Superstition? Exploring Psychological Factors Influencing Belief in AI Predictions about Personal Behavior* (No. arXiv:2408.06602). arXiv. https://doi.org/10.48550/arXiv.2408.06602
* **Description:** Measures the perceived validity, personalization, reliability, and usefulness of predictions about personal behavior attributed to different sources (AI, Astrology, Personality).
* **Constructs:** Validity, Personalization, Reliability, Usefulness.
* **Details:** 8 items (2 per construct) rated on a 7-point Likert scale (Strongly disagree to Strongly agree). 

### 4.9. Lee et al. (2024) Perception of Prediction Methods
* **Reference:** Lee, E., Pataranutaporn, P., Amores, J., & Maes, P. (2024). *Super-intelligence or Superstition? Exploring Psychological Factors Influencing Belief in AI Predictions about Personal Behavior* (No. arXiv:2408.06602). arXiv. https://doi.org/10.48550/arXiv.2408.06602
* **Description:** Measures agreement with statements about the accuracy of predictions based on personality type, astrology, AI models, and past behavior.
* **Details:** 4 items rated on a 7-point Likert scale (Strongly disagree to Strongly agree). 

### 4.10. Ovsyannikova et al. (2025) Perceived Compassion & Responsiveness
* **Reference:** Ovsyannikova, D., De Mello, V. O., & Inzlicht, M. (2025). Third-party evaluators perceive AI as more compassionate than expert humans. *Communications Psychology, 3*(1). https://doi.org/10.1038/s44271-024-00182-6
* **Description:** Measures third-party evaluations of compassion (reflecting emotion, compassionate, impersonal) and responsiveness (understanding, validation, caring) in responses (from humans or AI) to empathy prompts.
* **Details:** Items rated on a 5-point Likert scale (Strongly Disagree to Strongly Agree). 

### 4.11. Fang et al. (2025) Emotional Dependence & Problematic Use
* **Reference:** Fang, C. M., Liu, A. R., Danry, V., Lee, E., Chan, S. W. T., Pataranutaporn, P., Maes, P., Phang, J., Lampe, M., Ahmad, L., & Agarwal, S. (2025). How AI and Human Behaviors Shape Psychosocial Effects of Chatbot Use: A Longitudinal Randomized Controlled Study (No. arXiv:2503.17473). arXiv. https://doi.org/10.48550/arXiv.2503.17473
* **Description:** Measures emotional dependence on AI chatbots (ADS-9 adapted) and problematic use patterns (PCUS).
* **Constructs:** Emotional Dependence, Problematic Use.
* **Details:** Items rated on a 5-point Likert scale (Disagree to Agree). 

### 4.12. Fang et al. (2025) Impressions of Agent(s)
* **Reference:** Fang, C. M., Liu, A. R., Danry, V., Lee, E., Chan, S. W. T., Pataranutaporn, P., Maes, P., Phang, J., Lampe, M., Ahmad, L., & Agarwal, S. (2025). How AI and Human Behaviors Shape Psychosocial Effects of Chatbot Use: A Longitudinal Randomized Controlled Study (No. arXiv:2503.17473). arXiv. https://doi.org/10.48550/arXiv.2503.17473
* **Description:** Measures user impressions of AI agent(s) after interaction, focusing on understanding, expertise, balance, inspiration, intelligence, and likeability.
* **Details:** 6 items rated on a 7-point Likert scale.

### 4.13. Complacency-Potential Rating Scale
* **Reference:** Singh, I. L., Molloy, R., & Parasuraman, R. (1993). Automation-induced "complacency": Development of the complacency-potential rating scale. *The International Journal of Aviation Psychology, 3*(2), 111-121. (As cited/used in Adams et al., 2003).
* **Description:** Measures potential for complacency when interacting with automated systems across various domains (library, surgery, banking, aviation, VCRs, medicine). Assesses trust, perceived reliability, safety, ease of use, and job satisfaction aspects.
* **Details:** 20 items rated on a 5-point Likert scale (Strongly disagree to Strongly agree). 

### 4.14. Gerlich (2025) Cognitive Offloading & Critical Thinking Items
* **Reference:** Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. *Societies, 15*(1), Article 1. https://doi.org/10.3390/soc15010006
* **Description:** Includes items measuring reliance on external tools (search engines, devices) for information retrieval and memory (Cognitive Offloading), and self-reported critical evaluation habits regarding information sources, including AI (Critical Thinking).
* **Details:** Items rated on 6-point frequency or Likert scales. 

### 4.15. Rheu & Cho (2025) Machine Heuristics & Credibility
* **Reference:** Rheu, M. (MJ), & Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–7. https://doi.org/10.1145/3706599.3719681
* **Description:** Measures perception of LLMs as expert, objective, and accurate (Machine Heuristics), and overall perceived credibility (Credibility).
* **Constructs:** Machine Heuristics (Expert, Objective, Accurate), Credibility.
* **Details:** Machine Heuristics uses 12 items on a 7-point Likert scale. Credibility uses 4 items on a 7-point semantic differential scale (-3 to +3).

### 4.16. Song et al. (2024) Social Influence Items
* **Reference:** Song, T., Tan, Y., Zhu, Z., Feng, Y., & Lee, Y.-C. (2024). Multi-Agents are Social Groups: Investigating Social Influence of Multiple Agents in Human-Agent Interactions. https://doi.org/10.48550/ARXIV.2411.04578
* **Description:** Measures perceived informational (persuasion-based) and normative (compliance-based) social influence exerted by AI agent(s) during a discussion task.
* **Constructs:** Informational Influence, Normative Influence.
* **Details:** 4 items rated on a 7-point Likert scale, plus open-ended questions. 

### 4.17. Zhu et al. (2024) Goal Interpretation & Needs Attribution
* **Reference:** Zhu, Q., Chong, L., Yang, M., & Luo, J. (2024). Reading Users’ Minds from What They Say: An Investigation into LLM-based Empathic Mental Inference. *ASME. J. Mech. Des. August 2024; 146*(6): 061401. https://doi.org/10.1115/DETC2024-143961
* **Description:** A task-based measure where participants (users or designers interpreting user comments) articulate goals at different levels (task, sub-action, overarching) and attribute these goals to fundamental psychological needs.
* **Details:** Involves open-ended goal generation and rating goal attribution to 13 needs on a 5-point scale (Not attributed at all to Highly attributed). 

---

## 5. AI Usage & Intention Scales

Instruments focused on measuring frequency, patterns, and intentions regarding AI use.

### 5.1. Gnambs et al. (2025) Future AI Experience Intentions
* **Reference:** Gnambs, T., Stein, J.-P., Zinn, S., Griese, F., & Appel, M. (2025). Attitudes, experiences, and usage intentions of artificial intelligence: A population study in Germany. *Telematics and Informatics, 98*, 102265. https://doi.org/10.1016/j.tele.2025.102265
* **Description:** Assesses desired future experience (intention to use) with specific AI scenarios/types (virtual assistants, recommender systems, robots, predictive analytics, monitoring, content generation) across different domains (workplace, healthcare, education).
* **Details:** Question rated on a 5-point scale (0=none to 4=very much). 

### 5.2. Gerlich (2025) AI Tool Usage Items
* **Reference:** Gerlich, M. (2025). AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking. *Societies, 15*(1), Article 1. https://doi.org/10.3390/soc15010006
* **Description:** Includes items measuring frequency of AI tool use for information/problem solving and extent of reliance on AI for decision-making.
* **Details:** Items 6 & 7 rated on a 6-point scale (Never/Not at all to Always/Completely). Items available in the source file (`Gerlich25_Survey.md`).

### 5.3. Tully, Longoni, & Appel (2023) AI Receptivity Measures
* **Reference:** Tully, S., Longoni, C., & Appel, G. (2023). Lower Artificial Intelligence Literacy Predicts Greater AI Receptivity. OSF. https://doi.org/10.31234/osf.io/t9u8g
* **Description:** Uses various measures across studies to assess AI receptivity, including:
    * **Adoption Readiness:** Agreement with statements about AI's impact, benefits, and trustworthiness (Study 1, 5). 4 items, Yes/No or 7-point Likert scale.
    * **Propensity to Use Generative AI:** Likelihood of using GenAI for specific academic assignments (Study 2). 4 scenarios rated on a 5-point scale of usage depth.
    * **Past AI Usage:** Frequency of using specific AI tools in the last six months (Study 3). 5 tool types rated on a 5-point frequency scale.
    * **Relative Preference (Human vs. AI):** Preference for human or AI agent for various tasks (Study 4, 6, 7). Multiple tasks rated on a 7-point preference scale.
* **Details:** Specific items and scales vary by study. 

### 5.4. Rheu & Cho (2025) Fact-checking Behavior
* **Reference:** Rheu, M. (MJ), & Cho, J. (2025). The Trap of AI Literacy: The Paradoxical Relationships Between College Students’ Use of LLMs, AI Literacy, and Fact-checking Behavior. *Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems*, 1–7. https://doi.org/10.1145/3706599.3719681
* **Description:** Measures the frequency of engaging in specific fact-checking behaviors (verifying credentials, checking currency, considering source reputation, using other search engines, seeking opinions) when using LLMs.
* **Details:** 5 items rated on a 7-point frequency scale (Never to Always). 








--------

# 1 AI Literacy Scales

### 1.1 MAILS – *Meta-Artificial Intelligence Literacy Scale*

Carolus et al. (2023) introduced a 72-item battery (60 literacy + 12 psychological meta-competence items).  Factor analyses yielded seven first-order facets—*Use & Apply*, *Understand*, *Detect*, *Create*, *Ethics*, *AI Self-Efficacy*, and *AI Self-Management*—plus a higher-order literacy factor ([arXiv][1]).  Items use 11-point Likert response anchors; Cronbach’s α for subscales ranged .79–.92.  All items are freely available via the authors’ OSF/ArXiv materials.

### 1.2 MAILS-Short (10 items)

Koch et al. (2024) distilled the original scale to ten indicators representing the same seven domains; the abbreviated form retains acceptable composite reliability (ω =.83) and strict measurement invariance across four validation samples ([HCI Downloads][2]).

### 1.3 AILQ – *AI Literacy Questionnaire*

Ng et al. (2024) validated a 32-item self-report covering *Affective, Behavioural, Cognitive,* and *Ethical* dimensions (8 items each).  A second-order CFA supported the four-factor structure (CFI =.95; RMSEA =.05) with student samples in Hong Kong ([ResearchGate][3]).

### 1.4 SNAIL (38 items)

Laupichler et al. (2023) produced an expert-elicited item bank for non-experts.  No factorial solution was reported, so psychometric quality remains provisional ([CEUR-WS][4]).

### 1.5 MAILS-related Objective Test (AICOS)

Weber et al. (2023) proposed an 11-point performance-style test aligned with MAILS’ domains; convergent validity with self-report literacy is modest (r ≈ .20) ([arXiv][5]).

### 1.6 Tully, Longoni & Appel (2023) Item Set

A 25-item knowledge quiz assessing misconceptions about AI capabilities; higher error rates predict greater *AI receptivity* across six studies ([The ARF][6]).

### 1.7 Rheu & Cho (2025) “Trap of AI Literacy” Battery

College-focused 14-item scale (α =.87) combining conceptual and procedural knowledge; higher scores correlate with **less** fact-checking when using LLMs ([arXiv][7]).

### 1.8 SAIL4ALL (23 items)

Soto-Sanfiel et al. (2024) supply a broad adult-population instrument; preliminary EFA indicates a three-factor solution (Understanding, Ethics, Societal Impact).  Full item list on OSF.

### 1.9 GSE-6-AI

Morales-García et al. (2024) adapted the general self-efficacy scale for AI contexts (6 items; α =.88).

---

# 2 General Attitude Toward AI Scales

### 2.1 ATAI (5 items)

Sindermann et al. (2021) created a bi-dimensional scale (*Acceptance* vs. *Fear*).  Items use 0-10 sliders; α =.80/.84 across German, Chinese, and UK samples ([SpringerLink][8]).

### 2.2 AIAS-4

Grassini (2023) validated a unidimensional 4-item measure capturing perceived societal utility; final CFA fit: CFI =.99, RMSEA =.02 ([Frontiers][9]).

### 2.3 ATTARI-12

Stein et al. (2024) offer a 12-item inventory emphasising anthropomorphic and ethical connotations; Big-Five traits predict scores modestly (|r| < .25) ([Nature][10]).

### 2.4 PAICE (European Barometer)

Scantamburlo et al. (2025) administered a 40-item omnibus survey (knowledge, trust, experience) to 17 k EU citizens; publicly released codebook supports secondary analyses.

### 2.5 Zhang & Dafoe (2019) “American Attitudes & Trends” Top-line

Large-N (n ≈ 2,000) repeat survey employing 28 fixed items; replication datasets available via SSRN.

---

# 3 Trust-Focused Instruments

### 3.1 TPA – *Trust Perception of Automation*

Jian et al. (2000) distilled 12 bipolar adjectives into *Trust* vs. *Distrust* subscales; α =.85.  Widely reused in HRI and displays convergent validity with behavioural reliance ([Finding the “Perfect” Scale][11]).

### 3.2 TiA (Körber, 2019)

Seven subscales (e.g., *Reliability, Predictability, Intention of Developers*).  The GitHub repository hosts English & German PDFs plus scoring manual ([GitHub][12]).

### 3.3 Semantic-Differential AI-Trust (27 items)

Shang & Hsieh (2025) separate **Affective** (15 items) from **Cognitive** (12 items) trust; multi-sample CFA confirms a correlated-two-factor model (CFI =.96) ([Ruoxi Shang][13]).

### 3.4 PTT-A (Propensity to Trust Technology)

Scholz et al. (2025) adapt dispositional trust to automated tech (8 items; α =.83); overlaps ϕ ≈ .40 with interpersonal trust.

### 3.5 TiA-derived *Trust in Automation* Short Forms

Scharowski et al. (2025) benchmark nine variants (including Jian-12, TiA-5) against behavioural calibration; only Jian-12 met scalar invariance.

---

# 4 Other Relevant Measures

| Domain                                  | Example Scales                                                      | Notes                                                                          |
| --------------------------------------- | ------------------------------------------------------------------- | ------------------------------------------------------------------------------ |
| **Mental-Model / Capacity Attribution** | Chen et al. (2025); Song et al. (2024); Ovsyannikova et al. (2025)  | Scenario-based vignettes manipulating agent framing (*machine vs. companion*). |
| **Uncertainty & Reliance**              | Kim et al. (2024) prompts; Duro et al. (2025) trust-factors battery | Focus on LLM confidence displays and user calibration.                         |
| **Self-Efficacy & Offloading**          | Gerlich (2025); Puppart & Aru (2025) pre/post intervention quizzes  | Examine cognitive offloading tendencies after literacy training.               |

---

# 5 Comparative Table

| Instrument      | Construct                                 | Items | Subscales / Factors | Sample α | Link / Access                                |
| --------------- | ----------------------------------------- | ----- | ------------------- | -------- | -------------------------------------------- |
| **MAILS**       | AI literacy (perceived + meta-competence) | 72    | 7                   | .79–.92  | ArXiv OSF ([arXiv][1])                       |
| **MAILS-S**     | AI literacy                               | 10    | 7                   | .77      | PDF ([HCI Downloads][2])                     |
| **AILQ**        | AI literacy                               | 32    | ABC\&E (4)          | .82–.90  | RG PDF ([ResearchGate][3])                   |
| **SNAIL**       | AI literacy (non-experts)                 | 38    | –                   | –        | CEUR ([CEUR-WS][4])                          |
| **ATAI**        | Acceptance/Fear of AI                     | 5     | 2                   | .80/.84  | Springer OA ([SpringerLink][8])              |
| **AIAS-4**      | General attitude                          | 4     | 1                   | .78      | Frontiers ([Frontiers][9])                   |
| **ATTARI-12**   | Attitude toward AI                        | 12    | 3                   | .84      | SciRep ([Nature][10])                        |
| **TPA**         | Trust (automation)                        | 12    | 2                   | .85      | Scale DB ([Finding the “Perfect” Scale][11]) |
| **TiA**         | Trust in automation                       | 20    | 7                   | .70–.90  | GitHub ([GitHub][12])                        |
| **SD-AI-Trust** | Affective/Cognitive trust                 | 27    | 2                   | .93/.91  | PDF ([Ruoxi Shang][13])                      |

*(Blank cells indicate data not reported in publicly available sources.)*

---


