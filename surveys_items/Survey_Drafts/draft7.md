---
title: "Survey: Perceptions of Large Language Models for Household Energy Management"
author: "Study Team"
format:
  html:
    toc: true
    toc-depth: 2
    number-sections: true
    theme: cosmoc
execute:
  echo: false
  warning: false
---


# Survey: Perceptions of Large Language Models for Household Energy Management

## Table of Contents

1.  Introduction and Consent
2.  Demographic Information
3.  Objective Numeracy
4.  Energy Literacy - Cognitive Knowledge
5.  Energy Literacy - Affective Attitudes
6.  AI Literacy (Self-Report)
7.  General Trust and Distrust in AI
8.  Attributional Beliefs about LLMs
9.  Perceived LLM Accuracy & Utility for Energy Tasks
10. Task-Specific Trust in LLMs for Energy Tasks
11. LLM Usage Intentions and Frequency for Energy Tasks
12. Debriefing

---

# Introduction and Consent

*(Standard informed consent text would appear here, explaining the study purpose, voluntary nature, confidentiality, risks, and benefits.)*

---

# Demographic Information

Please provide some information about yourself.

1.  What is your age?
    *   (Open-ended numeric entry)
    (Demographic Question)

2.  What is your gender?
    *   Male
    *   Female
    *   Non-binary
    *   Prefer to self-describe: \_\_\_\_\_\_\_\_\_\_\_
    *   Prefer not to answer
    (Demographic Question)

3.  What is the highest level of education you have completed?
    *   Less than High School
    *   High School Diploma or Equivalent
    *   Some College, No Degree
    *   Associate's Degree
    *   Bachelor's Degree
    *   Master's Degree
    *   Doctoral Degree
    *   Professional Degree (e.g., MD, JD)
    *   Prefer not to answer
    (Demographic Question)

4.  Which of the following best describes your current employment status?
    *   Employed full-time
    *   Employed part-time
    *   Unemployed and looking for work
    *   Unemployed and not looking for work
    *   Retired
    *   Student
    *   Homemaker
    *   Disabled, not able to work
    *   Other: \_\_\_\_\_\_\_\_\_\_\_
    (Demographic Question)

5.  Please indicate your approximate total household income before taxes in the past year.
    *   Less than $20,000
    *   $20,000 to $39,999
    *   $40,000 to $59,999
    *   $60,000 to $79,999
    *   $80,000 to $99,999
    *   $100,000 to $149,999
    *   $150,000 to $199,999
    *   $200,000 or more
    *   Prefer not to answer
    (Demographic Question)

6.  What type of housing do you currently live in?
    *   Single-family house (detached)
    *   Townhouse or row house
    *   Duplex or two-family house
    *   Apartment or condominium (in a building with 3+ units)
    *   Mobile home
    *   Other: \_\_\_\_\_\_\_\_\_\_\_
    (Demographic Question)

7.  Do you own or rent your home?
    *   Own
    *   Rent
    *   Other: \_\_\_\_\_\_\_\_\_\_\_
    (Demographic Question)

8.  Do you pay your own electricity bill?
    *   Yes
    *   No (Utility bill included in rent/HOA fees, etc.)
    *   Not applicable (e.g., live with parents)
    (Demographic Question)

---

# Objective Numeracy

We would like to ask you a few questions to understand how people think about numbers and probabilities.

1.  Imagine we are throwing a fair six-sided die. What is the probability of rolling a 6?
    *   (Open-ended numeric entry, e.g., 1/6 or 0.1667)
    (Berlin Numeracy Test item, adapted)

2.  Which of the following numbers represents the biggest risk?
    *   1 in 100
    *   1 in 1000
    *   1 in 10
    (Berlin Numeracy Test item, adapted)

3.  If the chance of getting a disease is 10% and you take a test that is 90% accurate (meaning it correctly identifies the disease 90% of the time it's present, and correctly identifies its absence 90% of the time it's not), and you test positive, what is the approximate probability that you actually have the disease?
    *   (Open-ended numeric entry, testing Bayesian reasoning)
    (Berlin Numeracy Test item, adapted)

*(Include ~1-2 more items from Berlin Numeracy Test or similar quantitative reasoning questions used by Attari et al., 2010 or Marghetis et al., 2019)*

---

# Energy Literacy - Cognitive Knowledge

These questions ask about energy use in households. There are correct answers.

1.  Which of the following energy units represents the total amount of energy consumed over time (e.g., typically measured on an electricity bill)?
    *   Watts (W)
    *   Kilowatt-hours (kWh)
    *   Amps (A)
    *   Volts (V)
    (Energy Literacy Questionnaire - ELQ, DeWaters & Powers 2011/2013, adapted)

2.  Which of these actions would typically save the most energy in an average U.S. household over a year?
    *   Turning off lights when leaving a room.
    *   Using a power strip to turn off multiple electronics at once.
    *   Lowering the thermostat temperature by a few degrees in winter.
    *   Replacing a standard incandescent light bulb with an LED bulb.
    (Adapted from energy knowledge questions/concepts in Attari et al., 2010; Marghetis et al., 2019; ELQ)

3.  Approximately what percentage of total energy used in a typical U.S. home goes towards heating and cooling (HVAC)?
    *   Less than 10%
    *   10% - 20%
    *   20% - 40%
    *   More than 40%
    (Adapted from energy knowledge/estimation concepts in Attari et al., 2010; Marghetis et al., 2019)

4.  True or False: Appliances use energy even when they are turned off, as long as they are plugged into the wall (sometimes called "phantom load" or "vampire power").
    *   True
    *   False
    *   Don't Know
    (Adapted from energy knowledge questions/concepts)

*(Include ~4-6 more multiple-choice questions covering basic energy concepts, sources, common appliance use, and effectiveness of common conservation actions, drawing from sources like ELQ, Canfield et al. 2017 adaptation, or concepts from Attari et al. 2010)*.

---

# Energy Literacy - Affective Attitudes

Please indicate how much you agree or disagree with the following statements.

*(Use a 5-point or 7-point Likert scale: 1 = Strongly Disagree to 5/7 = Strongly Agree or 1 = Totally not like me to 7 = Totally like me)*

1.  Protecting the environment is important to me, even if it requires some personal sacrifice.
    (Biospheric Values subscale, Environmental Portrait Value Questionnaire / New Ecological Paradigm - NEP items)

2.  I am concerned about the impact of climate change.
    (Climate Change Attitudes)

3.  It is important to conserve energy for future generations.
    (Energy Literacy Questionnaire - ELQ Affective subscale, DeWaters & Powers 2011/2013, adapted)

4.  I believe my individual actions to save energy can make a difference.
    (Energy Literacy Questionnaire - ELQ Affective subscale, Self-efficacy item, DeWaters & Powers 2011/2013, adapted)

*(Include ~3-5 more items capturing environmental concern, perceived effectiveness of conservation, or sense of responsibility, drawing from NEP, Environmental Value Questionnaires, or ELQ Affective subscale)*.

---

# AI Literacy (Self-Report)

Please indicate how much you agree or disagree with the following statements about Artificial Intelligence (AI) systems, including chatbots like ChatGPT or Gemini.

*(Use a 5-point Likert scale: 1 = Strongly Disagree to 5 = Strongly Agree)*

1.  I know how to use AI tools to help me with everyday tasks.
    (MAILS Short Form - Use & Apply AI, Koch et al. 2024, adapted)

2.  I understand the basic ideas of how AI systems work.
    (MAILS Short Form - Know & Understand AI, Koch et al. 2024, adapted)

3.  I can tell if a piece of information was created by an AI or a human.
    (MAILS Short Form - Detect AI, Koch et al. 2024, adapted)

4.  I can evaluate whether the information provided by an AI is reliable or not.
    (MAILS Short Form - Evaluate AI / AI Self-efficacy, Koch et al. 2024, adapted)

5.  I am concerned about the ethical implications of using AI.
    (MAILS Short Form - AI Ethics, Koch et al. 2024, adapted)

6.  I am confident in my ability to interact effectively with AI systems.
    (MAILS Short Form - AI Self-competency, Koch et al. 2024, adapted)

*(Include the remaining items from the MAILS Short Form (Koch et al. 2024) to cover the core facets of self-reported AI literacy)*.

---

# General Trust and Distrust in AI

Please indicate how well each of the following adjectives describes AI systems in general.

*(Semantic Differential Scale: Use a 7-point bipolar scale, e.g., 1 = Unreliable, 7 = Reliable)*

1.  Unreliable - Reliable
    (Semantic Differential AI-Trust Scale, Shang et al. 2024; TPA-Revised concepts)

2.  Incompetent - Competent
    (Semantic Differential AI-Trust Scale, Shang et al. 2024; TPA-Revised concepts)

3.  Predictable - Unpredictable (R)
    (Semantic Differential AI-Trust Scale, Shang et al. 2024; TPA-Revised concepts)

4.  Dishonest - Honest
    (Semantic Differential AI-Trust Scale, Shang et al. 2024; TPA-Revised concepts)

5.  Caring - Indifferent (R)
    (Semantic Differential AI-Trust Scale, Shang et al. 2024; Affective Trust)

*(Select a subset of ~10-15 bipolar adjective pairs from the Semantic Differential AI-Trust scale (Shang et al. 2024), ensuring representation of both cognitive (competence, reliability, integrity) and affective (benevolence, warmth) dimensions, as well as items reflecting general distrust)*.

Now, please indicate the extent to which you agree or disagree with the following statements about AI systems in general.

*(Use a 5-point Likert scale: 1 = Strongly Disagree to 5 = Strongly Agree)*

6.  In general, AI systems are reliable.
    (TPA-Revised - Trust item, Lai et al. 2024, adapted)

7.  I am cautious about relying on advice from AI systems.
    (TPA-Revised - Distrust item, Lai et al. 2024, adapted)

8.  I believe AI systems generally act in the user's best interest.
    (TPA-Revised - Trust item, Lai et al. 2024, adapted)

9.  I often feel suspicious of AI systems.
    (TPA-Revised - Distrust item, Lai et al. 2024, adapted)

*(Include the remaining items from the TPA-Revised scale (Lai et al. 2024) to capture both general trust (7 items) and distrust (5 items) dimensions)*.

---

# Attributional Beliefs about LLMs

Please indicate how much you agree or disagree with the following statements about how Large Language Models (LLMs) like ChatGPT or Gemini work, especially when providing information or advice about household energy use.

*(Use a 7-point Likert scale: 1 = Strongly Disagree to 7 = Strongly Agree)*

1.  LLMs have access to real-time, comprehensive databases of energy usage for all types of homes and appliances.
    (Custom item, probing mental models of data access)

2.  LLMs genuinely understand energy principles in a way similar to a human expert.
    (Custom item, probing mental models of processing/understanding)

3.  LLMs might sometimes make up numbers or facts about energy that sound plausible but are incorrect ("hallucinate").
    (Custom item, probing mental models of potential error/fabrication)

4.  LLMs can accurately figure out details about my specific home situation to give truly personalized energy advice.
    (Custom item, probing mental models of contextual understanding/personalization)

5.  LLMs primarily work by finding patterns in the text they were trained on, rather than having true knowledge.
    (Custom item, probing mental models of processing/nature of knowledge)

*(Include ~3-5 more custom items to further probe user assumptions about LLM data sources, reasoning processes, limitations, and potential for error specifically in the energy domain)*.

---

# Perceived LLM Accuracy & Utility for Energy Tasks

Please indicate how accurate and useful you believe a state-of-the-art Large Language Model (LLM) like ChatGPT or Gemini would be for the following tasks related to household energy management.

*(Use a 7-point Likert scale for Accuracy: 1 = Very Inaccurate to 7 = Very Accurate)*
*(Use a 7-point Likert scale for Utility: 1 = Not at all Useful to 7 = Extremely Useful)*

1.  Estimating the annual electricity consumption (in kWh) of a typical refrigerator.
    *   Perceived Accuracy: (Scale 1-7)
    *   Perceived Utility: (Scale 1-7)
    (Custom item, based on Attari et al. 2010 estimation task content)

2.  Estimating the annual electricity consumption (in kWh) of a typical electric clothes dryer.
    *   Perceived Accuracy: (Scale 1-7)
    *   Perceived Utility: (Scale 1-7)
    (Custom item, based on Attari et al. 2010 estimation task content)

3.  Estimating the annual electricity consumption (in kWh) of a typical LED light bulb used for 3 hours per day.
    *   Perceived Accuracy: (Scale 1-7)
    *   Perceived Utility: (Scale 1-7)
    (Custom item, based on Attari et al. 2010 estimation task content)

*(Include ~5-8 more common household appliances covering a range of energy use (low to high) from lists like Attari et al. 2010)*.

4.  Generating a personalized energy-saving plan for your specific home and habits.
    *   Perceived Accuracy: (Scale 1-7)
    *   Perceived Utility: (Scale 1-7)
    (Custom item, based on study proposal planning task)

5.  Answering specific factual questions about energy (e.g., efficiency ratings, definitions of terms).
    *   Perceived Accuracy: (Scale 1-7)
    *   Perceived Utility: (Scale 1-7)
    (Custom item, based on study proposal factual question task)

---

# Task-Specific Trust in LLMs for Energy Tasks

Please indicate how much you would trust the information or advice provided by a state-of-the-art Large Language Model (LLM) when it is performing the following tasks.

*(Use a 7-point Likert scale: 1 = Would not trust at all to 7 = Would fully trust)*

1.  Trusting the accuracy of an LLM's estimate for the annual energy use of a specific appliance in your home.
    (Custom item, specific trust for estimation)

2.  Trusting an LLM to generate a safe and effective energy-saving plan for your home.
    (Custom item, specific trust for planning)

3.  Trusting an LLM to provide correct factual information about energy efficiency terms or technologies.
    (Custom item, specific trust for factual questions)

4.  How likely would you be to rely on an LLM's recommendation for an energy-saving action (e.g., adjust thermostat) without seeking a second opinion?
    (Custom item, specific reliance intention)

*(Include ~2-3 more custom items related to trusting LLMs for specific energy-related recommendations or calculations)*.

---

# LLM Usage Intentions and Frequency for Energy Tasks

Please answer the following questions about your past and future use of Large Language Models (LLMs) like ChatGPT, Gemini, Claude, etc.

1.  In the past month, how often have you used any LLM (e.g., ChatGPT, Gemini, Claude) to get information or advice specifically related to managing or reducing your household energy consumption?
    *   Never
    *   Rarely (1-2 times)
    *   Sometimes (3-5 times)
    *   Often (More than 5 times)
    *   Very Often (Almost daily)
    (Custom item, past usage frequency)

2.  How likely are you to use an LLM in the future to find out how much energy a specific appliance uses?
    *(Use a 7-point Likert scale: 1 = Very Unlikely to 7 = Very Likely)*
    (Custom item, future willingness/intention for estimation)

3.  How likely are you to use an LLM in the future to help you create a plan to save energy in your home?
    *(Use a 7-point Likert scale: 1 = Very Unlikely to 7 = Very Likely)*
    (Custom item, future willingness/intention for planning)

*(Include ~1-2 more custom items related to willingness/intention for other specific energy-related LLM uses, drawing from concepts in technology acceptance models (UTAUT) if desired)*.

---

# Debriefing

*(Standard debriefing text would appear here, thanking the participant, providing contact information, and potentially offering links to reliable energy information resources and noting the current limitations of LLMs regarding factual accuracy.)*

---





### Justification Report

This survey instrument is designed to empirically investigate lay perceptions of Large Language Models (LLMs) in the context of household energy management, as outlined in the study proposal. Drawing upon literatures in cognitive psychology, energy decision-making, human-AI interaction, and psychometrics, the instrument employs a multi-method approach incorporating validated scales and targeted custom items to capture the nuanced interplay between individual differences, AI perceptions, and behavioral intentions. The structure and content are specifically aligned to address the research questions (RQs) and test the proposed hypotheses (H).

The survey begins with standard demographic questions. While not directly tied to specific hypotheses, demographics are crucial control variables in cognitive and behavioral research, potentially revealing group differences in literacy, AI exposure, or energy habits that could influence findings.

The core of the instrument is organized to follow a logical progression, moving from stable individual difference predictors to more dynamic perceptions of AI and intended behaviors.

**Addressing Research Questions and Hypotheses:**

*   **RQ1: What are the prevailing lay beliefs concerning the accuracy and utility of contemporary LLMs... for estimating appliance-level electricity use... and designing personalized household energy-saving plans? How do individuals differentiate their trust in LLMs...?**
    *   **Section 9: Perceived LLM Accuracy & Utility for Energy Tasks** directly measures participants' subjective beliefs about LLM capabilities for the specific tasks of energy estimation and planning. These items are custom-developed because no pre-existing scale captures perceptions of LLM performance *in this specific domain*. The content of the estimation items is inspired by the appliance lists used in established energy perception research by Attari et al. (2010) and Marghetis et al. (2019), ensuring relevance to a domain where human cognitive biases are well-documented.
    *   **Section 10: Task-Specific Trust in LLMs for Energy Tasks** complements Section 9 by assessing trust specifically tied to relying on LLM outputs for energy advice and data. Cognitive theories of trust emphasize its context-dependent nature; trust in an AI for factual information may differ from trust in its ability to synthesize complex plans. Custom items here directly address RQ1's focus on differentiation in trust across tasks.
    *   These sections are foundational for exploring **Hypothesis H1**, which posits that lay perceptions of LLM accuracy will mirror known human biases in energy estimation (e.g., range compression, over/underestimation of specific appliance use or action effectiveness). While the survey omits the human estimation task itself (per the 'no tasks' constraint), the belief questions about LLM estimation accuracy use similar content, allowing for comparison of *perceived* LLM bias against documented *human* bias patterns. This comparison informs the understanding of users' mental models of LLM capabilities, particularly whether they project human limitations onto the AI or expect superior performance.

*   **RQ2: To what extent do individual differences in objective numeracy..., multidimensional energy literacy..., and AI literacy... predict these lay beliefs about LLM capabilities...?**
    *   **Section 3: Objective Numeracy** includes items adapted from established tests (e.g., Berlin Numeracy Test, or those used by Attari et al. 2010; Marghetis et al. 2019). Quantitative reasoning is a key cognitive ability influencing the comprehension and evaluation of numerical information, directly relevant to interpreting energy data or evaluating LLM-provided estimates. This section provides the measure for testing **Hypothesis H2a**, predicting that higher numeracy is associated with potentially better-calibrated assessments of LLM quantitative outputs.
    *   **Section 4: Energy Literacy - Cognitive Knowledge** utilizes multiple-choice items inspired by validated instruments like the ELQ (DeWaters & Powers, 2011/2013). Cognitive energy literacy—factual knowledge about energy systems, consumption, and conservation—provides the domain-specific knowledge base necessary for individuals to critically evaluate the plausibility of LLM outputs in the energy context. **Section 5: Energy Literacy - Affective Attitudes** captures non-cognitive dimensions of energy literacy and environmental values (e.g., NEP, Environmental Portrait Value Questionnaire). While RQ2 and H2b specifically highlight the cognitive component for critical evaluation, affective factors can influence engagement and perception. Together, these sections measure the multidimensional energy literacy constructs relevant to RQ2 and test **Hypothesis H2b**, which posits that higher energy literacy (especially cognitive knowledge) correlates with a more critical stance towards LLM outputs, particularly for complex or nuanced energy concepts.
    *   **Section 6: AI Literacy (Self-Report)** employs items representing facets of the MAILS Short Form (Koch et al., 2024). This self-report measure captures perceived knowledge, application skills, critical evaluation capabilities (e.g., detecting AI, understanding limitations), and self-efficacy regarding AI systems generally. This section directly measures the AI literacy constructs for RQ2 and tests **Hypothesis H2c**, predicting that higher AI literacy (especially evaluation/understanding facets) is associated with more cautious or nuanced beliefs about LLM capabilities for energy tasks, potentially mitigating tendencies toward uncritical acceptance. **Section 8: Attributional Beliefs about LLMs** further probes the cognitive structures underlying perceived capabilities by examining users' explicit mental models of how LLMs function in the energy domain (e.g., perceived data access, understanding, potential for error). These beliefs are components of AI literacy and mental models, providing deeper insight into *why* users perceive LLMs as they do, supporting RQ2 and H2c.

*   **RQ3: How do perceptions of LLM accuracy for specific energy-related tasks and associated task-specific trust... jointly influence lay individuals' self-reported willingness to utilize LLMs... and their self-reported frequency of such usage...?**
    *   **Sections 9 & 10** provide the perceived accuracy and task-specific trust measures (as described for RQ1).
    *   **Section 11: LLM Usage Intentions and Frequency for Energy Tasks** includes custom self-report items measuring past frequency of using LLMs for energy tasks and future willingness to do so. These measures directly capture the outcome variables for RQ3 and serve as the criterion variables for testing **Hypothesis H3**, which predicts a positive association between favorable beliefs about LLM accuracy and trustworthiness for energy tasks and greater self-reported willingness/frequency of use. This aligns with technology acceptance models where perceived usefulness and ease of use drive behavioral intentions.

*   **RQ4: Do general trust and distrust in AI... mediate or moderate the relationship between specific beliefs about LLM capabilities for energy tasks and self-reported willingness/frequency of use?**
    *   **Section 7: General Trust and Distrust in AI** incorporates items from validated scales (e.g., TPA-Revised, Semantic Differential AI-Trust Scale) to measure broader, dispositional trust and distrust towards AI systems generally. Measuring general trust and distrust as distinct constructs is psychometrically supported and allows for investigating their potentially differential influences on the relationship between task-specific perceptions and usage. This section provides the measures for testing **Hypothesis H4**, which posits that general trust in AI mediates the positive relationship between favorable specific beliefs about LLM energy capabilities and usage outcomes. This mechanism suggests that task-specific positive experiences or beliefs can reinforce broader trust in the technology class, subsequently influencing adoption. General trust/distrust could also moderate this relationship, making individuals with high general trust more likely to translate positive specific beliefs into action than those with high general distrust, even if their specific beliefs are similar.

**Manageable Runtime and Limitations:**
By prioritizing short forms of multi-dimensional scales (e.g., MAILS-SF) and selecting a representative subset of items from longer scales (e.g., Semantic Differential), the instrument aims for a manageable runtime (estimated at ~30-40 minutes, depending on exact item counts per section). The exclusion of interactive estimation or behavioral tasks significantly reduces potential time burden compared to a mixed-method design. However, a limitation of this approach is relying solely on self-report for constructs like energy literacy behaviors or LLM usage frequency, which are susceptible to social desirability or recall bias. Furthermore, while the custom items for LLM perceptions are carefully designed based on the study's specific focus, they would benefit from psychometric validation (e.g., pilot testing, factor analysis) in future work.

In conclusion, the proposed survey instrument provides a comprehensive framework for investigating the complex interplay of individual cognitive factors, energy perception biases, AI perceptions, and trust in the context of LLM use for household energy management. Its structure and item selection are well-aligned with the theoretical underpinnings, research questions, and hypotheses of the study proposal, offering a robust foundation for collecting the necessary data through efficient survey methodology.
