






# https://chatgpt.com/c/6818c63d-f2e0-8006-9282-4c30d45dcebb

### **Survey Instrument and Materials**

The following survey instrument (Phase 1) is designed to measure key individual difference variables and knowledge *before* participants engage with the AI advisor. The estimated completion time for the survey + estimation task is approximately 15-20 minutes. Table 1 below outlines the sections, constructs, and approximate length:

**Table 1. Pre-Task Survey Structure and Timing**

| Section | Construct Measured                    | Instrument/Source (if applicable)                                          | Format                             | Items    | Est. Time     |
| :-----: | :------------------------------------ | :------------------------------------------------------------------------- | :--------------------------------- | :------- | :------------ |
|    1    | Propensity to Trust Technology (PTT)  | PTT-A Scale (Scholz et al., 2024)                                          | 5-pt Likert                        | 14       | 2–3 min       |
|    2    | AI Literacy                           | AICOS – Short Form (Markus et al., 2025)                                   | Multiple-choice                    | \~10–15  | 5–7 min       |
|    3    | Energy Literacy (Objective knowledge) | Adapted cognitive items (DeWaters et al., 2013)                            | Multiple-choice                    | \~5      | 2–3 min       |
|    4    | Numeracy                              | Berlin Numeracy Test (Cokely et al., 2012)                                 | Adaptive numeric                   | 2–3      | 2–3 min       |
|    5    | **Appliance Energy Estimation**       | **Custom task (adapted from Attari et al., 2010; Marghetis et al., 2019)** | Open numeric entry                 | \~8      | 4–6 min       |
|    6    | **Energy Knowledge & Beliefs**        | **Custom items (factual, heuristic, confidence)**                          | Multiple formats (MC, T/F, Likert) | 8        | 3–5 min       |
|         | **Total (Survey + Estimation)**       |                                                                            |                                    | **\~50** | **15–20 min** |

**Section 1–4** constitute the individual differences battery, while **Sections 5–6** are the newly added energy-focused tasks. By placing the estimation task (Sec. 5) and knowledge questions (Sec. 6) *after* the trait measures but *before* the AI interaction, we capture participants’ unbiased perceptions and knowledge of energy. To mitigate fatigue, the survey alternates between different response formats: for instance, Likert agreement scales are followed by interactive estimation entries, then by multiple-choice questions. Participants are thus less likely to become bored by a long series of identical questions, and the transition between sections is smoothed with clear instructions.


---------



# https://chatgpt.com/c/6813fa48-2e18-8006-9f8d-c0268ab19247

## AI Literacy Instruments

| Instrument                                                              | Direct link to full items                                                       | Access                                                                | Notes                                                                                       |
| ----------------------------------------------------------------------- | ------------------------------------------------------------------------------- | --------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- |
| **MAILS – Meta-AI Literacy Scale** (34-item long & 18-item short forms) | PDF on Würzburg HCI lab server ([downloads.hci.informatik.uni-wuerzburg.de][1]) | **Open**                                                              | Appendix A lists every item in English & German.                                            |
| **SNAIL – Scale for Non-experts’ AI Literacy** (31 items)               | Elsevier link includes full appendix in the article’s HTML ([ScienceDirect][2]) | Paywalled → open pre-print lacks items; use MAILS short form instead. |                                                                                             |
| **AISES – Artificial Intelligence Self-Efficacy Scale** (22 items)      | ResearchGate author upload (PDF) ([ResearchGate][3])                            | **Open**                                                              | Appendix B contains all items; Springer final version paywalled ([ACM Digital Library][4]). |

---

## AI Attitudes / Trust Instruments

| Instrument                                                            | Direct link                                             | Access   | Notes                                                                                                                       |
| --------------------------------------------------------------------- | ------------------------------------------------------- | -------- | --------------------------------------------------------------------------------------------------------------------------- |
| **TPA-R – Trust between People & Automation (Revised)** (12 items)    | DRDC technical report PDF, pp. 17-18 ([CRADPDF][5])     | **Open** | Identical wording to Jian et al. (2000); Hoffman et al. (2024) validation pre-print adds revised instructions ([arXiv][6]). |
| **Semantic-Differential AI-Trust Scale** (27 bipolar adjective pairs) | AIES 2024 conference PDF, Table 1 ([ruoxishang.com][7]) | **Open** | Items reproduced verbatim in paper and supplementary .csv.                                                                  |
| **TiA – Trust-in-Automation Questionnaire** (19 items)                | GitHub repository with manual & item PDF ([GitHub][8])  | **Open** | Widely used if you prefer domain-general wording.                                                                           |
| **TILLMI – Trust-in-LLMs Index** (6 items)                            | arXiv pre-print appendix A ([arXiv][9])                 | **Open** | Includes scoring syntax in OSF repository (link in paper).                                                                  |
| **TAI – Trust Scale for the AI Context** (8 items)                    | Items reproduced in validation pre-print ([arXiv][10])  | **Open** | Shorter alternative; psychometrics reported.                                                                                |

---

## Energy Literacy & Appliance-Knowledge Instruments

| Instrument                                                    | Direct link                                                                       | Access   | Notes                                                  |
| ------------------------------------------------------------- | --------------------------------------------------------------------------------- | -------- | ------------------------------------------------------ |
| **ELS – Energy Literacy Scale (28-item short form)**          | ResearchGate PDF with all items ([ResearchGate][11])                              | **Open** | Supplementary file lists Rasch codes.                  |
| **ELQ – Energy Literacy Questionnaire** (60 items)            | ASEE conference PDF, pp. 6-14 ([ASEE PEER][12])                                   | **Open** | Original long form used in DeWaters & Powers (2013).   |
| **NEF National Energy Literacy Survey** (high-school version) | White-paper PDF, Appendix B ([National Energy Foundation][13])                    | **Open** | 17 knowledge items + 11 behavior items.                |
| **Attari Appliance-Estimate Task**                            | PNAS article PDF, Table S2 lists the 15 appliances & true kWh values ([PNAS][14]) | **Open** | Tasks are open-ended; scoring instructions in methods. |

---

## Pay-walled or Restricted Instruments & Open Substitutes

* **SNAIL**: Article PDF is paywalled, but the conceptual overlap with the freely available MAILS short form makes SNAIL redundant for most studies.
* **KPMG Global AI Use Survey battery**: Proprietary; not publicly released. For open data on usage frequency, adapt the **UTAUT-2 AI adoption short block** (four items) or the **AI tool-use frequency items** published with TiA validation datasets ([ResearchGate][15]).




--------


# https://gemini.google.com/app/d39da36f5b5e6389

## **Part 3: Annotated Bibliography of Relevant Validated Surveys**

### **Section 3.1: Introduction to Survey Selection Criteria**

The following annotated bibliography includes 15 validated surveys or measurement approaches relevant to the core constructs of the proposed research: Energy Literacy/Knowledge/Perception, AI Literacy, Trust in AI/Automation, Reliance/Calibration, Numeracy/Risk Literacy, and Mental Model Assessment. Selection prioritizes instruments with published psychometric data (reliability, validity) or established conceptual frameworks widely used in the relevant fields. The aim is to provide a toolkit of potential measures to enhance the methodological rigor of the proposed study.

### **Section 3.2: Annotated Bibliography**

**Table 2: Annotated Bibliography of Validated Surveys and Measurement Approaches**

| Survey Name & Citation | Construct(s) Measured | Description | Items & Format | Validation Info / Source Snippet |
| :---- | :---- | :---- | :---- | :---- |
| 1\. Energy Literacy Scale Framework (DeWaters & Powers, 2013\) | Energy Literacy (Cognitive, Affective, Behavioral) | Foundational framework defining energy literacy dimensions. Used to develop various assessment tools, often for students/households. | Varies; framework, not single scale. Items typically assess knowledge (facts, concepts), attitudes (beliefs, values), and behaviors (reported actions). | Framework widely cited and used as basis for scale development.1 |
| 2\. Attari et al. (2010) Energy Perception Task 8 | Energy Consumption/Savings Perception; Perceptual Bias | Participants estimate energy use/savings for \~15 items relative to a 100W bulb reference. Open-ended estimation. | \~15 estimation items \+ ranking tasks \+ open-ended "most effective" question. Numerical estimates. | Demonstrated systematic underestimation (factor 2.8), compression bias. Perceptions correlated with numeracy & pro-environmental attitudes.8 Replicated for water.7 |
| 3\. Marghetis, Attari, & Landy (2019) Energy Intervention Measures 12 | Energy Perception; Conservation Judgments; Intervention Effectiveness | Includes energy estimation task (36 items, Wh) and questions assessing judgment of conservation behaviors. Used to test interventions (numerical extremes, heuristics). | 36 estimation items (Wh) \+ judgment questions. | Showed heuristic intervention improved underlying understanding and conservation judgments more than numerical info.12 |
| 4\. Kantenbacher & Attari (2021) Expert Heuristic Elicitation Method 13 | Energy Decision Heuristics (Expert vs. Novice) | Interview/think-aloud protocol presenting device comparisons to elicit judgment heuristics. Not a survey, but identifies heuristics to probe. | Qualitative method; identifies heuristic categories (function, component, cue). | Identified 24 unique expert heuristics rated more accurate than novice ones. Experts showed more accurate estimates.13 |
| 5\. Meta AI Literacy Scale (MAILS) (Carolus, Koch et al., 2023\) 16 | AI Literacy (Know/Understand, Use/Apply, Detect, Evaluate/Create, Ethics); AI Self-Efficacy; AI Self-Competency | Comprehensive self-report scale for non-experts. | 34 items. 11-point Likert scale (0-10). | Confirmed factor structure via CFA in multiple samples. Showed correlations with related constructs (tech openness, attitudes).17 |
| 6\. MAILS-Short (Koch et al., 2024\) 17 | AI Literacy (Multidimensional); AI Self-Efficacy; AI Self-Competency | Short version of MAILS for efficiency. | 10 items selected from MAILS. 11-point Likert scale (0-10). | Items selected to represent original factors. Initial CFA showed good model fit, but further validation recommended.17 |
| 7\. Artificial Intelligence Literacy Scale (AILS) (Wang et al., 2022; Adapted by Çolak et al., 2024\) 15 | AI Literacy (Awareness, Usage, Evaluation, Ethics) | Measures AI literacy for non-expert adults. | 12 items, 4 factors. Likert scale. | Turkish adaptation showed good fit via CFA (X2/df=1.82, RMSEA=0.04, CFI=0.98). Good reliability (alpha=0.85 overall).15 |
| 8\. Trust between People and Automation (TPA) Scale \- AI Adaptation (Jian et al., 2001; Validated by Gari et al., 2024\) 22 | Trust in AI; Distrust in AI | Adaptation of widely used automation trust scale. | 12 items (7 positive/Trust, 5 negative/Distrust). Typically 7-point Likert scale. | Validation in AI context supported a 2-factor structure (Trust/Distrust) with good fit, reliability, and validity (convergent, divergent, criterion).22 |
| 9\. Affective/Cognitive Trust Semantic Differential Scale (Shang, Hsieh, & Shah, 2024\) 29 | Affective Trust in AI; Cognitive Trust in AI | Measures distinct emotional and cognitive trust dimensions towards AI agents. | 27 items. Semantic differential format (pairs of bipolar adjectives). | Developed and validated via scenario-based survey and experiment. Showed interaction between dimensions shaping overall trust.29 (Specific items not in snippets). |
| 10\. Lee & See (2004) Trust Framework 23 | Trust in Automation (Conceptual Basis) | Influential conceptual model defining trust (attitude under uncertainty/vulnerability) and its basis (analytic, analogical, affective processes; context). | Conceptual framework, not a single scale. Provides basis for developing context-specific trust items. | Widely adopted definition and framework in human-automation trust research.22 |
| 11\. Appropriate Reliance Metrics (Schemmer et al., 2022/2023) 33 | Appropriate Reliance (Behavioral) | Behavioral metrics calculated from sequential decision task (Initial response \-\> AI advice \-\> Final response). | Relative AI Reliance (RAIR), Relative Self-Reliance (RSR). Calculated ratios (0 to 1). | Proposed as operationalization of appropriate reliance, measuring ability to follow correct advice (RAIR) and correctly ignore wrong advice (RSR).35 Used in experimental studies.35 |
| 12\. Over/Under-Reliance Metrics (e.g., Kim et al., 2024; Zhang et al., 2023 framework) 38 | Over-reliance; Under-reliance (Behavioral) | Behavioral metrics calculated from tasks where user decides whether to follow AI advice. | Negative LLM Reliance (NL \- % follow wrong advice); Negative Self-Reliance (NS \- % ignore correct advice). Rates/proportions. | Used in experiments studying LLM reliance interventions. Captures key miscalibration behaviors.38 |
| 13\. Calibration & Discrimination Gap Measures (Steyvers et al., 2025\) 47 | Trust Calibration (Perceptual Accuracy) | Measures alignment between user confidence in LLM output and LLM's actual accuracy. | Per-item confidence rating ("Prob. LLM correct?"). Compared to objective accuracy. Metrics: Calibration Gap (mean diff), Discrimination Gap (AUC diff). | Method demonstrated misalignment (users overestimate LLM accuracy) and showed adjusting LLM explanations improved calibration.47 |
| 14\. Berlin Numeracy Test (Cokely et al., 2012\) 50 | Statistical Numeracy; Risk Literacy | Assesses ability to understand and use statistical information, particularly probabilities and risks. | 4 items (traditional) or adaptive test format. Open-ended or multiple choice. \~3 min completion. | Robust psychometric properties across diverse samples/countries. Strong predictor of risk comprehension, outperforming other numeracy tests.50 |
| 15\. Mental Model Probes (Conceptual \- based on HCI/AI Lit) 19 | User Mental Models of AI | Assesses user understanding of AI capabilities, limitations, mechanisms, agency. | Varies; typically qualitative (open-ended Qs, analogies) or quantitative (Likert ratings on belief statements). Used pre/post interaction. | Methods like interviews, think-aloud, trace analysis discussed in literature.19 Requires careful development for specific context. |



-----------



# https://gemini.google.com/app/e00a4864450bcfb7


* **Table 4.1: Summary of Measurement Instruments**

| Construct Measured | Instrument Source/Adaptation | Format | Approx. Items | Link to RQ/Hypothesis | Phase |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **Individual Differences** |  |  |  |  | Pre-Task |
| Demographics | Standard Questions | MC / Open | \~6-8 | Sample Description | Pre-Task |
| Energy Literacy (Cognitive) | Adapted from DeWaters & Powers (2011, 2013\) framework 15 | Multiple Choice | \~8-10 | H4.1, RQ4 | Pre-Task |
| AI Literacy (Understand/Detect) | MAILS-S (Carolus & Koch, 2023; Koch et al., 2024\) 20 | 0-10 Rating Scale | \~6-8 | H4.2, H5.1, RQ4, RQ5 | Pre-Task |
| Propensity to Trust Automation | PTT-A Scale (e.g., Kok & Soh, 2024\) 21 | 5-pt Likert | 14 | H4.3, H5.2, RQ4, RQ5 | Pre-Task |
| Environmental Attitudes | Revised NEP Scale (Dunlap et al., 2000\) 22 | 5-pt Likert | 15 | H4.4, RQ4 | Pre-Task |
| Numeracy | Berlin Numeracy Test \- Short Form 16 | Open / MC | 4 | H4.1, RQ4 | Pre-Task |
| Cognitive Reflection | CRT (Frederick, 2005\) 19 | Open | 3 | H4.1, H5.1, RQ4, RQ5 | Pre-Task |
| **Mental Model (Baseline)** |  |  |  |  | Pre-Task |
| Expected LLM Accuracy | Custom Questions (Overall & by Type) | 0-100% Slider / 7-pt Likert | \~5 | H1.1, RQ1 | Pre-Task |
| Expected LLM Bias | Custom Question | Yes/No/Unsure | 1 | H2.1, RQ2 | Pre-Task |
| **Interaction Measures** |  |  |  |  | Trial |
| Trust in AI Response | Adapted Jian et al. (2000) \- Trust Items 14 | 7-pt Likert | \~3-4 | H1.3, H3.1, H3.2, H3.4, RQ3 | Trial |
| Distrust in AI Response | Adapted Jian et al. (2000) \- Distrust Items 14 | 7-pt Likert | \~3-4 | H1.3, H3.2, H3.4, RQ3 | Trial |
| Reliance / Agreement | Custom Question (e.g., Agree Y/N or Likert) | Dichotomous / Likert | 1 | H3.2, H3.3, RQ3 | Trial |
| Participant Answer | Task-Specific (MC, Rank, Estimate) | Varies | 1 | Outcome Measure | Trial |
| Participant Confidence | Custom Question | 7-pt Likert | 1 | Exploratory | Trial |
| **Mental Model (Refined)** |  |  |  |  | Post-Task |
| Perceived Overall Accuracy | Custom Question | 0-100% Slider | 1 | H1.2, RQ1 | Post-Task |
| Perceived Type Accuracy | Custom Questions | 7-pt Likert | \~4 | H1.2, RQ1 | Post-Task |
| Perceived Strengths/Weaknesses | Custom Question | Open-ended | 1 | RQ1 | Post-Task |
| Perceived Reasoning/Heuristics | Custom Questions | Open / MCQ | \~2 | RQ1, RQ2 | Post-Task |
| Reliability Cues Used | Custom Question | Open-ended | 1 | Exploratory | Post-Task |
| **Overall Evaluation** |  |  |  |  | Post-Task |
| Overall Trust in AI | Adapted Jian et al. (2000) \- Trust Items 14 | 7-pt Likert | \~3-4 | H1.2, H1.3 | Post-Task |
| Overall Distrust in AI | Adapted Jian et al. (2000) \- Distrust Items 14 | 7-pt Likert | \~3-4 | H1.2, H1.3 | Post-Task |
| **Manipulation Check** |  |  |  |  | Post-Task |
| Perceived AI Uncertainty | Custom Questions | Likert / Yes/No/Sometimes | \~2 | Validity Check | Post-Task |



### **4.2 Measurement Instruments**

The following validated and adapted scales will be used:

* **Energy Literacy (Cognitive):** An 8-10 item multiple-choice scale adapted from the framework and principles of the Energy Literacy Questionnaire (ELQ) by DeWaters & Powers (2011, 2013).15 Items will focus on assessing "citizenship understanding" relevant to household energy decisions, covering topics like energy units (kWh), major consumption areas (heating/cooling vs. lighting), relative appliance energy use, and the impact of common conservation actions (e.g., LED replacement, thermostat adjustments). Items will be sourced from available ELQ materials or constructed following the original framework and validated through pilot testing if necessary. *Rationale:* Measures essential domain knowledge required to critically evaluate the AI's energy advice. *Adaptation Note:* Given potential difficulty sourcing original ELQ items and modest reported reliability 15, careful adaptation and potential piloting are warranted.  
* **AI Literacy:** The Meta AI Literacy Scale-Short (MAILS-S) 20, selecting items primarily from the *Understand AI* (e.g., "I can assess what the limitations and opportunities of using an AI are") and *Detect AI* (e.g., "I can tell if I am dealing with an application based on artificial intelligence") sub-dimensions (approx. 6-8 items total). Items derived from Carolus, Koch, et al. (2023) and Koch et al. (2024).20 Responses collected on the original 0 ("not at all pronounced") to 10 ("very well pronounced") scale.  
  *Rationale:* Measures self-assessed competence in understanding AI capabilities/limits and recognizing AI interaction, directly relevant hypotheses H4.2 and H5.1. Focuses on evaluation-relevant facets.  
* **Propensity to Trust Automation (PTT-A):** The 14-item PTT-A scale validated by Kok & Soh (2024) 21, based on the theoretical structure outlined in their work.21 This scale measures dispositional trust towards automated technology across facets like Trusting Stance, Competence, Benevolence, and Integrity. Items (e.g., "Automated technological systems are competent," "I rarely trust automated technological systems because I can't handle the uncertainty" \[reverse-coded\]) are rated on a 5-point Likert scale (Strongly Disagree to Strongly Agree). *Rationale:* Captures trait-level trust specifically towards automation, shown to be more predictive than general trust measures.12 Directly tests H4.3 and H5.2.  
* **New Ecological Paradigm (NEP) Scale:** The revised 15-item NEP scale (Dunlap et al., 2000).22 Standard instrument measuring environmental worldview using items like "We are approaching the limit of the number of people the Earth can support" and "Humans have the right to modify the natural environment to suit their needs" (reverse-coded). Responses on a 5-point Likert scale (Strongly Agree to Strongly Disagree).  
  *Rationale:* Assesses underlying environmental attitudes, a potential motivator for engaging with energy advice (H4.4). Standard, widely validated measure.  
* **Numeracy:** The Berlin Numeracy Test (BNT) \- Short Form.16 Consists of 4 quantitative reasoning problems assessing understanding of probabilities and statistical concepts. Can be administered in open-ended or multiple-choice format. *Rationale:* Energy decisions frequently involve numerical information (kWh, costs, percentages). Numeracy is crucial for interpreting this information and evaluating quantitative claims made by the LLM (H4.1). BNT is validated for assessing risk literacy.16  
* **Cognitive Reflection:** The original 3-item Cognitive Reflection Test (CRT) (Frederick, 2005).18 Includes items like the "bat and ball" problem designed to elicit an incorrect intuitive answer that must be overridden by deliberation.  
  *Rationale:* Measures the tendency to engage in reflective thought versus relying on intuition. Hypothesized to relate to the ability to question and verify LLM responses, especially those that seem plausible but are incorrect (H4.1, H5.1).  
* **Trust/Distrust (Trial & Post-Task):** Adapted from the Jian, Bisantz, & Drury (2000) Checklist for Trust between People and Automation.14 Two separate factors will be measured using 7-point Likert scales (Strongly Disagree to Strongly Agree):  
  * *Trust Factor (3-4 items):* e.g., "The AI's response is reliable," "The AI's response is dependable," "I am confident in the AI's response."  
  * *Distrust Factor (3-4 items):* e.g., "I am suspicious of the AI's response," "I am wary of the AI's response," "The AI's response seems questionable," "The AI's response could be deceptive."  
  * *Rationale:* Utilizes empirically derived items from a widely cited scale but measures trust and distrust as distinct constructs, addressing recent theoretical developments 9 and potential biases in using the original scale as unidimensional.14 Allows testing of H3.4.  
* **Mental Model Assessment (Baseline & Post-Task):** Custom-developed items including:  
  * *Overall Accuracy Estimation:* Sliders (0-100%) for expected (pre-task) and perceived (post-task) overall LLM accuracy.  
  * *Type-Specific Accuracy Ratings:* Likert scales (e.g., 1=Very Inaccurate to 7=Very Accurate) for expected/perceived accuracy on factual, estimation, comparison, and recommendation questions.  
  * *Bias Prediction (Pre-task):* "Do you think the AI is likely to make systematic errors, like underestimating energy use for large appliances?" (Yes/No/Unsure).  
  * *Qualitative Probes (Post-task):* Open-ended questions asking about perceived strengths, weaknesses, reasoning methods, and cues used to judge trustworthiness.  
  * *Rationale:* Captures explicit user beliefs about the AI's capabilities, allowing assessment of initial accuracy (RQ1), bias anticipation (RQ2), and change over time (RQ1). Qualitative data provides richer insights into the *content* of mental models.  
* **Manipulation Check:** Direct Likert scale questions assessing perceived AI confidence and (for relevant conditions) awareness of uncertainty expressions. *Rationale:* Essential for verifying that the experimental manipulation of uncertainty expression was successfully perceived by participants.



-----------



# https://chatgpt.com/c/68147c67-8de0-8006-8db5-e9a22ec9c08d


## Instrument Audit and Recommendations for Your LLM-Energy Study

*(All instruments are freely available unless noted; approximate completion times assume adult online participants.)*

| Construct                            | Recommended primary survey(s)                                                                                                             | Rationale for fit                                                                                                                                                                    | Open?                                                                                                                   | Est. time       |
| ------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------- | --------------- |
| **Objective Numeracy**               | **Berlin Numeracy Test (BNT)** – 4-item adaptive or 8-item fixed versions                                                                 | Gold-standard, short, robust predictive validity for risk comprehension; strong psychometrics in educated samples                                                                    | ✔️ PDF + online scoring tool ([Risk Literacy][1])                                                                       | 3–5 min         |
| **Multidimensional Energy Literacy** | (a) **DeWaters & Powers K-A-B battery** (27 knowledge MC, 30 attitude, 18 behavior) + (b) **Attari appliance-estimation task** (15 items) | (a) Broad coverage of cognitive/affective/behavioral facets; validated across cultures; (b) directly targets numerical misperceptions your proposal seeks to compare with LLM output | (a) items in open dissertation & ERIC record ([ResearchGate][2]); (b) full supplemental items in PNAS paper ([PNAS][3]) | 12–15 min total |
| **AI/LLM Literacy**                  | (a) **MAILS-S** 24-item short form (competence & meta-competence) + (b) **SAIL4ALL** 30 MC objective quiz                                 | Combines self-perceived capability (MAILS-S) with objective knowledge (SAIL4ALL); both adult-normed, 2023–24 validation                                                              | (a) full PDF ([PMC][4]); (b) OSF zip file with items ([OSF][5])                                                         | 6 min + 8 min   |
| **General Trust in AI**              | **Semantic Differential AI-Trust (SD-AIT)** – 12 affective + 12 cognitive adjective pairs                                                 | Separates emotional from cognitive trust; high reliability; easily adapted to “AI in general” wording                                                                                | ✔️ arXiv PDF ([ResearchGate][6])                                                                                        | 3 min           |
| **LLM-specific Trust / Reliance**    | **TILLMI** 6-item scale                                                                                                                   | Purpose-built for conversational LLMs; maps to reliance vs. closeness factors; brevity limits fatigue                                                                                | ✔️ full item list in preprint ([arXiv][7])                                                                              | 1 min           |
| **AI Usage Frequency**               | **HEPI Student Gen-AI Usage battery** (12 activity items)                                                                                 | Captures concrete past-month frequency across creation, summarization, planning; language easily repurposed for “home energy decisions”                                              | ✔️ PDF appendix ([HEPI][8])                                                                                             | 2 min           |
| **Reliance/Over-reliance Tendency**  | **Reliance on Generative AI Scale (RGAI-12)** (Hou et al., 2025)                                                                          | Produces latent score for habitual compliance with AI suggestions; complements behavioral error metrics in your interaction phase                                                    | RG preprint with items ([ResearchGate][9])                                                                              | 2 min           |

### 1 . Are the surveys you already collect sufficient?

Your existing battery (Berlin Numeracy + MAILS-S + DeWaters or NEF + global AI-trust) covers most predictors, but two *gaps* remain:

* **LLM-specific trust/accuracy beliefs** – global AI-trust scales (TPA, SD-AIT) do not capture affective reliance on *large language models*. Add **TILLMI** for precision.
* **Quantitative misperception of appliance energy use** – general energy-literacy items do not elicit the magnitude estimates necessary to compare human and LLM compression biases. Incorporate the **Attari task** or its 2021 expert-judgment variant.

### 2 . Additional instruments that would strengthen hypothesis tests

| Need                                                  | Recommended addition                                                                                                                       | Why helpful                                                                                            |
| ----------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------ |
| Calibration between perceived and actual LLM accuracy | Post-task **confidence slider** (0–100%) + record **commission/omission errors** during LLM-assisted decisions (automation-bias paradigm). | Produces continuous “over-confidence” index and behavioral *over-reliance* metric aligning with H1/H3. |
| Ethical / societal AI dimension                       | **AILQ (ABCE-AI Literacy)** 32-item scale ([ResearchGate][10])                                                                             | Adds ethics & affect facets if you aim to test whether value-laden literacy predicts cautious use.     |
| Real-world goal setting                               | 3-item Goal-Commitment form adapted from Becker (1978): target %-reduction, three concrete actions, willingness to share result.           | Enables mediation analysis between calibrated trust and *intended behavior change*.                    |

### 3 . Instrument length trade-off

A full battery as above (*excluding* interactive phase) clocks in at ≈ 35 minutes for most adults. If you need ≤ 20 minutes, prioritize:

1. Berlin Numeracy (adaptive)
2. MAILS-S (24 items)
3. Attari estimation task (shortened to 10 appliances)
4. TILLMI (6 items)
5. SD-AIT (12 adjective pairs)
6. HEPI usage frequency (compress to 6 high-relevance items)

### 4 . Energy-saving tip sheets for the intervention phase

Provide the DOE *Energy Saver Guide* (downloadable PDF) as baseline content and build an LLM prompt library from the concise **SaveOnEnergy “Easy & Affordable Tips”** sheet for quick idea generation. Both are open-access and written for lay readers. ([The Department of Energy's Energy.gov][11], [Save on Energy][12])






--------


# https://www.perplexity.ai/search/you-are-a-meticulous-critic-an-3qcr70RFSrGqyS6f9BpRdw


## Annotated Bibliography of 15 Most Relevant Validated Surveys

| Scale Name | Author(s) | Construct | Description |
|------------|-----------|-----------|-------------|
| MAILS-Short | Koch et al. (2024) | AI Literacy | 10-item short form measuring 6 dimensions: Use & Apply AI, Know & Understand AI, Detect AI, AI Ethics, AI Self-efficacy, and AI Self-competency. Good model fit and reliability. |
| Berlin Numeracy Test | Cokely et al. (2012) | Numeracy | 4-item test with strong psychometric properties. Predicts risk literacy and decision-making skills. Adaptive format available. |
| Energy Literacy Questionnaire | DeWaters & Powers (2011/2013) | Energy Literacy | Multidimensional measure: cognitive knowledge, affective attitudes, behavioral engagement. Validated with diverse samples. |
| Trust Perception Scale-AI (TPA) | Jian et al. (2000) | Trust in AI | 12-item scale adapted from automation trust. Measures trust and distrust as separate constructs. High internal consistency. |
| Semantic Differential AI Trust Scale | Shang & Hsieh (2025) | AI Trust | Measures cognitive and affective trust using bipolar adjective pairs. High convergent/discriminant validity. |
| Attari Energy Estimation Methodology | Attari et al. (2010) | Energy Perception | Uses 100W light bulb as reference for estimating appliance energy use. Reveals systematic misperceptions. |
| AICOS | Markus et al. (2025) | AI Literacy | Performance-based measure of AI competency. Assesses actual ability to understand AI concepts and detect outputs. |
| PAILQ-6 | Grassini (2024) | AI Literacy | 6-item self-assessed AI knowledge. Good reliability but limited to self-perception. |
| TAIS | Chu et al. (2023) | Trust in AI | 31-item scale across 6 dimensions (competence, predictability, security, humanness, openness, value alignment). Good reliability. |
| SAIL4ALL | Soto-Sanfiel et al. (2024) | AI Literacy | 33-item scale for general population. Measures knowledge, skills, attitudes. Good reliability. |
| Numeracy Scale (Expanded) | Lipkus et al. (2001) | Numeracy | Expanded scale for general population. Measures ability to process probability and numerical concepts. |
| AIMS | Li et al. (2025) | AI Motivation | Measures motivation for using AI based on self-determination theory. Assesses autonomous and controlled motivations. |
| ReaLMistake | Chen et al. (2023) | AI Error Detection | Benchmark for measuring ability to detect factual errors in LLM outputs. Categorizes error types and detection difficulty. |
| SNAIL | Laupichler et al. (2023) | AI Literacy | 27-item scale with 4 factors: conceptual knowledge, interaction skills, critical thinking, societal discourse. |
| PTT-A | Scholz et al. (2025) | Trust in AI | Propensity to Trust in Automated Technology. Measures dispositional trust in AI systems. Strong reliability. |

---

## Verification of Solution Comprehensiveness

### Checklist: Mapping Survey Components to Research Questions

| Survey Component | RQ1 | RQ2 | RQ3 | RQ4 |
|------------------|-----|-----|-----|-----|
| Numeracy (Berlin) |   | X |   |   |
| Energy Literacy (ELQ) |   | X |   |   |
| AI Literacy (MAILS-Short) |   | X |   |   |
| Beliefs about LLMs (Custom) | X |   | X | X |
| Task-Specific Trust (Custom) | X |   | X | X |
| General Trust/Distrust (TPA, Semantic Differential) |   |   |   | X |
| LLM Use Intentions/Frequency |   |   | X |   |
| Demographics/Background |   |   |   |   |


## New Outline of Specific Surveys for the Full Study

1. **Individual Differences Measures**
    - Berlin Numeracy Test (objective numeracy)
    - Energy Literacy Questionnaire (full, validated subscales)
    - MAILS-Short (AI literacy, self-report)
    - AICOS (AI literacy, performance-based)

2. **Beliefs and Mental Models**
    - Open-ended and attributional belief probes about LLM mechanisms
    - Custom items on perceived accuracy, utility, and planning competence of LLMs

3. **Trust Measures**
    - Task-specific trust in LLMs for energy tasks (custom items)
    - General trust and distrust in AI (TPA, Semantic Differential AI Trust)

4. **Behavioral and Experimental Modules**
    - Comparative Energy-LLM Estimation Task (self vs. LLM vs. ground truth)
    - LLM Error Detection Module (identification of hallucinations/inaccuracies)
    - Trust Adaptation Tracking (sequential reliance decisions with feedback)
    - Uncertainty Perception and Confidence Calibration (influence of LLM-expressed uncertainty)

5. **Reliance Intentions and Usage**
    - Self-reported willingness to use LLMs for energy decisions
    - Self-reported frequency of LLM use for energy tasks

6. **Demographics and Contextual Variables**
    - Responsibility for energy bills, prior LLM use, technology familiarity


---

## Annotated Bibliography of 15 Most Relevant Validated Surveys

1. **MAILS-Short (Koch et al., 2024):** A 10-item short form of the Meta AI Literacy Scale, measuring six dimensions of AI literacy with strong psychometric properties. Suitable for general populations and adaptable to various domains[5][18].
2. **Berlin Numeracy Test (Cokely et al., 2012):** A 4-item objective numeracy test with demonstrated predictive validity for risk literacy and decision-making. Available in adaptive formats.
3. **Energy Literacy Questionnaire (DeWaters & Powers, 2011/2013):** A multidimensional measure assessing cognitive, affective, and behavioral components of energy literacy. Validated with diverse samples and widely used in energy research[12].
4. **Trust Perception Scale-AI (TPA; Jian et al., 2000):** A 12-item scale measuring trust and distrust in AI systems. Adapted from automation trust research, with high internal consistency[19].
5. **Semantic Differential AI Trust Scale (Shang & Hsieh, 2025):** Measures cognitive and affective trust using bipolar adjective pairs. Demonstrates strong convergent and discriminant validity.
6. **Attari Energy Estimation Methodology (Attari et al., 2010):** A reference-based estimation task revealing systematic misperceptions in energy use. Provides a benchmark for both human and LLM performance[11][14].
7. **AICOS (Markus et al., 2025):** A performance-based measure of AI competency, assessing actual ability to understand AI concepts and detect outputs. Addresses limitations of self-report AI literacy measures[6][17].
8. **PAILQ-6 (Grassini, 2024):** A 6-item self-assessed AI knowledge scale with good reliability. Limited to self-perception.
9. **TAIS (Chu et al., 2023):** A 31-item trust in AI scale covering competence, predictability, security, humanness, openness, and value alignment. Good reliability.
10. **SAIL4ALL (Soto-Sanfiel et al., 2024):** A 33-item AI literacy scale for general populations, measuring knowledge, skills, and attitudes.
11. **Numeracy Scale (Expanded; Lipkus et al., 2001):** An expanded numeracy scale for general populations, measuring probability and numerical concept processing.
12. **AIMS (Li et al., 2025):** Measures motivation for using AI based on self-determination theory, assessing both autonomous and controlled motivations.
13. **ReaLMistake (Chen et al., 2023):** A benchmark for measuring the ability to detect factual errors in LLM outputs, categorizing error types and detection difficulty.
14. **SNAIL (Laupichler et al., 2023):** A 27-item AI literacy scale with four factors: conceptual knowledge, interaction skills, critical thinking, and societal discourse.
15. **PTT-A (Scholz et al., 2025):** Measures dispositional trust in AI systems, with strong reliability and demonstrated relationship to actual reliance behavior.




--------



# https://chatgpt.com/g/g-p-680c9643408c8191a128bbb19854ccee-ai-brainstorm/c/681659c5-a68c-8006-a855-b8ac7396b620

## 4 Annotated bibliography of 15 validated instruments

| #  | Instrument                                                                       | Core construct                                    | Key psychometrics                                              |
| -- | -------------------------------------------------------------------------------- | ------------------------------------------------- | -------------------------------------------------------------- |
| 1  | **Berlin Numeracy Test** (Cokely et al., 2012)                                   | Objective numeracy                                | 4-item adaptive; r ≈ .78 test-retest([ACM Digital Library][8]) |
| 2  | **Energy Literacy Questionnaire** – cognitive subscale (DeWaters & Powers, 2011) | Energy knowledge                                  | α ≈ .83; three-factor model                                    |
| 3  | **Energy Misperception Estimation Task** (Attari et al., 2010)                   | Quantitative bias                                 | range-compression index                                        |
| 4  | **MAILS-S** (Koch et al., 2024)                                                  | AI literacy (self-report)                         | 10 items; α ≈ .86                                              |
| 5  | **PAILQ-6** (Grassini, 2024)                                                     | Perceived AI literacy                             | α ≈ .83; scalar-invariant                                      |
| 6  | **TILLMI-6** (Duro et al., 2025)                                                 | Trust in LLMs (affective + cognitive)             | 2-factor; CFI = .995                                           |
| 7  | **TPA-Revised 6-item** (Jian et al., 2000)([PNAS][2])                            | Dispositional AI trust/distrust                   | bifactor structure                                             |
| 8  | **Semantic-Differential AI-Trust** (Shang & Hsieh, 2025)                         | Cognitive trust facets                            | 11 bipolar items                                               |
| 9  | **Complacency-Potential Scale** (Singh et al., 1993)([ScienceDirect][9])         | Automation bias proneness                         | 20 items; α ≈ .74                                              |
| 10 | **Human–Computer Trust (Madsen & Gregor, 2000)**([arXiv][10])                    | Reliability, competence, understandability, faith | 25 items                                                       |
| 11 | **SNAIL** (Laupichler et al., 2023)                                              | Non-experts’ AI literacy                          | 3 factors; α >.80                                              |
| 12 | **AILQ** (Ng et al., 2024)                                                       | Affective-Behavioural-Cognitive-Ethical literacy  | 28 items                                                       |
| 13 | **GLAT** (Jin et al., 2024)                                                      | Objective generative-AI literacy                  | 30 scored MCQs                                                 |
| 14 | **MAILS-Create AI** subscale (Carolus et al., 2023)([SAGE Journals][3])          | Coding/design skill                               | α ≈ .88                                                        |
| 15 | **Energy Attitude Scale** (Mei-Shiu & Jan, 2018)                                 | Pro-efficiency values                             | α ≈ .81                                                        |

---

## 6 Re-organised survey outline

1. **Screeners & consent**
2. **Numeracy (Berlin 4-item)**
3. **Energy literacy—cognitive** (8 MC, harder items added)
4. **Energy attitude & behaviour (short)**
5. **AI literacy** (MAILS-S, 7-point)
6. **Mental-model diagnostics** (Analogy + SD + open)
7. **Energy estimation task** (own estimate → view LLM estimate → confidence)
8. **Plan-evaluation task** (spot-the-gap + confidence)
9. **Task-specific trust & perceived utility**
10. **Calibration summary quiz** (three LLM Q\&A snippets)
11. **General LLM trust (TILLMI-6) & truncated TPA**
12. **Reliance intentions & past use**
13. **Demographics**




-------

# https://aistudio.google.com/prompts/1mSwoQDfe4LSBPYuqT9bpradcZQGKaJS8

**Table 1: Measurement Instruments**

| Construct Measured                | Instrument Source/Adaptation                                           | Format               | # Items | Est. Time | Link to RQ/Hypothesis |
| :-------------------------------- | :--------------------------------------------------------------------- | :------------------- | :------ | :-------- | :-------------------- |
| **Pre-Task**                      |                                                                        |                      |         |           |                       |
| Propensity to Trust Automation    | PTT-A Scale (Neufeld et al., 2024 / Kok & Soh, 2024 adaptation)        | 7-pt Likert          | \~14    | 2 min     | H3.1                  |
| Objective AI Literacy             | AICOS-SV (Markus et al., 2025)                                         | MCQ                  | \~18    | 5-7 min   | H1.3                  |
| Energy Literacy (Cognitive/Heuristic) | Hybrid: Adapted DeWaters & Powers (2011), Kantenbacher & Attari (2021) | MCQ / Choice         | \~10-12 | 3-5 min   | H1.3                  |
| Numeracy                          | Berlin Numeracy Test - Adaptive (Cokely et al., 2012)                  | Open Numeric Entry   | 2-4     | 2-3 min   | H3.2                  |
| Beliefs about LLM Capabilities/Bias | Custom Scale (Accuracy, Bias, Limitations)                           | 7-pt Likert / MCQ    | \~8-10  | 2 min     | RQ1 (Mental Model)    |
| **Trial-Level (Per LLM Response)**  |                                                                        |                      |         |           |                       |
| Judgment of Correctness           | Custom                                                                 | Categorical          | 1       | < 1 min   | Calibration Metric    |
| Judgment Confidence               | Custom                                                                 | 0-100% Slider        | 1       | < 1 min   | Calibration Metric    |
| Reliance Intention                | Custom                                                                 | Likert / Choice      | 1       | < 1 min   | H2.2                  |
| Trust in AI Response              | Adapted TPA - Trust Factor (Perrig et al., 2023)                       | 7-pt Likert          | \~3     | < 1 min   | H1.2, H2.1, H2.3      |
| Distrust in AI Response           | Adapted TPA - Distrust Factor (Perrig et al., 2023)                    | 7-pt Likert          | \~3     | < 1 min   | H1.2, H2.1, H2.3      |
| **Post-Task**                     |                                                                        |                      |         |           |                       |
| Overall Trust in AI               | Adapted TPA - Trust Factor Items                                       | 7-pt Likert          | \~5     | 1 min     | H1.1, H1.2            |
| Overall Distrust in AI            | Adapted TPA - Distrust Factor Items                                      | 7-pt Likert          | \~5     | 1 min     | H1.1, H1.2            |
| Mental Model Assessment           | Custom Questions (Perceived accuracy, reasoning, limits)               | Likert / Open-ended  | \~5-7   | 2-3 min   | H1.1, H1.3, RQ1       |
| Manipulation Check                | Perception of AI uncertainty                                           | Likert               | 1       | < 1 min   | Validity Check        |
| *Total Estimated Time*            |                                                                        |                      |         | **30-40 min** |                       |

*Note: Specific items for validated scales (PTT-A, AICOS-SV, BNT, TPA Factors) will be sourced directly from cited literature/instruments.*

## **V. Justification of Design**

The proposed study design is constructed to rigorously investigate the research questions and test the hypotheses, drawing strength from several key features:

*   **Alignment with RQs/Hypotheses:** The design directly maps onto the research questions. The multi-trial task allows observation of learning/calibration over time (RQ1, H1.1) through trial-level measures (H1.2) and post-task assessments. The manipulation of LLM correctness (within-subjects) and uncertainty expression (between-subjects) directly tests the causal effects of these factors on trust, reliance, and calibration (RQ2, H2.1, H2.2, H2.3). Measuring individual differences (AI Lit, Energy Lit, PTT-A, Numeracy) allows for testing moderation effects (RQ1, RQ3, H1.3, H3.1, H3.2).
*   **Task Stimuli Rationale:** Grounding the task stimuli in empirically documented energy misperceptions (Attari et al., 2010) provides significant advantages. It increases ecological validity, targeting known cognitive difficulties where users might genuinely seek LLM help. It creates a demanding testbed for evaluating LLM advice and user calibration.
*   **Scale Selection and Adaptation:** The use of established, validated scales (AICOS-SV, BNT, PTT-A) enhances measurement reliability and validity. The hybrid Energy Literacy measure targets specific knowledge relevant to the task. Crucially, adopting the TPA 2-Factor approach for trust/distrust aligns with recent psychometric findings in AI contexts, offering a more nuanced view than single-factor trust scales (Perrig et al., 2023; Razin et al., 2023).
*   **Objective Calibration Measurement:** Incorporating judgment correctness and confidence ratings allows for objective calculation of calibration metrics (Brier score, ECE, calibration curves), moving beyond purely self-reported trust. This directly addresses the core concept of trust calibration (Lee & See, 2004).
*   **Mental Model Assessment:** The methodology combines multiple approaches: pre-task belief scales, objective LLM knowledge questions, and post-task assessments probing perceived accuracy, reasoning, and limitations. This multi-pronged approach provides a richer understanding of users' mental models (Liao & Sundar, 2022).
*   **Controlled LLM Responses:** Using pre-generated and curated LLM responses ensures strict experimental control over correctness and uncertainty expression, isolating the effects of these variables. Relying on live generation would introduce noise and unpredictability, hindering causal inference (Kim et al., 2024; Steyvers et al., 2025). The conciseness ensures feasibility within the time frame.
